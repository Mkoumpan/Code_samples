{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Datathon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "myGe-jZkBBsx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Activation, Dropout, RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from math import sqrt, log, exp\n",
        "import tensorflow as tf\n",
        "import statistics\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import Flatten\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stWNhn7pBP10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b200f16a-6b5d-4fc7-88e5-7cd438511acc"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print (\"TensorFlow version found:\", tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version found: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjZEriMBYIzp"
      },
      "source": [
        "I used google colab to run this notebook and import my data. Thus my import methods are dependent on google colab and google drive. You can use any other import you wish to import the data but the easiest for me was to upload them in my google drive and load them in google colab.\n",
        "\n",
        "Only run the above cell if you run the notebook on google colab. Else ignore it completely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdwPsPTFfAK9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f299c84-2c2e-4cd2-a50d-91df1a25773e"
      },
      "source": [
        "from google.colab import drive #run only if using google colab\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzj68f6cYmJd"
      },
      "source": [
        "Below I build a datetime object which contains dates from March 7th to September 13th which is the final day we have data for the Datathon to predict next week. I use this datetime object as an index in my Pandas DataFrame later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqcSb51bjOX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9395df28-e8f3-46f6-c8b2-1948fecd9a86"
      },
      "source": [
        "import datetime\n",
        "datetime_object_2= list()\n",
        "today = datetime.date.today()\n",
        "today = today.day\n",
        "today_index = today-30\n",
        "month = np.linspace(1,9,9)\n",
        "day = np.linspace(1,31,31)\n",
        "for i in month:\n",
        "  for j in day:\n",
        "    if(j==31 and i ==6 or j==31 and i==4 or j==31 and i==9 or j==29 and i==2):\n",
        "      break\n",
        "    datetime_object_2.append(datetime.date(2020,int(i),int(j)).strftime('%m/%d/%Y'))\n",
        "\n",
        "datetime_object_hosp = datetime_object_2[90:-17]#index for hospitalizations\n",
        "#here I set the datetime_index of my dataframe. If you want to insert new days you have to\n",
        "#change the last index -17--> x (dates until end of september)\n",
        "print(datetime_object_hosp)\n",
        "datetime_object_deaths = datetime_object_2[65:-17] #index for deaths\n",
        "print(datetime_object_deaths)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['04/01/2020', '04/02/2020', '04/03/2020', '04/04/2020', '04/05/2020', '04/06/2020', '04/07/2020', '04/08/2020', '04/09/2020', '04/10/2020', '04/11/2020', '04/12/2020', '04/13/2020', '04/14/2020', '04/15/2020', '04/16/2020', '04/17/2020', '04/18/2020', '04/19/2020', '04/20/2020', '04/21/2020', '04/22/2020', '04/23/2020', '04/24/2020', '04/25/2020', '04/26/2020', '04/27/2020', '04/28/2020', '04/29/2020', '04/30/2020', '05/01/2020', '05/02/2020', '05/03/2020', '05/04/2020', '05/05/2020', '05/06/2020', '05/07/2020', '05/08/2020', '05/09/2020', '05/10/2020', '05/11/2020', '05/12/2020', '05/13/2020', '05/14/2020', '05/15/2020', '05/16/2020', '05/17/2020', '05/18/2020', '05/19/2020', '05/20/2020', '05/21/2020', '05/22/2020', '05/23/2020', '05/24/2020', '05/25/2020', '05/26/2020', '05/27/2020', '05/28/2020', '05/29/2020', '05/30/2020', '05/31/2020', '06/01/2020', '06/02/2020', '06/03/2020', '06/04/2020', '06/05/2020', '06/06/2020', '06/07/2020', '06/08/2020', '06/09/2020', '06/10/2020', '06/11/2020', '06/12/2020', '06/13/2020', '06/14/2020', '06/15/2020', '06/16/2020', '06/17/2020', '06/18/2020', '06/19/2020', '06/20/2020', '06/21/2020', '06/22/2020', '06/23/2020', '06/24/2020', '06/25/2020', '06/26/2020', '06/27/2020', '06/28/2020', '06/29/2020', '06/30/2020', '07/01/2020', '07/02/2020', '07/03/2020', '07/04/2020', '07/05/2020', '07/06/2020', '07/07/2020', '07/08/2020', '07/09/2020', '07/10/2020', '07/11/2020', '07/12/2020', '07/13/2020', '07/14/2020', '07/15/2020', '07/16/2020', '07/17/2020', '07/18/2020', '07/19/2020', '07/20/2020', '07/21/2020', '07/22/2020', '07/23/2020', '07/24/2020', '07/25/2020', '07/26/2020', '07/27/2020', '07/28/2020', '07/29/2020', '07/30/2020', '07/31/2020', '08/01/2020', '08/02/2020', '08/03/2020', '08/04/2020', '08/05/2020', '08/06/2020', '08/07/2020', '08/08/2020', '08/09/2020', '08/10/2020', '08/11/2020', '08/12/2020', '08/13/2020', '08/14/2020', '08/15/2020', '08/16/2020', '08/17/2020', '08/18/2020', '08/19/2020', '08/20/2020', '08/21/2020', '08/22/2020', '08/23/2020', '08/24/2020', '08/25/2020', '08/26/2020', '08/27/2020', '08/28/2020', '08/29/2020', '08/30/2020', '08/31/2020', '09/01/2020', '09/02/2020', '09/03/2020', '09/04/2020', '09/05/2020', '09/06/2020', '09/07/2020', '09/08/2020', '09/09/2020', '09/10/2020', '09/11/2020', '09/12/2020', '09/13/2020']\n",
            "['03/07/2020', '03/08/2020', '03/09/2020', '03/10/2020', '03/11/2020', '03/12/2020', '03/13/2020', '03/14/2020', '03/15/2020', '03/16/2020', '03/17/2020', '03/18/2020', '03/19/2020', '03/20/2020', '03/21/2020', '03/22/2020', '03/23/2020', '03/24/2020', '03/25/2020', '03/26/2020', '03/27/2020', '03/28/2020', '03/29/2020', '03/30/2020', '03/31/2020', '04/01/2020', '04/02/2020', '04/03/2020', '04/04/2020', '04/05/2020', '04/06/2020', '04/07/2020', '04/08/2020', '04/09/2020', '04/10/2020', '04/11/2020', '04/12/2020', '04/13/2020', '04/14/2020', '04/15/2020', '04/16/2020', '04/17/2020', '04/18/2020', '04/19/2020', '04/20/2020', '04/21/2020', '04/22/2020', '04/23/2020', '04/24/2020', '04/25/2020', '04/26/2020', '04/27/2020', '04/28/2020', '04/29/2020', '04/30/2020', '05/01/2020', '05/02/2020', '05/03/2020', '05/04/2020', '05/05/2020', '05/06/2020', '05/07/2020', '05/08/2020', '05/09/2020', '05/10/2020', '05/11/2020', '05/12/2020', '05/13/2020', '05/14/2020', '05/15/2020', '05/16/2020', '05/17/2020', '05/18/2020', '05/19/2020', '05/20/2020', '05/21/2020', '05/22/2020', '05/23/2020', '05/24/2020', '05/25/2020', '05/26/2020', '05/27/2020', '05/28/2020', '05/29/2020', '05/30/2020', '05/31/2020', '06/01/2020', '06/02/2020', '06/03/2020', '06/04/2020', '06/05/2020', '06/06/2020', '06/07/2020', '06/08/2020', '06/09/2020', '06/10/2020', '06/11/2020', '06/12/2020', '06/13/2020', '06/14/2020', '06/15/2020', '06/16/2020', '06/17/2020', '06/18/2020', '06/19/2020', '06/20/2020', '06/21/2020', '06/22/2020', '06/23/2020', '06/24/2020', '06/25/2020', '06/26/2020', '06/27/2020', '06/28/2020', '06/29/2020', '06/30/2020', '07/01/2020', '07/02/2020', '07/03/2020', '07/04/2020', '07/05/2020', '07/06/2020', '07/07/2020', '07/08/2020', '07/09/2020', '07/10/2020', '07/11/2020', '07/12/2020', '07/13/2020', '07/14/2020', '07/15/2020', '07/16/2020', '07/17/2020', '07/18/2020', '07/19/2020', '07/20/2020', '07/21/2020', '07/22/2020', '07/23/2020', '07/24/2020', '07/25/2020', '07/26/2020', '07/27/2020', '07/28/2020', '07/29/2020', '07/30/2020', '07/31/2020', '08/01/2020', '08/02/2020', '08/03/2020', '08/04/2020', '08/05/2020', '08/06/2020', '08/07/2020', '08/08/2020', '08/09/2020', '08/10/2020', '08/11/2020', '08/12/2020', '08/13/2020', '08/14/2020', '08/15/2020', '08/16/2020', '08/17/2020', '08/18/2020', '08/19/2020', '08/20/2020', '08/21/2020', '08/22/2020', '08/23/2020', '08/24/2020', '08/25/2020', '08/26/2020', '08/27/2020', '08/28/2020', '08/29/2020', '08/30/2020', '08/31/2020', '09/01/2020', '09/02/2020', '09/03/2020', '09/04/2020', '09/05/2020', '09/06/2020', '09/07/2020', '09/08/2020', '09/09/2020', '09/10/2020', '09/11/2020', '09/12/2020', '09/13/2020']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xctKqE0iZZFg"
      },
      "source": [
        "Here I import the time series data for the covid deaths in 8 counties in Texas. Then I load them in a Pandas Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnj1nVNcaZAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "07f0fbbd-b282-4c6c-ad92-784c3e523c7e"
      },
      "source": [
        "#data from John Hopkins repository, more accurate\n",
        "import xlrd\n",
        "#files can be imported by any available method, I import them from my drive using google colab\n",
        "fatality_per_county_2 = pd.read_csv('/content/drive/My Drive/time_series_covid19_confirmed_HOU_09-13.csv',skiprows=0)\n",
        "fatality_per_county = pd.read_csv('/content/drive/My Drive/time_series_covid19_confirmed_HOU_09-13.csv',skiprows=1)\n",
        "Austin = fatality_per_county_2.iloc[0,58:]\n",
        "Austin = pd.concat([Austin, pd.DataFrame([9.])],axis = 0)\n",
        "fatality_per_county = fatality_per_county.T.iloc[58:]\n",
        "fatality_per_county.columns = [\"Brazoria\",\"Chambers\",\"Fort_Bend\",\"Galveston\",\"Harris\",\"Liberty\",\"Montgomery\"]\n",
        "test = pd.DataFrame([{'a': 155, 'b': 8., 'c':167.,'d':165.,'e':2420.,'f':46.,'g':145.}])\n",
        "test.columns = [\"Brazoria\",\"Chambers\",\"Fort_Bend\",\"Galveston\",\"Harris\",\"Liberty\",\"Montgomery\"]\n",
        "fatality_per_county = pd.concat([fatality_per_county,test])\n",
        "fatality_per_county['Austin'] = Austin.values\n",
        "fatality_per_county.index = datetime_object_deaths\n",
        "print(fatality_per_county)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Brazoria Chambers Fort_Bend  ... Liberty Montgomery Austin\n",
            "03/07/2020        0        0         0  ...       0          0      0\n",
            "03/08/2020        0        0         0  ...       0          0      0\n",
            "03/09/2020        0        0         0  ...       0          0      0\n",
            "03/10/2020        0        0         0  ...       0          0      0\n",
            "03/11/2020        0        0         0  ...       0          0      0\n",
            "...             ...      ...       ...  ...     ...        ...    ...\n",
            "09/09/2020      148        6       255  ...      46        137      7\n",
            "09/10/2020      148        6       255  ...      46        137      7\n",
            "09/11/2020      154        8       263  ...      46        140      7\n",
            "09/12/2020      155        8       266  ...      46        144      8\n",
            "09/13/2020      155        8       167  ...      46        145      9\n",
            "\n",
            "[191 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s2xKd_nZxUG"
      },
      "source": [
        "Here I create a list which contains in every index an array which contains the deaths of the county. (list of lists)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9_IDLWbtp6W"
      },
      "source": [
        "all = [fatality_per_county.iloc[:,4],fatality_per_county.iloc[:,5],fatality_per_county.iloc[:,6],fatality_per_county.iloc[:,0],fatality_per_county.iloc[:,1],fatality_per_county.iloc[:,2],fatality_per_county.iloc[:,3],fatality_per_county.iloc[:,7]]\n",
        "all_title = [\"Harris_deaths\",\"Liberty_deaths\",\"Montgomery_deaths\",\"Brazoria_deaths\",\"Chambers_deaths\",\"Fort_Bend_deaths\",\"Galveston_deaths\",\"Austin_deaths\"]\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5CSw_gcBCA7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "5288ccb4-dc85-49ea-a750-8cb0d8132c8a"
      },
      "source": [
        "all_dataframe = pd.concat(all,axis=1,names = all_title)\n",
        "all_dataframe.columns = all_title\n",
        "rolling_means = []\n",
        "exp_means = []\n",
        "for i in range(0,len(all_dataframe.columns)):\n",
        "  rolling_mean = all_dataframe.iloc[:,i].rolling(window=7).mean()\n",
        "  rolling_mean = rolling_mean.fillna(0)\n",
        "  rolling_means.append(rolling_mean)\n",
        "  exp_mean = all_dataframe.iloc[:,i].ewm(span=7, adjust=False).mean()\n",
        "  exp_mean = exp_mean.fillna(0)\n",
        "  exp_means.append(exp_mean)\n",
        "print(all_dataframe)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Harris_deaths Liberty_deaths  ... Galveston_deaths Austin_deaths\n",
            "03/07/2020             0              0  ...                0             0\n",
            "03/08/2020             0              0  ...                0             0\n",
            "03/09/2020             0              0  ...                0             0\n",
            "03/10/2020             0              0  ...                0             0\n",
            "03/11/2020             0              0  ...                0             0\n",
            "...                  ...            ...  ...              ...           ...\n",
            "09/09/2020          2363             46  ...              165             7\n",
            "09/10/2020          2363             46  ...              165             7\n",
            "09/11/2020          2395             46  ...              165             7\n",
            "09/12/2020          2414             46  ...              165             8\n",
            "09/13/2020          2420             46  ...              165             9\n",
            "\n",
            "[191 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX9Zvy13bvdB"
      },
      "source": [
        "Here I visualize the data for each county and analyze its trend according to the 7 day exponential (green) and simple moving average (red)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9QEEoxA5NFL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b3d82bb-dc6b-4c6f-c1d7-b332f83f98e6"
      },
      "source": [
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "i = 0\n",
        "for k in range(0,len(all)):\n",
        "  fig, ax = plt.subplots()\n",
        "  sns.scatterplot(list(all[k].index),list(all[k].values),ax=ax)\n",
        "  plt.plot(all[k].index,rolling_means[i],color='r')\n",
        "  plt.plot(all[k].index,exp_means[i],color='g')\n",
        "\n",
        "# set the frequency for labelling the xaxis\n",
        "  freq = int(15)\n",
        "  plt.title(all_title[i])\n",
        "  plt.ylabel(\"Cumulative deaths\")\n",
        "  plt.xlabel(\"Date\")\n",
        "# set the xlabels as the datetime data for the given labelling frequency,\n",
        "# also use only the date for the label\n",
        "  ax.set_xticklabels(all[k].iloc[::freq].index)\n",
        "# set the xticks at the same frequency as the xlabels\n",
        "  xtix = ax.get_xticks()\n",
        "  ax.set_xticks(xtix[::freq])\n",
        "# nicer label format for dates\n",
        "  fig.autofmt_xdate()\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  i = i +1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm5dciC9BQnQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff74b9ae-5706-4a62-835d-cbaefb073bc5"
      },
      "source": [
        "fatality_per_county.isnull().values.any() #checking for nan values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obR17rMGcDOV"
      },
      "source": [
        "Here I split my data to train_test for each county. I set a 97% train and 3% test which corresponds to a week ahead in order to evaluate my model. To make predictions for the week to come I train my model to 100% of the data.\n",
        "\n",
        "The split_sequence function transforms my data to supervised learning where the X_data is a list that contains the features e.g. [45,45,46] with a specific window I set e.g. 3. The Y_data are the labels; the next day/timestep after X_data which is compared with the predicted value to calculate the error in training.\n",
        "\n",
        "Depending on the data and on the county I choose different parameters value for the window e.g. [2,5,10,15]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQEaRdWoBRCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "be0c62bb-25f5-4339-a106-dbfc603a7d82"
      },
      "source": [
        "def split_sequence(sequence, n_steps): #n_steps = window\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)\n",
        "def split_train_test(data,tr,window):\n",
        "\t#train_deaths,test_deaths = [],[]\n",
        "\ttrain_size = int(len(data)*tr/100.0)\n",
        "\t#test_deaths.append(data[train_size-3:])\n",
        "\t#train_deaths.append(data[:train_size])\n",
        "\ttemp_test_X = data[train_size-window-1:]#had -1, not good\n",
        "\ttemp_train_X = data[:train_size]\n",
        "\treturn np.array(temp_train_X),np.array(temp_test_X)\n",
        "tr = 100 #was 97 now all training set!# percent.#change it when you change the data so the test set contains 9 value, in the split it will contain 7, exactly one week!\n",
        "window = 10 #was 2\n",
        "train_deaths=[]\n",
        "test_deaths=[]\n",
        "for i in all:\n",
        "\t #scaler.fit(i.values.reshape(-1,1))\n",
        "\t #temp_value = scaler.transform([i.values])\n",
        "\t #print(temp_value)\n",
        "\t tempp = i.values.reshape(len(i.values),)\n",
        "\t temp_train,temp_test = split_train_test(tempp,tr,window)\n",
        "\t #temp_train,temp_test = split_train_test(temp_value,tr,window)\n",
        "\t train_deaths.append(temp_train)\n",
        "\t test_deaths.append(temp_test)\n",
        "X_train,Y_train = [],[]\n",
        "X_test, Y_test = [],[]\n",
        "for i in train_deaths:\n",
        "\ttemp_X, temp_Y = split_sequence(i,window)\n",
        "\tX_train.append(temp_X)\n",
        "\tY_train.append(temp_Y)\n",
        "  \n",
        "for i in test_deaths:\n",
        "\ttemp_Xx, temp_Yy = split_sequence(i,window)\n",
        "\tX_test.append(temp_Xx)\n",
        "\tY_test.append(temp_Yy)\n",
        "print(\"X_test data for Libery county are \",X_test[1])# contains only one list with window 10 because I use 100% of training to predict next day\n",
        "print(\"Y_test data for Liberty county are\",Y_test[1])\n",
        "#test must contain 9 values in order to predict 7!because we have train 2231, 2238\n",
        "#X_test must contain 7!\n",
        "\n",
        "\t\n",
        "\n",
        "#X_train_H, Y_train_H = split_sequence(train_Harris_deaths,window)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_test data for Libery county are  [[43 44 46 46 46 46 46 46 46 46]]\n",
            "Y_test data for Liberty county are [46.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjcPgel20A0N"
      },
      "source": [
        "look_ahead = 7 #how many days ahead the model will predict\n",
        "value_Harris = X_test[0][0].reshape(1, window, 1) \n",
        "value_Liberty = X_test[1][0].reshape(1, window, 1)\n",
        "value_Montgomery = X_test[2][0].reshape(1, window, 1)\n",
        "value_Brazoria = X_test[3][0].reshape(1, window, 1)\n",
        "value_Chambers = X_test[4][0].reshape(1, window, 1)\n",
        "value_Fort_Bend = X_test[5][0].reshape(1, window, 1)\n",
        "value_Galveston = X_test[6][0].reshape(1, window, 1)\n",
        "value_Austin = X_test[7][0].reshape(1, window, 1)\n",
        "initialvalue_Harris = tf.convert_to_tensor(list(value_Harris), dtype=tf.float32)# I transform the first day of the test data for each county to a tensor. Because otherwise the LSTM can't read it as input.\n",
        "initialvalue_Liberty = tf.convert_to_tensor(list(value_Liberty),dtype=tf.float32)\n",
        "initialvalue_Montgomery = tf.convert_to_tensor(list(value_Montgomery),dtype=tf.float32)\n",
        "initialvalue_Brazoria = tf.convert_to_tensor(list(value_Brazoria), dtype=tf.float32)\n",
        "initialvalue_Chambers = tf.convert_to_tensor(list(value_Chambers),dtype=tf.float32)\n",
        "initialvalue_Fort_Bend = tf.convert_to_tensor(list(value_Fort_Bend),dtype=tf.float32)\n",
        "initialvalue_Galveston = tf.convert_to_tensor(list(value_Galveston), dtype=tf.float32)\n",
        "initialvalue_Austin = tf.convert_to_tensor(list(value_Austin),dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sm3-Kw2gxgE"
      },
      "source": [
        "Below starts the model preparation. Data processing complete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnWcxsuL04mJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "bc340288-ede7-4dbf-99b0-7049641b6eae"
      },
      "source": [
        "\"\"\"def build_simple_univ_model(train_X,test_X,train_Y,test_Y,window):\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed = 42\n",
        "  verbose, epochs, batch_size = 0, 486, 16 #8.8 best, 386\n",
        "  #n_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[0], train_Y.shape[1]\n",
        "  n_features = 1\n",
        "  train_X = train_X.reshape((train_X.shape[0],train_X.shape[1],n_features))\n",
        "  print(train_X.shape)\n",
        "  test_X = test_X.reshape((test_X.shape[0],test_X.shape[1],n_features))\n",
        "  train_X = tf.convert_to_tensor(list(train_X), dtype=tf.float32)\n",
        "  test_X = tf.convert_to_tensor(list(test_X), dtype=tf.float32)\n",
        "  model = Sequential() \n",
        "  model.add(LSTM(30 ,activation='relu',return_sequences=False,recurrent_activation ='sigmoid',input_shape=(window, n_features)))#30 best,window = 3 -->2 is better!\n",
        "  #model.add(LeakyReLU(alpha=0.7))\n",
        "  model.add(Dropout(0.2))\n",
        "  #model.add(LSTM(60, activation='relu',return_sequences=False,recurrent_activation ='sigmoid',))#30 best\n",
        "  #model.add(Dropout(0.2))\n",
        "  #model.add(LSTM(50, activation='relu',recurrent_activation ='sigmoid'))#50,50\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='mae',optimizer='adam')\n",
        "  from tensorflow.keras.callbacks import EarlyStopping \n",
        "  early_stopping = EarlyStopping(patience = 150, restore_best_weights = True,monitor='val_loss')#150 good\n",
        "  history = model.fit(train_X, train_Y, epochs=epochs, batch_size=batch_size, shuffle = False,validation_data = (test_X, test_Y),callbacks = [early_stopping])\n",
        "  return model,history\"\"\"\n",
        "\n",
        "#model, history = build_simple_univ_model(X_train[0][10:],X_test[0],np.array(Y_train[0][10:]),np.array(Y_test[0]),window)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"def build_simple_univ_model(train_X,test_X,train_Y,test_Y,window):\\n  tf.random.set_seed(42)\\n  np.random.seed = 42\\n  verbose, epochs, batch_size = 0, 486, 16 #8.8 best, 386\\n  #n_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[0], train_Y.shape[1]\\n  n_features = 1\\n  train_X = train_X.reshape((train_X.shape[0],train_X.shape[1],n_features))\\n  print(train_X.shape)\\n  test_X = test_X.reshape((test_X.shape[0],test_X.shape[1],n_features))\\n  train_X = tf.convert_to_tensor(list(train_X), dtype=tf.float32)\\n  test_X = tf.convert_to_tensor(list(test_X), dtype=tf.float32)\\n  model = Sequential() \\n  model.add(LSTM(30 ,activation='relu',return_sequences=False,recurrent_activation ='sigmoid',input_shape=(window, n_features)))#30 best,window = 3 -->2 is better!\\n  #model.add(LeakyReLU(alpha=0.7))\\n  model.add(Dropout(0.2))\\n  #model.add(LSTM(60, activation='relu',return_sequences=False,recurrent_activation ='sigmoid',))#30 best\\n  #model.add(Dropout(0.2))\\n  #model.add(LSTM(50, activation='relu',recurrent_activation ='sigmoid'))#50,50\\n  #model.add(Dropout(0.2))\\n  model.add(Dense(1))\\n  model.compile(loss='mae',optimizer='adam')\\n  from tensorflow.keras.callbacks import EarlyStopping \\n  early_stopping = EarlyStopping(patience = 150, restore_best_weights = True,monitor='val_loss')#150 good\\n  history = model.fit(train_X, train_Y, epochs=epochs, batch_size=batch_size, shuffle = False,validation_data = (test_X, test_Y),callbacks = [early_stopping])\\n  return model,history\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tj3L5yqcKQo"
      },
      "source": [
        "\n",
        "def build_encoder_decoder(train_X,test_X,train_Y,test_Y,window):\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed = 42\n",
        "  temp_Y_train = np.array(train_Y)\n",
        "  temp_Y_test = np.array(test_Y)\n",
        "  n_steps_out = 1\n",
        "  Y_train_encoder = temp_Y_train.reshape((temp_Y_train.shape[0],1,1))\n",
        "  Y_test_encoder = temp_Y_test.reshape((temp_Y_test.shape[0],1,1))\n",
        "  verbose, epochs, batch_size = 0, 686, 16 #8.8 best, 386\n",
        "  #n_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[0], train_Y.shape[1]\n",
        "  n_features = 1\n",
        "  train_X = train_X.reshape((train_X.shape[0],train_X.shape[1],n_features))\n",
        "  print(train_X.shape)\n",
        "  test_X = test_X.reshape((test_X.shape[0],test_X.shape[1],n_features))\n",
        "  train_X = tf.convert_to_tensor(list(train_X), dtype=tf.float32)\n",
        "  test_X = tf.convert_to_tensor(list(test_X), dtype=tf.float32)\n",
        "  model = Sequential() \n",
        "  model.add(LSTM(100 ,activation='relu',recurrent_activation ='sigmoid',input_shape=(window, n_features)))#30 best,window = 3 -->2 is better!\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(RepeatVector(n_steps_out))\n",
        "  model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(TimeDistributed(Dense(1)))\n",
        "  model.compile(loss='mae',optimizer='adam')\n",
        "  plotted_model = plot_model(model, show_shapes=True, show_layer_names=True)\n",
        "  from tensorflow.keras.callbacks import EarlyStopping \n",
        "  early_stopping = EarlyStopping(patience = 100, restore_best_weights = True,monitor='val_loss')#150 good\n",
        "  history = model.fit(train_X, Y_train_encoder, epochs=epochs, batch_size=batch_size, shuffle = False,validation_data = (test_X, Y_test_encoder),callbacks = [early_stopping])\n",
        "  return model,history, plotted_model #20: good"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir5CbwD2kyIu"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eZLeg7dAPVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c06fb53f-6cbd-45c4-d0e6-a606ffc44534"
      },
      "source": [
        "encoder_model,encoder_history, plotted_model = build_encoder_decoder(np.array(X_train[0][15:]),np.array(X_test[0]),np.array(Y_train[0][15:]),np.array(Y_test[0]),window)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(166, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 711.7532 - val_loss: 1757.1731\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 494.8482 - val_loss: 975.4808\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 196.9036 - val_loss: 195.2085\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 202.1516 - val_loss: 118.6360\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 243.6623 - val_loss: 1320.0708\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 421.6610 - val_loss: 602.6265\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 175.5490 - val_loss: 269.2483\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 262.2914 - val_loss: 170.0376\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 195.7341 - val_loss: 60.0654\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 186.8334 - val_loss: 205.7646\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 143.1172 - val_loss: 90.1128\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 148.6384 - val_loss: 92.4663\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 127.5274 - val_loss: 180.7041\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 200.6431 - val_loss: 235.4241\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 160.9203 - val_loss: 336.7754\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 136.4192 - val_loss: 93.1653\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 141.0187 - val_loss: 163.1892\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 119.9858 - val_loss: 43.0244\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 108.3615 - val_loss: 111.1741\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 128.2650 - val_loss: 264.6345\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 122.7088 - val_loss: 296.9917\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 114.5954 - val_loss: 302.2246\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 170.2714 - val_loss: 276.9031\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 140.6447 - val_loss: 31.8264\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 117.4180 - val_loss: 287.5098\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 131.3593 - val_loss: 179.1189\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 124.3532 - val_loss: 91.1914\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 116.3954 - val_loss: 230.4043\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 125.6618 - val_loss: 114.3401\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 105.5867 - val_loss: 260.5476\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 150.5463 - val_loss: 247.9119\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 137.7468 - val_loss: 107.5698\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 197.2530 - val_loss: 289.2683\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 166.0219 - val_loss: 42.2625\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 119.7577 - val_loss: 300.6987\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 126.4027 - val_loss: 64.0432\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 113.3434 - val_loss: 40.6113\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 103.2670 - val_loss: 178.1531\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 126.5785 - val_loss: 231.5383\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 115.3237 - val_loss: 149.1348\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 120.1743 - val_loss: 303.1731\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 116.0276 - val_loss: 204.6301\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 120.8832 - val_loss: 218.1104\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 145.9010 - val_loss: 202.7400\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 181.4624 - val_loss: 438.0262\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 171.0498 - val_loss: 84.7236\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 112.9583 - val_loss: 268.1509\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 121.4902 - val_loss: 208.0710\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 118.5090 - val_loss: 273.4094\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 116.5203 - val_loss: 47.3943\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 113.0512 - val_loss: 220.2439\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 119.6840 - val_loss: 108.6736\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 113.1600 - val_loss: 238.5105\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 118.9368 - val_loss: 62.9702\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 106.0283 - val_loss: 285.1636\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 112.8827 - val_loss: 179.8591\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 105.8776 - val_loss: 171.6086\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 116.4196 - val_loss: 120.7290\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 86.1877 - val_loss: 320.4666\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 117.1304 - val_loss: 355.5537\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 138.1264 - val_loss: 4.7146\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 117.3311 - val_loss: 454.5874\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 178.9968 - val_loss: 129.8718\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 99.5653 - val_loss: 218.9275\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 120.5940 - val_loss: 55.4485\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 150.0100 - val_loss: 306.0081\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 244.2846 - val_loss: 554.4900\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 159.7384 - val_loss: 143.4807\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 116.3723 - val_loss: 103.3765\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 142.1028 - val_loss: 147.7515\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 169.5536 - val_loss: 492.9949\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 294.3037 - val_loss: 606.8124\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 152.3399 - val_loss: 105.0674\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 153.1408 - val_loss: 232.6145\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 114.3665 - val_loss: 97.3359\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 156.5378 - val_loss: 248.2336\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 136.3570 - val_loss: 97.9353\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 157.7331 - val_loss: 338.8264\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 153.5884 - val_loss: 38.9399\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 148.8431 - val_loss: 318.7761\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 111.1276 - val_loss: 27.2944\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 100.9462 - val_loss: 191.7507\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 110.9180 - val_loss: 245.5007\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 103.4493 - val_loss: 332.0173\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 157.2536 - val_loss: 320.3865\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 115.1960 - val_loss: 141.9204\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 114.0053 - val_loss: 116.7805\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 127.2426 - val_loss: 78.2881\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 140.2733 - val_loss: 167.8730\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 119.0298 - val_loss: 93.6064\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 103.0378 - val_loss: 219.9644\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 99.0955 - val_loss: 214.3240\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 115.6302 - val_loss: 230.6729\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 103.0941 - val_loss: 241.0635\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 124.7261 - val_loss: 134.2417\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 145.2145 - val_loss: 65.9846\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 135.9292 - val_loss: 347.0442\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 103.5326 - val_loss: 96.9136\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 82.6494 - val_loss: 358.8569\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 122.9907 - val_loss: 27.0107\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 128.3058 - val_loss: 358.9900\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 227.7117 - val_loss: 613.6599\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 136.1190 - val_loss: 58.2456\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 118.0044 - val_loss: 265.6848\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 95.5163 - val_loss: 118.3635\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 104.7113 - val_loss: 164.2053\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 107.2920 - val_loss: 135.8738\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 137.0619 - val_loss: 120.2375\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 123.9512 - val_loss: 69.5874\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 113.8780 - val_loss: 76.0879\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 113.0703 - val_loss: 225.6758\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 98.9417 - val_loss: 174.6150\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 158.9957 - val_loss: 144.9873\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 215.5964 - val_loss: 697.8225\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 345.5494 - val_loss: 650.2838\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 152.0275 - val_loss: 191.0022\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 191.5519 - val_loss: 364.2441\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 139.2288 - val_loss: 226.6733\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 126.2115 - val_loss: 95.2998\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 139.1302 - val_loss: 275.9993\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 120.4119 - val_loss: 38.0320\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 137.4691 - val_loss: 298.4104\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 242.9932 - val_loss: 563.9807\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 143.5640 - val_loss: 1.9438\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 149.5031 - val_loss: 417.0107\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 110.2782 - val_loss: 45.9692\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 112.7725 - val_loss: 279.1377\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 106.5416 - val_loss: 111.7593\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 102.6938 - val_loss: 231.7456\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 145.3447 - val_loss: 187.2778\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 170.7310 - val_loss: 7.2861\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 150.7819 - val_loss: 332.1028\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 114.1587 - val_loss: 115.1353\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 124.8188 - val_loss: 266.9136\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 138.8011 - val_loss: 185.6367\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 122.7192 - val_loss: 191.2764\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 101.6248 - val_loss: 131.3015\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 157.1719 - val_loss: 187.8086\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 157.7796 - val_loss: 121.0928\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 144.5789 - val_loss: 267.9756\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 130.7525 - val_loss: 57.7788\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 99.5408 - val_loss: 148.1733\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 104.8628 - val_loss: 197.0845\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 129.4154 - val_loss: 192.4321\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 107.1646 - val_loss: 111.4138\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 112.7906 - val_loss: 288.9441\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 114.2559 - val_loss: 87.0283\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 104.1925 - val_loss: 150.5603\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 98.8749 - val_loss: 252.2747\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 105.4624 - val_loss: 116.6191\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 112.0329 - val_loss: 346.5764\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 87.3566 - val_loss: 108.2610\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 121.7259 - val_loss: 108.8608\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 111.8372 - val_loss: 239.8125\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 105.8450 - val_loss: 137.4202\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 119.0296 - val_loss: 266.7378\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 101.6786 - val_loss: 70.6560\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 98.2306 - val_loss: 320.4016\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 89.4871 - val_loss: 137.7466\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 92.4423 - val_loss: 171.2012\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 111.3311 - val_loss: 270.3547\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 101.0420 - val_loss: 126.3616\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 103.5716 - val_loss: 178.4490\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 101.6544 - val_loss: 194.5803\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 88.2261 - val_loss: 133.9216\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 94.0381 - val_loss: 140.0901\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 99.0437 - val_loss: 300.8538\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 95.2467 - val_loss: 231.2178\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 108.5843 - val_loss: 200.6809\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 92.0682 - val_loss: 146.6599\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 96.7538 - val_loss: 175.7183\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 97.5951 - val_loss: 221.7720\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 95.4754 - val_loss: 258.0386\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 90.6694 - val_loss: 124.0598\n",
            "Epoch 175/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 98.4695 - val_loss: 337.0195\n",
            "Epoch 176/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 170.3726 - val_loss: 445.0875\n",
            "Epoch 177/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 108.4174 - val_loss: 37.1531\n",
            "Epoch 178/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 108.1901 - val_loss: 289.9363\n",
            "Epoch 179/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 96.4968 - val_loss: 29.3611\n",
            "Epoch 180/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 94.6893 - val_loss: 207.5562\n",
            "Epoch 181/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 110.6446 - val_loss: 199.0840\n",
            "Epoch 182/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 95.8983 - val_loss: 233.4656\n",
            "Epoch 183/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 102.6354 - val_loss: 205.6824\n",
            "Epoch 184/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 95.6034 - val_loss: 68.4370\n",
            "Epoch 185/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 125.2376 - val_loss: 260.0344\n",
            "Epoch 186/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 108.7244 - val_loss: 47.5120\n",
            "Epoch 187/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 99.3709 - val_loss: 302.8840\n",
            "Epoch 188/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 93.2869 - val_loss: 160.3977\n",
            "Epoch 189/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 85.7896 - val_loss: 205.5620\n",
            "Epoch 190/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 97.3591 - val_loss: 226.7683\n",
            "Epoch 191/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 94.0667 - val_loss: 166.7869\n",
            "Epoch 192/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 89.2281 - val_loss: 204.2546\n",
            "Epoch 193/686\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 81.4794 - val_loss: 139.2119\n",
            "Epoch 194/686\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 97.3251 - val_loss: 276.1086\n",
            "Epoch 195/686\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 144.5306 - val_loss: 448.8350\n",
            "Epoch 196/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 95.9380 - val_loss: 207.0718\n",
            "Epoch 197/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 83.0840 - val_loss: 170.5884\n",
            "Epoch 198/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 84.8014 - val_loss: 252.4309\n",
            "Epoch 199/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 97.6199 - val_loss: 217.7847\n",
            "Epoch 200/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 96.1241 - val_loss: 216.9326\n",
            "Epoch 201/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 127.8198 - val_loss: 390.1819\n",
            "Epoch 202/686\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 84.0507 - val_loss: 248.0618\n",
            "Epoch 203/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 108.8302 - val_loss: 327.9502\n",
            "Epoch 204/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 166.2826 - val_loss: 341.6833\n",
            "Epoch 205/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 113.3566 - val_loss: 127.7766\n",
            "Epoch 206/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 120.2452 - val_loss: 547.2388\n",
            "Epoch 207/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 245.1114 - val_loss: 157.2952\n",
            "Epoch 208/686\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 207.5268 - val_loss: 271.6670\n",
            "Epoch 209/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 146.1981 - val_loss: 199.7153\n",
            "Epoch 210/686\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 121.9103 - val_loss: 5.7278\n",
            "Epoch 211/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 122.7574 - val_loss: 212.0588\n",
            "Epoch 212/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 144.8051 - val_loss: 127.2144\n",
            "Epoch 213/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 209.2170 - val_loss: 171.4001\n",
            "Epoch 214/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 185.7117 - val_loss: 467.1083\n",
            "Epoch 215/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 263.6636 - val_loss: 300.8491\n",
            "Epoch 216/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 374.1360 - val_loss: 101.3623\n",
            "Epoch 217/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 394.3891 - val_loss: 1060.8928\n",
            "Epoch 218/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 159.2834 - val_loss: 210.4126\n",
            "Epoch 219/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 169.1425 - val_loss: 252.2207\n",
            "Epoch 220/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 132.9652 - val_loss: 143.2712\n",
            "Epoch 221/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 190.0228 - val_loss: 246.3120\n",
            "Epoch 222/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 197.9107 - val_loss: 133.4407\n",
            "Epoch 223/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 135.2336 - val_loss: 156.5095\n",
            "Epoch 224/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 135.2575 - val_loss: 56.6365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwECg2hFl8eG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "00abb457-01ff-4e7c-af90-f04a04b87998"
      },
      "source": [
        "plotted_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozycx3O51wKo"
      },
      "source": [
        "def build_conv_model(train_X,test_X,train_Y,test_Y,window):\n",
        "\t# prepare data\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed = 42\n",
        "  temp_Y_train = np.array(train_Y)\n",
        "  temp_Y_test = np.array(test_Y)\n",
        "  Y_train_conv = temp_Y_train.reshape((temp_Y_train.shape[0],1,1))\n",
        "  Y_test_conv = temp_Y_test.reshape((temp_Y_test.shape[0],1,1))\n",
        "  verbose, epochs, batch_size = 0, 686, 16 #was 16\n",
        "  n_features = 1\n",
        "  train_X = train_X.reshape((train_X.shape[0],train_X.shape[1],n_features))\n",
        "  test_X = test_X.reshape((test_X.shape[0],test_X.shape[1],n_features))\n",
        "  train_X = tf.convert_to_tensor(list(train_X), dtype=tf.float32)\n",
        "  test_X = tf.convert_to_tensor(list(test_X), dtype=tf.float32)\n",
        "  n_outputs=1\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(window,n_features)))#was 32, 32\n",
        "  model.add(MaxPooling1D())#pool_size=2\n",
        "  model.add(Flatten())\n",
        "  model.add(RepeatVector(n_outputs))\n",
        "  model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(50, activation='relu')))\n",
        "  model.add(TimeDistributed(Dense(1)))\n",
        "  model.compile(loss='mae', optimizer='adam')\n",
        "  from tensorflow.keras.callbacks import EarlyStopping \n",
        "  early_stopping = EarlyStopping(patience = 160, restore_best_weights = True,monitor='val_loss')#160 good\n",
        "\t# fit network\n",
        "  history = model.fit(train_X, Y_train_conv, epochs=epochs, batch_size=batch_size, shuffle = False,validation_data = (test_X, Y_test_conv),callbacks = [early_stopping])\n",
        "  plotted_model = plot_model(model, show_shapes=True, show_layer_names=True)\n",
        "  return model,history,plotted_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExsXQoMF1w41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9df8b568-9320-42cc-a32f-81e3ded9c3e8"
      },
      "source": [
        "conv_model,conv_history, plotted_model = build_conv_model(np.array(X_train[0][15:]),np.array(X_test[0]),np.array(Y_train[0][15:]),np.array(Y_test[0]),window)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 556.9108 - val_loss: 1036.7673\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 122.9622 - val_loss: 391.0803\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 43.0262 - val_loss: 102.9148\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 120.7628 - val_loss: 35.8118\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 119.1222 - val_loss: 210.0127\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45.1645 - val_loss: 72.5364\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 39.5949 - val_loss: 6.3623\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 144.3714 - val_loss: 57.6316\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 104.5469 - val_loss: 188.7876\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 39.7467 - val_loss: 56.4700\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 47.7492 - val_loss: 93.3799\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45.2607 - val_loss: 71.5955\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 47.2866 - val_loss: 98.5706\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.0755 - val_loss: 60.7715\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 78.4739 - val_loss: 61.9167\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 46.2226 - val_loss: 44.8818\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 138.3522 - val_loss: 115.9136\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 70.3237 - val_loss: 72.4985\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 150.0597 - val_loss: 165.5928\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 77.1745 - val_loss: 218.9851\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.8569 - val_loss: 77.0850\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 39.3156 - val_loss: 35.8811\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 127.1898 - val_loss: 94.1846\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 74.9659 - val_loss: 194.1853\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.3086 - val_loss: 7.7102\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 90.2296 - val_loss: 115.3687\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 163.2936 - val_loss: 359.9128\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 69.6565 - val_loss: 52.3455\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 93.4972 - val_loss: 167.8625\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 108.2606 - val_loss: 47.6292\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 77.0212 - val_loss: 158.2068\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 56.2938 - val_loss: 96.5508\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 36.8397 - val_loss: 7.9473\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 158.9969 - val_loss: 200.8911\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 76.1392 - val_loss: 227.1343\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 48.3889 - val_loss: 108.8984\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 41.2563 - val_loss: 31.1362\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 134.9927 - val_loss: 140.9800\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 70.9131 - val_loss: 207.3506\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45.0225 - val_loss: 62.0186\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 75.5988 - val_loss: 133.9346\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 47.0307 - val_loss: 47.6604\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 202.7976 - val_loss: 374.6003\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 56.8139 - val_loss: 145.3789\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35.4767 - val_loss: 52.7776\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 47.5186 - val_loss: 116.7561\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.9347 - val_loss: 21.9822\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 122.5775 - val_loss: 105.9822\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 66.1571 - val_loss: 179.4700\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 69.6673 - val_loss: 48.2412\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 87.8953 - val_loss: 179.4529\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 89.7337 - val_loss: 29.8811\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 71.4973 - val_loss: 185.6196\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 63.2901 - val_loss: 63.8777\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 75.4640 - val_loss: 137.9021\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 102.9040 - val_loss: 78.1174\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 62.4939 - val_loss: 173.5740\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 34.5012 - val_loss: 40.9839\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 78.9330 - val_loss: 95.2810\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 120.9687 - val_loss: 232.0161\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 93.0349 - val_loss: 44.0005\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 70.7355 - val_loss: 172.4106\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 72.8932 - val_loss: 45.1570\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 88.7553 - val_loss: 181.1465\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 88.2444 - val_loss: 29.6238\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 70.0882 - val_loss: 181.2222\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 63.1132 - val_loss: 70.0996\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 93.9554 - val_loss: 204.9282\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 75.6406 - val_loss: 5.9541\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 70.2490 - val_loss: 161.7678\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 76.9803 - val_loss: 10.4502\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 72.3825 - val_loss: 169.5283\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 73.6296 - val_loss: 19.2192\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 73.4426 - val_loss: 159.3193\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 83.2848 - val_loss: 0.5085\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 72.7024 - val_loss: 170.0015\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 73.3603 - val_loss: 20.1064\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 73.0522 - val_loss: 174.6353\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 69.5054 - val_loss: 27.5757\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 73.7766 - val_loss: 178.2395\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 67.3814 - val_loss: 32.9944\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 73.2431 - val_loss: 171.8467\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 70.9620 - val_loss: 18.0415\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 69.5253 - val_loss: 169.9834\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 66.9886 - val_loss: 33.1345\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 73.1085 - val_loss: 177.3816\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 65.9639 - val_loss: 33.1453\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 72.7193 - val_loss: 179.2783\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 63.7258 - val_loss: 39.9990\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 73.4863 - val_loss: 179.6960\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 64.0459 - val_loss: 36.7781\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 72.2646 - val_loss: 179.1621\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 62.5242 - val_loss: 41.5378\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 72.3908 - val_loss: 177.6621\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 63.4282 - val_loss: 36.5708\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 71.0429 - val_loss: 177.2371\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 61.6672 - val_loss: 42.1755\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 72.3039 - val_loss: 182.1104\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 68.6288 - val_loss: 6.6118\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 64.9806 - val_loss: 180.7512\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 51.0523 - val_loss: 29.1875\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.1585 - val_loss: 90.8474\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.6284 - val_loss: 51.7910\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 52.4097 - val_loss: 121.2585\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 64.8767 - val_loss: 72.6628\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 82.2962 - val_loss: 105.7839\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 122.0862 - val_loss: 158.0110\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 60.7151 - val_loss: 204.0381\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.4478 - val_loss: 65.1055\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31.1273 - val_loss: 61.2148\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 61.5006 - val_loss: 70.8481\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 78.6988 - val_loss: 169.8271\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 72.9431 - val_loss: 6.5515\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 64.0174 - val_loss: 175.7256\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 50.5341 - val_loss: 26.5032\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.7663 - val_loss: 83.9153\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 59.9415 - val_loss: 60.3430\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 71.1346 - val_loss: 162.1638\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 68.1342 - val_loss: 8.6157\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 64.8880 - val_loss: 175.7302\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 50.5787 - val_loss: 39.2563\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 40.8026 - val_loss: 88.1426\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 73.4124 - val_loss: 7.3730\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 65.9442 - val_loss: 173.2759\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 53.3268 - val_loss: 52.6284\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 62.9948 - val_loss: 147.8313\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 66.5690 - val_loss: 14.0154\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 65.0246 - val_loss: 175.1460\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 50.1510 - val_loss: 45.5193\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45.0997 - val_loss: 97.4121\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 74.9310 - val_loss: 6.7583\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 63.7327 - val_loss: 181.4053\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45.7620 - val_loss: 35.8948\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.7660 - val_loss: 73.1370\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 60.0993 - val_loss: 50.9568\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 66.9443 - val_loss: 158.8098\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 62.5112 - val_loss: 20.9458\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 64.0671 - val_loss: 165.3496\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 54.2689 - val_loss: 51.6233\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 71.0941 - val_loss: 171.8618\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.6441 - val_loss: 30.3572\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 63.7757 - val_loss: 159.0649\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.2114 - val_loss: 35.0403\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 66.1910 - val_loss: 168.1787\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 54.6240 - val_loss: 45.8865\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 68.1969 - val_loss: 170.5178\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 55.2811 - val_loss: 41.3213\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 66.4286 - val_loss: 167.9092\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 54.7724 - val_loss: 43.1162\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 66.7352 - val_loss: 169.3352\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 54.1246 - val_loss: 45.0767\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 67.2415 - val_loss: 171.7808\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 53.3236 - val_loss: 46.2334\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 67.1006 - val_loss: 171.7104\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 52.9421 - val_loss: 46.6868\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 66.9108 - val_loss: 171.6472\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 52.5097 - val_loss: 47.3606\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 66.8101 - val_loss: 171.9126\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 51.9670 - val_loss: 48.3503\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 66.8017 - val_loss: 172.5408\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 51.2821 - val_loss: 41.4248\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57.7608 - val_loss: 154.9297\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.0307 - val_loss: 50.1289\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 56.3347 - val_loss: 145.1880\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 55.1416 - val_loss: 41.7734\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 65.5509 - val_loss: 170.0242\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 50.9659 - val_loss: 42.2256\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57.7042 - val_loss: 153.8882\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.3195 - val_loss: 49.6121\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 60.3431 - val_loss: 160.3088\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 49.7482 - val_loss: 49.1042\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 59.4561 - val_loss: 157.2959\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.5491 - val_loss: 45.8662\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.3490 - val_loss: 153.4734\n",
            "Epoch 175/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.9989 - val_loss: 44.7183\n",
            "Epoch 176/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.7371 - val_loss: 157.0764\n",
            "Epoch 177/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 49.2778 - val_loss: 49.9248\n",
            "Epoch 178/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 59.7018 - val_loss: 158.5183\n",
            "Epoch 179/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 49.4063 - val_loss: 48.1824\n",
            "Epoch 180/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.8092 - val_loss: 155.4927\n",
            "Epoch 181/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.1146 - val_loss: 45.3423\n",
            "Epoch 182/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.4969 - val_loss: 156.2917\n",
            "Epoch 183/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.8616 - val_loss: 49.7466\n",
            "Epoch 184/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 59.3643 - val_loss: 157.7297\n",
            "Epoch 185/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.9048 - val_loss: 48.3215\n",
            "Epoch 186/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.6710 - val_loss: 155.1150\n",
            "Epoch 187/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 49.5261 - val_loss: 45.8274\n",
            "Epoch 188/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57.7188 - val_loss: 152.2307\n",
            "Epoch 189/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.1260 - val_loss: 43.4233\n",
            "Epoch 190/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57.5506 - val_loss: 153.5645\n",
            "Epoch 191/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.7035 - val_loss: 48.3442\n",
            "Epoch 192/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.5958 - val_loss: 155.5735\n",
            "Epoch 193/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 48.9671 - val_loss: 45.5613\n",
            "Epoch 194/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 57.2614 - val_loss: 150.7871\n",
            "Epoch 195/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 49.8659 - val_loss: 42.7090\n",
            "Epoch 196/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57.0810 - val_loss: 152.2131\n",
            "Epoch 197/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.7833 - val_loss: 45.9771\n",
            "Epoch 198/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57.3599 - val_loss: 151.8054\n",
            "Epoch 199/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 49.3472 - val_loss: 43.0303\n",
            "Epoch 200/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 57.1408 - val_loss: 152.0427\n",
            "Epoch 201/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 48.5131 - val_loss: 45.0679\n",
            "Epoch 202/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 56.4285 - val_loss: 150.1360\n",
            "Epoch 203/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 55.7170 - val_loss: 25.4209\n",
            "Epoch 204/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 59.8285 - val_loss: 167.7710\n",
            "Epoch 205/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 43.2257 - val_loss: 23.3479\n",
            "Epoch 206/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 67.0316 - val_loss: 154.0588\n",
            "Epoch 207/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 77.6996 - val_loss: 11.3879\n",
            "Epoch 208/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 63.7255 - val_loss: 133.1597\n",
            "Epoch 209/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 69.1739 - val_loss: 14.8386\n",
            "Epoch 210/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 55.0554 - val_loss: 150.4016\n",
            "Epoch 211/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 46.6858 - val_loss: 42.2002\n",
            "Epoch 212/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 39.8416 - val_loss: 60.9182\n",
            "Epoch 213/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 87.5855 - val_loss: 40.3726\n",
            "Epoch 214/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 59.4610 - val_loss: 169.7458\n",
            "Epoch 215/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 43.5161 - val_loss: 30.9768\n",
            "Epoch 216/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.3761 - val_loss: 68.1382\n",
            "Epoch 217/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 57.1238 - val_loss: 49.2217\n",
            "Epoch 218/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 64.2037 - val_loss: 144.0996\n",
            "Epoch 219/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 62.4618 - val_loss: 3.9062\n",
            "Epoch 220/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.2082 - val_loss: 160.7900\n",
            "Epoch 221/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44.9138 - val_loss: 27.1450\n",
            "Epoch 222/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.8318 - val_loss: 68.6282\n",
            "Epoch 223/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 56.3794 - val_loss: 48.7927\n",
            "Epoch 224/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 71.4346 - val_loss: 172.2424\n",
            "Epoch 225/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 52.7882 - val_loss: 28.1362\n",
            "Epoch 226/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 59.3576 - val_loss: 153.6809\n",
            "Epoch 227/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.5711 - val_loss: 41.3953\n",
            "Epoch 228/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 63.3587 - val_loss: 161.0042\n",
            "Epoch 229/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 50.4537 - val_loss: 38.3555\n",
            "Epoch 230/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 61.6827 - val_loss: 157.9016\n",
            "Epoch 231/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 50.2794 - val_loss: 38.7607\n",
            "Epoch 232/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 61.6037 - val_loss: 158.3923\n",
            "Epoch 233/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 49.5947 - val_loss: 40.2673\n",
            "Epoch 234/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 61.7718 - val_loss: 159.4539\n",
            "Epoch 235/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 49.2453 - val_loss: 39.9170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7RAVdKOXD9s"
      },
      "source": [
        "#here you load your model because when the kernel disconnects you lose the weights! No need to run this cell, just for reference. I used it to load good trained weights\n",
        "\"\"\"\n",
        "from tensorflow.keras.models import model_from_json\n",
        "model_json = conv_model_Galveston.to_json()\n",
        "with open(\"conv_model_Galveston_hosp.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "conv_model_Galveston.save_weights(\"conv_model_Galveston_hosp.h5\")\n",
        "print(\"Saved model to disk\")\"\"\"\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0NLs7Bnmy2u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "outputId": "e6fe29b2-8a52-45ae-a4fe-685644175d6b"
      },
      "source": [
        "plotted_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAANQCAIAAADIaK5IAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVwT57o48HcggSzsq8gim6AoKq22hkW0VKpQRVQWl3NKPVrE9oDLqRQtsgnWYoGLgrYWba/Wsn9ARYrXKkVbsLaWpdgqoFaFK4vsBCQh8/vj/Z3cnAAhkIEEeL5/mXmTZ55JYh5m5l0IkiQRAAAAAGSmJO8EAAAAgCkCaioAAABADaipAAAAADWgpgIAAADUoMk7gcmhtLQ0ISFB3lkAAIB8cDicvXv3yjuLSQDOU6Xy9OnT7OxseWcBwHjJzs5+9uyZvLMYd2VlZWVlZfLOYvIpKysrLS2VdxaTA5ynjkJWVpa8UwBgXBAEsWfPHl9fX3knMr58fHwQ/EcePfy+AWnAeSoAAABADaipAAAAADWgpgIAAADUgJoKAAAAUANqKgAAAEANqKkAgDG6cuWKpqbmpUuX5J0IxXbu3En829atW0Wbrl27FhYWJhAIvL29zczMGAyGsbGxl5dXZWWl9PEFAkFiYqKjo+Pgplu3bjk5ObFYLCMjo9DQ0JcvX44q8yEjX7x48ejRowMDA8IteXl5wgPU09Mb1S6AZFBTAQBjNIVXtdLR0SksLLx//35aWppwY0RERHJy8oEDBwQCwc2bNy9cuNDa2nrr1q3e3t5ly5Y1NDRIE7mmpmbZsmV79+7lcrliTdXV1e7u7m5ubs3Nzbm5uWfOnAkKCpI+5+Eir127lsFguLm5tbe34y1eXl7Pnj0rKSnx8PCQPj6QBtRUAMAYeXp6dnR0rFmzZrx31NvbO+RZ3fhhMpmrVq2ysbFRVVXFWz755JP09PTMzEx1dXWEEIfDcXZ2ZrFYFhYWsbGxHR0dX3311YhhKyoqPvroo6CgoEWLFg1ujYmJmTFjRlRUFJvN5nA4oaGhX3311Z9//ilNwpIjh4SELFy40MPDg8/nI4QIgjA2NnZxcZk9e7Y0wYH0oKYCABRdWlpaU1OTHBOora0NDw+PiopiMBgIIRqNJnrF29LSEiFUV1c3YpyFCxfm5ORs2bJFWKqF+Hx+QUGBq6srQRB4y+rVq0mSzM/PlyZDCZGxyMjI8vLypKQkaaKBMYOaCgAYi1u3bpmZmREEceLECYRQamoqm81msVj5+fmrV6/W0NAwMTH59ttv8ZOTk5MZDIaBgcHOnTuNjIwYDIajo+Pt27dxa3BwsIqKyowZM/DD999/n81mEwTR0tKCENq9e/e+ffvq6uoIgrC2tkYIfffddxoaGrGxsRN2sMnJySRJrl27dsjW3t5ehJCGhoYsu3j48GF3d7eZmZlwi5WVFUJoVHdqJdDW1nZ1dU1KSprCV+wVAdRUAMBYODs7//TTT8KHu3bt2rNnT29vr7q6ekZGRl1dnaWl5Y4dO3g8HkIoODg4ICCAy+WGhIQ8fvz47t27fD5/5cqVT58+RQglJyeLTouYkpISFRUlfJiUlLRmzRorKyuSJGtraxFCuLuNQCCYsIMtKCiwtbVlsVhDtv78888IIWdnZ1l28fz5c4QQvrCMMRgMJpPZ2NgoS1hRDg4O9fX1FRUVVAUEg0FNBQBQydHRUUNDQ19f39/fv6en58mTJ8ImGo02d+5cVVVVOzu71NTUrq6us2fPjmEXnp6enZ2d4eHh1GUtSU9Pz6NHj/BZo5jGxsb09PSQkBAOhzPcWayUcBdfZWVl0Y10Oh2fBFMC3z2tqqqiKiAYDObQBwCMCxUVFYQQPk8dbPHixSwWS8oOOPLV1NREkuSQJ6kcDqenp8fX1/fw4cN0Ol2WveA7tbgPkVB/fz+TyZQlrCh8CBSe+ILBoKYCAORDVVW1ublZ3lmMrK+vDyE0ZN8fAwODtLS0efPmyb4XfDu5s7NTuIXL5fb19RkZGckeHMPlGR8OGCdw7RcAIAc8Hq+9vd3ExETeiYwMlyLROROE9PX1tbS0KNmLhYWFurr6X3/9JdyCbx4vWLCAkvgIof7+fvTvwwHjBM5TAQByUFxcTJLk0qVL8UMajTbcVWK5MzAwIAiio6NjcBOFc0jRaDQPD4+SkhKBQKCkpIQQKiwsJAhCxtu0ovAhGBoaUhUQDAbnqQCACSIQCNra2vh8fmVl5e7du83MzAICAnCTtbV1a2trXl4ej8drbm4WPV1DCOno6DQ0NDx+/Lirq4vH4xUWFk7kWBoWi2Vpafns2TOx7bW1tYaGhn5+fqIb/f39DQ0N7969O4YdhYeHNzY2RkRE9PT0lJaWxsfHBwQE2Nrayh4Zw4dgb28/5ghgRFBTAQBjceLEiSVLliCEQkNDvby8UlNTExMTEUILFix4+PDh6dOn9+3bhxBatWpVTU0NfklfX5+9vT2TyXRxcbGxsblx44bwJuWuXbtWrFixadMmW1vbmJgYfH2Sw+HgwTZBQUEGBgZ2dnYeHh6tra0Tf7Cenp7V1dViXXCHHOjZ39/f1NQ03EQNZWVlzs7OM2fOvH37dkVFhZGRkZOTU0lJCW6dN29eUVHR1atXdXV1N2zYsG3btpMnT1ISGbtz546xsTGFF5PBEEgghYyMDHivwBSGEMrIyBjXXQQGBuro6IzrLka0cePGjRs3jvi0wMBAY2Nj0S01NTU0Gu3cuXMjvnZgYMDFxSUtLW3sWY5P5JaWFgaDcezYMdGNISEhurq6I75WyvcNkCQJ56kAgAkyZDcfxdTb21tUVFRTU4P79VhbW0dHR0dHR3d3d0t41cDAQF5eXldXl7+/P7X5yB45MjJy0aJFwcHBCCGSJBsaGm7duoW7QQEKQU0FAABxra2teA79bdu24S1hYWE+Pj7+/v5DdlbCiouLc3JyCgsLh5txacxkjJyQkFBeXn7lyhU8iDY/Px/PoV9QUEBtngBq6lQgYTlGoe3bt6urqxMEUV5eTm3kwRRwWc2ysrK5c+cqKSkRBGFoaHj48OEJ23VOTo6lpSVeq3LGjBli63FOEwcOHDh79mxHR4eFhUV2dra80xnBqVOnhJfyzp8/L9weGxsbHBx85MiR4V7o5ub2zTffCCcuppAskfPz81++fFlcXKytrY23rFu3TniAeFJlQBUYSzPp1dTUvPvuuz/++OPChQslPO3LL7988803N23aRHnkwUjFm6R76dKlf/zxx6pVq4qKiu7fv0/VmEJpbNiwYcOGDdbW1i0tLXhO12koLi4uLi5O3llQwN3d3d3dXd5ZjI6Xl5eXl5e8s5guoKZObhUVFdHR0UFBQT09PdRWMlki42U1KUxmOL29vW5ubqIzuSsIhU0MADCu4Nrv5DbioomihOsyUh5ZXuS+rOZwFDYxAMC4gppKsXPnzi1evJjBYLDZbHNz85iYGIQQSZIJCQl4RQ5tbe1169YJpw6XvOrk3LlzCYJQUlJ69dVXuVwuQmj//v2ampoMBuOrr74aMRmSJOPj421tbVVVVTU1NT/88MPxOmwRk2VZzYlMTBo3b960s7PDH669vX1RURFCaPv27fhGrJWV1W+//YYQevfdd1kslqam5sWLFxFCAwMDhw4dMjMzYzKZCxYswIO+Pv30UxaLpa6u3tTUtG/fPmNj4/v370uZBgBAJhM7dGeyknJ8Kh7zfuTIkRcvXrS2tn7++edbtmwhSfLQoUMqKirnzp1rb2+vrKx85ZVX9PT0nj9/jl918OBBhND333/f0dHR1NTk4uLCZrP7+/tJkuTz+ebm5mZmZnw+X7iXPXv2JCYmiu369ddfX7hwodjGgwcPEgTx2WeftbW1cbnclJQUhNBvv/02qmMfMrJkeJz+8ePHRzxAkiQDAwPZbPa9e/f6+vqqq6uXLFmirq7+5MkT3LplyxZDQ0Nh5Pj4eIRQc3Mzfrhhwwa8rCZ2+fJldXX16Ojo4RJ76623EEJtbW0TnBhJklZWVpqamhLetKysrMjIyNbW1hcvXixdulQ4anDDhg3Kysr19fXCZ27evPnixYv43//6179UVVWzs7Pb2toOHDigpKR0584d4aGFhIQcP358/fr1f/zxh4RdkxMyPlURwDjLsYH3TXpwnkoZHo8XFRW1YsWKjz76SEdHR1tb+x//+MeSJUt6e3sTEhLWr1+/detWTU1Ne3v7U6dOtbS0fPHFF6IvH3LVSWVl5ZCQkCdPnuTm5uKncbncnJwcYf9+CXp7exMTE9988829e/dqaWkxmUwdHZ3xOHApKeyymhOQmDQ2btwYERGhra2to6Ozdu3aFy9e4DVbgoKCBgYGhPvt7Oy8c+eOh4cHQqivry81NdXb23vDhg1aWloff/wxnU4XzfCTTz754IMPcnJy5syZM05pAwBEQU2lTGVlZXt7Oz4TwnBFrK6u7u7uXrx4sXD7kiVLVFRUhBcSxYitOrl9+3ZNTc2kpCT88Pz58+vWrdPQ0Bgxn9raWi6X6+bmNuYjGicKu6ym4iSGBxHiGRLeeOMNGxubM2fOkCSJEEpPT/f398crV9+/f5/L5c6fPx+/islkzpgxY8wZ+vn5EVNddnZ2dna2vLOYfBR/+JPigH6/lMELHw4epNHe3o4QUlNTE92opaXV1dUlTVg1NbX33nsvPj7+559/fu21106ePCnl9xvPl62vry/NkxWKwi6rOa6JFRQUxMfHV1dXd3Z2itZ1giB27ty5d+/e77///s033/zv//7vb775Bjf19PQghD7++OOPP/5Y+PwxL7e5e/duDocjwxFMAvjuzJ49e+SdyCSD3zcgDaiplJk5cyZCaPAAalxlxSroqFaODA4OTkpKSkxMDAoKMjU1tbKykuZVDAYDIfTy5Usp96IgFHZZzfFIrKSk5Ndff92zZ8+TJ0+8vb3Xr19/5syZmTNnHj9+fP/+/cKnBQQEHDhw4MsvvzQ1NdXQ0Jg1axbejv9gSkxM3L17t+zJcDgcX19f2eMosqysLITQlD9MyuH3DUgDrv1SxtzcXEdH5+rVq2Lb58+fr6am9ssvvwi33L59u7+//9VXX5UysomJia+vb3Z2dnh4uPS/nvPnz1dSUvrhhx+kfL6CUNhlNccjsV9//ZXNZiOEqqqqeDzerl27LC0tGQwG8Z+jnrS1tf38/PLy8o4dO7Zjxw7hdlNTUwaDMaqJsQAA4wpqKmVUVVUPHDhQUlISHBxcX18vEAi6urru3bvHYDD27duXm5t7/vz5zs7OqqqqoKAgIyOjwMBA6YPv27ePz+e3tbW98cYbUr5EX19/w4YN2dnZaWlpnZ2dlZWVYr2iFIfCLqtJVWKDI/N4vMbGxuLiYlxTzczMEELXrl3r6+urqakZfK89KCjo5cuXly9fXrNmjXAjg8F49913v/3229TU1M7OzoGBgWfPnv3v//4vVYcPABg1Ofc7niSkX+vtxIkT9vb2DAaDwWA4ODikpKSQJCkQCOLj42fPnk2n07W1tb29ve/fv4+fn5KSgifFnj17dl1d3RdffIH7H82aNevBgweikVesWPHll1+K7a60tNTJyUl4C23GjBmOjo4//PADbu3q6tq+fbuurq6ampqzs/OhQ4cQQiYmJhUVFSMeiOTIEhw/fhwP3GSxWGvXrh3xAAMDA+l0urGxMY1G09DQWLduXV1dnTDaixcvVqxYwWAwLCws/vnPf+IhttbW1nhMy927d2fNmsVkMp2dnZ8/f37lyhV1dfXDhw8PzqqsrGzevHlKSkr4WGJjYycssZMnT0q4XJ+bm4sDhoaG6ujoaGlp+fj44KG9VlZWwqE7JEk6ODiEhYWJHdfLly9DQ0PNzMxoNBr+K6q6uvro0aN4/VFTU1NplicjYSwNkAjeN+kRpOJNzaqAMjMz/fz84L0aDzt37szKynrx4oW8ExGnaIl5enqeOHHCwsJiPIITBJGRkTHlbzT6+PgguDs4evC+SQ+u/QL5U9hlNeWemPC6cWVlJT4nlm8+AADJoKZOR3/++aeEsWiSFz2W5bVgtEJDQ2tqah48ePDuu+/ieS7BBNi5c6fwKy22Nt+1a9fCwsIEAoG3t7eZmRmDwTA2Nvby8qqsrJQ+voQlFG/duuXk5MRisYyMjEJDQ0fbb3/IyBcvXjx69KjoH4h5eXnCA9TT0xvVLsAI5H3xeXKQ/n4qGJWwsDA804K5uXlWVpa80/k/CpLYwYMHlZSUTE1NhZMRjhME91NFBAYG6ujoFBYW3r9/v6+vT7j90KFDa9aswQOIdXV1b9682dPT8/Dhw5UrV2pqaorOHynBgwcPnJycEEKDp/z8/fffmUxmeHh4d3f3Tz/9pKen9+6770p/dBIiJyUlubq6CmflFAgEz549Kykp8fDwEM6CKQHcT5Ue1AmpQE0FU9t411Qul8vhcOQeSvqaamxsLLbxyJEjNjY2vb29JEnyeLy3335b2PTzzz8jhGJjY0eMXF5evn79+vPnzy9atGhw5fPz87OwsBAIBPhhfHw8QRAjztUsTWSSJIODgzkcDo/HE90YEhICNZVacO0XADDuKFz8Ti7r6NXW1oaHh0dFReGpVGg02qVLl4StlpaWCKG6uroR40hYQpHP5xcUFLi6ugpHJ69evZokyfz8fGkyHHFxxsjIyPLycuEsp2CcQE0FAEiFHH7JwlEtfifHBf7GLDk5mSTJtWvXDtna29uLEJJmFm4JHj582N3djUcqY3gI1qju1Eqgra3t6uqalJREwviF8QQ1FQAglcjIyLCwsIMHDzY1NZWUlDx9+tTFxaWxsREhlJycLDoOJyUlJSoqSvgwKSlpzZo1ePG72tra4ODggIAALpcbEhLy+PHju3fv8vn8lStX4iUCRxUK/btvtkAgGNdjLygosLW1xQOaB8PXfp2dnWXZxfPnzxFC6urqwi0MBoPJZOJ3mBIODg719fUVFRVUBQSDQU0FAIxMyiULpSffBf5Gpaen59GjR0NO3NHY2Jienh4SEsLhcIY7i5US7uKLVxwSotPp+CSYErNnz0YIVVVVURUQDAZz6AMARjbaJQtHRY4L/EmjqamJJMkhT1I5HE5PT4+vr+/hw4fxCn1jhu/U8vl80Y39/f14SixK4EOg8MQXDAY1FQAwMhmXLByRwi7whxDq6+tDCA3Z98fAwCAtLW3evHmy7wXfQsZLRmJcLrevr2/Mi/cNhsszPhwwTuDaLwBgZLIvWSiBwi7wh+FSNOSkWvr6+oOXTB4bCwsLdXV10cUY8A3jBQsWUBIfIdTf34/+fThgnMB5KgBgZCMuWSjL4ncKu8AfZmBgQBBER0fH4CbRETUyotFoHh4eJSUlAoEAL/ZQWFhIEISMt2lF4UMwNDSkKiAYDM5TAQAjG3HJwtEufqewC/wNxmKxLC0tnz17Jra9trbW0NDQz89PdKO/v7+hoeHdu3fHsKPw8PDGxsaIiIienp7S0tL4+PiAgABbW1vZI2P4EOzt7cccAYwIaioAQCoRERFxcXHR0dF6enqurq7m5ubC9V8RQrt27VqxYsWmTZtsbW1jYmLwBUYOh4NHyAQFBRkYGNjZ2Xl4eLS2tiKE+vr67O3tmUymi4uLjY3NjRs3hDcsRxtqAnh6elZXV4t1wR1yoGd/f39TU9NwEzWUlZU5OzvPnDnz9u3bFRUVRkZGTk5OJSUluHXevHlFRUVXr17V1dXdsGHDtm3bTp48SUlk7M6dO8bGxhReTAZDkNsMTpMKzE0IpjY0sfP94gl1J2x3QmOem7CmpoZGo0mzGO3AwICLi0taWtrYsxyfyC0tLQwG49ixY6IbYW5CysF5KgBADuS+jp5kvb29RUVFNTU1uF+PtbV1dHR0dHR0d3e3hFcNDAzk5eV1dXVRvkCT7JEjIyMXLVoUHByMECJJsqGh4datW7gbFKAQ1FQAABDX2tq6atUqGxubbdu24S1hYWE+Pj7+/v5DdlbCiouLc3JyCgsLh5txacxkjJyQkFBeXn7lyhU8iDY/P9/Y2NjFxaWgoIDaPAHUVADAhDpw4MDZs2c7OjosLCyys7Plnc4QTp06JbyUd/78eeH22NjY4ODgI0eODPdCNze3b775RjhZMYVkiZyfn//y5cvi4mJtbW28Zd26dcIDxBMpA6rAWBoAwISKi4uLi4uTdxZj5O7u7u7uLu8sRsfLy8vLy0veWUwXcJ4KAAAAUANqKgAAAEANqKkAAAAANaCmAgAAANSAPkqjkJmZKe8UABgvpaWl8k5h3OHJ+eA/8mg9e/ZMYVc4UDQEOdT0WkBMZmam2KyeAAAwfWzcuDErK0veWUwCUFMBmAQIgsjIyPD19ZV3IgAASeB+KgAAAEANqKkAAAAANaCmAgAAANSAmgoAAABQA2oqAAAAQA2oqQAAAAA1oKYCAAAA1ICaCgAAAFADaioAAABADaipAAAAADWgpgIAAADUgJoKAAAAUANqKgAAAEANqKkAAAAANaCmAgAAANSAmgoAAABQA2oqAAAAQA2oqQAAAAA1oKYCAAAA1ICaCgAAAFADaioAAABADaipAAAAADWgpgIAAADUgJoKAAAAUANqKgAAAEANqKkAAAAANaCmAgAAANSAmgoAAABQA2oqAAAAQA2oqQAAAAA1oKYCAAAA1ICaCgAAAFADaioAAABADYIkSXnnAAAQFxgYeP/+feHDu3fvWlhYaGtr44fKyspff/21iYmJnLIDAAyNJu8EAABDMDQ0/OKLL0S3VFZWCv9taWkJBRUABQTXfgFQRJs3bx6uSUVFJSAgYAJzAQBIC679AqCg5s+ff+/evSH/h96/f9/GxmbiUwIASAbnqQAoqL///e/KyspiGwmCWLhwIRRUABQT1FQAFNSmTZsGBgbENiorK7/zzjtyyQcAMCK49guA4nJ0dLx9+7ZAIBBuIQji6dOnxsbGcswKADAcOE8FQHH97W9/IwhC+FBJScnZ2RkKKgAKC2oqAIrLx8dH9CFBEH//+9/llQwAYERQUwFQXHp6em5ubsKeSgRBeHt7yzclAIAEUFMBUGhbt27FnR6UlZXfeustXV1deWcEABgW1FQAFNr69etVVFQQQiRJbt26Vd7pAAAkgZoKgEJjs9lvv/02QkhFRWXNmjXyTgcAIAnUVAAU3ZYtWxBC3t7ebDZb3rkAACSB8amKxcfHJzs7W95ZAAAmDfgNVyiwLo3CWbp06Z49e+SdBVAUpaWlSUlJa9as8ff3p9Gm8n9YPz+/3bt3czgceScyaeDvhryzAP9hKv8XnaRMTEx8fX3lnQVQIElJSZmZmQwGQ96JjC8/Pz8OhwNf/lGBmqpo4H4qAJPAlC+oAEwNUFMBAAAAakBNBQAAAKgBNRUAAACgBtRUAAAAgBpQUwGYgq5cuaKpqXnp0iV5JzJxrl27FhYWJhAIvL29zczMGAyGsbGxl5dXZWWl9EEEAkFiYqKjo+Pgplu3bjk5ObFYLCMjo9DQ0JcvX44qvSEjX7x48ejRo4NXngeTF9RUAKag6TYPQERERHJy8oEDBwQCwc2bNy9cuNDa2nrr1q3e3t5ly5Y1NDRIE6SmpmbZsmV79+7lcrliTdXV1e7u7m5ubs3Nzbm5uWfOnAkKCpI+veEir127lsFguLm5tbe3Sx8NKDKoqQBMQZ6enh0dHRMwP3Bvb++QZ3UT6ZNPPklPT8/MzFRXV0cIcTgcZ2dnFotlYWERGxvb0dHx1VdfjRikoqLio48+CgoKWrRo0eDWmJiYGTNmREVFsdlsDocTGhr61Vdf/fnnn9KkJzlySEjIwoULPTw8+Hy+NNGAgoOaCgAYu7S0tKamJjkmUFtbGx4eHhUVhYfw0mg00SvelpaWCKG6uroR4yxcuDAnJ2fLli2qqqpiTXw+v6CgwNXVlSAIvGX16tUkSebn50uToYTIWGRkZHl5OczeMDVATQVgqrl165aZmRlBECdOnEAIpaamstlsFouVn5+/evVqDQ0NExOTb7/9Fj85OTmZwWAYGBjs3LnTyMiIwWA4Ojrevn0btwYHB6uoqMyYMQM/fP/999lsNkEQLS0tCKHdu3fv27evrq6OIAhra2uE0HfffaehoREbGzthB5ucnEyS5Nq1a4ds7e3tRQhpaGjIsouHDx92d3ebmZkJt1hZWSGERnWnVgJtbW1XV9ekpKTpdsV+SoKaCsBU4+zs/NNPPwkf7tq1a8+ePb29verq6hkZGXV1dZaWljt27ODxeAih4ODggIAALpcbEhLy+PHju3fv8vn8lStXPn36FCGUnJwsOllgSkpKVFSU8CGeiNjKyookydraWoQQ7m4jEAgm7GALCgpsbW1ZLNaQrT///DNCyNnZWZZdPH/+HCGELyxjDAaDyWQ2NjbKElaUg4NDfX19RUUFVQGBvEBNBWC6cHR01NDQ0NfX9/f37+npefLkibCJRqPNnTtXVVXVzs4uNTW1q6vr7NmzY9iFp6dnZ2dneHg4dVlL0tPT8+jRI3zWKKaxsTE9PT0kJITD4Qx3Fisl3MVXWVlZdCOdTscnwZSYPXs2QqiqqoqqgEBeYA59AKYdFRUVhBA+Tx1s8eLFLBZLyg448tXU1ESS5JAnqRwOp6enx9fX9/Dhw3Q6XZa94Du1Yn2I+vv7mUymLGFF4UOg8MQXyAvUVACAOFVV1ebmZnlnMbK+vj6E0JB9fwwMDNLS0ubNmyf7XvDt5M7OTuEWLpfb19dnZGQke3AMl2d8OGBSg2u/AID/wOPx2tvbTUxM5J3IyHApGnLOBH19fS0tLUr2YmFhoa6u/tdffwm34JvHCxYsoCQ+Qqi/vx/9+3DApAbnqQCA/1BcXEyS5NKlS/FDGo023FViuTMwMCAIoqOjY3AThXNI0Wg0Dw+PkpISgUCgpKSEECosLCQIQsbbtKLwIRgaGlIVEMgLnKcCAJBAIGhra+Pz+ZWVlbt37zYzMwsICMBN1tbWra2teXl5PB6vublZ9HQNIaSjo9PQ0PD48eOuri4ej1dYWDiRY2lYLJalpeWzZ8/EttfW1hoaGvr5+Ylu9Pf3NzQ0vHv37hh2FB4e3tjYGBER0dPTU1paGh8fHxAQYGtrK3tkDIdUQrIAACAASURBVB+Cvb39mCMABQE1FYCp5sSJE0uWLEEIhYaGenl5paamJiYmIoQWLFjw8OHD06dP79u3DyG0atWqmpoa/JK+vj57e3smk+ni4mJjY3Pjxg3hTcpdu3atWLFi06ZNtra2MTEx+Pokh8PBg22CgoIMDAzs7Ow8PDxaW1sn/mA9PT2rq6vFuuAOOdCzv7+/qalpuIkaysrKnJ2dZ86cefv27YqKCiMjIycnp5KSEtw6b968oqKiq1ev6urqbtiwYdu2bSdPnqQkMnbnzh1jY2MKLyYDuSGBItm4cePGjRvlnQVQIBkZGeP9/zQwMFBHR2dcdyENhFBGRsZoX1VTU0Oj0c6dOzfiMwcGBlxcXNLS0saU3ThGbmlpYTAYx44dG+0LJ+C7AUYLzlMBAEN385kUrK2to6Ojo6Oju7u7JTxtYGAgLy+vq6vL39+f2gRkjxwZGblo0aLg4GBqEwNyATUVjIKElbCEtm/frq6uThBEeXk5tZGHc//+/X/+85/z5s1TV1en0Wiampo2Njaenp6lpaVjiDYGQyafk5NjaWlJiFBRUTEwMFi+fHl8fHxbW9vE5DYdhIWF+fj4+Pv7D9lZCSsuLs7JySksLBxuxqUxkzFyQkJCeXn5lStXZBxECxSFvE+UwX9Q5Gu/Dx48cHJyQggtXLhQ8jPxXLK//fYb5ZEH+/LLL+l0+rJly7777ru2tra+vr66urr09HRHR8fPP/98tNHGQHLyVlZWmpqaJEniTkA3btwICAggCMLIyOjOnTvSxB/v63thYWF4Cghzc/OsrKzx29GI0Jiu/QoVFRWFhoZSmM8EyMvLi4uL4/P5Y3s5XPtVQDCWBkiloqIiOjo6KCiop6eHpHSmb1kil5WVBQYGurq6FhUV0Wj//8tsaWlpaWmppaUl7IAzfqRPniAILS2t5cuXL1++3NPT08/Pz9PT88GDB5qamuOdpGRxcXFxcXHyzYES7u7u7u7u8s5idLy8vLy8vOSdBaASXPsFUhlxvSpRwiWxKI8s5vDhwwMDA0eOHBEWVKG33nrrgw8+GG3A0Rpb8hs3bgwICGhqajp16tT45QYAmHhQUyerc+fOLV68mMFgsNlsc3PzmJgYhBBJkgkJCXgydG1t7XXr1glnbZW84NfcuXMJglBSUnr11Ve5XC5CaP/+/ZqamgwGQ5r1nEmSjI+Pt7W1VVVV1dTU/PDDD6k6TAlrh/X393///fe6urqvvfbaiOnJ5W2RAI/+LCwslCUIAEDhyPPCMxhEyvupeLjhkSNHXrx40dra+vnnn2/ZsoUkyUOHDqmoqJw7d669vb2ysvKVV17R09N7/vw5ftXBgwcRQt9//31HR0dTU5OLiwubze7v7ydJks/nm5ubm5mZid7a2bNnT2JiotiuX3/99cE3Dg8ePEgQxGeffdbW1sblclNSUtBo7qdKiHz58mV1dfXo6OjBz3/w4AFCaOnSpSNGltfbQorcTxWDJ481NTUdMfnpc88MyXY/dRqaPt+NSQQ+D8UiTU3t7+/X0tJasWKFcAufz09KSuJyuWpqav7+/sLtePFIYUHCxaO3txc/xJWvtrYWP8R1OjMzEz/s6ekxMzPr6OgQ2/vg4sHlclks1sqVK4VbRttHabjIkv3yyy8IoTfffFPy0+T1tmDD1VSSJPEd1hEOcjr9bkJNHa3p892YRKCP0uRTWVnZ3t7+1ltvCbcoKyuHhIT88ssv3d3dixcvFm5fsmSJiorK7du3h4wjtuDX9u3bIyMjk5KSfHx8EELnz59ft26dhobGiPnU1tZyuVw3NzdZDmoM1NTUEEL4kqwE1dXVcnlbJMN9mqSPk5mZKeMeJ4UJG/40NcDbpYCgpk4++LLh4DU32tvb0b8rjZCWllZXV5c0YdXU1N577734+Piff/75tddeO3nyZHZ2tjQvxFOV6uvrS/NkCpmbmzMYDHwFWAJ5vS2S4bTnzJkj5fPFpq6dqpKSkpKSkuSdBQBjB32UJp+ZM2cihFpaWsS24yorVipGtWhXcHAwnU5PTEwsKSkxNTW1srKS5lV4xeaXL19KuReqqKqqvvXWWy0tLT/++OPg1tbW1u3btyP5vS2Sfffddwih1atXS/l8eV/QmggIrv2OEr72CxQK1NTJx9zcXEdH5+rVq2Lb58+fr6amhu8yYrdv3+7v73/11VeljGxiYuLr65udnR0eHr57924pXzV//nwlJaUffvhByudTKDIyUlVVde/evWJTqCOEfv/9dzzARl5viwTPnz9PTEw0MTHZtm2b7NEAAIoDaurko6qqeuDAgZKSkuDg4Pr6eoFA0NXVde/ePQaDsW/fvtzc3PPnz3d2dlZVVQUFBRkZGQUGBkoffN++fXw+v62t7Y033pDyJfr6+hs2bMjOzk5LS+vs7KysrPziiy/GdGRDkLx22KJFi7755pvff//dxcXlypUrHR0dPB7v0aNHp0+f/sc//oEne5PX2yJEkmR3d7dAICBJsrm5OSMjw8nJSVlZOS8vT/b7sgAAxSLvqxfgP0g/N+GJEyfs7e0ZDAaDwXBwcEhJSSFJUiAQxMfHz549m06na2tre3t7379/Hz8/JSUFz0c6e/bsurq6L774Av+gz5o168GDB6KRV6xY8eWXX4rtrrS01MnJycjICH9tZsyY4ejo+MMPP+DWrq6u7du36+rqqqmpOTs7Hzp0CCFkYmJSUVEx4oFIjnzlyhV1dfXDhw9LiPDkyZN//etf9vb2ampqysrKWlpaDg4O//jHP3788Uf8BLm8LRcvXlywYAGLxVJRUcELWeOOvq+99lp0dPSLFy9GfGew6dO3E8G131GaPt+NSYQgKZ1nDsgIdy7NysqSdyJAUWRmZvr5+U2H/6cEQWRkZPj6+so7kUlj+nw3JhG49gsAAABQA2oqGEd//vknMTzKV7IEAAD5gpoKxtGcOXMk3HhIT0+Xd4Jgsrp27VpYWJhAIPD29jYzM2MwGMbGxl5eXpWVldIHkbBq761bt5ycnFgslpGRUWhoqPRDxY4ePTpnzhwmk8lms+fMmRMeHo4HlGPR0dF2dnYaGhqqqqrW1tb79+8XLqV+8eLFo0ePTt7F4QEGNRUAMMlEREQkJycfOHBAIBDcvHnzwoULra2tt27d6u3tXbZsWUNDgzRBampqli1btnfv3sFTcVVXV7u7u7u5uTU3N+fm5p45cyYoKEjK3G7evLljx44nT540NjbGxMQcPXp048aNwtbr169/8MEHjx8/bmlpiYuLE87PhRBau3Ytg8Fwc3PDs5SAyWpiukIBKSnymuRALiagbyeXy+VwOHIPhaTr93vkyBEbGxs8PzOPx3v77beFTXgm59jY2BGDlJeXr1+//vz584sWLRo8UbOfn5+FhQUe/kSSZHx8PEEQf/zxhzRH4e3tLZw7miRJXDIbGhrwQ09PT9H1GHCHrCdPngi3BAcHczgcHo8nzb6g368CgvNUAKa7tLS0pqYmRQs1pNra2vDw8KioKDx7F41Gu3TpkrDV0tISIVRXVzdiHAkL3/L5/IKCAldXV+EywKtXryZJMj8/X5oMc3NzcW6YsbExQkh4gffy5cvKysrCVj09PfSfc1ZHRkaWl5fDBI2TF9RUAKYCcvg1YoODg1VUVGbMmIEfvv/++2w2myAIPL3l7t279+3bV1dXRxCEtbV1cnIyg8EwMDDYuXOnkZERg8FwdHQUrjcwqlBI4vK3Y5OcnEyS5Nq1a4dsxdNpyTiTxsOHD7u7u83MzIRb8GyUo7pTK1RTU6OlpTVr1qwhW+vr65lMpoWFhXCLtra2q6trUlISCSNkJieoqQBMBZGRkWFhYQcPHmxqaiopKXn69KmLi0tjYyNCKDk5WXTQZ0pKSlRUlPBhUlLSmjVrrKysSJKsra0NDg4OCAjgcrkhISGPHz++e/cun89fuXLl06dPRxsKIYR73AgEAqoOs6CgwNbWFk/TMRi+9uvs7CzLLp4/f44QUldXF25hMBhMJhO/mVLi8Xj19fUnTpy4du3a8ePH8WJHYrhc7vXr13fs2CHW6uDgUF9fX1FRMdYjAPIENRWASa+3tzchIWH9+vVbt27V1NS0t7c/depUS0vLmCeJpNFo+JTXzs4uNTW1q6vr7NmzY4jj6enZ2dkZHh4+tjTE9PT0PHr0aMg1DBobG9PT00NCQjgcznBnsVLCXXxFr9AihOh0+uA5pSUwNTU1MTGJjIz89NNPh1tTKC4uzsjI6PDhw2LbZ8+ejRCqqqoaXd5AMUBNBWDSG+0asaOyePFiFoslvJIsR01NTSRJDnmSyuFwQkJC1q1bV1hYiOd5HjN8N5TP54tu7O/vZzKZ0gd5+vRpU1PThQsXvv76awcHh8H3mHNzczMzM4uKikRPiDF8gKM6LQaKA9ZPBWDSk3GN2BGpqqo2NzdTEkoWfX19OJnBTQYGBmlpafPmzZN9L/huseigUi6X29fXJ5zVWRp0Ol1fX9/d3d3CwsLGxgYPmxG2pqenJyQkFBcX43UbxeDijQ8WTDpQUwGY9GRfI1YCHo9HVSgZ4WIz5KwI+vr6+E2QnYWFhbq6+l9//SXcgu8NL1iwYAzRrK2tlZWVq6urhVuOHz9eVFR0/fp1sb+BhPr7+9G/DxZMOnDtF4BJb8Q1Ymk0Go/HG1vw4uJikiSXLl0qeygZGRgYEATR0dExuOnSpUt41IrsaDSah4dHSUmJsGtVYWEhQRDS3KZ98eLF5s2bRbfU1NQMDAyYmpoihEiSDA0NraqqysvLG66gIoTwARoaGsp0GEBOoKYCMOmNuEastbV1a2trXl4ej8drbm4WPQlDCOno6DQ0NDx+/LirqwvXS4FA0NbWxufzKysrd+/ebWZmFhAQMIZQkpe/HS0Wi2Vpafns2TOx7bW1tYaGhmJdgfz9/Q0NDe/evTuGHYWHhzc2NkZERPT09JSWlsbHxwcEBNja2o4Ymc1mX7169fr1652dnTwe77fffnvnnXfYbPbevXsRQvfu3fv0009Pnz5Np9NFJ74+duyYaBB8gPb29mPIHMgd1FQApoKIiIi4uLjo6Gg9PT1XV1dzc/Pi4mI2m41bd+3atWLFik2bNtna2sbExODrihwOB4+QCQoKMjAwsLOz8/DwaG1tRQj19fXZ29szmUwXFxcbG5sbN24I72KONhS1PD09q6urxbrgDjmUs7+/v6mpabiJGsrKypydnWfOnHn79u2KigojIyMnJ6eSkhLcOm/evKKioqtXr+rq6m7YsGHbtm0nT56UJjKDwXByctq+fbuxsbG6urqPj4+5uXlZWdn8+fOHy3OwO3fuGBsbj+1SM5A/Oc3fBIYGcxMCMRM//1xgYKCOjs5E7hFDUsxNWFNTQ6PRzp07N2K0gYEBFxeXtLQ0irKbiMgkSba0tDAYjGPHjknzZJibUAHBeSoAQJzCro5ibW0dHR0dHR0tnO1vSAMDA3l5eV1dXZSvJzh+kbHIyMhFixYFBwePR3AwAaCmAgAmk7CwMB8fH39//yE7K2HFxcU5OTmFhYXDzbg0ZuMXGSGUkJBQXl5+5coVGYfYAjmCmgoA+D8HDhw4e/ZsR0eHhYVFdna2vNMZWmxsbHBw8JEjR4Z7gpub2zfffCOcl5hC4xc5Pz//5cuXxcXF2tralAcHEwbGpwIA/k9cXFxcXJy8sxiZu7u7u7u7vLOgkpeXl5eXl7yzALKC81QAAACAGlBTAQAAAGpATQUAAACoATUVAAAAoAb0UVI4ZWVlPj4+8s4CKAo8U900+UokJiZmZWXJO4tJY/A0jUDuCFK66bLAxEhISCgtLZV3FkDhFBYWOjg4jMcQDjDZwV8hCgVqKgCTAEEQGRkZvr6+8k4EACAJ3E8FAAAAqAE1FQAAAKAG1FQAAACAGlBTAQAAAGpATQUAAACoATUVAAAAoAbUVAAAAIAaUFMBAAAAakBNBQAAAKgBNRUAAACgBtRUAAAAgBpQUwEAAABqQE0FAAAAqAE1FQAAAKAG1FQAAACAGlBTAQAAAGpATQUAAACoATUVAAAAoAbUVAAAAIAaUFMBAAAAakBNBQAAAKgBNRUAAACgBtRUAAAAgBpQUwEAAABqQE0FAAAAqAE1FQAAAKAG1FQAAACAGlBTAQAAAGpATQUAAACoATUVAAAAoAbUVAAAAIAaUFMBAAAAatDknQAAYAjt7e0kSYpu6enpaWtrEz5UU1Oj0+kTnhcAQBJC7P8tAEARvPHGGzdu3BiuVVlZub6+3tDQcCJTAgCMCK79AqCINm3aRBDEkE1KSkrLli2DggqAAoKaCoAi2rhxI4029K0ZgiD+/ve/T3A+AABpQE0FQBFpa2u7u7srKysPblJSUvL29p74lAAAI4KaCoCC2rp1q0AgENtIo9E8PT01NTXlkhIAQDKoqQAoqLVr16qqqoptHBgY2Lp1q1zyAQCMCGoqAAqKxWJ5e3uLDZhhMpkeHh7ySgkAIBnUVAAU1+bNm3k8nvAhnU7fuHEjk8mUY0oAAAmgpgKguN566y3RW6c8Hm/z5s1yzAcAIBnUVAAUF51O9/f3V1FRwQ+1tLTc3NzkmxIAQAKoqQAotE2bNvX39yOE6HT61q1bhxu0CgBQBDA3IQAKTSAQzJw5s7GxESF069YtJycneWcEABgWnKcCoNCUlJT+9re/IYSMjIwcHR3lnQ4AQJIpfh3p2bNnP/30k7yzAEAmenp6CKHXX389KytL3rkAIBNTU1MOhyPvLMYTOaVlZGTI+w0GAADw/23cuFHeZWF8TfHzVIyEe8ZgksvOzt64caO8s5CKj48PQmjKn1JnZmb6+fnBb8uo4O/G1Ab3UwGYBCZLQQVgmoOaCgAAAFADaioAAABADaipAAAAADWgpgIAAADUgJoKAAAAUANqKgBA/q5cuaKpqXnp0iV5JzJerl27FhYWJhAIvL29zczMGAyGsbGxl5dXZWWl9EEEAkFiYuKQ02nheStZLJaRkVFoaOjLly+ljHn06NE5c+YwmUw2mz1nzpzw8PDOzk5ha3R0tJ2dnYaGhqqqqrW19f79+7u7u3HTxYsXjx49OjAwIH3+0wHUVACA/E3tgZ4RERHJyckHDhwQCAQ3b968cOFCa2vrrVu3ent7ly1b1tDQIE2QmpqaZcuW7d27l8vlijVVV1e7u7u7ubk1Nzfn5uaeOXMmKChIytxu3ry5Y8eOJ0+eNDY2xsTEHD16VHTg1vXr1z/44IPHjx+3tLTExcUlJSUJx5iuXbuWwWC4ubm1t7dLua9pQc5zTowzPI+SvLMAYBrZuHGjIs+Vw+VyORyO7HGk/205cuSIjY1Nb28vSZI8Hu/tt98WNv38888IodjY2BGDlJeXr1+//vz584sWLVq4cKFYq5+fn4WFhUAgwA/j4+MJgvjjjz+kSc/b2xvnhuGS2dDQgB96enry+Xxhq6+vL0LoyZMnwi3BwcEcDofH40mzLwX/blACzlMBANNIWlpaU1PThO2utrY2PDw8KiqKwWAghGg0muj1bUtLS4RQXV3diHEWLlyYk5OzZcsWVVVVsSY+n19QUODq6koQBN6yevVqkiTz8/OlyTA3NxfnhhkbGyOEhBd4L1++rKysLGzFU0+LnihHRkaWl5cnJSVJs6/pAGoqAEDObt26ZWZmRhDEiRMnEEKpqalsNpvFYuXn569evVpDQ8PExOTbb7/FT05OTmYwGAYGBjt37jQyMmIwGI6Ojrdv38atwcHBKioqM2bMwA/ff/99NptNEERLSwtCaPfu3fv27aurqyMIwtraGiH03XffaWhoxMbGjtOhJScnkyS5du3aIVt7e3sRQhoaGrLs4uHDh93d3WZmZsItVlZWCKFR3akVqqmp0dLSmjVr1pCt9fX1TCbTwsJCuEVbW9vV1TUpKYmc0lfvpQc1FQAgZ87OzqLrR+3atWvPnj29vb3q6uoZGRl1dXWWlpY7duzg8XgIoeDg4ICAAC6XGxIS8vjx47t37/L5/JUrVz59+hQhlJycjK9PYikpKVFRUcKHSUlJa9assbKyIkmytrYWIYS72AgEgnE6tIKCAltbWxaLNWQrvvbr7Owsyy6eP3+OEFJXVxduYTAYTCYTr7krJR6PV19ff+LEiWvXrh0/flxFRWXwc7hc7vXr13fs2CHW6uDgUF9fX1FRMdYjmFKgpgIAFJSjo6OGhoa+vr6/v39PT8+TJ0+ETTQabe7cuaqqqnZ2dqmpqV1dXWfPnh3DLjw9PTs7O8PDw6nL+v/09PQ8evQInzWKaWxsTE9PDwkJ4XA4w53FSgl38RW9QosQotPp+CRYSqampiYmJpGRkZ9++qmfn9+Qz4mLizMyMjp8+LDY9tmzZyOEqqqqRpf3FAU1FQCg6PCJET5PHWzx4sUsFuvPP/+c2KRG1tTURJLkkCepHA4nJCRk3bp1hYWFdDpdlr3gu6F8Pl90Y39/P5PJlD7I06dPm5qaLly48PXXXzs4OAy+5Zybm5uZmVlUVCR6QozhAxzVafEUNi3WegMATG2qqqrNzc3yzkJcX18fQmhwryKEkIGBQVpa2rx582TfC755LDqolMvl9vX1GRkZSR+ETqfr6+u7u7tbWFjY2NjgYTPC1vT09ISEhOLi4pkzZw5+LS7e+GAB1FQAwOTG4/Ha29tNTEzknYg4XGyGnBVBX19fS0uLkr1YWFioq6v/9ddfwi34VvGCBQvGEM3a2lpZWbm6ulq45fjx40VFRdevX1dTUxvyJf39/ejfBwvg2i8AYHIrLi4mSXLp0qX4IY1GG+4q8QQzMDAgCKKjo2Nw06VLl/CoFdnRaDQPD4+SkhJhT6vCwkKCIKS5TfvixYvNmzeLbqmpqRkYGDA1NUUIkSQZGhpaVVWVl5c3XEFFCOEDNDQ0lOkwpgqoqQCAyUcgELS1tfH5/MrKyt27d5uZmQUEBOAma2vr1tbWvLw8Ho/X3NwsegKHENLR0WloaHj8+HFXVxePxyssLBy/sTQsFsvS0vLZs2di22traw0NDcW6Avn7+xsaGt69e3cMOwoPD29sbIyIiOjp6SktLY2Pjw8ICLC1tR0xMpvNvnr16vXr1zs7O3k83m+//fbOO++w2ey9e/cihO7du/fpp5+ePn2aTqcTIo4dOyYaBB+gvb39GDKfeqCmAgDk7MSJE0uWLEEIhYaGenl5paamJiYmIoQWLFjw8OHD06dP79u3DyG0atWqmpoa/JK+vj57e3smk+ni4mJjY3Pjxg3hbctdu3atWLFi06ZNtra2MTEx+Jokh8PBg22CgoIMDAzs7Ow8PDxaW1vH+9A8PT2rq6vFuuAOOZSzv7+/qalpuIkaysrKnJ2dZ86cefv27YqKCiMjIycnp5KSEtw6b968oqKiq1ev6urqbtiwYdu2bSdPnpQmMoPBcHJy2r59u7Gxsbq6uo+Pj7m5eVlZ2fz584fLc7A7d+4YGxuP7VLzFCS3GZwmBMxNCMAEm4D55wIDA3V0dMZ1FyOS8relpqaGRqOdO3duxGcODAy4uLikpaVRkd0ERSZJsqWlhcFgHDt2TJonw9yEAACgiCbLcijW1tbR0dHR0dHC2f6GNDAwkJeX19XV5e/vT20C4xcZi4yMXLRoUXBw8HgEn4ygpk5lx44dw70kTp06hbdQvqKWhMWnhLZv366urk4QRHl5ObWRxeTk5FhaWuJbPsON4k9ISCAIQklJac6cOcJLZ6MluiOCIOh0urGx8ZYtW/7444+xBRQlr09N7KAIglBRUTEwMFi+fHl8fHxbWxtVe59uwsLCfHx8/P39h+yshBUXF+fk5BQWFg4349KYjV9khFBCQkJ5efmVK1dkHGI7pcj7RHl8wbVffP/p5MmT+OHly5c1NDQuXrxISfAHDx44OTkhhAYvlCEGT9b622+/UR55MDxtzYwZM/r7+8Wa+Hw+nsjUzc1ttGGH3JGmpiZJkt3d3RcvXjQzM1NTU/vzzz9ljyzHT014ULgT0I0bNwICAgiCMDIyunPnjjTxx/v6XlhYGJ4CwtzcPCsra/x2JNlof1uKiopCQ0PHL5+Jl5eXFxcXJ7pqzYimw7VfGJ86vXh6ekr4Y3lUKioqoqOjg4KCenp6SEqnz5Y98quvvvrrr7/m5eUJ13rEcnJyjI2NxTqCyo7NZq9Zs2ZgYMDb2/v48eN4IngKyeVTIwhCS0tr+fLly5cv9/T09PPz8/T0fPDggaamJiWZjFlcXFxcXJx8cxgDd3d3d3d3eWdBJS8vLy8vL3lnoXDg2i+QFkmSWVlZX3zxBX4oYfGpwYSrUEljVJGHtGvXLoSQaNdHLCEhAfcgHQ+vvfYaQuj3338fp/hjI8unJrRx48aAgICmpibh5WgAwJCgpqKkpCQ2m62kpPTqq68aGhrS6XQ2m/3KK6+4uLiYmpoyGAwtLa39+/cLn3/z5k07OztNTU0Gg2Fvb19UVIQQ+uqrr9TU1AiC0NbWzsvL++WXX2bNmqWsrCw2nnpIkteuQgiRJJmQkIBnDNfW1l63bp3o1KaSW0WNakUthNDAwEBcXJytrS2TydTT07OwsIiLixNd9EMCkiTj4+NtbW1VVVU1NTU//PBDaV4lDWkW53rjjTfmzp1748aN+/fvCzf++OOPXC538LkCVR8onnBVWKsm46cmAR79WVhYKGMcAKY4eV10nhhS3vOIiIhACN2+fbunp6elpWXVqlUIoYKCgubm5p6eHtylrby8HD85KysrMjKytbX1xYsXS5cu1dXVxdvv3bvHYrHeeecd/DAsLOzLL7+UMs/AwEA2m33v3r2+vr7q6uolS5aoq6s/efIEtx46dEhFReXcuXPt7e2VlZWvvPKKnp7e8+fPpWkVuzOHh+gdP34cPzx48CBC6Pvvv+/o6GhqanJxcWGz2cLbkLGxscrKyvn5+Vwu99dffzU0NFy+fPng5F9//fXBd+YOHjxIEMRnuMNw1gAAIABJREFUn33W1tbG5XJTUlLQaO6nSoh8+fJldXX16Ojo4V5lZWX16NGj//qv/0II7d69W7jd29v77NmzXV1d6D/vp475AxXeesTOnTuHEPrwww/xw8n4qQ0+KCE8naypqengJjHT4Z4ZCX01xmQ6fDem+HdiVDW1q6sLP/z6668RQlVVVfghXuMwPT198AvxfR28+gRJkp9//jlC6Pz58xcuXNi7d6/0eQYGBor+kN25cwchFBUVRZIkl8tVU1Pz9/cXtuJ8cFGR3EpK9+vc29uLH+LKV1tbix8uWbLktddeE0Z+7733lJSUXr58KZb84F9nLpfLYrFWrlwp3DLaPkrDRZYGrqnt7e1sNltbW5vL5ZIkWVdXZ2Ji8vLly8E1VdSoPlDRPkrZ2dmGhoYGBgbPnj0jJ+enJnZQg+E7rEM2iZoOv5sk1NQxmQ7fDeijNATcq1C4dhLuJj7kDKK4SThU7r333vuf//mfnTt3vvnmm9nZ2WNOQHTtqurq6u7u7sWLFwtblyxZoqKigi8OS24dLbEVtfr6+vAyUtjAwACdThdbpnFItbW1XC7Xzc1tDDlQRVNTc/PmzadPn05PT3/33XcTExN37dqloqKC5/sezmg/0I6ODoIglJWVZ8yY4eHhERERgSdxnYyfmmS4T5OGhoY0Ty4rKxPrHTb14An5pvxhUqusrEw4LfNUBfdTR62goGD58uX6+vqqqqqi91mx2NjY7u7uwasPjpZw7ar29naEkNgE1lpaWvh8S3KrjDw8PH799df8/Pze3t5ffvklLy/v7bfflubXGf/c6Ovry56DLHBPpVOnTrW3t2dlZe3cuXPIp8nygeJTOj6f/+zZszNnzuCBOmhyfmqSPXjwACE0Z84c2TMEYAqD89TRefLkibe39/r168+cOTNz5szjx4+L/grzeLyQkBDcufTw4cP4kvIYiK5dhReEEvu1lbJVRpGRkb/++mtAQEB3d7eRkZGvr6+UU43j86SXL1/KnoMsFi1atHTp0rKyssDAQB8fH21t7cHPGacPdDJ+apJ99913CKHVq1dL8+SlS5dmZWXJvlNFlpmZ6efnN+UPk1rT4bQeauroVFVV8Xi8Xbt2WVpaokFDRP75z3/u2LFj/fr19fX1MTEx7u7uHA5nDHsRXbtq/vz5ampqv/zyi7D19u3b/f39r7766oitMqqurq6rq2tubqbRRvc9mT9/vpKS0g8//BAUFCR7GrLYtWtXWVlZdna2cO51MeP0gU7GT02C58+fJyYmmpiYbNu2jaqYAExJcO13dMzMzBBC165d6+vrq6mpEb0BlpKSYmxsvH79eoRQXFycnZ3dli1bcG9JaQy3dhWDwdi3b19ubu758+c7OzurqqqCgoKMjIwCAwNHbJXRBx98YGZmJnme0iHp6+tv2LAhOzs7LS2ts7OzsrJSOD5SdqNanMvX11dPT8/b2xuXzMHG6QOdjJ+aEEmS3d3dAoGAJMnm5uaMjAwnJydlZeW8vDwp76cCMH3JtYfUuJOmb15SUhKeCdPc3PzmzZuffPIJninG0NDwm2++SU9Px2vtamtrf/vttyRJhoaG6ujoaGlp+fj44CGDVlZWixYtIghCR0fnp59+Iklyz549SkpKCCFNTc1ffvllxDwDAwPxnLE0Gk1DQ2PdunV1dXXCVoFAEB8fP3v2bDqdrq2t7e3tff/+fWlaP/vsM5w8m81ev3798ePHZ8yYgRBisVhr165NSUnBBz579uy6urovvvgC/2LOmjXrwYMHJElev35dV1dX+FWh0+lz587NycnBwUtLS52cnIyMjHDrjBkzHB0df/jhB9za1dW1fft2XV1dNTU1Z2fnQ4cOIYRMTEwqKipGfDckR75y5Yq6uvrhw4cHvzA3NxdPTKinp/fBBx/gjfv378cfCkmSH3/8MX4HlJSU7Ozsbt68ObYP9Mcff7SxscHpGRkZ+fj4DE5m0n1qFy9eXLBgAYvFUlFRwQeLO/q+9tpr0dHRL168GPGDw6ZD304S+v2OyXT4bhAkpbPKKRp8z0Pxj3Hnzp1ZWVkvXryQdyL/ITU1taamBq9kiRDq7+//6KOPUlNT29ra8JqUQAHJ/VPD98ym/I3GyfLbolCmw3cD7qcqCkVbu+r58+fBwcGiK8moqKiYmZnxeDwejwc1VTHBpwaAfMH91HH3559/EsMbp0UNZcdkMul0elpaWmNjI4/Ha2ho+PLLLw8dOuTv7y/LTbVJ+m5MFuP0qQHKXbt2LSwsTCAQeHt7m5mZMRgMY2NjLy+vyspKaV5++PBhsf878+fPl3LXR48enTNnDpPJZLPZc+bMCQ8PF+0lEB0dbWdnp6Ghoaqqam1tvX//fuG9+YsXLx49elTR/vpXOHK+9jzOJsU9DwVZu2qwkpKSN998U0NDQ1lZWVNT09HRMSUlhcfjyTsvIIncP7XpcM+MlO235dChQ2vWrOns7OTxeLq6ujdv3uzp6Xn48OHKlSs1NTXr6+tHjBATEyP2Sz5v3jwp9+7p6Xns2LGmpqaurq7MzEw6nS465Zmrq2tKSsqLFy86OzszMjLodPqqVauErUlJSa6urm1tbaM9ZGw6fDcUvd7IaFLUVACmkgn43eRyuRwOR76hxvzbcuTIERsbGzy1JI/He/vtt4VNeIrK2NjYEYPExMScO3duDHsnSdLb21s4sSVJkvgeZ0NDA37o6ekpuiQqXn1BOPc4SZLBwcEcDmdsf6VNh5oK134BAJNMWlqa7FOVUR5KGrW1teHh4VFRUXheFBqNdunSJWErHvFVV1c3rjnk5uaKzl6JZ9MUXuC9fPmy6Kxbenp6CCEulyvcEhkZWV5enpSUNK5JTl5QUwEAckAOv9pdcHCwiooKHkGEEHr//ffZbDZBEC0tLQih3bt379u3r66ujiAIa2tryUsljioUkm4lQVkkJyeTJLl27dohW3t7exFCE3znu6amRktLSzitppj6+nomk2lhYSHcoq2t7erqmpSUREKf56FATQUAyEFkZGRYWNjBgwebmppKSkqePn3q4uLS2NiIEEpOThZd8DUlJSUqKkr4MCkpac2aNVZWViRJ1tbWBgcHBwQEcLnckJCQx48f3717l8/nr1y5Ei/mM6pQ6N/d7wUCwTgddUFBga2tLR5hPBi+9uvs7CxNqLCwMG1tbRUVFQsLi3Xr1uHFrKTH4/Hq6+tPnDhx7dq148eP4y4dYrhc7vXr13fs2CHW6uDgUF9fX1FRMao9ThNQUwEAE623tzchIWH9+vVbt27V1NS0t7c/depUS0vLmOfbotFo+JTXzs4uNTW1q6vr7NmzY4jj6enZ2dkZHh4+tjQk6+npefToEZ6WRExjY2N6enpISAiHwxnuLFbUO++8c/HixadPn3Z3d3/77bdPnjxxdXWtrq6WPhlTU1MTE5PIyMhPP/3Uz89vyOfExcUZGRkdPnxYbPvs2bMRQlVVVdLvbvqAmgoAmGjUrnYnRnSpRIWC1+Ud8iSVw+GEhISsW7eusLAQLzgomampqYODg5qamoqKytKlS8+ePdvb24tX0pXS06dPm5qaLly48PXXXzs4OAy+qZybm5uZmVlUVKSuri7WhA8BX1QAYmDOBwDARBvX1e6QyFKJCqWvrw8hpKqqOrjJwMAgLS1t3rx5Y4tsb2+vrKyM1+OTEp1O19fXd3d3t7CwsLGxiYuLE+12lJ6enpCQUFxcPHPmzMGvxZOH4MMBYqCmAgAm2riudie6VKJCwaVoyDkT9PX18XsyNgKBQCAQDFmtR2Rtba2srCx63fj48eNFRUXXr18X+6NHqL+/H/37cIAYuPYLAJhoI652R6PReDze2IKLLpUoYyhqGRgYEATR0dExuOnSpUt4TIuU3nrrLdGHd+7cIUlSmoUIX7x4sXnzZtEtNTU1AwMDpqamCCGSJENDQ6uqqvLy8oYrqAghfAh4pQcgBmoqAGCijbjanbW1dWtra15eHo/Ha25u/uuvv0RfrqOj09DQ8Pjx466uLlwvh1sqcbShRrWS4GixWCxLS8tnz56Jba+trTU0NBTrKOTv729oaHj37t0hQ9XX16enp7e3t/N4vNLS0u3bt5uZmQmXK5bwWjabffXq1evXr+NZnH777bd33nmHzWbv3bsXIXTv3r1PP/309OnTdDpddOLDY8eOiQbBh2Bvbz/Wd2Iqg5oKAJCDiIiIuLi46OhoPT09V1dXc3Pz4uJiNpuNW3ft2rVixYpNmzbZ2trGxMTgy4wcDgePkAkKCjIwMLCzs/Pw8GhtbUUI9fX12dvbM5lMFxcXGxubGzduCC+EjjbUuPL09KyursbjUIWGHOjZ39/f1NSUn58/ZJxVq1Z9/PHHJiYmLBbL19fXycmprKxMuMafhNcyGAwnJ6ft27cbGxurq6v7+PiYm5uXlZXh6YKlHHJ6584dY2PjBQsWSPPkaUdO8zdNEJibEPw/9u48rqkr7x/4uRIghB1lE0RZFAVR3KaGRcbySKu2ICqCS1vG13QQ9RdcZopgGQEFtVrkoS6ddtC2bqDigBapjlMZoAraImCpOiCiIpVFZJEASUh+f9ynefKEsIULCfB5/+W9555zv5cEv9ztfGGIDf38cyEhISYmJkO5R4my/7eUlZWxWKy+TCvY2dnp6emZnJysRGwD6dur+vp6Npt98OBBJfpibkIAgGFguBRLcXBwiI2NjY2Nlc4FqFBnZ2d6enpLS4sSlZoG0rcvoqOjXV1deTzeYAw+AiCnAgAMnYiIiICAgKCgIIUPK9Gys7PT0tKysrK6m3GpBwPp26uEhISioqIrV6705SXa0Qk5FQCGscjIyBMnTjQ1Ndna2l64cEHV4fRJXFwcj8fbu3dvdxt4e3ufPn1aOk1xvwykb88yMjI6Ojqys7ONjY0ZH3zEwPupADCMxcfHx8fHqzqKfvPx8fHx8VF1FP3j5+fn5+en6ijUHc5TAQAAmIGcCgAAwAzkVAAAAGYgpwIAADADORUAAIAZo+K5X4qiVB0CwOgySn7pRslhMmjlypWqDmFwUZK+TfA4TFVVVd28eVPVUQAMVGBg4JYtW/pSeARAnU2YMGFkf41HeE4FGBkoikpNTV21apWqAwGAnuB+KgAAADOQUwEAAJiBnAoAAMAM5FQAAABmIKcCAAAwAzkVAACAGcipAAAAzEBOBQAAYAZyKgAAADOQUwEAAJiBnAoAAMAM5FQAAABmIKcCAAAwAzkVAACAGcipAAAAzEBOBQAAYAZyKgAAADOQUwEAAJiBnAoAAMAM5FQAAABmIKcCAAAwAzkVAACAGcipAAAAzEBOBQAAYAZyKgAAADOQUwEAAJiBnAoAAMAM5FQAAABmIKcCAAAwAzkVAACAGcipAAAAzEBOBQAAYAZL1QEAgAJnz55taWmRXXP9+vXGxkbpor+/v6mp6ZDHBQA9oSQSiapjAAB5wcHBX3/9taamJr1I/55SFEUI6ezs1NPTq62t1dbWVmWIANAFrv0CqKPVq1cTQoS/EYlEIpGI/reGhkZAQAASKoAawnkqgDoSiUTm5uYNDQ0KW//1r3+9+eabQxwSAPQK56kA6ojFYq1evVp67VfWuHHjvLy8hj4kAOgVciqAmlq9erVQKJRbqamp+d5772loaKgkJADoGa79AqgpiURiY2NTVVUlt/727dvz5s1TSUgA0DOcpwKoKYqi1q1bJ3f5d8KECXPnzlVVSADQM+RUAPUld/lXU1MzODiYfqMGANQQrv0CqLWpU6c+fPhQuvjzzz87OzurMB4A6AHOUwHU2nvvvSe9/Ovk5ISECqDOkFMB1Nq6detEIhEhRFNT84MPPlB1OADQE1z7BVB3c+fO/emnnyiKqqystLGxUXU4ANAtnKcCqLv333+fEPLGG28goQKoOdSlGSECAgJUHQIMlvb2doqiOjo68CmPYNu2beNyuaqOAgYK56kjxIULF7pODgDDSFVV1YULFxQ2sdlsc3Nza2vrIQ5pkOC72tWFCxeePXum6iiAAThPHTm2bt26atUqVUcBSjp37lxgYOD58+cVtpaXlzs4OAxxSIOEoih8V+XgneMRA+epAMPAiEmoACMbcioAAAAzkFMBAACYgZwKAADADORUAAAAZiCnAgxjV65cMTQ0vHz5sqoDGSzXr1+PiIgQi8X+/v42NjZsNtvKysrPz6+kpKQv3ffs2UP9X9OnT+/jrvfv3z916lQdHR1dXd2pU6dGRUU1NzdLW2NjY52cnAwMDLS1tR0cHD766KPXr1/TTZcuXdq/f39nZ2d/DxZGAORUgGFsZM8tumvXrqSkpMjISLFYnJube+bMmYaGhry8vLa2tgULFlRXVw/q3nNzcz/88MOnT5/W1NTs3r17//79K1eulLZ+//33mzdvrqysrK+vj4+PT0xMlM7I4evry2azvb29GxsbBzVCUEPIqQDD2NKlS5uamt59993B3lFbW5ubm9tg70XWvn37UlJSzp07p6+vTwjhcrkeHh4cDsfW1jYuLq6pqemrr77qyzgnT56UyPj555/7GICWltamTZtMTU319PQCAgKWLVv2z3/+89dff6Vb9fT0QkJCTExM9PX1V61a5e/v/91330nnbQgLC5s5c+aSJUvo+gcweiCnAkDvkpOTa2trh2x35eXlUVFRMTExbDabEMJisWSvb9vZ2RFCHj16NKgxXLx4kd47zcrKihAivcD77bffamhoSFvHjRtHCOHz+dI10dHRRUVFiYmJgxokqBvkVIDhKi8vz8bGhqKow4cPE0KOHj2qq6vL4XAyMjIWL15sYGBgbW199uxZeuOkpCQ2m21mZrZhwwZLS0s2m+3m5lZQUEC38ng8LS0tCwsLenHTpk26uroURdXX1xNCtmzZsn379kePHlEURc8+8d133xkYGMTFxQ3SoSUlJUkkEl9fX4WtbW1thBADA4NB2rtCZWVlRkZGEydOVNj6/PlzHR0dW1tb6RpjY2MvL6/ExMSRfX0e5CCnAgxXHh4eN2/elC5u3Lhx69atbW1t+vr6qampjx49srOz+/DDD4VCISGEx+MFBwfz+fywsLDKysrCwkKRSLRo0SL6cmVSUpLsZIFHjhyJiYmRLiYmJr777rv29vYSiaS8vJwQQj+AIxaLB+nQMjMzHR0dORyOwtbbt28TQjw8PPoyVEREhLGxsZaWlq2t7bJly+7cudOvSIRC4fPnzw8fPnz9+vXPPvtMS0ur6zZ8Pv/777//8MMP5VpnzZr1/Pnz4uLifu0RhjXkVICRxs3NzcDAwNTUNCgoqLW19enTp9ImFos1bdo0bW1tJyeno0ePtrS0nDhxQoldLF26tLm5OSoqirmo/1dra+vjx4/t7e27NtXU1KSkpISFhXG53O7OYmV98MEHly5devbs2evXr8+ePfv06VMvL6/S0tK+BzNhwgRra+vo6OhPPvkkMDBQ4Tbx8fGWlpZ79uyRWz958mRCyL179/q+OxjukFMBRiz6tIk+T+1q7ty5HA7nwYMHQxtU72prayUSicKTVC6XGxYWtmzZsqysLE1NzV6HmjBhwqxZs/T09LS0tObPn3/ixIm2trYjR470PZhnz57V1taeOXPm66+/njVrVtebyhcvXjx37tzVq1fpZ6lk0YdQU1PT993BcIe6NACjl7a2dl1dnaqjkNfe3k4I0dbW7tpkZmaWnJzs7Oys3MguLi4aGhr/+c9/+t5FU1PT1NTUx8fH1tZ2ypQp9Gsz0taUlJSEhITs7Ozx48d37aujo0N+OxwYJZBTAUYpoVDY2NiohmVZ6VSkcM4EU1NTIyMjpUcWi8VisVhhtu6Vg4ODhoaG7HXjzz777OrVq99//72enp7CLgKBgPx2ODBK4NovwCiVnZ0tkUjmz59PL7JYrO6uEg8xMzMziqKampq6Nl2+fJl+p6WP3nrrLdnFO3fuSCQSLpfba8eXL1+uWbNGdk1ZWVlnZ+eECRMIIRKJJDw8/N69e+np6d0lVEIIfQjm5uZ9DxiGO+RUgFFELBa/evVKJBKVlJRs2bLFxsYmODiYbnJwcGhoaEhPTxcKhXV1dU+ePJHtaGJiUl1dXVlZ2dLSIhQKs7KyBu9dGg6HY2dnV1VVJbe+vLzc3Nxc7kGhoKAgc3PzwsJChUM9f/48JSWlsbFRKBTeunXrj3/8o42NTWhoaK99dXV1r1279v333zc3NwuFwrt3737wwQe6urrbtm0jhPzyyy+ffPLJl19+qampKTvx4cGDB2UHoQ/BxcVF2Z8EDD/IqQDD1eHDh+fNm0cICQ8P9/PzO3r06KFDhwghM2bMqKio+PLLL7dv304Iefvtt8vKyugu7e3tLi4uOjo6np6eU6ZMuXHjhvRC6MaNGxcuXLh69WpHR8fdu3fTVyy5XC79sk1oaKiZmZmTk9OSJUsaGhoG+9CWLl1aWlpKv4cqpfBFT4FAUFtbm5GRoXCct99+++OPP7a2tuZwOKtWrXJ3d8/Pzx87dmyvfdlstru7+x//+EcrKyt9ff2AgIBJkybl5+fT0wX38ZXTO3fuWFlZzZgxoy8bwwghgRGBEJKamqrqKEB5qampg/37SM+lN6i76Iu+fFfLyspYLJbctIIKdXZ2enp6JicnKxHJQPr2qr6+ns1mHzx4sC8b4/d3xMB5KsAoMlyKpTg4OMTGxsbGxkrnAlSos7MzPT29paUlKCiov7sYSN++iI6OdnV15fF4gzE4qC3kVABQRxEREQEBAUFBQQofVqJlZ2enpaVlZWV1N+NSDwbSt1cJCQlFRUVXrlzpy0u0MJIgp44uHR0dYWFhFhYWHA7nv/7rv+gHLD///HNVx6WYWCw+dOhQv8qhpKWl2dnZUYpMmjSJEHLw4EE1P+pBEhkZeeLEiaamJltb2wsXLqg6nD6Ji4vj8Xh79+7tbgNvb+/Tp09Lpynul4H07VlGRkZHR0d2draxsTHjg4OaQ04dXT799NPvvvvuwYMHiYmJGzZskJ0tVt2UlZUtWLBg27ZtsrU+erVixYqKigp7e3tDQ0P69oZIJOLz+TU1NfTpyJ///Gd1PurBEx8f39HRIZFIHj9+LFsHVM35+Pjs27dP1VH0j5+fX0REhGzVGhg9kFNHl/T09Llz5xoZGf3pT3/q+3+scrUzh6CUZnFx8Y4dO0JDQ11dXQc4lIaGho6OjpmZ2ZQpU/rVceiPGgCGO+TU0aWqqkqJGzxytTOHoJTmzJkz09LS1q5dq9yUNwqlp6f3a/uhP2oAGO6QU0eLf/7znw4ODr/++uvXX39NUZTCyV9yc3OdnJwMDQ3ZbLaLi8vVq1dJl9qZXUtpdnZ2/vWvf7WxsdHR0ZkxYwb9TkjPtTwHiNnincPlqAFA/SGnjhaLFi2ip6H54IMPJBKJwlcUampqAgMDKysrq6ur9fT01q5dS7rUzuxaSnPHjh2ffPLJoUOHfv3113fffXfNmjU//vhjz7U8B6i/xTu///57uQluhuNRA4D6Q06F/7Vy5cpdu3YZGxubmJj4+vq+fPmy16Il7e3tR48e9ff3X7FihZGR0ccff6ypqSlbkrOHWp5K60vxzqamJukTv97e3j1sOVyOGgDUH+rSgGL0bddepwh4+PAhn8+nJ2wjhOjo6FhYWCgsydlzLU/GGRoaNjY20v/Ozs7+8ccf+9JL5UdNUVQftxzWAgMDu6vvDTCsIafC/8rMzDxw4EBpaSk9b3hfurS2thJCPv74448//li60tLScrBCVMrvf//73//+9921qtVR0/dlR7bAwMAtW7b0pTjM6IG/MEYM5FT4H0+fPvX391++fPnx48fHjx//2WefffTRR732MjU1JYQcOnRoy5Ytgx8j89TtqFetWsXsgGooMDCQy+WOhiPtO+TUEQM5Ff7HvXv3hELhxo0b7ezsSJ8vQk6YMIHNZhcVFQ1ydINldB41AAwSPKME/8PGxoYQcv369fb29rKysoKCAmmTXO1M2UUNDY0//OEPZ8+ePXr0aHNzc2dnZ1VV1a+//jqooTJYvHMYHTUADAMqqocDDCO91YqqrKycNWsWIYTFYs2ePfvChQuffvqpubk5IURXV3f58uUSiSQ8PNzExMTIyCggIODw4cOEEHt7+6dPnxYWFk6cOFFHR8fDw+PFixdyix0dHeHh4TY2NiwWy9TUdMWKFaWlpUeOHKHnApw8efKjR4+++OILAwMDQsjEiRP/85//9Ho4t27dcnd3l96htLCwcHNz+/e//023XrlyRV9ff8+ePV07/vDDD9L5kiwsLLy9veU2UNujHoJab2qi1+/qKISfyYhBSfpWXBfUHEVRqampuEc1fJ07dy4wMHA0/D7iu9oVfiYjBq79AgAAMAM5FYbagwcPFNZiow1SgWgYGa5fvx4RESEWi/39/W1sbNhstpWVlZ+fX0lJSd8H6aGGoFAojI+Pd3Bw0NLSMjIymj59emVlpbQ1Ly/P3d2dw+FYWlqGh4d3dHTQ6y9durR///7hUu8dBhVyKgy1qVOn9nA3IiUlRdUBgpratWtXUlJSZGSkWCzOzc09c+ZMQ0NDXl5eW1vbggULqqur+zJIzzUEAwMDv/nmm9OnT/P5/Pv379vb20tn8SwtLfXx8fH29q6rq7t48eLx48dDQ0PpJl9fXzab7e3tLZ1mBEavIbpvC4OM4BmHYW4InlHi8/lcLlflQyn3Xd27d++UKVPa2tokEolQKHznnXekTbdv3yaExMXF9TpIUVHR8uXLT5065erqOnPmTLnWs2fPUhRVUlKisG9gYKCtra1YLKYXDxw4QFHU/fv3pRvweDwulysUCvt7aBL8/o4gOE8FGC0YLFc3xJXvysvLo6KiYmJi2Gw2IYTFYl2+fFnaSr9b/OjRo17H6bmG4LFjx2bPnu3i4tK1SSQSZWZmenl5Sd9gXrx4sUQiycjIkG4THR1dVFSUmJjYz4ODEQU5FWAdelmpAAAgAElEQVQ4kUgkCQkJ06ZN09bWNjY2XrZsmXSeYR6Pp6WlZWFhQS9u2rRJV1eXoqj6+nrSpXpdUlISm802MzPbsGGDpaUlm812c3OTvp7br6EI09X3ukpKSpJIJL6+vgpb29raCCH0a0tKEwgE+fn5rq6uClsrKipev35Nv81Ms7e3J4TI3sc1Njb28vJKTEyUjIKHt6E7yKkAw0l0dHRERMTOnTtra2tzcnKePXvm6elZU1NDCElKSpJ9GePIkSMxMTHSRblydTweLzg4mM/nh4WFVVZWFhYWikSiRYsWPXv2rL9Dkf5X3+uvzMxMR0dH+t3fruhrvx4eHgPZRXV1tUAg+OmnnxYuXEj/kTFt2rQjR47QCfLFixeEEH19fen2bDZbR0eH/slLzZo16/nz58XFxQOJBIY15FSAYaOtrS0hIWH58uXr1q0zNDR0cXH5/PPP6+vrv/jiC+UGZLFY9Cmvk5PT0aNHW1paZCvW9V1fqu8prbW19fHjx/R5oZyampqUlJSwsDAul9vdWWwf0c8imZqaxsXFlZaW1tTULFu2bPPmzWfOnCGE0I/4amhoyHbR1NSkT5GlJk+eTAi5d+/eQCKBYQ05FWDYKC0tff369dy5c6Vr5s2bp6WlJTulotLmzp3L4XAUVqxTrdraWolEovAklcvlhoWFLVu2LCsri67TpzT6Dquzs7Obm5uJiYmhoWFMTIyhoSH99wp9H1ckEsl2EQgEOjo6smvoIOVOXmFUwRz6AMMG/aqGnp6e7EojI6OWlhZGxtfW1u61HvvQa29vJ7/lPDlmZmbJycnOzs4D3ws9ESZ9w5impaU1ceJE+tEn+tZyc3OztJXP57e3t8sV+KNTLB0wjE44TwUYNoyMjAghchm0sbHR2tp64IMLhUKmhmIWnagUzqhgampK/0wGTk9Pb/Lkyb/88ovsSpFIZGhoSAixtbXV19d/8uSJtIm+kTxjxgzZ7QUCgTRgGJ2QUwGGjenTp+vp6f3444/SNQUFBQKBYM6cOfQii8XqY1n1rrKzsyUSyfz58wc+FLPMzMwoimpqauradPnyZSsrK6Z2FBgYePfu3YqKCnqRz+c/efKEfrWGxWItWbIkJydH+hxWVlYWRVFyN3HpIOkiDTA6IacCDBtsNnv79u0XL148depUc3PzvXv3QkNDLS0tQ0JC6A0cHBwaGhrS09OFQmFdXZ3seRXpUr2OECIWi1+9eiUSiUpKSrZs2WJjYxMcHKzEUAxW3+uKw+HY2dlVVVXJrS8vLzc3N5er5h0UFGRubl5YWKjEjrZt2zZx4sTg4OCnT5++fPkyPDy8ra1tx44ddGtUVFRNTc2uXbtaW1tv3bp14MCB4OBgR0dH2RHoIBW+4QqjBHIqwHCya9eu+Pj42NjYcePGeXl5TZo0KTs7W1dXl27duHHjwoULV69e7ejouHv3bvoiJJfLpd+QCQ0NNTMzc3JyWrJkSUNDAyGkvb3dxcVFR0fH09NzypQpN27ckN627O9Qg2rp0qWlpaVyD9kqfA1UIBDU1tbKTsUgKz8/38PDY/z48QUFBcXFxZaWlu7u7jk5OXSrsbFxbm6utbW1q6urlZXV7du3MzMzpW+sOjs7X7169dq1a2PHjl2xYsX69euPHTsmN/6dO3esrKzkLgjD6KKqCZyAWQRzmw1zQ18/NSQkxMTEZCj3SFPiu1pWVsZisU6ePNnrlp2dnZ6ensnJycpGp7z6+no2m33w4EEl+uL3d8TAeSrA6DVcSqk4ODjExsbGxsZKZ7RXqLOzMz09vaWlRSXVjaKjo11dXXk83tDvGtQHcioADAMREREBAQFBQUEKH1aiZWdnp6WlZWVldTfj0uBJSEgoKiq6cuXKAF+TheEOORVgNIqMjDxx4kRTU5Otre2FCxdUHU6fxMXF8Xi8vXv3dreBt7f36dOnpdMUD5mMjIyOjo7s7GxjY+Mh3jWoG8z5ADAaxcfHx8fHqzqKfvPx8fHx8VF1FPL8/Pz8/PxUHQWoBZynAgAAMAM5FQAAgBnIqQAAAMxATgUAAGAGnlEaOW7duqXqEEB59Md37tw5VQcyFPBdhZGKkiia3wuGHYqiVB0CACgvNTV11apVqo4CBgo5FWAYoCgK/+cCqD/cTwUAAGAGcioAAAAzkFMBAACYgZwKAADADORUAAAAZiCnAgAAMAM5FQAAgBnIqQAAAMxATgUAAGAGcioAAAAzkFMBAACYgZwKAADADORUAAAAZiCnAgAAMAM5FQAAgBnIqQAAAMxATgUAAGAGcioAAAAzkFMBAACYgZwKAADADORUAAAAZiCnAgAAMAM5FQAAgBnIqQAAAMxATgUAAGAGcioAAAAzkFMBAACYgZwKAADADORUAAAAZiCnAgAAMAM5FQAAgBnIqQAAAMxATgUAAGAGJZFIVB0DAMgLCQl5+PChdLGwsNDW1tbY2Jhe1NDQ+Prrr62trVUUHQAoxlJ1AACggLm5+RdffCG7pqSkRPpvOzs7JFQANYRrvwDqaM2aNd01aWlpBQcHD2EsANBXuPYLoKamT5/+yy+/KPwNffjw4ZQpU4Y+JADoGc5TAdTU+++/r6GhIbeSoqiZM2cioQKoJ+RUADW1evXqzs5OuZUaGhoffPCBSuIBgF7h2i+A+nJzcysoKBCLxdI1FEU9e/bMyspKhVEBQHdwngqgvt577z2KoqSLY8aM8fDwQEIFUFvIqQDqKyAgQHaRoqj3339fVcEAQK+QUwHU17hx47y9vaVPKlEU5e/vr9qQAKAHyKkAam3dunX0Qw8aGhpvvfXW2LFjVR0RAHQLORVArS1fvlxLS4sQIpFI1q1bp+pwAKAnyKkAak1XV/edd94hhGhpab377ruqDgcAeoKcCqDu1q5dSwjx9/fX1dVVdSwA0BO8n9qtc+fOBQYGqjoKAAD1snLlyvPnz6s6CjWFujS9SE1NVXUIAOTUqVNBQUEs1hD9wh46dIgQsnXr1qHZnarcunUrMTERv+P9Qn83oDvIqb1YtWqVqkMAIL6+vmw2e8h2R5+FjIYvf2Ji4mg4TAbhDLVnuJ8KMAwMZUIFAKUhpwIAADADORUAAIAZyKkAAADMQE4FAABgBnIqADDjypUrhoaGly9fVnUgqnH9+vWIiAixWOzv729jY8Nms62srPz8/EpKSvo+iFgsPnTokJubW9cmoVAYHx/v4OCgpaVlZGQ0ffr0yspKaWteXp67uzuHw7G0tAwPD+/o6KDXX7p0af/+/V2L28MgQU4FAGaM5glkdu3alZSUFBkZKRaLc3Nzz5w509DQkJeX19bWtmDBgurq6r4MUlZWtmDBgm3btvH5/K6tgYGB33zzzenTp/l8/v379+3t7V+/fk03lZaW+vj4eHt719XVXbx48fjx46GhoXQT/RaWt7d3Y2MjUwcLPZFAN+g3wVUdBYAKrFy5cuXKlaqOolt8Pp/L5Q58HKZ+x/fu3TtlypS2tjaJRCIUCt955x1p0+3btwkhcXFxvQ5SVFS0fPnyU6dOubq6zpw5U6717NmzFEWVlJQo7BsYGGhraysWi+nFAwcOUBR1//596QY8Ho/L5QqFwv4eWldq/t1QOZynAsAwk5ycXFtbq+oo/kd5eXlUVFRMTAz9DjGLxZK9+m1nZ0cIefToUa/jzJw5My0tbe3atdra2l1bjx07Nnv2bBcXl65NIpEoMzPTy8uLoih6zeLFiyUSSUZGhnSb6OjooqKixMTEfh4c9BtyKgAwIC8vz8bGhqKow4cPE0KOHj2qq6vL4XAyMjIWL15sYGBgbW199uxZeuOkpCQ2m21mZrZhwwZLS0s2m+3m5lZQUEC38ng8LS0tCwsLenHTpk26uroURdXX1xNCtmzZsn379kePHlEU5eDgQAj57rvvDAwM4uLiVHDYhCQlJUkkEl9fX4WtbW1thBADA4OB7EIgEOTn57u6uipsraioeP36tY2NjXSNvb09IUT2Pq6xsbGXl1diYqJkFF+fHxrIqQDAAA8Pj5s3b0oXN27cuHXr1ra2Nn19/dTU1EePHtnZ2X344YdCoZAQwuPxgoOD+Xx+WFhYZWVlYWGhSCRatGjRs2fPCCFJSUmy8wUeOXIkJiZGupiYmPjuu+/a29tLJJLy8nJCCP0AjlgsHrKDlZWZmeno6MjhcBS20td+PTw8BrKL6upqgUDw008/LVy4kP4TZNq0aUeOHKET5IsXLwgh+vr60u3ZbLaOjk5NTY3sILNmzXr+/HlxcfFAIoFeIacCwCByc3MzMDAwNTUNCgpqbW19+vSptInFYk2bNk1bW9vJyeno0aMtLS0nTpxQYhdLly5tbm6OiopiLuq+am1tffz4MX1eKKempiYlJSUsLIzL5XZ3FttH9LNIpqamcXFxpaWlNTU1y5Yt27x585kzZwgh9CO+Ghoasl00NTXpU2SpyZMnE0Lu3bs3kEigV8ipADAUtLS0CCH0eWpXc+fO5XA4Dx48GNqgBqq2tlYikSg8SeVyuWFhYcuWLcvKytLU1BzIXug7rM7Ozm5ubiYmJoaGhjExMYaGhl988QX5bS5okUgk20UgEOjo6MiuoYOUO3kFxqEuDQCoBW1t7bq6OlVH0T/t7e3kt5wnx8zMLDk52dnZeeB7sbS0JITQt5NpWlpaEydOpB99om88Nzc3S1v5fH57ezvdS4pOsXTAMHhwngoAqicUChsbG62trVUdSP/QiUrhjAqmpqZGRkaM7EVPT2/y5Mm//PKL7EqRSGRoaEgIsbW11dfXf/LkibSJvs08Y8YM2e0FAoE0YBg8yKkAoHrZ2dkSiWT+/Pn0IovF6u4qsVoxMzOjKKqpqalr0+XLl62srJjaUWBg4N27dysqKuhFPp//5MkT+tUaFou1ZMmSnJwc6VNaWVlZFEXJ3cSlgzQ3N2cqJFAIORUAVEMsFr969UokEpWUlGzZssXGxiY4OJhucnBwaGhoSE9PFwqFdXV1sidhhBATE5Pq6urKysqWlhahUJiVlaWqd2k4HI6dnV1VVZXc+vLycnNz88DAQNmVQUFB5ubmhYWFSuxo27ZtEydODA4Ofvr06cuXL8PDw9va2nbs2EG3RkVF1dTU7Nq1q7W19datWwcOHAgODnZ0dJQdgQ5S4RuuwCDkVABgwOHDh+fNm0cICQ8P9/PzO3r06KFDhwghM2bMqKio+PLLL7dv304Iefvtt8vKyugu7e3tLi4uOjo6np6eU6ZMuXHjhvTG5MaNGxcuXLh69WpHR8fdu3fTVyy5XC79sk1oaKiZmZmTk9OSJUsaGhpUcrxSS5cuLS0tlXvIVuFroAKBoLa2VnYqBln5+fkeHh7jx48vKCgoLi62tLR0d3fPycmhW42NjXNzc62trV1dXa2srG7fvp2ZmSl9Y9XZ2fnq1avXrl0bO3bsihUr1q9ff+zYMbnx79y5Y2VlJXdBGJinuimc1B3mJoRRawjmnwsJCTExMRnUXfSKkd/xsrIyFot18uTJXrfs7Oz09PRMTk4e4B6VUF9fz2azDx48OPChMDdhz3CeCgCqMTKKpTg4OMTGxsbGxkpntFeos7MzPT29paUlKChoyGKTio6OdnV15fF4Q7/r0QY5FdRXe3v71KlTP/74475snJaWZmdnR8lgs9m2trbr169//PjxYIfas5CQEHp2PU1NzZkzZ96/f1/adPz4cXpKP3Nz86+++kp1MYLyIiIiAgICgoKCFD6sRMvOzk5LS8vKyupuxqXBk5CQUFRUdOXKlQG+Jgt9gZwK6mvnzp0PHz7s48YrVqyoqKiwt7c3NDSUSCSdnZ1Pnz6NjY1NTU2dP3/+y5cvBzXUnv3tb3+7desWIWTOnDnFxcXTpk2TNq1fvz43N3f8+PFVVVXSJ3RGvMjIyBMnTjQ1Ndna2l64cEHV4TAgLi6Ox+Pt3bu3uw28vb1Pnz4tncR4yGRkZHR0dGRnZxsbGw/xrkcn5NThqq2tTWHh4hGz65s3b/78889Kdx8zZoyZmdl77723efPm2tra69evMxhbX8j9lGbMmOHh4VFQUND1sc/PP/98/fr1SpxDqPA7MEDx8fEdHR0SieTx48crV65UdTjM8PHx2bdvn6qjkOfn5xcRESE3cyEMHuTU4UqF5a6GYNdtbW1/+ctfGClNRZcuoecZH0pdf0qbN28mhBw5ckR2pUAg+Oabb0JCQhjZBQCoFnLqgHzyySccDkdfX7+2tnb79u1WVlYPHz7s7Oz861//amNjo6OjM2PGDPrZwp6LWxFCFPYihOTm5jo5ORkaGrLZbBcXl6tXrxJF5a56MG3aNIqixowZM2fOHD6fTwj56KOP6AHpG3jd7ZoQcvLkyblz57LZbF1d3UmTJu3evbvrriUSSUJCAj0ZurGx8bJly6Sztir8+fTlB7tz585NmzaZmprKrVeiqhf95sbMmTOla1T1Aa1YsWL8+PEpKSmNjY3SYS9cuPDGG2/Q8wep4QcBAP2j2seO1Vkfn7PfuXMnISQsLOyzzz5bvnz5/fv3//znP2tra1+4cOHVq1eRkZFjxoy5c+eORCKhH1T55Zdf2tvbS0tL582bp6+v//TpU3qc7nqdP38+Ojq6oaHh5cuX8+fPHzt2LL39ihUr6HJXvRKJRJMmTbKxsRGJRNKVW7duPXToUM+7pt8v3Lt378uXLxsaGv72t7+tXbu2667/+te/amlpnTx5srGxsaSkZPbs2ePGjXvx4kV3P59eA87Ly/P19ZVIJPTsrzt37pQ2ffvtt/r6+rGxsd31ld5PlUgkr169+uqrrzgcztKlS2W3UeEHFB0dTQhJSEiQrvHw8Lh+/bq6fRCj5H0JvC+nhFHy3VAavk/d6ldObWtroxfb2to4HE5QUBC9yOfztbW1N27cKJFIQkJCpP/dSySSO3fuEEJiYmJ67iUrPj6e/FYKo+85VfLbf8rnzp2jF1tbW21sbJqamnrYtUAgMDIyWrhwoXQQkUhE1zSW3TWfz9fT05N2l0gkdMFIadqT+/n0is/nz507t6qqSqIop/ZKruoWRVF79uwRCATSDVT7Af3666+amppTpkwRi8USiaSkpGTq1Kk9B6aSD2KU/L+JnKqEUfLdUBrq0jDs4cOHfD5/+vTp9KKOjo6FhYXCClayxa362It+jEWJt/r++Mc/RkdHJyYmBgQEEEJOnTq1bNkyAwODHnZdUlLS2Nj41ltvSQfR0NAICwuTG7m0tPT169dz586Vrpk3b56WlpbsVdN+iYyM/NOf/jSQiVINDQ3pi6sfffTRgQMHDA0NZR//Ue0HZGFhsWLFipSUlOvXry9atOjYsWOhoaE9B6aqD6KqqurcuXPK9R0u6IexR/xhMquqqmrYlToYSsipDGttbSWEfPzxx7JvVcoVXZKSFrfqoVdmZuaBAwdKS0ubm5uVnlVcT0/vT3/604EDB27fvv273/3u2LFj0hcYuts1XTqq18IadPbS09OTXWlkZNTS0qJEnHl5effu3UtISFCib1dRUVEnT56MjIz08/ObMGECvVLlH9DmzZtTUlKOHj06f/78f/zjH9LErFYfBCEkPz9fbrrakWqUHCaDRsyj2oMBzygxjH6sRnqrkkb/OSxHtrhVd72ePn3q7+9vYWFRUFDQ1NS0f/9+pQPj8XiampqHDh3KycmZMGGC9Bppd7seP348+b8lGxWi/6+X+49b6aJdycnJ//rXv8aMGUNP2kDHFhcXR1HUjz/+2N/R9PX19+3b19LSsnHjRulKlX9A7u7us2bNunz58t69e/38/OhyXT3sQiUfBCFkNFzfw7VfJSCh9gw5lWETJkxgs9lFRUW9bilb3Kq7Xvfu3RMKhRs3brSzs2Oz2RRFKR2YtbX1qlWrLly4EBUVtWXLll4DnjRpkomJybVr13oedvr06Xp6erIJr6CgQCAQzJkzR4kgT5w4IfvbK3s/VfaqZt+9//77b7zxxrfffiu9vqcOH9CmTZs6Ozv37dsnm+zV6oMAAOUgpzKMzWb/4Q9/OHv27NGjR5ubmzs7O6uqqn799Ve6tbviVt31srGxIYRcv369vb29rKxM9t6YXLmrvsS2fft2kUj06tWrN998s9eAtbW1IyMjc3JyeDze8+fPxWJxS0sLXRVZdtcaGhrbt2+/ePHiqVOnmpub7927FxoaamlpqdwLl73qb1UviqKSkpIoiuLxeK9everheOnth+YDWrNmjYmJibu7u2yRkOH1QQCAYqq4eDA89OW60P79++kqVBMmTJAWpujo6AgPD7exsWGxWKampitWrCgtLZVIJCEhIZqamlZWViwWy8DAYNmyZY8ePZIO1V2v8PBwExMTIyOjgICAw4cPE0Ls7e2fPn1aWFg4ceJEHR0dDw8P6fsSvVq4cOHf//53uZXd7VoikRw+fNjFxYXNZrPZ7FmzZh05ckQikcjtWiwWHzhwYPLkyZqamsbGxv7+/g8fPuzh59N3XZ/7vXLlir6+/p49e7pu/MMPP0yZMoX+Vo8fP37Dhg3SJjovGhkZ7d27t4fjHcoP6C9/+cuZM2fU9oMYJc924tqvEkbJd0NplERRnT8ghJw7dy4wMJDBn8+GDRvOnz+v2olnoQf4gKTo58PPnz+v6kAGF+O/46PBKPluKA3XfofUyChuNYLhAwKAgUBOHfYePHhAdU8lxRq7M4xCBQBQAnLqEBm84lbSiXgUSklJYXBfA6TOoY686mPAuOvXr0dERIjFYn9/fxsbGzabbWVl5efnV1JS0vdBxGLxoUOHlCso1ENfoVAYHx/v4OCgpaVlZGQ0ffr0yspKaWteXp67uzuHw7G0tAwPD+/o6KDXX7p0af/+/bg8wyDk1CEyIotbjST4gKBnu3btSkpKioyMFIvFubm5Z86caWhoyMvLa2trW7BgQXV1dV8GKSsrW7BgwbZt2+hqFv3Sc9/AwMBvvvnm9OnTfD7//v379vb2r1+/pptKS0t9fHy8vb3r6uouXrx4/Phx6exdvr6+bDbb29tbtq4DDARyKgCoAIPFX4egjuy+fftSUlLOnTunr69PCOFyuR4eHhwOx9bWNi4urqmpiS7x1LPi4uIdO3aEhoa6urr2N4Ce+6akpKSnp58/f/6NN95gsViWlpYZGRnSeS53795tYWERExOjq6vL5XLDw8O/+uor6QReYWFhM2fOXLJkiUgk6m9U0BVyKgCoAIPFXwe7jmx5eXlUVFRMTAybzSaEsFisy5cvS1vt7OwIIY8ePep1nJkzZ6alpa1du1ZbW7u/MfTc99ixY7Nnz3ZxcenaJBKJMjMzvby8pBOSLF68WCKRZGRkSLeJjo4uKipipFwxIKcCgJIk3Vds5fF4WlpaFhYW9OKmTZt0dXUpiqInWZQr/tpz8dp+DUWUKrLbs6SkJIlE4uvrq7C1ra2NEEJXpFAJgUCQn5/f3blvRUXF69ev6clJaPS8pLL3gI2Njb28vOhiR4Md7YiHnAoASoqOjo6IiNi5c2dtbW1OTs6zZ888PT1ramoIIUlJSatWrZJueeTIkZiYGOliYmLiu+++SxeqKy8v5/F4wcHBfD4/LCyssrKysLBQJBItWrTo2bNn/R2K/PZClFgsZuowMzMzHR0dORyOwla6pp6HhwdTu+uv6upqgUDw008/LVy4kP6LZNq0afSsIISQFy9eEELoS9Y0Nputo6NDf0xSs2bNev78eXFx8RAHP/IgpwKAMtra2hISEpYvX75u3TpDQ0MXF5fPP/+8vr7+iy++UG5AFotFn/I6OTkdPXq0paXlxIkTSoyzdOnS5ubmqKgo5cKQ09ra+vjxY7m6vLSampqUlJSwsDAul9vdWewQoJ9FMjU1jYuLKy0trampWbZs2ebNm8+cOUMIoR/x1dDQkO2iqalJn15LTZ48mRBy7969oYt7hEJOBQBlMF6xVZZs8VrVoivMKzxJ5XK5YWFhy5Yty8rKkq3RO8ToO6zOzs5ubm4mJiaGhoYxMTGGhob0Hzf0PWC5548EAgE9V6UUfYByJ6+gBNRPBQBlMF6xVY60eK1qtbe3k9/ylhwzM7Pk5GRnZ+chD+r/oOv4ylYD1NLSmjhxIv3YFH0fmq7CS+Pz+e3t7XI1g+kUSx8sDATOUwFAGYxXbJUlW7xWtehko3BWBFNT015rxQ8BPT29yZMn06WKpEQiEV2a19bWVl9f/8mTJ9Im+q6zbE0kQohAICC/HSwMBHIqACij14qtLBarj1UIu5ItXjvAoQbIzMyMoqimpqauTZcvX7ayshr6kLoKDAy8e/duRUUFvcjn8588eUK/WsNisZYsWZKTkyN9aCsrK4uiKLkbwPQBmpubD23gIxByKgAog81m91yx1cHBoaGhIT09XSgU1tXVyZ4qEUX1ZbsrXtvfofpbZLdnHA7Hzs6uqqpKbn15ebm5uXlgYKDsyqCgIHNz88LCQiV2NJC+27ZtmzhxYnBw8NOnT1++fBkeHt7W1rZjxw66NSoqqqamZteuXa2trbdu3Tpw4EBwcLCjo6PsCPQBKnzDFfoFORUAlLRr1674+PjY2Nhx48Z5eXlNmjQpOztbV1eXbt24cePChQtXr17t6Oi4e/du+roil8ul35AJDQ01MzNzcnJasmRJQ0MDIaS9vd3FxUVHR8fT03PKlCk3btyQ3sXs71DMWrp0aWlpqdyDsgpf5RQIBLW1tbLTKcjKz8/38PAYP358QUFBcXGxpaWlu7t7Tk7OwPsaGxvn5uZaW1u7urpaWVndvn07MzNT+saqs7Pz1atXr127Nnbs2BUrVqxfv/7YsWNy49+5c8fKykrugjAoY8AVWEcs1CuGUWvo606HhISYmJgM5R4lff4dLysrY7FYfanl3tnZ6enpmZycrEQwA+k7QPX19Ww2++DBg33ZGDXJe4bzVABQC2pbHcXBwSE2NjY2NlY6K71CnZ2d6enpLS0tSlQtHEjfgYuOjm0qgOEAACAASURBVHZ1deXxeEO/65EHORUAoBcREREBAQFBQUEKH1aiZWdnp6WlZWVldTfjUg8G0neAEhISioqKrly5osJXbEcS5FQAULFhUbw2Li6Ox+Pt3bu3uw28vb1Pnz4tnZe4XwbSdyAyMjI6Ojqys7ONjY2HeNcjFeZ8AAAVi4+Pj4+PV3UUvfPx8fHx8VF1FEzy8/Pz8/NTdRQjCs5TAQAAmIGcCgAAwAzkVAAAAGYgpwIAADADzyj1IiAgQNUhAAy1/Px8Mgq+/PSEfCP+MJmVn58vnYcZuqIkimbYAkLIrVu3EhISVB0FACGEZGVlzZo1a+jftQDoisvlbtu2TdVRqCnkVIBhgKKo1NTUVatWqToQAOgJ7qcCAAAwAzkVAACAGcipAAAAzEBOBQAAYAZyKgAAADOQUwEAAJiBnAoAAMAM5FQAAABmIKcCAAAwAzkVAACAGcipAAAAzEBOBQAAYAZyKgAAADOQUwEAAJiBnAoAAMAM5FQAAABmIKcCAAAwAzkVAACAGcipAAAAzEBOBQAAYAZyKgAAADOQUwEAAJiBnAoAAMAM5FQAAABmIKcCAAAwAzkVAACAGcipAAAAzEBOBQAAYAZyKgAAADOQUwEAAJiBnAoAAMAM5FQAAABmsFQdAAAo0NjYKJFIZNe0tra+evVKuqinp6epqTnkcQFATyi531sAUAdvvvnmjRs3umvV0NB4/vy5ubn5UIYEAL3CtV8AdbR69WqKohQ2jRkzZsGCBUioAGoIORVAHa1cuZLFUnxrhqKo999/f4jjAYC+QE4FUEfGxsY+Pj4aGhpdm8aMGePv7z/0IQFAr5BTAdTUunXrxGKx3EoWi7V06VJDQ0OVhAQAPUNOBVBTvr6+2tracis7OzvXrVunkngAoFfIqQBqisPh+Pv7y70wo6Ojs2TJElWFBAA9Q04FUF9r1qwRCoXSRU1NzZUrV+ro6KgwJADoAXIqgPp66623ZG+dCoXCNWvWqDAeAOgZciqA+tLU1AwKCtLS0qIXjYyMvL29VRsSAPQAORVAra1evVogEBBCNDU1161b191LqwCgDjA3IYBaE4vF48ePr6mpIYTk5eW5u7urOiIA6BbOUwHU2pgxY9577z1CiKWlpZubm6rDAYCe4DrSiHLu3DlVhwDMGzduHCHkjTfeOH/+vKpjAea5ublZW1urOgpgBq79jijdzboOAGorNTV11apVqo4CmIHz1JEGv59qiKKoAX4uFy5cWLlyJYMhDYaAgABCCE6m+wV/B48wuJ8KMAyof0IFAIKcCgAAwBTkVAAAAGYgpwIAADADORUAAIAZyKkAAADMQE4FUFNXrlwxNDS8fPmyqgMZLNevX4+IiBCLxf7+/jY2Nmw228rKys/Pr6SkpO+DiMXiQ4cOKTfDVA99hUJhfHy8g4ODlpaWkZHR9OnTKysrpa30JJEcDsfS0jI8PLyjo4Nef+nSpf3793d2dioRDIwMyKkAampkz8eya9eupKSkyMhIsVicm5t75syZhoaGvLy8tra2BQsWVFdX92WQsrKyBQsWbNu2jc/n9zeAnvsGBgZ+8803p0+f5vP59+/ft7e3f/36Nd1UWlrq4+Pj7e1dV1d38eLF48ePh4aG0k2+vr5sNtvb27uxsbG/8cAIIYERhBCSmpqq6ihAnpp/Lnw+n8vlDnyclStXrly5si9b7t27d8qUKW1tbRKJRCgUvvPOO9Km27dvE0Li4uJ6HaSoqGj58uWnTp1ydXWdOXNmv0Ltue/Zs2cpiiopKVHYNzAw0NbWViwW04sHDhygKOr+/fvSDXg8HpfLFQqFfYlEzb8b0F84TwUY7ZKTk2tra4dsd+Xl5VFRUTExMWw2mxDCYrFkr2/b2dkRQh49etTrODNnzkxLS1u7dq22tnZ/Y+i577Fjx2bPnu3i4tK1SSQSZWZmenl5Sec/Wrx4sUQiycjIkG4THR1dVFSUmJjY36hgBEBOBVBHeXl5NjY2FEUdPnyYEHL06FFdXV0Oh5ORkbF48WIDAwNra+uzZ8/SGyclJbHZbDMzsw0bNlhaWrLZbDc3t4KCArqVx+NpaWlZWFjQi5s2bdLV1aUoqr6+nhCyZcuW7du3P3r0iKIoBwcHQsh3331nYGAQFxc3SIeWlJQkkUh8fX0Vtra1tRFCDAwMBmnvvRIIBPn5+a6urgpbKyoqXr9+bWNjI11jb29PCJG9B2xsbOzl5ZWYmCgZ0VfvQSHkVAB15OHhcfPmTenixo0bt27d2tbWpq+vn5qa+ujRIzs7uw8//FAoFBJCeDxecHAwn88PCwurrKwsLCwUiUSLFi169uwZISQpKUl2quEjR47ExMRIFxMTE9999117e3uJRFJeXk4IoR+xEYvFg3RomZmZjo6OHA5HYSt97dfDw2OQ9t6r6upqgUDw008/LVy4kP4DZdq0aUeOHKET5IsXLwgh+vr60u3ZbLaOjg5d4FZq1qxZz58/Ly4uHuLgQeWQUwGGEzc3NwMDA1NT06CgoNbW1qdPn0qbWCzWtGnTtLW1nZycjh492tLScuLECSV2sXTp0ubm5qioKOai/l+tra2PHz+mz+3k1NTUpKSkhIWFcbnc7s5ihwD9LJKpqWlcXFxpaWlNTc2yZcs2b9585swZQgj9iK+GhoZsF01NTfr0Wmry5MmEkHv37g1d3KAekFMBhiUtLS1CCH2e2tXcuXM5HM6DBw+GNqje1dbWSiQShSepXC43LCxs2bJlWVlZmpqaQx8bjb7D6uzs7ObmZmJiYmhoGBMTY2ho+MUXXxBC6HvAIpFItotAINDR0ZFdQx+g3MkrjAao9QYwMmlra9fV1ak6Cnnt7e3kt7wlx8zMLDk52dnZeciD+j8sLS0JIfTNZpqWltbEiRPpx6bo29LNzc3SVj6f397eTveSolMsfbAwquA8FWAEEgqFjY2N1tbWqg5EHp1sFM6KYGpqamRkNOQRydPT05s8efIvv/wiu1IkEhkaGhJCbG1t9fX1nzx5Im2ib0LPmDFDdnuBQEB+O1gYVZBTAUag7OxsiUQyf/58epHFYnV3lXiImZmZURTV1NTUteny5ctWVlZDH1JXgYGBd+/eraiooBf5fP6TJ0/oV2tYLNaSJUtycnKkz3BlZWVRFCV3A5g+QHNz86ENHFQPORVghBCLxa9evRKJRCUlJVu2bLGxsQkODqabHBwcGhoa0tPThUJhXV2d7GkWIcTExKS6urqysrKlpUUoFGZlZQ3euzQcDsfOzq6qqkpufXl5ubm5eWBgoOzKoKAgc3PzwsJCJXY0kL7btm2bOHFicHDw06dPX758GR4e3tbWtmPHDro1KiqqpqZm165dra2tt27dOnDgQHBwsKOjo+wI9AEqfMMVRjbkVAB1dPjw4Xnz5hFCwsPD/fz8jh49eujQIULIjBkzKioqvvzyy+3btxNC3n777bKyMrpLe3u7i4uLjo6Op6fnlClTbty4Ib1tuXHjxoULF65evdrR0XH37t30NUkul0u/bBMaGmpmZubk5LRkyZKGhobBPrSlS5eWlpbKPSir8FVOgUBQW1srO52CrPz8fA8Pj/HjxxcUFBQXF1taWrq7u+fk5Ay8r7GxcW5urrW1taurq5WV1e3btzMzM6VvrDo7O1+9evXatWtjx45dsWLF+vXrjx07Jjf+nTt3rKys5C4Iw6iguimcgHkE85yppSH4XEJCQkxMTAZ1F73q49yEZWVlLBbr5MmTvW7Z2dnp6emZnJysRDAD6TtA9fX1bDb74MGDfdkYv7MjDM5TAUaI4VIOxcHBITY2NjY2VjorvUKdnZ3p6ektLS1BQUH93cVA+g5cdHS0q6srj8cb+l2DyiGnji4HDx6kHxL5/PPPVRLA73//e6oLPT29XjumpaXZ2dnR21tYWKxbt667LYuLi4OCgmxtbbW1tceNGzdz5sw9e/bQTUFBQV33Luvbb7+V3VF38x4kJCRQFDVmzJipU6dKLxhC30VERAQEBAQFBSl8WImWnZ2dlpaWlZXV3YxLPRhI3wFKSEgoKiq6cuWKCl+xBRVCTh1d/vznP8vOeKcm+jIR3YoVKyoqKuzt7Q0NDV+8eHHq1CmFm927d8/Nzc3CwuLGjRtNTU03b958++23s7OzpRtcu3atsbFRKBT++uuvhBBfX1+BQNDa2lpbW/vhhx/K7ogQ8ve//73r47KdnZ1JSUmEkDfffPPBgwcLFixQ8rCZExkZeeLEiaamJltb2wsXLqg6nD6Ji4vj8Xh79+7tbgNvb+/Tp09Lpynul4H0HYiMjIyOjo7s7GxjY+Mh3jWoCeRUUKCtrU25Is+9YrPZzc3NsrcfQkJCPvroI6bGP3jwoJGRUWJi4qRJk9hs9pQpU6SP5BBCKIpyd3c3NDRksVjSNZqamhwOx9TUdM6cObJDzZkz58WLF+np6XK7SEtLU5NXPqTi4+M7OjokEsnjx49Xrlyp6nD6ysfHZ9++faqOgkl+fn4RERFyMxfCqIKcCgoMXvGv7777Tnb+8WfPnv38889vvvkmU+O/fPmyqalJ9uFVLS0taSmxs2fP9nAxMCQk5J133pEubty4kRDS9ZHOhIQE+plbAAA5yKmj3b///e/f/e53HA7HwMDAxcWlublZrvhXYmKirq7umDFj5syZY25urqmpqaurO3v2bE9PzwkTJrDZbCMjI6VPNPft2xcWFiZdHHiVsXnz5rW2tr755ps//PCD0oPQ3nzzzWnTpt24cePhw4fSlT/88AOfz/fx8Rng4AAwIiGnjmqtra2+vr4rV65saGgoKyubMmWKQCCQK/61ZcuWv/zlLxKJ5NixY48fP37x4sWCBQvu3r0bERFx9+7dhoaGDz744MCBA0qUtXr+/Hl2dvaKFSukawZeZeyjjz6aO3ducXGxh4eHs7PzJ598MpAXLjds2EAIkX2e69NPP922bZvSAwLAyIacOqpVVlY2Nzc7Ozuz2Wxzc/O0tLRx48Z1t7GTkxOHwxk7duzq1asJITY2NuPGjeNwOPQjuEqUQNm3b9//+3//b8yY//0SDrzKmI6Ozs2bN//7v/976tSpv/zyS3h4+LRp0/79738rN9oHH3ygq6v79ddf0xMUVFRU3LlzZ82aNUqHBwAjG+rSjGp2dnZmZmbr1q0LCwsLDg6eNGlSX3rRVcak5a7odwb6O51sdXX1pUuXDhw40L+I+0BTU5PH4/F4vIKCgn379qWnpwcEBDx8+FCJRzENDQ3XrFnz5ZdfpqSk/OEPfzh06NDGjRu1tLToGdL75dChQ+fPn+9vr+ElPz+fEBIQEKDqQABUBuepo5qOjs7333/v4eERFxdnZ2cXFBQkN2Pc4Nm/f/+HH35IV6McJG+88cY//vGP0NDQurq6GzduKDcI/aTS559/3tjYeP78efpqMACAQjhPHe2cnZ0vX75cV1eXkJCwb98+Z2fngVx67aMXL16cOXNG9tmfgcjJyfnpp5+2bt1KCFmxYkVqaqr0VRlCyHvvvXfs2DE+n6/c4K6urvPnz8/Pzw8JCQkICFD6vcOtW7euWrVKub7DBX2GOuJPx5lFUZSqQwAm4Tx1VKuurqbrRJqamu7du3f27NlyZSMHyf79+9etW2diYsLIaD/99JOuri79746ODrlDoDP3QGYzp09VL1y4QKdtAIDuIKeOatXV1Rs2bHjw4IFAILh79+6TJ0/oiptyxb+Y3WlNTc3x48cV5qf+VhkTCoU1NTXZ2dnSnEoI8ff3P3fuXGNjY1NTU0ZGxo4dO/z8/AaSU1etWjVu3Dh/f387OzulBwGAUUElM/fDICG91bj49NNP6TrJurq6y5cvr6ysdHNzMzY21tDQGD9+/M6dO0UikUQiKSwsnDhxoo6OjoeHR0REBD1PwqRJk3Jzc/ft22doaEgIMTc3P336dEpKCj2gsbHx2bNn+xLktm3b1q1bp7DpypUr+vr6e/bs6dp08eJFer5AhS5evEhvdu3atcDAQHt7e21tbS0tLUdHx+jo6Pb2dtmhmpubFyxYQJ8ljxkzxsHBIS4uruuOxo0bt3nzZnrlRx99dPPmTfrfH3/8MT3p3ZgxY5ycnHJzc3s95F4/l5Ghj3VpQNYo+W6MHpREUdlCGKYoikpNTR3x9+2GnVHyueB+qhJGyXdj9MC1XwAAAGYgpwJjHjx40EMZNZVUsgR1dv369YiICLFY7O/vb2Njw2azrays/Pz8SkpK+j6IWCw+dOiQciUfeuibl5fn7u7O4XAsLS3Dw8M7Ojr60nrp0qX9+/cPl0K2MBiQU4ExU6dO7eE2Q0pKiqoDBDWya9eupKSkyMhIsVicm5t75syZhoaGvLy8tra2BQsWVFdX92WQsrKyBQsWbNu2TYl3pXroW1pa6uPj4+3tXVdXd/HixePHj4eGhval1dfXl81me3t7NzY29jceGBmQUwGGPQZr8w1emT9Z+/btS0lJOXfuHF2kiMvlenh4cDgcW1vbuLi4pqamr776qtdBiouLd+zYERoa6urq2t8Aeu67e/duCwuLmJgYXV1dLpcbHh7+1VdfSWff7Lk1LCxs5syZS5YskU40BqMKcirAsMdgbb7BK/MnVV5eHhUVFRMTQ8+ixWKxpMX4CCH0C0uPHj3qdZyZM2empaWtXbtWW1u7vzH00FckEmVmZnp5eUlnY1i8eLFEIsnIyOi1lRYdHV1UVJSYmNjfqGAEQE4FUAsSiSQhIWHatGna2trGxsbLli2TnvrweDwtLS36BR5CyKZNm3R1dSmKqq+vJ4TI1eZLSkpis9lmZmYbNmywtLRks9lubm4FBQVKDEWYqL7XVVJSkkQi8fX1VdhKz45pYGDA4B77paKi4vXr1zY2NtI19LtV9F3enltpxsbGXl5eiYmJeKtiFEJOBVAL0dHRERERO3furK2tzcnJefbsmaenZ01NDSEkKSlJ9l2LI0eOxMTESBflavPxeLzg4GA+nx8WFlZZWVlYWCgSiRYtWvTs2bP+DkWYqL7XVWZmpqOjY3fF4W/fvk0I8fDwYHCP/fLixQtCCH1RmsZms3V0dOjPoudWqVmzZj1//lyJAogw3CGnAqheW1tbQkLC8uXL161bZ2ho6OLi8vnnn9fX13/xxRfKDchisehTXicnp6NHj7a0tJw4cUKJcQZefU9Oa2vr48ePFU7fUVNTk5KSEhYWxuVyuzuLHQL0Q7waGhqyKzU1NekT6J5bpSZPnkwIuXfv3mBHC+oGc+gDqF5paenr16/nzp0rXTNv3jwtLS3pNduBmDt3LofDUaLA7WCora2VSCQKT1K5XG5ra+uqVav27NlDFxBUCfour9wTRgKBQEdHp9dWKfoA5U5eYTRATgVQPfrVCz09PdmVRkZGLS0tjIyvra1dV1fHyFAD1N7eTghR+FSRmZlZcnKys7PzkAf1f9A3m5ubm6Vr+Hx+e3u7paVlr61SdIqlDxZGFVz7BVA9IyMjQohcBm1sbLS2th744EKhkKmhBo5ONgpnRTA1NaV/Dqpla2urr6//5MkT6Rr61jJdhqHnVim6ar3cySuMBjhPBVC96dOn6+np/fjjj9I1BQUFAoFgzpw59CKLxVK6QFB2drZEIqErDg1wqIEzMzOjKKqpqalrk+wbNSrEYrGWLFmSk5MjFovHjBlDCMnKyqIoir7F23OrFH2AdHkJGFVwngqgemw2e/v27RcvXjx16lRzc/O9e/dCQ0MtLS1DQkLoDRwcHBoaGtLT04VCYV1dnex5ElFUm08sFr969UokEpWUlGzZssXGxiY4OFiJofpbfa9XHA7Hzs6uqqpKbn15ebm5uXlgYKDsyqCgIHNz88LCQiV2NJC+UVFRNTU1u3btam1tvXXr1oEDB4KDgx0dHfvSSqMP0MXFRYm9w7CGnAqgFnbt2hUfHx8bGztu3DgvL69JkybJ1oXduHHjwoULV69e7ejouHv3bvqiIpfLpd+QCQ0NNTMzc3JyWrJkSUNDAyGkvb3dxcVFR0fH09NzypQpN27ckN7C7O9QjFu6dGlpaancg7IKX+UUCAS1tbWy0ynIys/P9/DwGD9+fEFBQXFxsaWlpbu7e05OzsD7Ojs7X7169dq1a2PHjl2xYsX69euPHTsm7dtzK+3OnTtWVlYDqdoLw9XglpKDoUVQi1EtDfHnEhISYmJiMmS7k+pj/dSysjIWi3Xy5Mlet+zs7PT09ExOTlYimIH0HaD6+no2m33w4MG+bIzf2REG56kAI5A6l0ZxcHCIjY2NjY19/fp1D5t1dnamp6e3tLQoUdFoIH0HLjo62tXVlcfjDf2uQeWQUwFgqEVERAQEBAQFBSl8WImWnZ2dlpaWlZXV3YxLPRhI3wFKSEgoKiq6cuWKCl+xBRVCTgUYUSIjI0+cONHU1GRra3vhwgVVh9OtuLg4Ho+3d+/e7jbw9vY+ffq0dGrifhlI34HIyMjo6OjIzs42NjYe4l2DmsC7NAAjSnx8fHx8vKqj6BMfHx8fHx9VR8EkPz8/Pz8/VUcBqoTzVAAAAGYgpwIAADADORUAAIAZyKkAAADMQE4FAABgBiVRNCUYDFMURak6BADon9TU1FWrVqk6CmAG3qUZUVJTU1UdAgyKwMDALVu2cLlcVQcCzHNzc1N1CMAYnKcCDAMU9f/bu/ewKKt9D+BrYBiG4S4BIohyUQxE1LQaLpKHR1NJ8ZJcjlbsjj2KPYFpHfKWiuJl2xYeTOuxiGprgGmPd6qntqSejWSHRKVMQfHGFlDuzCAzzHv+WE/vmT0M79zeuYjfz1/Oe1nvWmsW8/O9rZ8AZzMAtg/3UwEAAPiBmAoAAMAPxFQAAAB+IKYCAADwAzEVAACAH4ipAAAA/EBMBQAA4AdiKgAAAD8QUwEAAPiBmAoAAMAPxFQAAAB+IKYCAADwAzEVAACAH4ipAAAA/EBMBQAA4AdiKgAAAD8QUwEAAPiBmAoAAMAPxFQAAAB+IKYCAADwAzEVAACAH4ipAAAA/EBMBQAA4AdiKgAAAD8QUwEAAPiBmAoAAMAPxFQAAAB+IKYCAADwAzEVAACAH4ipAAAA/EBMBQAA4AdiKgAAAD+E1q4AAGhRXFzc2dmpvuSHH35oa2tjP86bN8/b29vi9QIALgKGYaxdBwDQlJ6e/sUXXzg4ONCP9O9UIBAQQvr6+lxcXJqamhwdHa1ZRQDoB9d+AWxRWloaIUTxJ6VSqVQq6b/t7e0XLlyIgApgg3CeCmCLlEqlr69vS0uL1rU//vjjf/zHf1i4SgCgE85TAWyRUChMS0tjr/2qe+qpp+Lj4y1fJQDQCTEVwEalpaUpFAqNhQ4ODq+88oq9vb1VqgQA3HDtF8BGMQwTGBh49+5djeU///zz5MmTrVIlAOCG81QAGyUQCBYvXqxx+Xf48OGTJk2yVpUAgBtiKoDt0rj86+DgkJ6eTt+oAQAbhGu/ADZtzJgxf/zxB/vxypUrERERVqwPAHDAeSqATXvllVfYy7/h4eEIqAC2DDEVwKYtXrxYqVQSQhwcHF577TVrVwcAuODaL4CtmzRp0v/+7/8KBIL6+vrAwEBrVwcABoTzVABb9+qrrxJCnnvuOQRUABv3b3lpKioqdu3aZa2qAIBWPT09AoHg0aNHCxcutHZdAODfSKXSlStXsh//7Tz1zp07hw4dsniVAICLWCz29fUNCAiwdkWeUOfPnz9//ry1a2F2d+/exe+/oc6fP19RUaG+REv+1K+//tpS9QEAvdTW1oaGhlq7Fk8oenlg0P8wHjx4MCUlZdA3k1/9Lx3hfirAYwABFeCxgJgKAADAD8RUAAAAfiCmAgAA8AMxFQAAgB+IqQAA/Dt16pS7u/vx48etXRFz+eGHH1avXq1SqebNmxcYGCgWi/39/ZOSki5duqR/ISqVKi8vLzo62ogKcOx77ty5mJgYiUTi5+eXnZ396NEjfdYeO3Zsx44dfX19RlSGhZgKAMC/wT3t64YNGwoKCtasWaNSqc6ePfvVV1+1tLScO3dOLpdPmTKloaFBn0KuX78+ZcqUlStXymQyQyvAsW9NTc306dMTEhKam5u/+eabzz77LCMjQ5+1c+bMEYvFCQkJbW1thtbn/zFqSktLNZYAADzhXn755ZdfftnatRiQTCaTSqWml6P/7/+2bdtGjx4tl8sZhlEoFC+99BK76ueffyaE5Obm6izk4sWL8+fP379///jx46OiogyqKve+KSkpQUFBKpWKfty5c6dAIPj999/1WcswTGZmplQqVSgU+tSk/9jAeSoAwGOssLCwqanJYoerra1dv379pk2bxGIxIUQoFKpf3w4ODiaE1NXV6SwnKirq8OHDixYtcnR0NLQOHPsqlcqTJ0/Gx8cLBAK6ZObMmQzDHD16VOdaauPGjRcvXszPzze0VhRiKgAAz86dOxcYGCgQCD788ENCyN69e52dnSUSydGjR2fOnOnm5hYQEFBcXEw3LigoEIvFPj4+y5Yt8/PzE4vF0dHRlZWVdG1mZqZIJBo6dCj9+Oabbzo7OwsEggcPHhBCVqxYsWrVqrq6OoFAQCcG+fbbb93c3HJzc83UtIKCAoZh5syZo3WtXC4nhLi5uZnp6DrduHGjq6tLPdtESEgIIYTe5eVeS3l6esbHx+fn5zNGXb1HTAUA4FlsbOw///lP9uPy5cvffvttuVzu6upaWlpaV1cXHBz8xhtvKBQKQkhmZmZ6erpMJsvKyqqvr6+qqlIqldOmTbtz5w4hpKCgIDk5mS1qz549mzZtYj/m5+fPnj07JCSEYZja2lpCCH3ERqVSmalpJ0+eDAsLk0gkWtfSa7+xsbFmOrpO9+/fJ4S4urqyS8RisZOTU2Njo861rAkTJty7d6+6utqICiCmAgBYSHR0tJubm7e3d2pqand39+3bt9lVQqHw6aefdnR0DA8P37t3b2dnZ1FRkRGHSExM7OjoWL9+PX+1zprx5wAAIABJREFU/n/d3d03b96k53YaGhsbS0pKsrKypFLpQGexFkAf4rW3t1df6ODgQE+gudeyRo0aRQi5fPmyERXQMoc+AACYlUgkIoTQ89T+Jk2aJJFIrl69atlK6dbU1MQwjNaTVKlU2t3dnZycvGXLFgcHB8vXjaJ3eZVKpfrC3t5eJycnnWtZtIEaJ696QkwFALA5jo6Ozc3N1q6Fpp6eHkKI1qeKfHx8CgsLIyIiLF6pf0NvPHd0dLBLZDJZT0+Pn5+fzrUsGmJpYw2Fa78AALZFoVC0tbXZYMZcGmy0zorg7e3t4eFh8RppCgoKcnV1vXXrFruE3mYeN26czrWs3t5e8mdjDYXzVAAA21JeXs4wzPPPP08/CoXCga4SW5iPj49AIGhvb++/ykZmjBIKhbNmzTpz5oxKpbKzsyOElJWVCQQCeouXey2LNtDX19eICuA8FQDA+lQqVWtrq1KpvHTp0ooVKwIDA9PT0+mq0NDQlpaWI0eOKBSK5uZm9dMsQsiQIUMaGhrq6+s7OzsVCkVZWZn53qWRSCTBwcF3797VWF5bW+vr65uSkqK+MDU11dfXt6qqyogDmbLv+vXrGxsbN2zY0N3dXVFRsXPnzvT09LCwMH3WUrSBkZGRRhwdMRUAgGcffvjh5MmTCSHZ2dlJSUl79+7Ny8sjhIwbN+7GjRuffPLJqlWrCCEzZsy4fv063aWnpycyMtLJySkuLm706NGnT59mb1suX7586tSpaWlpYWFhmzdvptckpVIpfdkmIyPDx8cnPDx81qxZLS0t5m5aYmJiTU2NxoOyWl/l7O3tbWpqUp9OQd358+djY2OHDRtWWVlZXV3t5+cXExNz5swZ0/eNiIj47rvvvv/+ey8vrwULFrz++usfffQRuy/3WurChQv+/v4aF4T1pT6pEuYmBADQYIG5CZcuXTpkyBCzHkInPX//r1+/LhQK//73v+vcsq+vLy4urrCw0IjKmLKviR48eCAWiz/44AN9NsbchAAAtsjEdCgWExoampOTk5OT09XVxbFZX1/fkSNHOjs7U1NTDT2EKfuabuPGjePHj8/MzDRud8RUAAAwwOrVqxcuXJiamqr1YSWqvLz88OHDZWVlA824xMGUfU20a9euixcvnjp1yuhXbHmIqdZNE7hkyRJXV1eBQHDx4kUe66NeyOTJk+3t7cePH89DdfXTv1HctmzZIvh3Y8eO7b8ZzXdo4rEsgKM5hiY4TE1NFXA6ceIE7wP48OHDwcHB6kcRiUQ+Pj4vvPDCzp07W1tb1Tce3MOVDjmDOsTceMmRya81a9YUFRW1t7cHBQUdOnTI2tXRS25ubmZm5rZt2wbaICEh4cCBA+w0xQYxZV9THD169NGjR+Xl5Z6enkYXwkNMZayaJvDTTz/95JNP1JfwUh/1Qi5cuDB16lTTy9Rf/0aZjs13aIFjmY8RCQ6///77trY2hULxr3/9i5bQ29vb3d3d1NT0xhtvEDMM4AULFty4cSMkJMTd3Z1hGJVK1dTUdPDgwaCgoOzs7IiIiF9++YXdeBAPV3bIGdQh5sZPjkxebd269dGjRwzD3Lx58+WXX7Z2dfQ1ffr07du3W7sWfEpKSlq9erXGzIWGMiamyuVy9dTqiYmJ7e3ts2fPNqUePNKnPhpN0KcQNjeQoXQeixcajwxcuXJFfe327dtLSkoOHjyoPnm0LeNoTlZWVlRU1KxZszQmGNNKIBDExMS4u7sLhUJ2iYODg0Qi8fb2fuaZZ4j5B7BAIPDw8HjhhReKiooOHjzY2NhIj0jXDtbhyjHkuDvEAgwaQgAGMSamWjhdn05G/HwY0QSjL68b111G/yb2p5Hv0KzHsgz9ExwWFxdz3JJZunTpSy+9xGvVdHj55ZfT09Obmpo+/vhj/fd67IarziHHMq5DTGdijkyAgRgcUzXS9WmkCczPz3d2drazs3vmmWd8fX0dHBycnZ0nTpwYFxc3fPhwsVjs4eHx3//932xpfX1977//fmBgoJOT07hx4+jD3DoxDLNz586wsDBHR0d3d/d3332XXaVRH0LITz/99Oyzz0okEjc3t8jIyI6ODo0m/PWvf5VIJK6urk1NTatWrfL39y8sLNQohBBSW1s7ZswYZ2dn+gLZuXPn6HJDsxsO1GSORpmof75D7mNprSF3Akit/czRWBNpJDg0JWGk5QcwfZG/rKys/9HJYBmu3Ck2OTpkoCPyPvxMzJEJMCD1K2x6vp+0YMECmq6Pou8d7969m37csGEDIaSysrK7u/vBgwczZswghJw8ebK5ubm7u5s+oHzx4kW68TvvvOPo6Hjo0KHW1tY1a9bY2dlduHBBZwXWrl0rEAj+9re/tba2ymSyPXv2EEJ+/fXX/vXp6upyc3PbsWOHXC6/f//+/Pnzm5ub+zdh7dq1hJCsrKzdu3fPnz//999/12hUQkJCcHDwzZs3FQrFlStXnnvuObFYfO3aNbp20aJFvr6+bGk7d+4khNAD9T/WQE3mbhS3zZs3BwQEeHh4ODg4jBw5Mikp6eeff2bXBgcHh4eH69+BHDUkhPz444/t7e1NTU1xcXHOzs69vb0c/Wzc98vdHIo+bEXrfOLECVdX15ycHO5i6f3UpKQkjeVmGsDs7UMN9Od++PDh/Y8+aIZr/yGnf4dYbPipDyFuFng/1RZgfgIj9B8b5oqpnZ2d9OMXX3xBCLl8+TL9SDPWlpSUMAwjl8slEklqaipdJZPJHB0dly9fzn10mUwmkUimTZvGLqH/XdUaU+l9uBMnTnA3gf65yuXygRqVkJAQFRXFrqVJ4d955x36Uf8fqYGarLNR3G7fvl1VVdXZ2fno0aOKiooJEyY4OTlduXKFYZiuri6BQDB79mw9O5DjS9HoJfozWltbO1A/G/f9cjeH9dlnnxFCvvzyS336hzIoppo+gAcKIQzD0BuK/Y8+OIZr/yGnf4dYcvjpP4QQU2EgVpjzgaYJZJ8FoLd56HzQf/zxh0wmY1+TcHJyGjp0qM6UgbW1tTKZLCEhQZ+jBwcH+/j4LF68eOPGjfX19cY2QlNkZKS7uzv9qTLIQE02qFH9DR8+fMKECS4uLiKR6Pnnny8qKpLL5fRHp3++Q+5j6f+lqCeA1NrPxn2/3M1hmZLg0CC8D+Du7m6GYdzc3PqvGhzDlSPFplbqHWLJ4WfQEDp06BD3S1mDAJ2t19q1eMz0f/fJmnlpuru7CSHr1q1bt24du1Ajj11/dHZjb29vfQ7h5OT0j3/847333svNzc3JyUlOTi4qKjIug48GBwcHIzJFDNRkgxqlU2RkpL29/bVr14i2fIfcxzLuS9Haz8YVxd0c9SMSYxMc8sW4BtKGjBkzpv+qwTFcOVJsaqXeIZYcfgYNoeeff/7tt9/Ws0WPqYqKivz8fL4eenhC0Gmc1VkzptK/yby8vBUrVui/F32S8NGjR3puHxERcfz48ebm5l27dm3fvj0iImL9+vVG1FadUqlsaWkJDAw0dMeBmnz69GliSKO4qVQqlUpFf9T65zvk7kDjvhSirZ/pvGJGFKVBvTksUxIc8sW4vvr2228JITNnztS6dhAMV44Um1qpd4glh59BQyggICA5OdmgKj2O8vPzn4Rm8ujrr7/WWGLNuQnpg5SGTt8zduxYOzu7n376SZ+NGxoafvvtN0KIt7f3tm3bJk6cSD+a6PTp0yqVauLEifSj/tkNB2qyQY3q78UXX1T/SB/EkEqlRFu+Q+5jGfelaO1n44ribg7LlASHfDGigffv38/LywsICHj99df7rx0cw5UjxWZ/Gh1iyeFnC0MIBh9jYqpGuj6jjy0Wi//yl78UFxfv3bu3o6Ojr6/v7t279EESDt7e3gsWLDh06FBhYWFHR8elS5f27ds30MYNDQ3Lli27evVqb2/vr7/+euvWLZrm14gm9Pb2tre3K5XKqqqqzMzMESNGGJHd0N7eXmuTDWpUf/fu3SspKaGzBVVUVCxZsiQwMDAjI4Noy3fIfSzjvhSt/WxcUdzNYaknODRrwkgOOhvIMExXV5dKpWIYprm5ubS0NCYmxt7e/siRI1rvpw6O4TpQik19OsSSw8+UHJkAA1J/YEnP576qqqpGjBjh5OQUGxu7bt06+q6bRCKZM2dOfn4+vfM/cuTIs2fPbt++3d3dnRDi6+t74MCBkpIS+r9CT0/P4uJihmEePXqUnZ0dGBgoFArpH2pNTY3OCnR2di5ZssTLy8vFxSU2Nvb9998nhAQEBFRXV+/evVu9PvX19dHR0Z6envb29sOGDVu7dq1SqdRowsqVK+n1n+HDh9PpezQKYRimqKho6tSpPj4+QqHQy8srLS3t1q1bbH0ePnw4depUsVgcFBT01ltv0Xf1QkNDb9++rXGs+/fvD9Rkjkbp7JBVq1aFhIQ4OzsLhcKAgIA33nijoaGBXZuZmeng4CCTyfTpwIG+lD179tBvdtSoUXV1dfv27aM/giNGjLh27dpA/Wzc98vdHCoxMdHf35/+Op86dcrV1XXLli0DFdjR0TFlypQhQ4YQQuzs7EJDQ3Nzc+kqje+alwF87NixcePGSSQSkUhkZ2dH/pw56Nlnn83JyXn48CFbscE6XDWGnP4dYsnhpz6EuOG5XxgIP+/SwONF/3yHjwuDEhyC5dn+kDMxR+aghN9/IyB/6pNIz3yHjxETExyCudn+kMMQAjOxuZh69epVjpeBrJKi1rp46RB98h1ahunNMT3BIViA7Qy5/jCEzIHm9VOpVPPmzQsMDBSLxf7+/klJSQa9GK1SqfLy8gzN4qAz2eW5c+diYmIkEomfn192djb7yLo5Ev/ZXEwdM2YMx4l2SUmJtStoaXx1iM58h5ZhYnN4SXAIlmEjQ04DhpA5sHn9VCrV2bNnv/rqq5aWlnPnzsnl8ilTpjQ0NOhTyPXr16dMmbJy5UqZTMZj3WpqaqZPn56QkNDc3PzNN9989tln7AOPZkn8p/6LhuvpAAAaLHA/VSaTSaVS6xZl9O//tm3bRo8eTaeNVCgUL730EruKzuXJPhLI4eLFi/Pnz9+/f//48ePVZ9bUx+bNmzlu3qekpAQFBbEPo+3cuVMgEPz+++/sBpmZmVKpVKFQGHRQCvdTAQBsDo8JNC2ci1Mjr59QKDx+/Di7Njg4mBBSV1ens5yoqKjDhw8vWrRI/xm49KFUKk+ePBkfHy/4Mx3hzJkzGYY5evQouw2/if8QUwEAeMAwzK5du55++mlHR0dPT8+5c+ey0wsblGKvoKBALBb7+PgsW7bMz89PLBZHR0dXVlYaURQxLROiPrjz+snlckKI1rexLePGjRtdXV3qk4iFhIQQQtTv8vKb+A8xFQCABxs3bly9evXatWubmprOnDlz586duLg4Okd/QUGB+px/e/bs2bRpE/sxPz9/9uzZNB1QbW1tZmZmenq6TCbLysqqr6+vqqpSKpXTpk2j2YcMKor8OUmkSqUyU6tPnjwZFhY2UMoEeu03NjbWTEdnrV692tPTUyQSBQUFzZ0798KFC3T5/fv3CSGurq7slmKx2MnJSSN3woQJE+7du1ddXW16TRBTAQBMJZfLd+3aNX/+/MWLF7u7u0dGRn788ccPHjwwaEI0dUKhkJ7yhoeH7927t7Ozs6ioyIhyEhMTOzo6TJ81Wqvu7u6bN2/SMz8NjY2NJSUlWVlZUqlUz+z0RnvttdeOHTt2586drq6u4uLi27dvx8fH19TUkD9npba3t1ff3sHBgZ5As0aNGkUIuXz5sumVQUwFADBVTU1NV1fXpEmT2CWTJ08WiUTsNVtTTJo0SSKR6JMn0cI48vpJpdKsrKy5c+eWlZWZ+50ljuyQ9C4vm6uR6u3t1cidwGPuSGvmpQEAGBzoyxguLi7qCz08PDo7O3kp39HRsbm5mZeieMSR18/Hx6ewsDAiIsLilfq37JD0xnNHRwe7ViaT9fT0aCQQ5DF3JM5TAQBM5eHhQQjRiKBtbW0BAQGmF65QKPgqil8cef28vb1pn1ieenbIoKAgV1dX9UQR9DbzuHHj1HfhMXckYioAgKnGjh3r4uLyyy+/sEsqKyt7e3ufeeYZ+lH/FHv9lZeXMwxDkxSZWBS/OPL6HT9+3N/f3zLV4MgOKRQKZ82adebMGfYprbKyMoFAoHGLl8fEf4ipAACmEovFq1at+uabb/bv39/R0XH58uWMjAw/P7+lS5fSDfRPsUfjpUqlam1tVSqVly5dWrFiRWBgoBHZ+hQKhVkzIQ6U16+2ttbX1zclJUV9YWpqqq+vb1VVlREH4t6XOzvk+vXrGxsbN2zY0N3dXVFRsXPnzvT09LCwMPUSeEz8h5gKAMCDDRs2bN26NScn56mnnoqPjx85cmR5ebmzszNdu3z58qlTp6alpYWFhW3evJleZpRKpfQNmYyMDB8fn/Dw8FmzZrW0tBBCenp6IiMjnZyc4uLiRo8effr0afa2paFFmVViYmJNTY3GY7RaX/Ts7e1tampSn2xB3fnz52NjY4cNG1ZZWVldXe3n5xcTE3PmzBl99p0xY8a6desCAgIkEklycnJMTMz58+e9vLzo2oiIiO++++7777/38vJasGDB66+//tFHH2mUcOHCBX9/f40LwkZSn1QJcxMCAGiwfK63pUuXDhkyxJJHZIz9/dc/r19fX19cXFxhYaERdTNlX51MyR2JuQkBAB4D/CZLMR898/r19fUdOXKks7PTiNxipuyrD34T/yGmAgCA8fTJ61deXn748OGysrKBZlziYMq+OvGe+A8xFQDAhqxZs6aoqKi9vT0oKOjQoUPWro5edOb1S0hIOHDgADtNsUFM2ZebORL/Yc4HAAAbsnXr1q1bt1q7FgabPn369OnTrV0LwyQlJSUlJfFbJs5TAQAA+IGYCgAAwA/EVAAAAH4gpgIAAPBDyzNKBw8etHw9AABsE524btD/MFZUVJAnoJn8unv3rmZuA/UJIOg8GgAAAKAPjXmUBIy2iRkBwKYIBILS0tLk5GRrVwQAuOB+KgAAAD8QUwEAAPiBmAoAAMAPxFQAAAB+IKYCAADwAzEVAACAH4ipAAAA/EBMBQAA4AdiKgAAAD8QUwEAAPiBmAoAAMAPxFQAAAB+IKYCAADwAzEVAACAH4ipAAAA/EBMBQAA4AdiKgAAAD8QUwEAAPiBmAoAAMAPxFQAAAB+IKYCAADwAzEVAACAH4ipAAAA/EBMBQAA4AdiKgAAAD8QUwEAAPiBmAoAAMAPxFQAAAB+IKYCAADwAzEVAACAH4ipAAAA/EBMBQAA4AdiKgAAAD8EDMNYuw4AoGnp0qV//PEH+7GqqiooKMjT05N+tLe3/+KLLwICAqxUOwDQTmjtCgCAFr6+vvv27VNfcunSJfbfwcHBCKgANgjXfgFs0X/+538OtEokEqWnp1uwLgCgL1z7BbBRY8eO/e2337T+hf7xxx+jR4+2fJUAgBvOUwFs1Kuvvmpvb6+xUCAQREVFIaAC2CbEVAAblZaW1tfXp7HQ3t7+tddes0p9AEAnXPsFsF3R0dGVlZUqlYpdIhAI7ty54+/vb8VaAcBAcJ4KYLteeeUVgUDAfrSzs4uNjUVABbBZiKkAtmvhwoXqHwUCwauvvmqtygCAToipALbrqaeeSkhIYJ9UEggE8+bNs26VAIADYiqATVu8eDF96MHe3v7FF1/08vKydo0AYECIqQA2bf78+SKRiBDCMMzixYutXR0A4IKYCmDTnJ2dX3rpJUKISCSaPXu2tasDAFwQUwFs3aJFiwgh8+bNc3Z2tnZdAIATw8natQMAALAhpaWlHEFTd16aFStWSKVSC1QUAAayf//+1NRUoRCJpKyvoqIiPz+/tLTU2hUxu5SUFPz+a0hJSeHeQMc8SgKBoLS0NDk5mddaAYBhenp6xGKxtWsBhBBy8ODBlJSUJ+EyHn7/+9PZJ7ifCvAYQEAFeCwgpgIAAPADMRUAAIAfiKkAAAD8QEwFAADgB2IqAIDZnTp1yt3d/fjx49auiLn88MMPq1evVqlU8+bNCwwMFIvF/v7+SUlJly5d0r8QlUqVl5cXHR1t0KG3bNki+Hdjx45V3+DcuXMxMTESicTPzy87O/vRo0d0+bFjx3bs2NHX12fQ4bghpgIAmN3gfvdmw4YNBQUFa9asUalUZ8+e/eqrr1paWs6dOyeXy6dMmdLQ0KBPIdevX58yZcrKlStlMhmPdaupqZk+fXpCQkJzc/M333zz2WefZWRk0FVz5swRi8UJCQltbW18HQ4xFQDA7BITE9vb2y0wY7NcLjf0PM9E27dvLykpOXjwoKurKyFEKpXGxsZKJJKgoKDc3Nz29vbPP/9cZyHV1dXvvfdeRkbG+PHjjajD3//+d/XJjK5cucKu2rx589ChQzdt2uTs7CyVSrOzsz///POrV6/StVlZWVFRUbNmzVIqlUYctz/EVACAwaOwsLCpqclih6utrV2/fv2mTZvoK9RCoVD9+nZwcDAhpK6uTmc5UVFRhw8fXrRokaOjI4/VUyqVJ0+ejI+PFwgEdMnMmTMZhjl69Ci7zcaNGy9evJifn8/LERFTAQDM69y5c4GBgQKB4MMPPySE7N2719nZWSKRHD16dObMmW5ubgEBAcXFxXTjgoICsVjs4+OzbNkyPz8/sVgcHR1dWVlJ12ZmZopEoqFDh9KPb775prOzs0AgePDgASFkxYoVq1atqqurEwgEoaGhhJBvv/3Wzc0tNzfXTE0rKChgGGbOnDla18rlckKIm5ubmY6u040bN7q6ugIDA9klISEhhBD1u7yenp7x8fH5+fm8XJ9HTAUAMK/Y2Nh//vOf7Mfly5e//fbbcrnc1dW1tLS0rq4uODj4jTfeUCgUhJDMzMz09HSZTJaVlVVfX19VVaVUKqdNm3bnzh1CSEFBgfrEeHv27Nm0aRP7MT8/f/bs2SEhIQzD1NbWEkLoAzgqlcpMTTt58mRYWJhEItG69ueffyaExMbGmunorNWrV3t6eopEoqCgoLlz5164cIEuv3//PiGEXpSmxGKxk5NTY2Oj+u4TJky4d+9edXW16TVBTAUAsI7o6Gg3Nzdvb+/U1NTu7u7bt2+zq4RC4dNPP+3o6BgeHr53797Ozs6ioiIjDpGYmNjR0bF+/Xr+av3/uru7b968Sc/8NDQ2NpaUlGRlZUml0oHOYvny2muvHTt27M6dO11dXcXFxbdv346Pj6+pqSGE0Ed87e3t1bd3cHCgJ9CsUaNGEUIuX75semUQUwEArEwkEhFC6Hlqf5MmTZJIJOxjNbajqamJYRitJ6lSqTQrK2vu3LllZWUODg5mrcbw4cMnTJjg4uIiEomef/75oqIiuVy+Z88e8udE2RrPH/X29jo5OakvoU3QOHk1DlJHAQDYOkdHx+bmZmvXQlNPTw8hROtTRT4+PoWFhRERERavFImMjLS3t7927RohhN547ujoYNfKZLKenh4/Pz/1XWiIpc0xEc5TAQBsmkKhaGtrCwgIsHZFNNFQpHXOBG9vbw8PD4vXiBBCVCqVSqWikT4oKMjV1fXWrVvsWnqbedy4ceq79Pb2kj+bYyLEVAAAm1ZeXs4wzPPPP08/CoXCga4SW5iPj49AIGhvb++/6vjx4/7+/papxosvvqj+8cKFCwzD0FTqQqFw1qxZZ86cYZ/SKisrEwgEGrd4aRN8fX1NrwxiKgCAzVGpVK2trUql8tKlSytWrAgMDExPT6erQkNDW1pajhw5olAompub1U/CCCFDhgxpaGior6/v7OxUKBRlZWXme5dGIpEEBwffvXtXY3ltba2vr29KSor6wtTUVF9f36qqKiMOxL3vvXv3SkpK2traFApFRUXFkiVLAgMD2cmS1q9f39jYuGHDhu7u7oqKip07d6anp4eFhamXQJsQGRlpRN00IKYCAJjXhx9+OHnyZEJIdnZ2UlLS3r178/LyCCHjxo27cePGJ598smrVKkLIjBkzrl+/Tnfp6emJjIx0cnKKi4sbPXr06dOn2duWy5cvnzp1alpaWlhY2ObNm+kVS6lUSl+2ycjI8PHxCQ8PnzVrVktLi7mblpiYWFNTo/EYrdYXPXt7e5uamtQnW1B3/vz52NjYYcOGVVZWVldX+/n5xcTEnDlzRp99Z8yYsW7duoCAAIlEkpycHBMTc/78eS8vL7o2IiLiu++++/777728vBYsWPD6669/9NFHGiVcuHDB399f44KwkRhOhJDS0lLubQAAnhylpaU6fzlNtHTp0iFDhpj1EPrQ5/f/+vXrQqFQY2pArfr6+uLi4goLC42oiSn76vTgwQOxWPzBBx/os7HOPsF5KgCAzeE3WYr5hIaG5uTk5OTkdHV1cWzW19d35MiRzs7O1NRUQw9hyr762Lhx4/jx4zMzM3kpjf+Yat2URkuWLHF1dRUIBBcvXuSxPuqFTJ482d7e3riJno3Tv1E6KRSKrVu3hoaGikQiDw+PsWPH1tfXa2xDczOZfiwLGKg5hqZqSk1NFXA6ceIE7wP48OHDwcHB6kcRiUQ+Pj4vvPDCzp07W1tb1Tce3MOVDjmDOsTczJHt60mzevXqhQsXpqaman1YiSovLz98+HBZWdlAMy5xMGVfnXbt2nXx4sVTp07x9RIt/zGVsWpKo08//fSTTz5RX8JLfdQLuXDhwtSpU00vU3/9G6VTSkrKl19+eeDAAZlM9vvvv4eEhGj8L5LNzWT6sSxgoOYYkarp+++/p88y/Otf/6Il9Pb2dnd3NzU1vfHGG8QMA3jBggU3btwICQlxd3dnGEalUjU1NR08eDAoKCg7OzsiIuKXX35hNx7Ew5UdcgZ1iLmZI9uXidasWVNUVNTe3h4UFHTo0CFrV0cvubm5mZmZ27ZtG2iDhISEAwcOsNMUG8SUfbkdPXr00aNH5eXlnp6evBVq4rVjhmFkMplUKtXnSrRl0Kmof/3D25eTAAAPJ0lEQVT1V/13MbQJCQkJ48ePN7xqxhyLMqhRxcXFAoHg0qVLA22wbdu20aNHy+Vy049lATqbk5mZKZVKFQqFzqLoDHD03zSmJiUlsWs//vjj48ePm15hrdgQou7rr7+2s7Pz8fFpa2vTv6jHcbj2H3I8dojp9B9CjEXup9oIfX7/nzQ6+4SH81QLpxbSic3poz8jmmD0hQLjusugRn300UcTJ04c6LlwjdxMJh7LAribQwxJ1VRcXMxx+Wjp0qUvvfSSkbU0yssvv5yent7U1PTxxx/rv9djN1x1DjmWcR1iOn6zfcETzcSYnJWVRWeqJISEhIScPXt2+PDhhJDdu3czDJOXlyeRSAQCwcSJE318fIRCoUQimTBhQmxsbEBAgKOjo7u7+7vvvsuWplQq169fP3z4cLFYHBkZWVJSos9/HFQq1V//+tfRo0eLRCI3NzdaAfp/ZI36MAxTXl4+efJkJycnV1fXsWPHtre3azRhx44dTk5OLi4ujY2NK1euHDZs2KeffqpRSEJCgqenJ83GIBaLY2Njz549S1e99dZbDg4Ovr6+9OPy5cvpj3hzc3P/7uJoMkejuD169EgkEv3Xf/3XQBu89dZb9vb27OmazmNpreGePXskEomTk9ORI0dmzJjh6urq7+//1VdfsWX272eOxprSHGrGjBn+/v4qlYphmLKyMldX1y1btnDv0v88lek3YHgcwFpPyxiGoW8LxMfH9z86M1iGa/8hp2eHDHREcww/9SHEDeepTzKdfcLDtd8FCxbQvzeKviPF/j1v2LCBEFJZWdnd3f3gwYMZM2YQQk6ePNnc3Nzd3U0ftbp48SLd+J133nF0dDx06FBra+uaNWvs7OzojBjc1q5dKxAI/va3v7W2tspkMjp1Mvv3rF6frq4uNze3HTt2yOXy+/fvz58/n/52aDRh7dq1hJCsrKzdu3fPnz//999/12hUQkJCcHDwzZs3FQrFlStXnnvuObFYfO3aNbp20aJF7I8UwzA7d+5kf6T6H2ugJnM3isPNmzcJIePHj3/hhReGDh3q6Og4ZsyYDz/8kP2xCA4ODg8P178DOWpICPnxxx/b29ubmpri4uKcnZ17e3s5+tmI71dncyj6sBWt84kTJ1xdXXNycrhL1hpTGbMN4IFCCJ2JdPjw4f2PPmiGa/8hp3+HWGz4qQ8hboipTzJbiamdnZ304xdffEEIuXz5Mv1Is+vR/zDK5XKJRJKamkpXyWQyR0fH5cuXcx9dJpNJJJJp06axSzTu5ajX58qVK4SQEydOcDeB/rmq3/vp/yMVFRXFrqXpbd955x36Uf8fqYGarLNRHGi6omnTpv3P//zPw4cP29ra3nvvPULI/v37GYbp6uoSCASzZ8/WswM5vhSNXqI/o7W1tQP1s3HfL3dzWJ999hkh5Msvv9TZPyyDYqrpA3igEMIwjEAg8PDw6H/0wTFc+w85/TvEksNP/yGEmPok09knls5LQy8lsZl36G0eOnflH3/8IZPJxo4dS1c5OTkNHTpUZ3qj2tpamUyWkJCgz9GDg4N9fHwWL16clZWVnp4+cuRIY9vxbyIjI93d3dUTx+tpoCYb1CgNdLKViIiI6OhoumTTpk0fffTRvn37Fi1a1D83E/ex9P9S1JNVae1n475f7uawm/GYqokb7wOYXhF1c3Prv2pwDFeOdGBaqXeIJYefoUPo4MGDem75WKuoqLB2FR4zNpTrrbu7mxCybt26devWsQs1MvL0R+dp9Pb21ucQTk5O//jHP957773c3NycnJzk5OSioiJechE4ODgYMav1QE02qFEaaI89ePCAXSISiUaMGFFXV0e05WbiPpZxX4rWfjauKO7mqB+R8JSqyWjGNZBmpBozZkz/VYNjuHKkA9NKvUMsOfwMHUIak9kOVvn5+Xh0yyA2NI8S/ZvMy8tTP4/W+b8k+iQhTeauj4iIiOPHjzc0NGRnZ5eWln7wwQcmVpsQolQqW1paAgMDDd1xoCYb2ih1Li4uo0aN+u233zRq6O7uTrTlZuI+lnFfCtHWz8YVxd0cFo+pmoxmXAO//fZbQsjMmTO1rh0Ew5UjHZhW6h1iyeFn6BDiuPo3aBBc++1H58CwoZhKn8czdPqesWPH2tnZ/fTTT/ps3NDQQH+dvb29t23bNnHiRI0fa+OcPn1apVJNnDiRftQ/E9NATTaoUf2lpKT8+uuvN27coB9lMtmtW7fouyj9czNxH8u4L0VrPxtXFHdzWDymajKaEQ28f/9+Xl5eQEDA66+/3n/t4BiuHOnA+tPoEEsOP1sYQjAI8BBTNVILGV2OWCz+y1/+UlxcvHfv3o6Ojr6+vrt379IHSTh4e3svWLDg0KFDhYWFHR0dly5d2rdv30AbNzQ0LFu27OrVq729vb/++uutW7doSkIjmtDb29ve3q5UKquqqjIzM0eMGGFEJiZ7e3utTTaoUf2tXLmS1uf27dsPHz7Mzs6Wy+X00Z7+uZm4j2Xcl6K1n40rirs5LPVUTWZNbsVBZwMZhunq6qJPLDc3N5eWlsbExNjb2x85ckTr/dTBMVwHSgemT4dYcvjxmO0Lnmg6z3N1nvtXVVWNGDHCyckpNjZ23bp1dAYpiUQyZ86c/Px8eud/5MiRZ8+e3b59O71k5+vre+DAgZKSEvq/Qk9Pz+LiYoZhHj16lJ2dHRgYKBQK6R9qTU2NzpPxzs7OJUuWeHl5ubi4xMbGvv/++4SQgICA6urq3bt3q9envr4+Ojra09PT3t5+2LBha9euVSqVGk1YuXIlvf4zfPhwmmxBoxCGYYqKiqZOnUpfWPTy8kpLS7t16xZbn4cPH06dOlUsFgcFBb311lvvvvsuISQ0NPT27dsax7p///5ATeZolM4OYRjmzp07aWlpnp6ejo6Ozz77bFlZGbsqMzPTwcFBJpPp04EDfSn0BUFCyKhRo+rq6vbt20d/BEeMGHHt2rWB+tm475e7OVRiYiL7cuGpU6e430/t6OiYMmXKkCFDCCF2dnahoaG5ubl0lcZ3zcsAPnbs2Lhx4yQSiUgksrOzI4TQ51qfffbZnJychw8fshUbrMNVY8jp3yGWHH7qQ4gbnvt9kunsE+R6e+Lon5vpcWFQqiawPNsfcgYNIcTUJ5nOPrGh+6lgGXrmZnqM8JuqCXhn+0MOQwj4Yusx9erVqxyZucyUTs+W8dIh+uRmsgzTm8N7qiYwB9sZcv1hCAGPbD2mjhkzhuMsu6SkxNoVtDS+OkRnbibLMLE5ZknVBOZhI0NOA4aQmdBcuSqVat68eYGBgWKx2N/fPykpyaDJRlQqVV5eHjvfi0G07muJdLkmXjsGAHii4H6qTu+///7s2bM7OjoUCoWXl9fZs2e7u7tv3Lgxbdo0d3f3e/fu6VPItWvXYmJiCCHqM2vqiWPf/Pz8+Pj41tZWQ8ukdPaJrZ+nAgA8aeRyuXEnZ2YtSk/bt28vKSk5ePCgq6srIUQqlcbGxkokkqCgoNzc3Pb29s8//1xnIdXV1e+9915GRsb48eMNrQD3vllZWVFRUbNmzWJnGOUXYioAgG3hMSm1hfNba+TKFQqFx48fZ9cGBwcTQjQmFtUqKirq8OHDixYt0n9WS/33NWu6XMRUAAD+MQyza9eup59+2tHR0dPTc+7cueyU/ZmZmSKRiL5GTAh58803nZ2dBQIBndd6xYoVq1atqqurEwgEoaGhBQUFYrHYx8dn2bJlfn5+YrE4Ojq6srLSiKIIId9++61ZZ0QpKChgGGbOnDla18rlckKI1hlOLMnT0zM+Pj4/P5/RY65BQyGmAgDwb+PGjatXr167dm1TU9OZM2fu3LkTFxdH894UFBQkJyezW+7Zs2fTpk3sx/z8/NmzZ9MUe7W1tZmZmenp6TKZLCsrq76+vqqqSqlUTps2jWb0M6go8ufEyyqVykytPnnyZFhY2EBpiGhuxNjYWDMdXX8TJky4d+9edXU17yUjpgIA8Ewul+/atWv+/PmLFy92d3ePjIz8+OOPHzx4YNAko+qEQiE95Q0PD9+7d29nZ2dRUZER5SQmJnZ0dKxfv964anDr7u6+efNmSEhI/1WNjY0lJSVZWVlSqXSgs1hLGjVqFCGEpmfmlw3legMAGBxqamq6uromTZrELpk8ebJIJGKv2Zpi0qRJEolEZ2pey+PIlSuVSru7u5OTk7ds2WIL7wGbL+MyYioAAM/a2toIIS4uLuoLPTw8Ojs7eSnf0dGxubmZl6J4xJEr18fHp7CwMCIiwuKV0s58GZdx7RcAgGceHh6EEI0I2tbWFhAQYHrhCoWCr6L4xZEr19vbm/aJjTBfxmWcpwIA8Gzs2LEuLi6//PILu6SysrK3t/eZZ56hH/VPW9tfeXk5wzA08Z+JRfGLI1eu+hs1tsB86XJxngoAwDOxWLxq1apvvvlm//79HR0dly9fzsjI8PPzW7p0Kd1A/7S1NF6qVKrW1lalUnnp0qUVK1YEBgYakQFXoVCYNbvwQLlya2trfX19U1JS1Bempqb6+vpWVVUZcSBT9qXMly4XMRUAgH8bNmzYunVrTk7OU089FR8fP3LkyPLycmdnZ7p2+fLlU6dOTUtLCwsL27x5M70IKZVK6RsyGRkZPj4+4eHhs2bNamlpIYT09PRERkY6OTnFxcWNHj369OnT7G1LQ4syq8TExJqaGvoeKkvra6C9vb1NTU1Hjx7VWs758+djY2OHDRtWWVlZXV3t5+cXExNz5swZ0/elLly44O/vP27cOGMayc3EuQ0BAJ4olp/vd+nSpUOGDLHkESkjfv/1z5Xb19cXFxdXWFhoRMVM2ZcxLeOyzj7BeSoAgK0zbyoV/uiZK7evr+/IkSOdnZ1G5Os0ZV/KrOlyEVMBAIA3+uTKLS8vP3z4cFlZ2UAzLnEwZV9i/nS5iKkAALZrzZo1RUVF7e3tQUFBhw4dsnZ19KIzV25CQsKBAwfYaYoNYsq+FkiXi3dpAABs19atW7du3WrtWhhs+vTp06dPt3YtNCUlJSUlJZn1EDhPBQAA4AdiKgAAAD8QUwEAAPiBmAoAAMAP3c8o5eXlff311xaoCgCA7aPT2i1cuNDaFbEE/P4bSsBomzWK9YSMGwAAAH2sXLlSKpUOtFZHTAUAAAA94X4qAAAAPxBTAQAA+IGYCgAAwA/EVAAAAH78H7SpAfIULrhZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs7a8nPfCI6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c8132226-5090-4c7e-b901-1d7f417317e9"
      },
      "source": [
        "\"\"\"from tensorflow.keras.models import model_from_json\n",
        "json_file = open('encoder_model_Harris_hosp.json','r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"encoder_model_Harris_hosp.h5\")# for Harris model.\n",
        "\n",
        "#loaded_model.predict(value)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw5Y8idEiLXL"
      },
      "source": [
        "Here I build a simple function that is used to make a 7-day forecast on our data. The LSTM model predicts one single value, so I append this predicted value to the last item of the test window and remove the first value of the window and repeat that 6 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No9ihkmVhZnZ"
      },
      "source": [
        "def predictionOnPredictionLSTM(initialValue, nOfPredictions,model):\n",
        "  \n",
        "  # Start the predictions.\n",
        "  inputs = initialValue\n",
        "  # Create an empty array.\n",
        "  predictions = []\n",
        "\n",
        "  # Loop over the test set data and make prediction using \n",
        "  for i in range(nOfPredictions) :\n",
        "    v = model.predict(inputs,verbose=0) # [5,6,7] 6.5 --> [6,6.5] -> [6.5,7]\n",
        "    predictions.append(v)\n",
        "    # Create the next input.\n",
        "    inputs = np.roll(inputs, -1) # [7,6,5] --> [7,6,6.5]\n",
        "    inputs[0][-1] = v \n",
        "  return np.array(predictions)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giUSEmA6aEJw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "22b803f7-78bb-4c6f-e02a-49a4862508af"
      },
      "source": [
        "\"\"\"from sklearn.metrics import mean_squared_log_error\n",
        "#Harris_predictions_model_1\n",
        "#print(len(train_deaths[0]),len(test_deaths[0]))\n",
        "predictions = predictions.reshape(len(predictions))\n",
        "print(predictions)\n",
        "print(test_deaths[0][window:])\n",
        "print(mean_absolute_error(predictions,test_deaths[0][window:]))\n",
        "print(mean_squared_log_error(predictions,test_deaths[0][window:]))\"\"\"\n",
        "#best 2.269217mean_absolute_error\n",
        "#1.8697e-06 mean_squared_log_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2281.6726 2277.6128 2271.6475 2266.4023 2260.9163 2255.5408 2250.1475]\n",
            "[2295.0 2298.0 2299.0 2300.0 2300.0 2300.0 2300.0]\n",
            "32.580043247767854\n",
            "0.00023238006195369865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vJ8w9D5jCoJ"
      },
      "source": [
        "predictions_encoder =  predictionOnPredictionLSTM(initialvalue_Harris,look_ahead,encoder_model)#encoder_model  predictions\n",
        "predictions_conv_Harris = predictionOnPredictionLSTM(initialvalue_Harris,look_ahead,conv_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhBUhKJtkc9o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "1b14a1db-d17a-40ec-c1c5-33e7b827c525"
      },
      "source": [
        "#Harris_prediction_model_1\n",
        "\n",
        "\"\"\"predictions_encoder = predictions_encoder.reshape(len(predictions_encoder))\n",
        "print(predictions_encoder)\n",
        "print(test_deaths[0][window:])\n",
        "#print(mean_absolute_error(predictions_encoder,test_deaths[0][window:]))#for evaluating when train is 97% and test 3%\n",
        "#print(mean_squared_log_error(predictions_encoder,test_deaths[0][window:]))\n",
        "#[2315.637  2337.772  2349.0872 2360.1472 2379.7527 2400.502  2416.9834] for window =10 and 15:\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2410.8052 2220.5317 2369.7473 2408.9995 2525.3313 2383.6375 2831.5552]\n",
            "[2420.0]\n",
            "[1812 1829 1838 1875 1920 1953 1978 2011 2028 2030 2072 2106 2140 2153\n",
            " 2177 2188 2192 2208 2247 2281 2300 2327 2335 2335 2342 2363 2363 2395\n",
            " 2414 2420.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzMZuLRmj8I2"
      },
      "source": [
        "This is my first prediction for week_2 (the first printed row). I trained another convolutional model with different window parameter and took the average between the two as my last prediction (ensemble). This can be seen far below in the 3rd from last cell of this notebook.\n",
        "\n",
        "Note that the values are not exactly the same (diffence of +-2) because everytime I run the model I get slightly differen weights due to randomness when training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNA3xWZc4sOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "348ecf53-78a1-463b-bac8-32e4ee307179"
      },
      "source": [
        "#Harris_prediction_model_3\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "predictions_conv_Harris = predictions_conv_Harris.reshape(len(predictions_conv_Harris))\n",
        "print(predictions_conv_Harris)\n",
        "print(test_deaths[0][window:])\n",
        "\n",
        "#print(mean_absolute_error(predictions_conv_Harris,test_deaths[0][window:]))\n",
        "#print(mean_squared_log_error(predictions_conv_Harris,test_deaths[0][window:]))\n",
        "print(train_deaths[0][-30:])\n",
        "#[2323.4692 2341.0374 2356.7148 2375.0168 2390.6448 2407.288  2421.0159] for window = 15\n",
        "#[2420.7942 2437.5059 2449.8225 2465.4849 2479.7554 2495.0405 2510.6333] for window = 10 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2420.7942 2437.5059 2449.8225 2465.4849 2479.7554 2495.0405 2510.6333]\n",
            "[2420.0]\n",
            "[1812 1829 1838 1875 1920 1953 1978 2011 2028 2030 2072 2106 2140 2153\n",
            " 2177 2188 2192 2208 2247 2281 2300 2327 2335 2335 2342 2363 2363 2395\n",
            " 2414 2420.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HORsvvGnlcwD"
      },
      "source": [
        "To train the second model for Liberty I use the [1] index of the X_train list of lists and ignore the first 20 days because they contain meaningless values (0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9_t5tbQB3O1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f51257d3-9435-48df-c3f3-56efb1d8871a"
      },
      "source": [
        "#Liberty model\n",
        "\n",
        "conv_model_Liberty,conv_history_Liberty = build_conv_model(np.array(X_train[1][20:]),np.array(X_test[1]),np.array(Y_train[1][20:]),np.array(Y_test[1]),window)\n",
        "encoder_model_Liberty,encoder_history_Liberty = build_encoder_decoder(np.array(X_train[1][20:]),np.array(X_test[1]),np.array(Y_train[1][20:]),np.array(Y_test[1]),window)\n",
        "#build_encoder_decoder\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 9.6285 - val_loss: 23.6094\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.6358 - val_loss: 4.3669\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.8493 - val_loss: 2.4949\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4312 - val_loss: 0.5154\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.4838 - val_loss: 4.2757\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3746 - val_loss: 3.7545\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.2720 - val_loss: 5.3903\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4840 - val_loss: 3.2578\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1250 - val_loss: 0.1009\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.9953 - val_loss: 6.6210\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.1236 - val_loss: 5.3617\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4851 - val_loss: 2.9237\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.2343 - val_loss: 0.8263\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3493 - val_loss: 6.1160\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.0842 - val_loss: 1.4973\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.4233 - val_loss: 1.5017\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.1242 - val_loss: 4.8311\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.6223 - val_loss: 3.1550\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4128 - val_loss: 2.7692\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.7185 - val_loss: 3.9163\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1341 - val_loss: 0.6111\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.8556 - val_loss: 6.6805\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.5346 - val_loss: 3.4580\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2882 - val_loss: 2.6049\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1422 - val_loss: 1.8020\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3515 - val_loss: 4.1174\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.4428 - val_loss: 4.1105\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0938 - val_loss: 1.8536\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.0586 - val_loss: 2.3219\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.4645 - val_loss: 3.1400\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.9995 - val_loss: 2.4815\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.2809 - val_loss: 2.3325\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1168 - val_loss: 2.9434\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3340 - val_loss: 2.5495\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1117 - val_loss: 3.5777\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9481 - val_loss: 1.5360\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.0025 - val_loss: 2.3865\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3426 - val_loss: 2.9016\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.7250 - val_loss: 1.2945\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.0181 - val_loss: 2.7956\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.4489 - val_loss: 5.2846\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8532 - val_loss: 1.0177\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.8013 - val_loss: 2.3501\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1909 - val_loss: 2.5529\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.0040 - val_loss: 2.3791\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1832 - val_loss: 2.6683\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.8146 - val_loss: 2.0067\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3088 - val_loss: 2.8515\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.7046 - val_loss: 2.1425\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1562 - val_loss: 2.6087\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.6039 - val_loss: 1.4160\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.4144 - val_loss: 3.1814\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.7136 - val_loss: 2.3172\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0011 - val_loss: 2.3153\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.6352 - val_loss: 1.4218\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2998 - val_loss: 3.1669\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5499 - val_loss: 1.3638\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2420 - val_loss: 2.9176\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5648 - val_loss: 1.4938\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2453 - val_loss: 2.7939\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.6022 - val_loss: 1.8881\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0662 - val_loss: 2.5462\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4793 - val_loss: 1.0768\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4165 - val_loss: 3.1335\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.6689 - val_loss: 2.1739\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0056 - val_loss: 2.1939\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.6403 - val_loss: 1.7684\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1379 - val_loss: 2.7003\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.5194 - val_loss: 1.4174\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1962 - val_loss: 2.7980\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.5694 - val_loss: 1.7226\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0679 - val_loss: 2.6626\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4544 - val_loss: 1.0989\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2368 - val_loss: 3.1156\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4109 - val_loss: 1.0851\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1869 - val_loss: 2.9298\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4976 - val_loss: 1.4515\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0552 - val_loss: 2.8077\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3882 - val_loss: 0.8443\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2270 - val_loss: 3.2820\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3356 - val_loss: 0.8020\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1943 - val_loss: 3.1519\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3388 - val_loss: 0.8453\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2207 - val_loss: 3.1639\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4209 - val_loss: 1.3810\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9213 - val_loss: 2.6390\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4511 - val_loss: 0.9072\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0659 - val_loss: 3.0872\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3817 - val_loss: 0.8668\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0782 - val_loss: 3.0605\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3348 - val_loss: 0.8632\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0874 - val_loss: 3.0798\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2973 - val_loss: 0.6290\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1525 - val_loss: 3.2949\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2522 - val_loss: 0.5519\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1533 - val_loss: 3.2720\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2461 - val_loss: 0.5708\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1363 - val_loss: 3.2249\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2257 - val_loss: 0.5366\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1339 - val_loss: 3.1972\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.2973 - val_loss: 0.8571\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9739 - val_loss: 3.5761\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0149 - val_loss: 0.0896\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6959 - val_loss: 1.4357\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0082 - val_loss: 3.4500\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2153 - val_loss: 0.0628\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.8860 - val_loss: 10.4848\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5853 - val_loss: 2.4714\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5169 - val_loss: 0.6595\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.9952 - val_loss: 2.7970\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3565 - val_loss: 2.9044\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.8069 - val_loss: 2.5062\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9570 - val_loss: 2.7602\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4388 - val_loss: 1.0413\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3083 - val_loss: 3.8352\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2064 - val_loss: 0.2636\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1847 - val_loss: 4.1535\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0645 - val_loss: 0.1426\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9948 - val_loss: 3.6577\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1590 - val_loss: 0.6837\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1636 - val_loss: 4.2874\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0179 - val_loss: 0.7153\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1779 - val_loss: 4.1279\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0810 - val_loss: 0.4182\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0684 - val_loss: 3.9164\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0535 - val_loss: 0.4973\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1250 - val_loss: 3.9821\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0377 - val_loss: 0.5129\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1110 - val_loss: 3.9870\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0355 - val_loss: 0.5572\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1077 - val_loss: 4.0780\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9705 - val_loss: 0.7392\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1827 - val_loss: 4.2160\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9400 - val_loss: 0.8284\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1851 - val_loss: 4.2776\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9222 - val_loss: 0.9127\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1817 - val_loss: 4.2094\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9838 - val_loss: 0.6672\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0975 - val_loss: 4.0802\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9053 - val_loss: 0.8067\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1813 - val_loss: 4.0381\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9979 - val_loss: 0.5399\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.0735 - val_loss: 3.8942\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9608 - val_loss: 0.6495\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1380 - val_loss: 4.0226\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9315 - val_loss: 0.7416\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1399 - val_loss: 4.0931\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9523 - val_loss: 0.8437\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1609 - val_loss: 4.1859\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9475 - val_loss: 0.7034\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0627 - val_loss: 4.2541\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8069 - val_loss: 0.3925\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4920 - val_loss: 1.4549\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3996 - val_loss: 1.3391\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3420 - val_loss: 0.2979\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7717 - val_loss: 0.7708\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7216 - val_loss: 0.1585\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4714 - val_loss: 1.4742\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6889 - val_loss: 1.1310\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4622 - val_loss: 0.5081\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.6230 - val_loss: 2.2432\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6089 - val_loss: 1.3941\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3491 - val_loss: 1.0429\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8037 - val_loss: 2.6258\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1269 - val_loss: 0.1194\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9481 - val_loss: 3.3319\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0414 - val_loss: 0.3462\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0307 - val_loss: 3.7286\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9539 - val_loss: 0.6054\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1003 - val_loss: 3.8969\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9275 - val_loss: 0.7032\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1052 - val_loss: 3.9793\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9082 - val_loss: 0.7975\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1172 - val_loss: 4.0665\n",
            "Epoch 175/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8873 - val_loss: 0.8875\n",
            "Epoch 176/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1259 - val_loss: 4.1465\n",
            "Epoch 177/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8651 - val_loss: 0.9953\n",
            "Epoch 178/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1385 - val_loss: 4.1265\n",
            "Epoch 179/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9076 - val_loss: 0.8013\n",
            "Epoch 180/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.0812 - val_loss: 4.0902\n",
            "Epoch 181/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8016 - val_loss: 0.1170\n",
            "Epoch 182/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5337 - val_loss: 1.6045\n",
            "Epoch 183/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3712 - val_loss: 0.4527\n",
            "Epoch 184/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2194 - val_loss: 0.1891\n",
            "Epoch 185/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.6175 - val_loss: 2.6429\n",
            "Epoch 186/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5063 - val_loss: 1.0423\n",
            "Epoch 187/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9051 - val_loss: 3.6302\n",
            "Epoch 188/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7883 - val_loss: 0.4870\n",
            "Epoch 189/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4863 - val_loss: 1.4778\n",
            "Epoch 190/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5863 - val_loss: 1.5536\n",
            "Epoch 191/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4695 - val_loss: 0.6798\n",
            "Epoch 192/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4684 - val_loss: 1.2402\n",
            "Epoch 193/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7773 - val_loss: 2.6195\n",
            "Epoch 194/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0787 - val_loss: 0.2465\n",
            "Epoch 195/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0082 - val_loss: 3.7050\n",
            "Epoch 196/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9313 - val_loss: 0.7943\n",
            "Epoch 197/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0950 - val_loss: 4.1229\n",
            "Epoch 198/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8495 - val_loss: 0.1249\n",
            "Epoch 199/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5214 - val_loss: 1.5325\n",
            "Epoch 200/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4183 - val_loss: 0.8607\n",
            "Epoch 201/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0242 - val_loss: 0.3044\n",
            "Epoch 202/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1620 - val_loss: 1.9338\n",
            "Epoch 203/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.9161 - val_loss: 2.8587\n",
            "Epoch 204/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7515 - val_loss: 2.7748\n",
            "Epoch 205/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9887 - val_loss: 0.8282\n",
            "Epoch 206/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2663 - val_loss: 4.7291\n",
            "Epoch 207/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8987 - val_loss: 0.0924\n",
            "Epoch 208/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4595 - val_loss: 1.6628\n",
            "Epoch 209/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5531 - val_loss: 0.9214\n",
            "Epoch 210/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3942 - val_loss: 0.5332\n",
            "Epoch 211/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7574 - val_loss: 0.9678\n",
            "Epoch 212/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6255 - val_loss: 0.2641\n",
            "Epoch 213/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6809 - val_loss: 1.4914\n",
            "Epoch 214/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5906 - val_loss: 1.1801\n",
            "Epoch 215/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4423 - val_loss: 1.4292\n",
            "Epoch 216/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9672 - val_loss: 2.4476\n",
            "Epoch 217/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2836 - val_loss: 1.0821\n",
            "Epoch 218/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8044 - val_loss: 2.6611\n",
            "Epoch 219/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0166 - val_loss: 0.1190\n",
            "Epoch 220/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0398 - val_loss: 3.6694\n",
            "Epoch 221/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8705 - val_loss: 0.7510\n",
            "Epoch 222/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1585 - val_loss: 4.1288\n",
            "Epoch 223/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8555 - val_loss: 0.7394\n",
            "Epoch 224/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0534 - val_loss: 4.0563\n",
            "Epoch 225/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8475 - val_loss: 0.1397\n",
            "Epoch 226/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4846 - val_loss: 1.5032\n",
            "Epoch 227/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4093 - val_loss: 0.9403\n",
            "Epoch 228/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8359 - val_loss: 1.7388\n",
            "Epoch 229/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.5995 - val_loss: 5.8529\n",
            "Epoch 230/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9516 - val_loss: 0.4994\n",
            "Epoch 231/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0147 - val_loss: 3.8489\n",
            "Epoch 232/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.9421 - val_loss: 0.7423\n",
            "Epoch 233/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1177 - val_loss: 4.2019\n",
            "Epoch 234/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7830 - val_loss: 0.1703\n",
            "Epoch 235/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4632 - val_loss: 1.4187\n",
            "Epoch 236/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3716 - val_loss: 0.7433\n",
            "Epoch 237/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6340 - val_loss: 1.4095\n",
            "Epoch 238/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7352 - val_loss: 0.4409\n",
            "Epoch 239/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9166 - val_loss: 0.6971\n",
            "Epoch 240/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5124 - val_loss: 1.3512\n",
            "Epoch 241/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2085 - val_loss: 0.4029\n",
            "Epoch 242/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9655 - val_loss: 3.3151\n",
            "Epoch 243/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9690 - val_loss: 0.3521\n",
            "Epoch 244/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0216 - val_loss: 3.7362\n",
            "Epoch 245/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8926 - val_loss: 0.7390\n",
            "Epoch 246/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0761 - val_loss: 4.1948\n",
            "Epoch 247/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7506 - val_loss: 0.3347\n",
            "Epoch 248/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5116 - val_loss: 1.4961\n",
            "Epoch 249/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4305 - val_loss: 1.1459\n",
            "Epoch 250/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7911 - val_loss: 0.2523\n",
            "Epoch 251/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4424 - val_loss: 0.0790\n",
            "Epoch 252/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3575 - val_loss: 1.2800\n",
            "Epoch 253/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7942 - val_loss: 2.4116\n",
            "Epoch 254/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0774 - val_loss: 6.6376e-04\n",
            "Epoch 255/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9277 - val_loss: 3.6039\n",
            "Epoch 256/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8001 - val_loss: 0.1333\n",
            "Epoch 257/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4826 - val_loss: 1.3819\n",
            "Epoch 258/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4399 - val_loss: 1.2096\n",
            "Epoch 259/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8156 - val_loss: 0.7414\n",
            "Epoch 260/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1371 - val_loss: 4.3078\n",
            "Epoch 261/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7652 - val_loss: 0.4816\n",
            "Epoch 262/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4278 - val_loss: 1.1978\n",
            "Epoch 263/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8235 - val_loss: 0.6684\n",
            "Epoch 264/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1036 - val_loss: 4.1230\n",
            "Epoch 265/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8286 - val_loss: 0.3182\n",
            "Epoch 266/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4406 - val_loss: 1.0621\n",
            "Epoch 267/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8311 - val_loss: 0.6004\n",
            "Epoch 268/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2021 - val_loss: 3.5611\n",
            "Epoch 269/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0669 - val_loss: 0.2181\n",
            "Epoch 270/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9660 - val_loss: 4.2067\n",
            "Epoch 271/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6407 - val_loss: 0.6712\n",
            "Epoch 272/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4488 - val_loss: 1.3553\n",
            "Epoch 273/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.5182 - val_loss: 1.4221\n",
            "Epoch 274/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4470 - val_loss: 1.0339\n",
            "Epoch 275/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6118 - val_loss: 1.1252\n",
            "Epoch 276/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4538 - val_loss: 0.2451\n",
            "Epoch 277/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4180 - val_loss: 1.6855\n",
            "Epoch 278/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6473 - val_loss: 2.0412\n",
            "Epoch 279/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0257 - val_loss: 0.0236\n",
            "Epoch 280/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9371 - val_loss: 3.4816\n",
            "Epoch 281/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7902 - val_loss: 0.9622\n",
            "Epoch 282/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1138 - val_loss: 4.1047\n",
            "Epoch 283/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7466 - val_loss: 0.2652\n",
            "Epoch 284/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4596 - val_loss: 1.3894\n",
            "Epoch 285/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4010 - val_loss: 1.0779\n",
            "Epoch 286/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7306 - val_loss: 1.1251\n",
            "Epoch 287/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4003 - val_loss: 4.1706\n",
            "Epoch 288/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8786 - val_loss: 0.7001\n",
            "Epoch 289/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0098 - val_loss: 4.0771\n",
            "Epoch 290/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6535 - val_loss: 0.6708\n",
            "Epoch 291/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4442 - val_loss: 1.1607\n",
            "Epoch 292/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5388 - val_loss: 1.2351\n",
            "Epoch 293/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4771 - val_loss: 0.6517\n",
            "Epoch 294/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1025 - val_loss: 0.6684\n",
            "Epoch 295/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0311 - val_loss: 2.5882\n",
            "Epoch 296/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0031 - val_loss: 0.2590\n",
            "Epoch 297/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8584 - val_loss: 3.0188\n",
            "Epoch 298/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8010 - val_loss: 0.6023\n",
            "Epoch 299/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0384 - val_loss: 3.7087\n",
            "Epoch 300/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7098 - val_loss: 0.2298\n",
            "Epoch 301/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4805 - val_loss: 1.2871\n",
            "Epoch 302/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4066 - val_loss: 1.0554\n",
            "Epoch 303/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4353 - val_loss: 1.1647\n",
            "Epoch 304/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4457 - val_loss: 0.7887\n",
            "Epoch 305/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5473 - val_loss: 1.4665\n",
            "Epoch 306/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6751 - val_loss: 0.0040\n",
            "Epoch 307/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.7242 - val_loss: 3.3971\n",
            "Epoch 308/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4878 - val_loss: 1.7504\n",
            "Epoch 309/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4302 - val_loss: 1.2104\n",
            "Epoch 310/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4975 - val_loss: 1.4373\n",
            "Epoch 311/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4140 - val_loss: 0.3471\n",
            "Epoch 312/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1186 - val_loss: 0.5847\n",
            "Epoch 313/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1544 - val_loss: 2.2677\n",
            "Epoch 314/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2047 - val_loss: 0.9078\n",
            "Epoch 315/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6857 - val_loss: 2.6276\n",
            "Epoch 316/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8680 - val_loss: 0.7302\n",
            "Epoch 317/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0732 - val_loss: 4.0815\n",
            "Epoch 318/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7109 - val_loss: 0.4818\n",
            "Epoch 319/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4394 - val_loss: 1.3906\n",
            "Epoch 320/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4399 - val_loss: 0.9832\n",
            "Epoch 321/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7608 - val_loss: 1.1588\n",
            "Epoch 322/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4242 - val_loss: 4.5603\n",
            "Epoch 323/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9634 - val_loss: 0.4796\n",
            "Epoch 324/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9311 - val_loss: 3.8187\n",
            "Epoch 325/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7435 - val_loss: 0.3586\n",
            "Epoch 326/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4734 - val_loss: 1.4175\n",
            "Epoch 327/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4533 - val_loss: 1.3195\n",
            "Epoch 328/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4640 - val_loss: 1.1860\n",
            "Epoch 329/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4121 - val_loss: 1.1190\n",
            "Epoch 330/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7413 - val_loss: 0.2685\n",
            "Epoch 331/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3958 - val_loss: 0.8457\n",
            "Epoch 332/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8613 - val_loss: 0.6633\n",
            "Epoch 333/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2828 - val_loss: 4.4291\n",
            "Epoch 334/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6524 - val_loss: 0.3952\n",
            "Epoch 335/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4242 - val_loss: 1.3138\n",
            "Epoch 336/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4414 - val_loss: 1.1924\n",
            "Epoch 337/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4042 - val_loss: 1.2173\n",
            "Epoch 338/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4731 - val_loss: 1.0341\n",
            "Epoch 339/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4418 - val_loss: 1.1298\n",
            "Epoch 340/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4522 - val_loss: 1.1649\n",
            "Epoch 341/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4574 - val_loss: 0.8882\n",
            "Epoch 342/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4378 - val_loss: 1.2073\n",
            "Epoch 343/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4519 - val_loss: 0.9225\n",
            "Epoch 344/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4076 - val_loss: 1.1964\n",
            "Epoch 345/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4779 - val_loss: 0.7367\n",
            "Epoch 346/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3993 - val_loss: 1.2230\n",
            "Epoch 347/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4575 - val_loss: 0.8426\n",
            "Epoch 348/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4102 - val_loss: 1.0148\n",
            "Epoch 349/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4055 - val_loss: 1.0903\n",
            "Epoch 350/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3901 - val_loss: 0.7760\n",
            "Epoch 351/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6355 - val_loss: 0.5464\n",
            "Epoch 352/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4769 - val_loss: 0.2677\n",
            "Epoch 353/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.6421 - val_loss: 2.9052\n",
            "Epoch 354/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4843 - val_loss: 1.6282\n",
            "Epoch 355/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7131 - val_loss: 0.8790\n",
            "Epoch 356/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2168 - val_loss: 3.7962\n",
            "Epoch 357/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9514 - val_loss: 0.2861\n",
            "Epoch 358/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8845 - val_loss: 3.4070\n",
            "Epoch 359/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8296 - val_loss: 0.8136\n",
            "Epoch 360/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0679 - val_loss: 3.9317\n",
            "Epoch 361/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7406 - val_loss: 0.1710\n",
            "Epoch 362/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4048 - val_loss: 1.3283\n",
            "Epoch 363/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3815 - val_loss: 1.0704\n",
            "Epoch 364/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4674 - val_loss: 1.1468\n",
            "Epoch 365/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4074 - val_loss: 0.0426\n",
            "Epoch 366/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5676 - val_loss: 2.5304\n",
            "Epoch 367/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4969 - val_loss: 1.7097\n",
            "Epoch 368/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7369 - val_loss: 1.0076\n",
            "Epoch 369/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2554 - val_loss: 4.4231\n",
            "Epoch 370/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6648 - val_loss: 0.3716\n",
            "Epoch 371/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4191 - val_loss: 1.3885\n",
            "Epoch 372/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3949 - val_loss: 0.9420\n",
            "Epoch 373/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7357 - val_loss: 0.8044\n",
            "Epoch 374/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1723 - val_loss: 3.9771\n",
            "Epoch 375/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8246 - val_loss: 0.8015\n",
            "Epoch 376/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9870 - val_loss: 3.8484\n",
            "Epoch 377/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7313 - val_loss: 0.2746\n",
            "Epoch 378/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3957 - val_loss: 1.0961\n",
            "Epoch 379/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5477 - val_loss: 0.9765\n",
            "Epoch 380/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4117 - val_loss: 0.7345\n",
            "Epoch 381/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1807 - val_loss: 0.9285\n",
            "Epoch 382/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8118 - val_loss: 1.5949\n",
            "Epoch 383/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3468 - val_loss: 1.6098\n",
            "Epoch 384/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5873 - val_loss: 2.0722\n",
            "Epoch 385/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8104 - val_loss: 0.4490\n",
            "Epoch 386/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1113 - val_loss: 3.6200\n",
            "Epoch 387/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7897 - val_loss: 0.3869\n",
            "Epoch 388/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8926 - val_loss: 3.2684\n",
            "Epoch 389/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8093 - val_loss: 0.7621\n",
            "Epoch 390/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0219 - val_loss: 3.7482\n",
            "Epoch 391/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7360 - val_loss: 0.1523\n",
            "Epoch 392/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3955 - val_loss: 1.1149\n",
            "Epoch 393/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4983 - val_loss: 0.8569\n",
            "Epoch 394/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3696 - val_loss: 0.3902\n",
            "Epoch 395/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1391 - val_loss: 0.9460\n",
            "Epoch 396/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9035 - val_loss: 2.3355\n",
            "Epoch 397/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9625 - val_loss: 0.2222\n",
            "Epoch 398/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8535 - val_loss: 2.9455\n",
            "Epoch 399/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7998 - val_loss: 0.5870\n",
            "Epoch 400/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0221 - val_loss: 3.6733\n",
            "Epoch 401/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6831 - val_loss: 0.2667\n",
            "Epoch 402/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4494 - val_loss: 1.3366\n",
            "Epoch 403/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3854 - val_loss: 0.9752\n",
            "Epoch 404/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6335 - val_loss: 0.5125\n",
            "Epoch 405/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4272 - val_loss: 0.4797\n",
            "Epoch 406/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1074 - val_loss: 0.5538\n",
            "Epoch 407/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8428 - val_loss: 2.8277\n",
            "Epoch 408/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8088 - val_loss: 0.4889\n",
            "Epoch 409/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0026 - val_loss: 3.5238\n",
            "Epoch 410/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6857 - val_loss: 0.1700\n",
            "Epoch 411/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4252 - val_loss: 1.0380\n",
            "Epoch 412/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4116 - val_loss: 1.0979\n",
            "Epoch 413/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4639 - val_loss: 0.8855\n",
            "Epoch 414/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3855 - val_loss: 0.6680\n",
            "(161, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 11.3940 - val_loss: 29.1536\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 4.9923 - val_loss: 6.1367\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 4.0892 - val_loss: 12.1522\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.7417 - val_loss: 1.0525\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 3.6486 - val_loss: 2.2607\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 4.7277 - val_loss: 0.9187\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 7.0186 - val_loss: 15.3023\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 4.2126 - val_loss: 4.9763\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 6.3109 - val_loss: 16.5933\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.2186 - val_loss: 3.8328\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 11.7218 - val_loss: 0.5580\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 6.7130 - val_loss: 13.8235\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 4.3195 - val_loss: 9.4786\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 8.2165 - val_loss: 18.9184\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 6.4065 - val_loss: 12.2867\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.4505 - val_loss: 2.4837\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 4.2977 - val_loss: 1.2974\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 4.7242 - val_loss: 6.1101\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 3.6891 - val_loss: 3.4421\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.8026 - val_loss: 3.8380\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 3.4065 - val_loss: 0.6625\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.8444 - val_loss: 6.4248\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.6452 - val_loss: 8.0276\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.0030 - val_loss: 1.6759\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 3.2152 - val_loss: 3.7536\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.6858 - val_loss: 0.9475\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.2934 - val_loss: 2.0689\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.8843 - val_loss: 1.5480\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 2.9687 - val_loss: 6.3615\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.6674 - val_loss: 2.5249\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.3760 - val_loss: 6.0518\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.5701 - val_loss: 8.9658\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.7171 - val_loss: 0.2226\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.7398 - val_loss: 1.7992\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.4133 - val_loss: 7.4432\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 3.2533 - val_loss: 3.5416\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.8779 - val_loss: 7.7166\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 3.1822 - val_loss: 1.7880\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 3.7701 - val_loss: 6.7963\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.8100 - val_loss: 2.1338\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 3.0907 - val_loss: 3.5487\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 2.4882 - val_loss: 3.9069\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.8783 - val_loss: 3.1279\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.5667 - val_loss: 7.9095\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 2.3864 - val_loss: 0.8412\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.3218 - val_loss: 3.4777\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.3844 - val_loss: 2.7436\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 4.0279 - val_loss: 5.1126\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 4.7907 - val_loss: 14.6671\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.0280 - val_loss: 6.5848\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.0696 - val_loss: 0.1998\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.0772 - val_loss: 2.5415\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 3.5545 - val_loss: 11.7343\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 2.1154 - val_loss: 3.5168\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.2409 - val_loss: 4.6851\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 3.0498 - val_loss: 9.3499\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.9210 - val_loss: 6.2958\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.8544 - val_loss: 4.7631\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.6051 - val_loss: 0.6033\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.0249 - val_loss: 10.6834\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 3.0742 - val_loss: 10.0162\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.9515 - val_loss: 2.7074\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.6304 - val_loss: 6.6956\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.2032 - val_loss: 5.4359\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.6691 - val_loss: 2.5056\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 2.6716 - val_loss: 7.2152\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 2.0075 - val_loss: 0.0779\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.9313 - val_loss: 5.7765\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.4479 - val_loss: 4.7855\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.3165 - val_loss: 1.2298\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.2102 - val_loss: 0.5311\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.8087 - val_loss: 0.5191\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.7666 - val_loss: 1.2971\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.2029 - val_loss: 10.8637\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.1121 - val_loss: 0.5160\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.3976 - val_loss: 2.2840\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 2.0729 - val_loss: 5.7180\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.9388 - val_loss: 1.6961\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.8193 - val_loss: 2.8296\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.6963 - val_loss: 7.6368\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.8898 - val_loss: 2.8813\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0173 - val_loss: 5.9520\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.2292 - val_loss: 6.0887\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.2254 - val_loss: 0.8149\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6892 - val_loss: 5.9227\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.8779 - val_loss: 1.6775\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.7225 - val_loss: 6.4114\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.0337 - val_loss: 2.3237\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.9648 - val_loss: 3.4571\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 1.8467 - val_loss: 8.2186\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 2.8639 - val_loss: 9.1925\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.6309 - val_loss: 1.2272\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 2.1761 - val_loss: 3.8428\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.0275 - val_loss: 10.5176\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.7939 - val_loss: 1.4712\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.7918 - val_loss: 2.1020\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 3.1372 - val_loss: 7.7106\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.8389 - val_loss: 2.9708\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.5019 - val_loss: 5.7548\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.9189 - val_loss: 3.0309\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.0947 - val_loss: 2.0631\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.0544 - val_loss: 6.5319\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.9386 - val_loss: 2.6340\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.8502 - val_loss: 8.0668\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6768 - val_loss: 0.8834\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.8078 - val_loss: 7.2699\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6644 - val_loss: 5.2031\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 3.5423 - val_loss: 0.5274\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 2.9840 - val_loss: 12.1287\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.8221 - val_loss: 2.7044\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 3.0295 - val_loss: 4.6555\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.2337 - val_loss: 1.7805\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.5891 - val_loss: 10.5493\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.4670 - val_loss: 4.9745\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.4214 - val_loss: 3.4927\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.1950 - val_loss: 0.0555\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0550 - val_loss: 6.7195\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.5109 - val_loss: 3.3661\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.9109 - val_loss: 7.0662\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.8730 - val_loss: 2.4660\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.8890 - val_loss: 2.9653\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6540 - val_loss: 2.1480\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.7261 - val_loss: 2.1814\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0820 - val_loss: 9.8939\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.4025 - val_loss: 9.0536\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.5976 - val_loss: 2.0536\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6114 - val_loss: 6.0382\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.8078 - val_loss: 7.2036\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.9097 - val_loss: 1.5633\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5945 - val_loss: 1.2160\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.4801 - val_loss: 5.3201\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.8109 - val_loss: 0.6688\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.8175 - val_loss: 5.9659\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.7858 - val_loss: 7.1580\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.9205 - val_loss: 3.0350\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.0229 - val_loss: 2.9844\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4018 - val_loss: 4.8816\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 2.4212 - val_loss: 10.3410\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0375 - val_loss: 8.1874\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.9600 - val_loss: 4.2820\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.8171 - val_loss: 9.1148\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6349 - val_loss: 2.6070\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.0389 - val_loss: 1.5193\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.2249 - val_loss: 8.5470\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.4518 - val_loss: 1.3012\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 2.2049 - val_loss: 0.7179\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0554 - val_loss: 7.2905\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4625 - val_loss: 4.8437\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.2824 - val_loss: 9.3719\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.2353 - val_loss: 9.9136\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.0027 - val_loss: 7.5642\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.7848 - val_loss: 2.0533\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.5694 - val_loss: 5.7293\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.5513 - val_loss: 3.0195\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5985 - val_loss: 6.0238\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.7496 - val_loss: 3.4141\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.8542 - val_loss: 6.2251\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.5742 - val_loss: 1.8643\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.4620 - val_loss: 4.2384\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.4093 - val_loss: 3.8861\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.9472 - val_loss: 7.1876\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.7742 - val_loss: 3.1696\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.7415 - val_loss: 7.2596\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.4254 - val_loss: 2.3292\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.9194 - val_loss: 0.8293\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.3374 - val_loss: 1.5669\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6098 - val_loss: 1.1590\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.9869 - val_loss: 0.3908\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5545 - val_loss: 3.8302\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.0245 - val_loss: 8.8988\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.1498 - val_loss: 6.4970\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.0536 - val_loss: 2.2412\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.8445 - val_loss: 8.5087\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.7243 - val_loss: 3.9959\n",
            "Epoch 175/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.2292 - val_loss: 5.6874\n",
            "Epoch 176/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.8124 - val_loss: 3.0408\n",
            "Epoch 177/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.8435 - val_loss: 8.1332\n",
            "Epoch 178/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.2644 - val_loss: 4.1264\n",
            "Epoch 179/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.7965 - val_loss: 3.0884\n",
            "Epoch 180/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6956 - val_loss: 8.5983\n",
            "Epoch 181/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.0469 - val_loss: 7.5852\n",
            "Epoch 182/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.8673 - val_loss: 2.5505\n",
            "Epoch 183/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6365 - val_loss: 7.0909\n",
            "Epoch 184/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.6698 - val_loss: 3.3212\n",
            "Epoch 185/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.5866 - val_loss: 3.8339\n",
            "Epoch 186/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.5812 - val_loss: 8.4565\n",
            "Epoch 187/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.2932 - val_loss: 4.4040\n",
            "Epoch 188/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5410 - val_loss: 3.3701\n",
            "Epoch 189/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.3486 - val_loss: 5.6193\n",
            "Epoch 190/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.5988 - val_loss: 2.9491\n",
            "Epoch 191/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.5983 - val_loss: 6.7432\n",
            "Epoch 192/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6175 - val_loss: 3.2699\n",
            "Epoch 193/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4907 - val_loss: 7.5403\n",
            "Epoch 194/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.4859 - val_loss: 5.1680\n",
            "Epoch 195/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0100 - val_loss: 7.3935\n",
            "Epoch 196/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.8303 - val_loss: 3.4416\n",
            "Epoch 197/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6754 - val_loss: 7.3242\n",
            "Epoch 198/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.4572 - val_loss: 6.0623\n",
            "Epoch 199/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.9847 - val_loss: 3.8248\n",
            "Epoch 200/686\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 1.5637 - val_loss: 5.3915\n",
            "Epoch 201/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.0898 - val_loss: 6.0991\n",
            "Epoch 202/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.7047 - val_loss: 2.9872\n",
            "Epoch 203/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 2.4155 - val_loss: 0.4702\n",
            "Epoch 204/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.0898 - val_loss: 7.7974\n",
            "Epoch 205/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.7470 - val_loss: 3.4454\n",
            "Epoch 206/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.6685 - val_loss: 7.6574\n",
            "Epoch 207/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 2.0387 - val_loss: 8.4261\n",
            "Epoch 208/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.7214 - val_loss: 7.3959\n",
            "Epoch 209/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6544 - val_loss: 3.7995\n",
            "Epoch 210/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.0119 - val_loss: 9.4505\n",
            "Epoch 211/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.9023 - val_loss: 8.8384\n",
            "Epoch 212/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.6385 - val_loss: 5.7838\n",
            "Epoch 213/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.3332 - val_loss: 1.9925\n",
            "Epoch 214/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.6804 - val_loss: 5.0593\n",
            "Epoch 215/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4722 - val_loss: 7.9509\n",
            "Epoch 216/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.8913 - val_loss: 3.8908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_1JBO6FuOSk"
      },
      "source": [
        "I tranform my predictions to integers because the predictions are almost stable regarding last week and thus it doesn't make sense to try to predict precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv7lFN_6lveg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kha0SnMDLJZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d13e3fd8-3507-4e46-e463-c1c5ccfa7c57"
      },
      "source": [
        "\n",
        "predictions_conv_Liberty = predictionOnPredictionLSTM(initialvalue_Liberty,look_ahead,conv_model_Liberty) #here write either the encoder or conv model, keep the best\n",
        "predictions_conv_Liberty = predictions_conv_Liberty.reshape(len(predictions_conv_Liberty))\n",
        "predictions_final = []\n",
        "for i in predictions_conv_Liberty[0:4]:\n",
        "  predictions_final.append(round(i))\n",
        "print(\"Predictions for first week are:\",predictions_final,round(46.92746) , round(47.16774) , 48 )\n",
        "print(\"Predictions for second week are:\",predictions_final,round(46.92746) , round(47.16774) , 47.5) # first and second week data didn't change so predictions almost stay the same!\n",
        "#print(mean_absolute_error(predictions_conv_Liberty,test_deaths[1][window:]))\n",
        "#print(mean_squared_log_error(predictions_conv_Liberty,test_deaths[1][window:]))\n",
        "#[46.5739, 46.68, 46.77, 46. 82, 46.92746  47.16774  47.554] prediction from other model. Keep last 3 values and make them integer or keep them between 0.5 and 1.\n",
        "#Last 3 days are from different prediction conv model that "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions for first week are: [46.0, 46.0, 46.0, 46.0] 47 47 48\n",
            "Predictions for second week are: [46.0, 46.0, 46.0, 46.0] 47 47 47.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqsU3Vi8Mg_N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0837963d-cb60-4360-f042-f37fa6221183"
      },
      "source": [
        "#Montgomery model\n",
        "\n",
        "conv_model_Montgomery,conv_history_Montgomery = build_conv_model(np.array(X_train[2][30:]),np.array(X_test[2]),np.array(Y_train[2][30:]),np.array(Y_test[2]),window)\n",
        "encoder_model_Montgomery,conv_history_Montgomery = build_encoder_decoder(np.array(X_train[2][30:]),np.array(X_test[2]),np.array(Y_train[2][30:]),np.array(Y_test[2]),window)\n",
        "#build_encoder_decoder, #150: best\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(145, 10, 1)\n",
            "(145, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 34.1874 - val_loss: 62.7980\n",
            "Epoch 2/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.8906 - val_loss: 18.5745\n",
            "Epoch 3/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6651 - val_loss: 4.4225\n",
            "Epoch 4/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3217 - val_loss: 8.9339\n",
            "Epoch 5/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2041 - val_loss: 4.8845\n",
            "Epoch 6/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4893 - val_loss: 7.9688\n",
            "Epoch 7/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.8084 - val_loss: 1.8299\n",
            "Epoch 8/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8157 - val_loss: 9.5364\n",
            "Epoch 9/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3547 - val_loss: 3.3485\n",
            "Epoch 10/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1914 - val_loss: 7.7585\n",
            "Epoch 11/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6452 - val_loss: 1.2455\n",
            "Epoch 12/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5741 - val_loss: 7.8457\n",
            "Epoch 13/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8580 - val_loss: 1.9687\n",
            "Epoch 14/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1127 - val_loss: 7.5567\n",
            "Epoch 15/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5389 - val_loss: 1.2986\n",
            "Epoch 16/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3117 - val_loss: 8.2450\n",
            "Epoch 17/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4977 - val_loss: 1.6219\n",
            "Epoch 18/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9126 - val_loss: 6.9506\n",
            "Epoch 19/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7205 - val_loss: 2.4163\n",
            "Epoch 20/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5572 - val_loss: 6.4410\n",
            "Epoch 21/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5448 - val_loss: 1.7640\n",
            "Epoch 22/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7252 - val_loss: 6.5865\n",
            "Epoch 23/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6910 - val_loss: 2.6590\n",
            "Epoch 24/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4258 - val_loss: 6.3434\n",
            "Epoch 25/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5501 - val_loss: 2.1366\n",
            "Epoch 26/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4881 - val_loss: 6.5714\n",
            "Epoch 27/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4024 - val_loss: 1.7408\n",
            "Epoch 28/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5827 - val_loss: 7.0043\n",
            "Epoch 29/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3933 - val_loss: 2.1209\n",
            "Epoch 30/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3929 - val_loss: 6.4806\n",
            "Epoch 31/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3530 - val_loss: 1.7835\n",
            "Epoch 32/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4202 - val_loss: 6.5318\n",
            "Epoch 33/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3100 - val_loss: 1.7851\n",
            "Epoch 34/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5009 - val_loss: 7.0998\n",
            "Epoch 35/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2011 - val_loss: 1.7587\n",
            "Epoch 36/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3459 - val_loss: 6.4614\n",
            "Epoch 37/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2854 - val_loss: 1.9998\n",
            "Epoch 38/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2294 - val_loss: 6.1342\n",
            "Epoch 39/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0000 - val_loss: 1.9542\n",
            "Epoch 40/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9272 - val_loss: 9.5491\n",
            "Epoch 41/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5415 - val_loss: 3.3453\n",
            "Epoch 42/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1123 - val_loss: 5.5493\n",
            "Epoch 43/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0811 - val_loss: 12.8952\n",
            "Epoch 44/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0806 - val_loss: 2.7660\n",
            "Epoch 45/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3166 - val_loss: 1.8409\n",
            "Epoch 46/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1772 - val_loss: 1.2680\n",
            "Epoch 47/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1800 - val_loss: 4.1796\n",
            "Epoch 48/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.4984 - val_loss: 13.1424\n",
            "Epoch 49/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3399 - val_loss: 5.6153\n",
            "Epoch 50/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3319 - val_loss: 5.5027\n",
            "Epoch 51/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.7603 - val_loss: 1.8506\n",
            "Epoch 52/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9779 - val_loss: 7.2120\n",
            "Epoch 53/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6446 - val_loss: 2.8189\n",
            "Epoch 54/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3809 - val_loss: 6.0608\n",
            "Epoch 55/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5240 - val_loss: 2.3403\n",
            "Epoch 56/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.3538 - val_loss: 6.0552\n",
            "Epoch 57/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3927 - val_loss: 2.0262\n",
            "Epoch 58/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3693 - val_loss: 6.1712\n",
            "Epoch 59/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3031 - val_loss: 2.2339\n",
            "Epoch 60/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1707 - val_loss: 5.8931\n",
            "Epoch 61/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3034 - val_loss: 2.3851\n",
            "Epoch 62/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1162 - val_loss: 6.4371\n",
            "Epoch 63/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8979 - val_loss: 1.3633\n",
            "Epoch 64/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4099 - val_loss: 6.7566\n",
            "Epoch 65/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.0087 - val_loss: 1.6527\n",
            "Epoch 66/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2959 - val_loss: 6.6280\n",
            "Epoch 67/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0071 - val_loss: 1.7927\n",
            "Epoch 68/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1178 - val_loss: 6.2976\n",
            "Epoch 69/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9262 - val_loss: 1.5306\n",
            "Epoch 70/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1317 - val_loss: 6.2814\n",
            "Epoch 71/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8643 - val_loss: 1.4266\n",
            "Epoch 72/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2822 - val_loss: 6.7285\n",
            "Epoch 73/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8833 - val_loss: 1.5981\n",
            "Epoch 74/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1008 - val_loss: 6.3980\n",
            "Epoch 75/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7992 - val_loss: 1.3985\n",
            "Epoch 76/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1346 - val_loss: 6.4630\n",
            "Epoch 77/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7594 - val_loss: 1.3939\n",
            "Epoch 78/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2054 - val_loss: 6.5816\n",
            "Epoch 79/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8332 - val_loss: 1.5696\n",
            "Epoch 80/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0518 - val_loss: 6.9496\n",
            "Epoch 81/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6572 - val_loss: 1.5270\n",
            "Epoch 82/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9297 - val_loss: 6.7102\n",
            "Epoch 83/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5445 - val_loss: 1.3457\n",
            "Epoch 84/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1070 - val_loss: 6.5597\n",
            "Epoch 85/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7579 - val_loss: 1.5944\n",
            "Epoch 86/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9396 - val_loss: 6.9548\n",
            "Epoch 87/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5098 - val_loss: 1.3931\n",
            "Epoch 88/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9557 - val_loss: 6.9280\n",
            "Epoch 89/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4453 - val_loss: 1.3032\n",
            "Epoch 90/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0575 - val_loss: 6.4334\n",
            "Epoch 91/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6306 - val_loss: 1.3392\n",
            "Epoch 92/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1790 - val_loss: 6.8452\n",
            "Epoch 93/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7570 - val_loss: 1.8261\n",
            "Epoch 94/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8119 - val_loss: 6.6696\n",
            "Epoch 95/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4718 - val_loss: 1.3396\n",
            "Epoch 96/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0603 - val_loss: 6.6998\n",
            "Epoch 97/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6699 - val_loss: 1.6479\n",
            "Epoch 98/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7539 - val_loss: 6.4019\n",
            "Epoch 99/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3814 - val_loss: 1.2682\n",
            "Epoch 100/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.0745 - val_loss: 6.7427\n",
            "Epoch 101/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9338 - val_loss: 1.4313\n",
            "Epoch 102/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8825 - val_loss: 3.1231\n",
            "Epoch 103/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7407 - val_loss: 1.8157\n",
            "Epoch 104/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8955 - val_loss: 2.0031\n",
            "Epoch 105/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0293 - val_loss: 1.7590\n",
            "Epoch 106/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8735 - val_loss: 1.9646\n",
            "Epoch 107/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0703 - val_loss: 1.3614\n",
            "Epoch 108/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8366 - val_loss: 2.4823\n",
            "Epoch 109/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8573 - val_loss: 1.4049\n",
            "Epoch 110/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8358 - val_loss: 2.5950\n",
            "Epoch 111/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5543 - val_loss: 1.7867\n",
            "Epoch 112/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8058 - val_loss: 1.8712\n",
            "Epoch 113/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8219 - val_loss: 1.5611\n",
            "Epoch 114/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8068 - val_loss: 2.0854\n",
            "Epoch 115/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6669 - val_loss: 1.7579\n",
            "Epoch 116/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8074 - val_loss: 1.9938\n",
            "Epoch 117/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7333 - val_loss: 1.6435\n",
            "Epoch 118/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8018 - val_loss: 2.1331\n",
            "Epoch 119/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7227 - val_loss: 1.4460\n",
            "Epoch 120/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8013 - val_loss: 2.4088\n",
            "Epoch 121/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5520 - val_loss: 1.6449\n",
            "Epoch 122/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7805 - val_loss: 2.0319\n",
            "Epoch 123/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5704 - val_loss: 1.8031\n",
            "Epoch 124/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7829 - val_loss: 1.8971\n",
            "Epoch 125/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7659 - val_loss: 1.4988\n",
            "Epoch 126/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7599 - val_loss: 1.9451\n",
            "Epoch 127/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6493 - val_loss: 1.6654\n",
            "Epoch 128/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7666 - val_loss: 1.8767\n",
            "Epoch 129/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7254 - val_loss: 1.5268\n",
            "Epoch 130/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7515 - val_loss: 1.8747\n",
            "Epoch 131/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6588 - val_loss: 1.6492\n",
            "Epoch 132/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7558 - val_loss: 1.7908\n",
            "Epoch 133/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7973 - val_loss: 1.3407\n",
            "Epoch 134/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7301 - val_loss: 1.8410\n",
            "Epoch 135/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6642 - val_loss: 1.5435\n",
            "Epoch 136/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7361 - val_loss: 1.7671\n",
            "Epoch 137/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7429 - val_loss: 1.4196\n",
            "Epoch 138/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7314 - val_loss: 1.7507\n",
            "Epoch 139/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6862 - val_loss: 1.5231\n",
            "Epoch 140/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7266 - val_loss: 1.6958\n",
            "Epoch 141/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8177 - val_loss: 1.3141\n",
            "Epoch 142/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7023 - val_loss: 1.7772\n",
            "Epoch 143/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6596 - val_loss: 1.4501\n",
            "Epoch 144/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7194 - val_loss: 1.7467\n",
            "Epoch 145/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6508 - val_loss: 1.4792\n",
            "Epoch 146/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7557 - val_loss: 1.7682\n",
            "Epoch 147/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6179 - val_loss: 1.4725\n",
            "Epoch 148/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7096 - val_loss: 1.6920\n",
            "Epoch 149/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8232 - val_loss: 3.3297\n",
            "Epoch 150/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8004 - val_loss: 9.0470\n",
            "Epoch 151/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6687 - val_loss: 2.3103\n",
            "Epoch 152/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9169 - val_loss: 5.0634\n",
            "Epoch 153/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7146 - val_loss: 1.8220\n",
            "Epoch 154/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0013 - val_loss: 5.2552\n",
            "Epoch 155/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8637 - val_loss: 2.5692\n",
            "Epoch 156/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8130 - val_loss: 5.0854\n",
            "Epoch 157/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6940 - val_loss: 1.9099\n",
            "Epoch 158/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9604 - val_loss: 5.6268\n",
            "Epoch 159/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6201 - val_loss: 1.8548\n",
            "Epoch 160/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8870 - val_loss: 5.3646\n",
            "Epoch 161/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6406 - val_loss: 1.9194\n",
            "Epoch 162/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8786 - val_loss: 5.4732\n",
            "Epoch 163/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5878 - val_loss: 1.8076\n",
            "Epoch 164/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8697 - val_loss: 5.5040\n",
            "Epoch 165/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5617 - val_loss: 1.9229\n",
            "Epoch 166/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7090 - val_loss: 5.4931\n",
            "Epoch 167/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3449 - val_loss: 1.4863\n",
            "Epoch 168/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7955 - val_loss: 5.0712\n",
            "Epoch 169/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5058 - val_loss: 1.5074\n",
            "Epoch 170/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8790 - val_loss: 5.5309\n",
            "Epoch 171/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5466 - val_loss: 2.2209\n",
            "(145, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 39.7634 - val_loss: 54.4666\n",
            "Epoch 2/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 15.1298 - val_loss: 37.7203\n",
            "Epoch 3/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 23.2997 - val_loss: 2.0713\n",
            "Epoch 4/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 12.7736 - val_loss: 4.3840\n",
            "Epoch 5/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 13.2126 - val_loss: 10.6447\n",
            "Epoch 6/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 12.9617 - val_loss: 19.4981\n",
            "Epoch 7/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 10.5265 - val_loss: 10.9711\n",
            "Epoch 8/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 9.9841 - val_loss: 12.1172\n",
            "Epoch 9/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 14.6747 - val_loss: 12.9001\n",
            "Epoch 10/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 11.9490 - val_loss: 2.8054\n",
            "Epoch 11/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 10.5477 - val_loss: 2.8675\n",
            "Epoch 12/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 10.6853 - val_loss: 5.8385\n",
            "Epoch 13/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 12.2787 - val_loss: 18.6568\n",
            "Epoch 14/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 12.5906 - val_loss: 18.7327\n",
            "Epoch 15/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 9.7732 - val_loss: 11.1149\n",
            "Epoch 16/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 14.4185 - val_loss: 12.8879\n",
            "Epoch 17/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 13.6589 - val_loss: 35.6204\n",
            "Epoch 18/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 9.0647 - val_loss: 9.3800\n",
            "Epoch 19/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.7494 - val_loss: 20.1953\n",
            "Epoch 20/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.3148 - val_loss: 22.8409\n",
            "Epoch 21/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 9.1824 - val_loss: 13.5680\n",
            "Epoch 22/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.4558 - val_loss: 2.4685\n",
            "Epoch 23/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 9.1241 - val_loss: 17.2032\n",
            "Epoch 24/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.0253 - val_loss: 10.5315\n",
            "Epoch 25/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 10.5123 - val_loss: 3.9520\n",
            "Epoch 26/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.3567 - val_loss: 11.9651\n",
            "Epoch 27/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 9.2944 - val_loss: 15.4316\n",
            "Epoch 28/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 9.7467 - val_loss: 12.4781\n",
            "Epoch 29/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.7941 - val_loss: 1.0132\n",
            "Epoch 30/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 7.0043 - val_loss: 5.9590\n",
            "Epoch 31/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.3687 - val_loss: 10.1722\n",
            "Epoch 32/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 7.9376 - val_loss: 26.2361\n",
            "Epoch 33/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.3049 - val_loss: 15.6982\n",
            "Epoch 34/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.1995 - val_loss: 17.1834\n",
            "Epoch 35/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.4312 - val_loss: 9.0602\n",
            "Epoch 36/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.7719 - val_loss: 2.7906\n",
            "Epoch 37/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 7.2788 - val_loss: 6.7630\n",
            "Epoch 38/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.2749 - val_loss: 23.0668\n",
            "Epoch 39/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.5802 - val_loss: 7.4304\n",
            "Epoch 40/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.6142 - val_loss: 24.2718\n",
            "Epoch 41/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 7.6743 - val_loss: 1.2754\n",
            "Epoch 42/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.4431 - val_loss: 21.2244\n",
            "Epoch 43/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.4073 - val_loss: 19.7911\n",
            "Epoch 44/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.9967 - val_loss: 14.8217\n",
            "Epoch 45/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 7.9037 - val_loss: 1.2172\n",
            "Epoch 46/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.7690 - val_loss: 10.6443\n",
            "Epoch 47/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.6933 - val_loss: 33.0561\n",
            "Epoch 48/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.3275 - val_loss: 6.8727\n",
            "Epoch 49/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.6248 - val_loss: 17.7050\n",
            "Epoch 50/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.0797 - val_loss: 3.1733\n",
            "Epoch 51/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 7.2247 - val_loss: 14.9892\n",
            "Epoch 52/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.0728 - val_loss: 17.5623\n",
            "Epoch 53/686\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.2473 - val_loss: 23.3433\n",
            "Epoch 54/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.4498 - val_loss: 18.2493\n",
            "Epoch 55/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.3651 - val_loss: 33.8436\n",
            "Epoch 56/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.6568 - val_loss: 10.2223\n",
            "Epoch 57/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.2912 - val_loss: 29.5829\n",
            "Epoch 58/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.5493 - val_loss: 33.0051\n",
            "Epoch 59/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.8501 - val_loss: 3.1594\n",
            "Epoch 60/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 11.8352 - val_loss: 1.0113\n",
            "Epoch 61/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 10.0943 - val_loss: 40.0168\n",
            "Epoch 62/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.5147 - val_loss: 7.3927\n",
            "Epoch 63/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.8127 - val_loss: 26.2962\n",
            "Epoch 64/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.5779 - val_loss: 28.9464\n",
            "Epoch 65/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 5.8213 - val_loss: 16.4943\n",
            "Epoch 66/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.7628 - val_loss: 35.0070\n",
            "Epoch 67/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.8207 - val_loss: 25.3035\n",
            "Epoch 68/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.7420 - val_loss: 10.2106\n",
            "Epoch 69/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.6671 - val_loss: 23.4820\n",
            "Epoch 70/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.3615 - val_loss: 16.0391\n",
            "Epoch 71/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.1406 - val_loss: 27.8799\n",
            "Epoch 72/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.1845 - val_loss: 14.7571\n",
            "Epoch 73/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 6.0210 - val_loss: 26.1556\n",
            "Epoch 74/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.3895 - val_loss: 28.6570\n",
            "Epoch 75/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.4899 - val_loss: 14.4369\n",
            "Epoch 76/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 7.2519 - val_loss: 29.8749\n",
            "Epoch 77/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.8368 - val_loss: 31.2713\n",
            "Epoch 78/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.6479 - val_loss: 35.6919\n",
            "Epoch 79/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.0583 - val_loss: 30.5620\n",
            "Epoch 80/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.9483 - val_loss: 26.4152\n",
            "Epoch 81/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.7625 - val_loss: 26.2212\n",
            "Epoch 82/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.2644 - val_loss: 21.1127\n",
            "Epoch 83/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.2606 - val_loss: 36.5882\n",
            "Epoch 84/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.2230 - val_loss: 31.5940\n",
            "Epoch 85/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.8130 - val_loss: 29.0710\n",
            "Epoch 86/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.9630 - val_loss: 26.8461\n",
            "Epoch 87/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.7509 - val_loss: 19.4768\n",
            "Epoch 88/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.4726 - val_loss: 33.3028\n",
            "Epoch 89/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.9130 - val_loss: 14.5130\n",
            "Epoch 90/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.4448 - val_loss: 27.6298\n",
            "Epoch 91/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 6.3161 - val_loss: 23.1521\n",
            "Epoch 92/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.8185 - val_loss: 9.5321\n",
            "Epoch 93/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.2959 - val_loss: 21.3157\n",
            "Epoch 94/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.9345 - val_loss: 25.2537\n",
            "Epoch 95/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.2096 - val_loss: 6.9135\n",
            "Epoch 96/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.1711 - val_loss: 19.3570\n",
            "Epoch 97/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.4024 - val_loss: 30.3771\n",
            "Epoch 98/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.2039 - val_loss: 14.2531\n",
            "Epoch 99/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 6.2673 - val_loss: 20.0764\n",
            "Epoch 100/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 5.9225 - val_loss: 14.8778\n",
            "Epoch 101/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.0397 - val_loss: 17.8734\n",
            "Epoch 102/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 7.1489 - val_loss: 26.6949\n",
            "Epoch 103/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.3659 - val_loss: 10.8685\n",
            "Epoch 104/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.0273 - val_loss: 27.7820\n",
            "Epoch 105/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.1784 - val_loss: 27.6857\n",
            "Epoch 106/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.8184 - val_loss: 21.5688\n",
            "Epoch 107/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.6202 - val_loss: 29.4925\n",
            "Epoch 108/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.5833 - val_loss: 15.6672\n",
            "Epoch 109/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.2036 - val_loss: 28.2353\n",
            "Epoch 110/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.2429 - val_loss: 20.2609\n",
            "Epoch 111/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.2929 - val_loss: 27.6417\n",
            "Epoch 112/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.4444 - val_loss: 18.5212\n",
            "Epoch 113/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 4.9659 - val_loss: 25.5756\n",
            "Epoch 114/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.2838 - val_loss: 36.9066\n",
            "Epoch 115/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.0498 - val_loss: 31.7167\n",
            "Epoch 116/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 7.3125 - val_loss: 25.4655\n",
            "Epoch 117/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.1313 - val_loss: 11.2735\n",
            "Epoch 118/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.5329 - val_loss: 30.3271\n",
            "Epoch 119/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.7769 - val_loss: 26.3382\n",
            "Epoch 120/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.7950 - val_loss: 13.1944\n",
            "Epoch 121/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 7.6568 - val_loss: 29.8964\n",
            "Epoch 122/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.8932 - val_loss: 8.0872\n",
            "Epoch 123/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.9565 - val_loss: 11.0528\n",
            "Epoch 124/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.7866 - val_loss: 34.4609\n",
            "Epoch 125/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.0244 - val_loss: 8.9981\n",
            "Epoch 126/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 8.1587 - val_loss: 11.3637\n",
            "Epoch 127/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.1804 - val_loss: 35.1599\n",
            "Epoch 128/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.6951 - val_loss: 15.3351\n",
            "Epoch 129/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.9956 - val_loss: 23.3992\n",
            "Epoch 130/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.1318 - val_loss: 23.8029\n",
            "Epoch 131/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.3662 - val_loss: 18.4580\n",
            "Epoch 132/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 6.0629 - val_loss: 23.6127\n",
            "Epoch 133/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.9651 - val_loss: 13.7922\n",
            "Epoch 134/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.3859 - val_loss: 27.1381\n",
            "Epoch 135/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.1150 - val_loss: 19.6547\n",
            "Epoch 136/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.6863 - val_loss: 11.5883\n",
            "Epoch 137/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 6.3432 - val_loss: 29.7992\n",
            "Epoch 138/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.9623 - val_loss: 14.4319\n",
            "Epoch 139/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.3599 - val_loss: 25.9881\n",
            "Epoch 140/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.4194 - val_loss: 17.0854\n",
            "Epoch 141/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 6.8420 - val_loss: 22.3821\n",
            "Epoch 142/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.6031 - val_loss: 3.2151\n",
            "Epoch 143/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.2597 - val_loss: 13.7684\n",
            "Epoch 144/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 9.0131 - val_loss: 34.5673\n",
            "Epoch 145/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.5935 - val_loss: 11.4844\n",
            "Epoch 146/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.3808 - val_loss: 12.2045\n",
            "Epoch 147/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.1125 - val_loss: 28.2723\n",
            "Epoch 148/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.9035 - val_loss: 7.1629\n",
            "Epoch 149/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.8847 - val_loss: 23.3232\n",
            "Epoch 150/686\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 7.0286 - val_loss: 18.4382\n",
            "Epoch 151/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.9585 - val_loss: 11.0266\n",
            "Epoch 152/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.2156 - val_loss: 23.0669\n",
            "Epoch 153/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.7240 - val_loss: 12.8903\n",
            "Epoch 154/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6.5460 - val_loss: 29.2337\n",
            "Epoch 155/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 4.8786 - val_loss: 12.7205\n",
            "Epoch 156/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.0366 - val_loss: 19.9169\n",
            "Epoch 157/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.4759 - val_loss: 23.2418\n",
            "Epoch 158/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 5.5663 - val_loss: 18.0453\n",
            "Epoch 159/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 6.6675 - val_loss: 8.8360\n",
            "Epoch 160/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.4137 - val_loss: 17.7723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SBYD6LXwedx"
      },
      "source": [
        "Predictions for second week can be seen below. The predictions start from the second value (145.1) because 144.24391 is an invalid prediction (< of last day).\n",
        "That's why we have 8 values and just select last 7. \n",
        "\n",
        "Again in the first printed row are the predictions and in the others the test data and the train data just for reference.\n",
        "\n",
        "Predictions for the first week cannot be seen here because the model parameters have been changed but the method is the same (just train until train[0:-7])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uquvBDEQThpF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f442ef96-5126-42bb-dee2-4cc94b4f13ab"
      },
      "source": [
        "\n",
        "predictions_conv_Mont = predictionOnPredictionLSTM(initialvalue_Montgomery,look_ahead+1,encoder_model_Montgomery)\n",
        "predictions_conv_Mont = predictions_conv_Mont.reshape(len(predictions_conv_Mont))\n",
        "print(predictions_conv_Mont)\n",
        "print(test_deaths[2][window:])\n",
        "print(train_deaths[2][150:])\n",
        "print(test_deaths[2])\n",
        "#print(mean_absolute_error(predictions_conv_Mont,test_deaths[2][window:]))\n",
        "#print(mean_squared_log_error(predictions_conv_Mont,test_deaths[2][window:]))#7.74 MAE best\n",
        "#prediction = [145.10944 146.31076 147.6109  149.19351 151.1802  153.07767 154.71606]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[144.24391 145.10944 146.31076 147.6109  149.19351 151.1802  153.07767\n",
            " 154.71606]\n",
            "[133 134 137 137 140 144 145]\n",
            "[73 76 77 82 82 85 90 94 95 95 97 102 103 103 107 109 110 110 112 113 113\n",
            " 115 117 119 120 120 120 122 125 130 132 132 133 133 133]\n",
            "[120 120 120 122 125 130 132 132 133 133 133 134 137 137 140 144 145]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQh-pjTjTvYM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7078d74d-6598-43e9-a36d-3460df911a1f"
      },
      "source": [
        "conv_model_Brazoria,conv_history_Brazoria = build_conv_model(np.array(X_train[3][50:]),np.array(X_test[3]),np.array(Y_train[3][50:]),np.array(Y_test[3]),window)#140 best\n",
        "encoder_model_Brazoria,encoder_history_Brazoria = build_encoder_decoder(np.array(X_train[3][50:]),np.array(X_test[3]),np.array(Y_train[3][50:]),np.array(Y_test[3]),window)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 38.0379 - val_loss: 81.8316\n",
            "Epoch 2/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.6553 - val_loss: 18.0734\n",
            "Epoch 3/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4953 - val_loss: 8.9747\n",
            "Epoch 4/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4832 - val_loss: 12.8793\n",
            "Epoch 5/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7588 - val_loss: 12.6079\n",
            "Epoch 6/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.0701 - val_loss: 3.6160\n",
            "Epoch 7/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7763 - val_loss: 2.8995\n",
            "Epoch 8/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1620 - val_loss: 8.2610\n",
            "Epoch 9/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7465 - val_loss: 12.6632\n",
            "Epoch 10/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4748 - val_loss: 4.9263\n",
            "Epoch 11/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.2218 - val_loss: 19.3878\n",
            "Epoch 12/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3644 - val_loss: 3.3867\n",
            "Epoch 13/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0285 - val_loss: 17.0624\n",
            "Epoch 14/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1078 - val_loss: 4.7273\n",
            "Epoch 15/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3501 - val_loss: 17.7946\n",
            "Epoch 16/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2125 - val_loss: 4.4050\n",
            "Epoch 17/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3909 - val_loss: 18.6587\n",
            "Epoch 18/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7234 - val_loss: 3.2363\n",
            "Epoch 19/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2018 - val_loss: 8.4436\n",
            "Epoch 20/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5912 - val_loss: 0.3511\n",
            "Epoch 21/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7641 - val_loss: 16.9678\n",
            "Epoch 22/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.6265 - val_loss: 2.4322\n",
            "Epoch 23/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.8105 - val_loss: 7.2085\n",
            "Epoch 24/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3880 - val_loss: 0.8131\n",
            "Epoch 25/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8770 - val_loss: 17.5404\n",
            "Epoch 26/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5094 - val_loss: 2.5296\n",
            "Epoch 27/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7179 - val_loss: 6.8094\n",
            "Epoch 28/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3829 - val_loss: 0.4848\n",
            "Epoch 29/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7294 - val_loss: 16.9180\n",
            "Epoch 30/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5400 - val_loss: 3.6946\n",
            "Epoch 31/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9027 - val_loss: 11.9675\n",
            "Epoch 32/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5840 - val_loss: 2.1985\n",
            "Epoch 33/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7254 - val_loss: 16.8112\n",
            "Epoch 34/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.4363 - val_loss: 2.2965\n",
            "Epoch 35/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6238 - val_loss: 6.7777\n",
            "Epoch 36/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1258 - val_loss: 0.9182\n",
            "Epoch 37/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6539 - val_loss: 16.7290\n",
            "Epoch 38/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3783 - val_loss: 2.2442\n",
            "Epoch 39/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5233 - val_loss: 6.2215\n",
            "Epoch 40/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2113 - val_loss: 0.2161\n",
            "Epoch 41/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.4503 - val_loss: 15.8760\n",
            "Epoch 42/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4327 - val_loss: 2.7614\n",
            "Epoch 43/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.8276 - val_loss: 7.6792\n",
            "Epoch 44/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9883 - val_loss: 0.4875\n",
            "Epoch 45/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.3138 - val_loss: 15.2117\n",
            "Epoch 46/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4461 - val_loss: 3.0794\n",
            "Epoch 47/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0391 - val_loss: 8.6929\n",
            "Epoch 48/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7731 - val_loss: 0.9464\n",
            "Epoch 49/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.3067 - val_loss: 15.1950\n",
            "Epoch 50/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3961 - val_loss: 2.9984\n",
            "Epoch 51/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9893 - val_loss: 8.5960\n",
            "Epoch 52/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6701 - val_loss: 1.1767\n",
            "Epoch 53/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3434 - val_loss: 15.4211\n",
            "Epoch 54/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3263 - val_loss: 2.9502\n",
            "Epoch 55/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.8840 - val_loss: 8.1123\n",
            "Epoch 56/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.7418 - val_loss: 0.6791\n",
            "Epoch 57/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1770 - val_loss: 14.8116\n",
            "Epoch 58/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3263 - val_loss: 2.7933\n",
            "Epoch 59/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8312 - val_loss: 7.9541\n",
            "Epoch 60/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6793 - val_loss: 0.6517\n",
            "Epoch 61/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1266 - val_loss: 14.6581\n",
            "Epoch 62/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2681 - val_loss: 2.8839\n",
            "Epoch 63/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8331 - val_loss: 8.1056\n",
            "Epoch 64/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5546 - val_loss: 0.9290\n",
            "Epoch 65/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1599 - val_loss: 14.8575\n",
            "Epoch 66/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2070 - val_loss: 2.7761\n",
            "Epoch 67/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7355 - val_loss: 7.6972\n",
            "Epoch 68/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5612 - val_loss: 0.7356\n",
            "Epoch 69/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0743 - val_loss: 14.5373\n",
            "Epoch 70/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1773 - val_loss: 4.1400\n",
            "Epoch 71/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5253 - val_loss: 3.5813\n",
            "Epoch 72/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9218 - val_loss: 1.3126\n",
            "Epoch 73/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2090 - val_loss: 16.8121\n",
            "Epoch 74/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9045 - val_loss: 2.0120\n",
            "Epoch 75/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6545 - val_loss: 7.5897\n",
            "Epoch 76/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1632 - val_loss: 1.3761\n",
            "Epoch 77/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.2123 - val_loss: 14.0504\n",
            "Epoch 78/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6979 - val_loss: 2.8821\n",
            "Epoch 79/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.1137 - val_loss: 14.4797\n",
            "Epoch 80/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2393 - val_loss: 2.2578\n",
            "Epoch 81/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3131 - val_loss: 5.6432\n",
            "Epoch 82/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9561 - val_loss: 3.6561\n",
            "Epoch 83/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4590 - val_loss: 2.1649\n",
            "Epoch 84/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6576 - val_loss: 1.4000\n",
            "Epoch 85/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2680 - val_loss: 0.6325\n",
            "Epoch 86/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1532 - val_loss: 5.7337\n",
            "Epoch 87/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5008 - val_loss: 10.4059\n",
            "Epoch 88/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2190 - val_loss: 4.9800\n",
            "Epoch 89/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4228 - val_loss: 11.1712\n",
            "Epoch 90/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2292 - val_loss: 1.9574\n",
            "Epoch 91/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4063 - val_loss: 14.1778\n",
            "Epoch 92/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7429 - val_loss: 3.2266\n",
            "Epoch 93/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4456 - val_loss: 14.6040\n",
            "Epoch 94/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5644 - val_loss: 3.3846\n",
            "Epoch 95/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3310 - val_loss: 14.5825\n",
            "Epoch 96/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2174 - val_loss: 3.0998\n",
            "Epoch 97/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8353 - val_loss: 7.7409\n",
            "Epoch 98/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6470 - val_loss: 1.2583\n",
            "Epoch 99/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9917 - val_loss: 13.9699\n",
            "Epoch 100/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3019 - val_loss: 3.4777\n",
            "Epoch 101/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9867 - val_loss: 12.5777\n",
            "Epoch 102/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7399 - val_loss: 2.9244\n",
            "Epoch 103/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7694 - val_loss: 7.4634\n",
            "Epoch 104/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8655 - val_loss: 2.2177\n",
            "Epoch 105/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0782 - val_loss: 10.5456\n",
            "Epoch 106/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4642 - val_loss: 3.6647\n",
            "Epoch 107/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2382 - val_loss: 12.2156\n",
            "Epoch 108/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7578 - val_loss: 1.6152\n",
            "Epoch 109/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6111 - val_loss: 12.6413\n",
            "Epoch 110/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2110 - val_loss: 3.5462\n",
            "Epoch 111/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9250 - val_loss: 14.1511\n",
            "Epoch 112/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9214 - val_loss: 1.7157\n",
            "Epoch 113/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8895 - val_loss: 5.1964\n",
            "Epoch 114/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9093 - val_loss: 2.1686\n",
            "Epoch 115/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0840 - val_loss: 14.5863\n",
            "Epoch 116/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9304 - val_loss: 2.9331\n",
            "Epoch 117/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.0112 - val_loss: 9.1948\n",
            "Epoch 118/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9866 - val_loss: 0.6223\n",
            "Epoch 119/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4633 - val_loss: 12.4368\n",
            "Epoch 120/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0001 - val_loss: 3.0199\n",
            "Epoch 121/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2740 - val_loss: 2.7699\n",
            "Epoch 122/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9563 - val_loss: 9.0217\n",
            "Epoch 123/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9809 - val_loss: 7.8568\n",
            "Epoch 124/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.6898 - val_loss: 2.0809\n",
            "Epoch 125/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1602 - val_loss: 10.6816\n",
            "Epoch 126/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2007 - val_loss: 0.7437\n",
            "Epoch 127/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0945 - val_loss: 1.2183\n",
            "Epoch 128/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2220 - val_loss: 1.1998\n",
            "Epoch 129/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1301 - val_loss: 6.5284\n",
            "Epoch 130/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1047 - val_loss: 3.8532\n",
            "Epoch 131/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5781 - val_loss: 9.6288\n",
            "Epoch 132/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9743 - val_loss: 3.3231\n",
            "Epoch 133/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3383 - val_loss: 11.0238\n",
            "Epoch 134/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4912 - val_loss: 1.9208\n",
            "Epoch 135/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5525 - val_loss: 12.7928\n",
            "Epoch 136/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.8785 - val_loss: 2.8672\n",
            "Epoch 137/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0144 - val_loss: 9.9160\n",
            "Epoch 138/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4349 - val_loss: 2.4258\n",
            "Epoch 139/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7550 - val_loss: 13.9457\n",
            "Epoch 140/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6168 - val_loss: 1.6477\n",
            "Epoch 141/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7599 - val_loss: 4.5058\n",
            "Epoch 142/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8194 - val_loss: 1.8776\n",
            "Epoch 143/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8559 - val_loss: 14.0496\n",
            "Epoch 144/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6912 - val_loss: 1.8422\n",
            "Epoch 145/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2806 - val_loss: 7.0120\n",
            "Epoch 146/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6302 - val_loss: 2.0479\n",
            "Epoch 147/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7456 - val_loss: 13.7902\n",
            "Epoch 148/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6166 - val_loss: 2.2494\n",
            "Epoch 149/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3516 - val_loss: 7.2324\n",
            "Epoch 150/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6861 - val_loss: 1.3403\n",
            "Epoch 151/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5055 - val_loss: 13.0777\n",
            "Epoch 152/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5553 - val_loss: 1.3232\n",
            "Epoch 153/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6095 - val_loss: 4.1390\n",
            "Epoch 154/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1843 - val_loss: 0.6456\n",
            "Epoch 155/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8527 - val_loss: 3.6554\n",
            "Epoch 156/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4347 - val_loss: 10.4240\n",
            "Epoch 157/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1744 - val_loss: 1.8647\n",
            "Epoch 158/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4600 - val_loss: 7.6916\n",
            "Epoch 159/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.0099 - val_loss: 2.0693\n",
            "Epoch 160/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1154 - val_loss: 6.2868\n",
            "Epoch 161/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9773 - val_loss: 2.4105\n",
            "Epoch 162/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0067 - val_loss: 4.8836\n",
            "Epoch 163/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5419 - val_loss: 2.8031\n",
            "Epoch 164/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4540 - val_loss: 9.5861\n",
            "Epoch 165/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6177 - val_loss: 3.0228\n",
            "Epoch 166/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1298 - val_loss: 9.1067\n",
            "Epoch 167/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.5509 - val_loss: 0.7558\n",
            "Epoch 168/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1844 - val_loss: 7.1202\n",
            "Epoch 169/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3370 - val_loss: 0.3819\n",
            "Epoch 170/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.8340 - val_loss: 5.6956\n",
            "Epoch 171/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4890 - val_loss: 2.9804\n",
            "Epoch 172/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.4324 - val_loss: 9.7693\n",
            "Epoch 173/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4531 - val_loss: 2.4116\n",
            "Epoch 174/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1055 - val_loss: 6.8781\n",
            "Epoch 175/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4057 - val_loss: 0.1783\n",
            "Epoch 176/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3984 - val_loss: 7.6723\n",
            "Epoch 177/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2459 - val_loss: 0.4421\n",
            "Epoch 178/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4371 - val_loss: 5.4642\n",
            "Epoch 179/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1654 - val_loss: 1.9569\n",
            "Epoch 180/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3010 - val_loss: 9.1449\n",
            "Epoch 181/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6431 - val_loss: 2.5816\n",
            "Epoch 182/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8593 - val_loss: 9.8449\n",
            "Epoch 183/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9989 - val_loss: 0.6255\n",
            "Epoch 184/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2488 - val_loss: 7.6598\n",
            "Epoch 185/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1583 - val_loss: 0.9818\n",
            "Epoch 186/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6381 - val_loss: 7.6245\n",
            "Epoch 187/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5516 - val_loss: 0.7616\n",
            "Epoch 188/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2484 - val_loss: 9.1034\n",
            "Epoch 189/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4805 - val_loss: 2.3881\n",
            "Epoch 190/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6361 - val_loss: 7.8636\n",
            "Epoch 191/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1487 - val_loss: 0.7146\n",
            "Epoch 192/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.5129 - val_loss: 7.5063\n",
            "Epoch 193/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5479 - val_loss: 1.9384\n",
            "Epoch 194/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7494 - val_loss: 6.6722\n",
            "Epoch 195/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.8553 - val_loss: 0.9331\n",
            "Epoch 196/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6586 - val_loss: 7.0392\n",
            "Epoch 197/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5467 - val_loss: 0.0193\n",
            "Epoch 198/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3868 - val_loss: 9.5703\n",
            "Epoch 199/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5448 - val_loss: 2.1032\n",
            "Epoch 200/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4623 - val_loss: 8.4672\n",
            "Epoch 201/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8176 - val_loss: 0.8597\n",
            "Epoch 202/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2681 - val_loss: 6.7267\n",
            "Epoch 203/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2186 - val_loss: 13.7470\n",
            "Epoch 204/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7115 - val_loss: 1.2426\n",
            "Epoch 205/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2426 - val_loss: 3.9404\n",
            "Epoch 206/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5395 - val_loss: 15.8504\n",
            "Epoch 207/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9806 - val_loss: 0.9240\n",
            "Epoch 208/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.8865 - val_loss: 11.1045\n",
            "Epoch 209/686\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.3843 - val_loss: 2.2801\n",
            "Epoch 210/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9859 - val_loss: 6.9448\n",
            "Epoch 211/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1617 - val_loss: 0.4466\n",
            "Epoch 212/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4723 - val_loss: 6.9568\n",
            "Epoch 213/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6214 - val_loss: 1.4800\n",
            "Epoch 214/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9787 - val_loss: 7.7953\n",
            "Epoch 215/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.7317 - val_loss: 1.6438\n",
            "Epoch 216/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6449 - val_loss: 9.2410\n",
            "Epoch 217/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4979 - val_loss: 1.9816\n",
            "Epoch 218/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4719 - val_loss: 6.7311\n",
            "Epoch 219/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6703 - val_loss: 1.7597\n",
            "Epoch 220/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8589 - val_loss: 7.9064\n",
            "Epoch 221/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4238 - val_loss: 2.3877\n",
            "Epoch 222/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6391 - val_loss: 8.9798\n",
            "Epoch 223/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5341 - val_loss: 1.4554\n",
            "Epoch 224/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3499 - val_loss: 6.9480\n",
            "Epoch 225/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3501 - val_loss: 0.3805\n",
            "Epoch 226/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.0927 - val_loss: 8.5282\n",
            "Epoch 227/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.5057 - val_loss: 1.9338\n",
            "Epoch 228/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3344 - val_loss: 8.2401\n",
            "Epoch 229/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6449 - val_loss: 1.8137\n",
            "Epoch 230/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5356 - val_loss: 8.0175\n",
            "Epoch 231/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9322 - val_loss: 0.3310\n",
            "Epoch 232/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1491 - val_loss: 7.8217\n",
            "Epoch 233/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6214 - val_loss: 0.7251\n",
            "Epoch 234/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1320 - val_loss: 7.1086\n",
            "Epoch 235/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7519 - val_loss: 1.3840\n",
            "Epoch 236/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.4925 - val_loss: 7.8842\n",
            "Epoch 237/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0915 - val_loss: 0.7445\n",
            "Epoch 238/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8537 - val_loss: 7.7598\n",
            "Epoch 239/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2048 - val_loss: 2.3036\n",
            "Epoch 240/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5469 - val_loss: 6.9690\n",
            "Epoch 241/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2412 - val_loss: 0.3890\n",
            "Epoch 242/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1338 - val_loss: 8.2139\n",
            "Epoch 243/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8459 - val_loss: 0.6993\n",
            "Epoch 244/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0654 - val_loss: 8.1075\n",
            "Epoch 245/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5340 - val_loss: 1.6121\n",
            "Epoch 246/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2020 - val_loss: 7.9245\n",
            "Epoch 247/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6662 - val_loss: 0.9500\n",
            "Epoch 248/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1287 - val_loss: 7.0723\n",
            "Epoch 249/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.9087 - val_loss: 0.4599\n",
            "Epoch 250/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1460 - val_loss: 8.0731\n",
            "Epoch 251/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5037 - val_loss: 1.0039\n",
            "Epoch 252/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0753 - val_loss: 7.5028\n",
            "Epoch 253/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3740 - val_loss: 1.9502\n",
            "Epoch 254/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4607 - val_loss: 6.6302\n",
            "Epoch 255/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5873 - val_loss: 2.3344\n",
            "Epoch 256/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6082 - val_loss: 7.4210\n",
            "Epoch 257/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2140 - val_loss: 2.1134\n",
            "Epoch 258/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8623 - val_loss: 6.5191\n",
            "Epoch 259/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7762 - val_loss: 0.6781\n",
            "Epoch 260/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2349 - val_loss: 6.6913\n",
            "Epoch 261/686\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.0846 - val_loss: 0.0325\n",
            "Epoch 262/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0578 - val_loss: 8.7464\n",
            "Epoch 263/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2559 - val_loss: 2.0720\n",
            "Epoch 264/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.0897 - val_loss: 8.0195\n",
            "Epoch 265/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2843 - val_loss: 2.3428\n",
            "Epoch 266/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3603 - val_loss: 7.4032\n",
            "Epoch 267/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1436 - val_loss: 1.1628\n",
            "Epoch 268/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6549 - val_loss: 7.0141\n",
            "Epoch 269/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2918 - val_loss: 1.4271\n",
            "Epoch 270/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3239 - val_loss: 6.1920\n",
            "Epoch 271/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2185 - val_loss: 0.4846\n",
            "Epoch 272/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1002 - val_loss: 8.5619\n",
            "Epoch 273/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5096 - val_loss: 1.4453\n",
            "Epoch 274/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9658 - val_loss: 7.6101\n",
            "Epoch 275/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5179 - val_loss: 1.3342\n",
            "Epoch 276/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9934 - val_loss: 6.9055\n",
            "Epoch 277/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7547 - val_loss: 0.8822\n",
            "Epoch 278/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1168 - val_loss: 6.9194\n",
            "Epoch 279/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9221 - val_loss: 0.3461\n",
            "Epoch 280/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0299 - val_loss: 8.4999\n",
            "Epoch 281/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2585 - val_loss: 2.0648\n",
            "Epoch 282/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1402 - val_loss: 7.9476\n",
            "Epoch 283/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2676 - val_loss: 2.1209\n",
            "Epoch 284/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.3222 - val_loss: 6.6530\n",
            "Epoch 285/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3263 - val_loss: 1.5659\n",
            "Epoch 286/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5539 - val_loss: 7.0562\n",
            "Epoch 287/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3177 - val_loss: 2.2820\n",
            "Epoch 288/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2235 - val_loss: 8.3103\n",
            "Epoch 289/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4078 - val_loss: 1.4729\n",
            "Epoch 290/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0054 - val_loss: 7.5963\n",
            "Epoch 291/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4500 - val_loss: 0.8677\n",
            "Epoch 292/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0753 - val_loss: 6.6381\n",
            "Epoch 293/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6666 - val_loss: 1.5072\n",
            "Epoch 294/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1167 - val_loss: 8.2696\n",
            "Epoch 295/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.5304 - val_loss: 0.9798\n",
            "Epoch 296/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.8264 - val_loss: 7.4083\n",
            "Epoch 297/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3954 - val_loss: 1.3353\n",
            "Epoch 298/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.9712 - val_loss: 7.6302\n",
            "Epoch 299/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3133 - val_loss: 1.3922\n",
            "Epoch 300/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1167 - val_loss: 6.0872\n",
            "Epoch 301/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9377 - val_loss: 0.4609\n",
            "Epoch 302/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9925 - val_loss: 8.2292\n",
            "Epoch 303/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3727 - val_loss: 1.5050\n",
            "Epoch 304/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9209 - val_loss: 7.2939\n",
            "Epoch 305/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3795 - val_loss: 1.3928\n",
            "Epoch 306/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.0727 - val_loss: 6.3891\n",
            "Epoch 307/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.9432 - val_loss: 0.2915\n",
            "Epoch 308/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9692 - val_loss: 8.4977\n",
            "Epoch 309/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1676 - val_loss: 1.5409\n",
            "Epoch 310/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6543 - val_loss: 6.3363\n",
            "Epoch 311/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3653 - val_loss: 1.3139\n",
            "Epoch 312/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3893 - val_loss: 6.1155\n",
            "Epoch 313/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2523 - val_loss: 1.5026\n",
            "Epoch 314/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5961 - val_loss: 7.7400\n",
            "Epoch 315/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.0228 - val_loss: 1.7611\n",
            "Epoch 316/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4771 - val_loss: 5.4645\n",
            "Epoch 317/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6477 - val_loss: 0.9624\n",
            "Epoch 318/686\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.3810 - val_loss: 6.8246\n",
            "Epoch 319/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0276 - val_loss: 0.7066\n",
            "Epoch 320/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6340 - val_loss: 7.5472\n",
            "Epoch 321/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0946 - val_loss: 1.8843\n",
            "Epoch 322/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5950 - val_loss: 5.9380\n",
            "Epoch 323/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5486 - val_loss: 0.6988\n",
            "Epoch 324/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2577 - val_loss: 6.3722\n",
            "Epoch 325/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9588 - val_loss: 0.3891\n",
            "Epoch 326/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7813 - val_loss: 8.2733\n",
            "Epoch 327/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9939 - val_loss: 1.6237\n",
            "Epoch 328/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2585 - val_loss: 4.6704\n",
            "Epoch 329/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6492 - val_loss: 0.3657\n",
            "Epoch 330/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.8470 - val_loss: 5.6448\n",
            "Epoch 331/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5434 - val_loss: 2.2891\n",
            "Epoch 332/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7513 - val_loss: 8.3817\n",
            "Epoch 333/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0545 - val_loss: 0.9322\n",
            "Epoch 334/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9253 - val_loss: 1.8092\n",
            "Epoch 335/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3477 - val_loss: 2.6521\n",
            "Epoch 336/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9492 - val_loss: 6.4427\n",
            "Epoch 337/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9732 - val_loss: 1.2626\n",
            "Epoch 338/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5224 - val_loss: 5.8668\n",
            "Epoch 339/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4068 - val_loss: 0.5564\n",
            "Epoch 340/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3452 - val_loss: 5.3801\n",
            "Epoch 341/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1312 - val_loss: 0.6472\n",
            "Epoch 342/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7648 - val_loss: 7.8010\n",
            "Epoch 343/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2300 - val_loss: 1.5837\n",
            "Epoch 344/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7078 - val_loss: 6.9096\n",
            "Epoch 345/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3228 - val_loss: 1.3468\n",
            "Epoch 346/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8985 - val_loss: 6.6260\n",
            "Epoch 347/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4954 - val_loss: 1.2644\n",
            "Epoch 348/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1079 - val_loss: 7.7667\n",
            "Epoch 349/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5275 - val_loss: 0.2296\n",
            "Epoch 350/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6852 - val_loss: 6.9360\n",
            "Epoch 351/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0665 - val_loss: 2.2018\n",
            "Epoch 352/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4854 - val_loss: 6.6577\n",
            "Epoch 353/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9571 - val_loss: 0.5389\n",
            "Epoch 354/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6653 - val_loss: 7.6059\n",
            "Epoch 355/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0734 - val_loss: 1.5111\n",
            "Epoch 356/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5486 - val_loss: 6.0443\n",
            "Epoch 357/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3303 - val_loss: 1.2533\n",
            "(131, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 45.5890 - val_loss: 94.0489\n",
            "Epoch 2/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 17.8581 - val_loss: 5.6647\n",
            "Epoch 3/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 11.6480 - val_loss: 2.8340\n",
            "Epoch 4/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 14.6199 - val_loss: 3.4078\n",
            "Epoch 5/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 11.4819 - val_loss: 1.1373\n",
            "Epoch 6/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 13.1140 - val_loss: 3.9127\n",
            "Epoch 7/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 15.9626 - val_loss: 3.4055\n",
            "Epoch 8/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 13.9693 - val_loss: 22.5670\n",
            "Epoch 9/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 13.1687 - val_loss: 5.5071\n",
            "Epoch 10/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 10.8527 - val_loss: 14.5058\n",
            "Epoch 11/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.8946 - val_loss: 6.9453\n",
            "Epoch 12/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 10.6287 - val_loss: 25.1680\n",
            "Epoch 13/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2636 - val_loss: 11.3069\n",
            "Epoch 14/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 7.7601 - val_loss: 1.9377\n",
            "Epoch 15/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 7.6183 - val_loss: 10.2450\n",
            "Epoch 16/686\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 8.2930 - val_loss: 11.1071\n",
            "Epoch 17/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 10.7505 - val_loss: 15.5001\n",
            "Epoch 18/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 11.3213 - val_loss: 11.4884\n",
            "Epoch 19/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.8766 - val_loss: 12.7608\n",
            "Epoch 20/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 13.9463 - val_loss: 17.9983\n",
            "Epoch 21/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.6082 - val_loss: 0.1845\n",
            "Epoch 22/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 10.3249 - val_loss: 19.0722\n",
            "Epoch 23/686\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 8.6133 - val_loss: 5.6646\n",
            "Epoch 24/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.6867 - val_loss: 8.6933\n",
            "Epoch 25/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 8.0947 - val_loss: 16.5474\n",
            "Epoch 26/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 11.5487 - val_loss: 25.1530\n",
            "Epoch 27/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.9239 - val_loss: 18.3593\n",
            "Epoch 28/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.3963 - val_loss: 13.9167\n",
            "Epoch 29/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 9.4997 - val_loss: 1.2130\n",
            "Epoch 30/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 8.7182 - val_loss: 15.4910\n",
            "Epoch 31/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.4743 - val_loss: 0.1641\n",
            "Epoch 32/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 8.2919 - val_loss: 20.7615\n",
            "Epoch 33/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.5499 - val_loss: 1.2431\n",
            "Epoch 34/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.0242 - val_loss: 10.2082\n",
            "Epoch 35/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.5187 - val_loss: 17.6040\n",
            "Epoch 36/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.9675 - val_loss: 7.5355\n",
            "Epoch 37/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 14.8921 - val_loss: 3.0219\n",
            "Epoch 38/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 10.0490 - val_loss: 28.2764\n",
            "Epoch 39/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 9.5758 - val_loss: 18.7286\n",
            "Epoch 40/686\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 9.9335 - val_loss: 31.7752\n",
            "Epoch 41/686\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 6.7586 - val_loss: 19.6772\n",
            "Epoch 42/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.6823 - val_loss: 13.6128\n",
            "Epoch 43/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.0267 - val_loss: 8.8515\n",
            "Epoch 44/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 8.4800 - val_loss: 29.1510\n",
            "Epoch 45/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.9648 - val_loss: 18.2826\n",
            "Epoch 46/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 8.6476 - val_loss: 6.6328\n",
            "Epoch 47/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.1912 - val_loss: 16.0896\n",
            "Epoch 48/686\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 7.0477 - val_loss: 15.7075\n",
            "Epoch 49/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 8.0083 - val_loss: 2.6028\n",
            "Epoch 50/686\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 6.8739 - val_loss: 20.3582\n",
            "Epoch 51/686\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 7.3492 - val_loss: 28.2663\n",
            "Epoch 52/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.3353 - val_loss: 22.6528\n",
            "Epoch 53/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 8.5784 - val_loss: 20.6773\n",
            "Epoch 54/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 11.8212 - val_loss: 38.3957\n",
            "Epoch 55/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 8.1018 - val_loss: 10.0191\n",
            "Epoch 56/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 11.0847 - val_loss: 7.7379\n",
            "Epoch 57/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 8.8628 - val_loss: 24.8817\n",
            "Epoch 58/686\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 7.9516 - val_loss: 10.2289\n",
            "Epoch 59/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.9844 - val_loss: 12.9534\n",
            "Epoch 60/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 7.3757 - val_loss: 22.7470\n",
            "Epoch 61/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.6346 - val_loss: 12.9864\n",
            "Epoch 62/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 8.6317 - val_loss: 15.6078\n",
            "Epoch 63/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 8.4772 - val_loss: 4.3467\n",
            "Epoch 64/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 10.3939 - val_loss: 15.3369\n",
            "Epoch 65/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 11.1572 - val_loss: 4.1519\n",
            "Epoch 66/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 8.6153 - val_loss: 24.4985\n",
            "Epoch 67/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.2266 - val_loss: 12.4561\n",
            "Epoch 68/686\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 7.9953 - val_loss: 3.4011\n",
            "Epoch 69/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.4318 - val_loss: 3.5585\n",
            "Epoch 70/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 8.6919 - val_loss: 5.2566\n",
            "Epoch 71/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.9914 - val_loss: 3.3313\n",
            "Epoch 72/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 7.0572 - val_loss: 5.9871\n",
            "Epoch 73/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.5027 - val_loss: 23.4592\n",
            "Epoch 74/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.2966 - val_loss: 22.5638\n",
            "Epoch 75/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 11.0369 - val_loss: 13.6890\n",
            "Epoch 76/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 11.5779 - val_loss: 29.4372\n",
            "Epoch 77/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 6.7490 - val_loss: 4.2430\n",
            "Epoch 78/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.8357 - val_loss: 2.3839\n",
            "Epoch 79/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.3250 - val_loss: 17.9783\n",
            "Epoch 80/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.5727 - val_loss: 11.0139\n",
            "Epoch 81/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 8.1006 - val_loss: 15.4241\n",
            "Epoch 82/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.1208 - val_loss: 5.9203\n",
            "Epoch 83/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 7.7205 - val_loss: 9.0211\n",
            "Epoch 84/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 7.3791 - val_loss: 4.8882\n",
            "Epoch 85/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.5061 - val_loss: 13.8633\n",
            "Epoch 86/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.0478 - val_loss: 18.4371\n",
            "Epoch 87/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 8.6491 - val_loss: 25.1320\n",
            "Epoch 88/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 8.7969 - val_loss: 3.6037\n",
            "Epoch 89/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 7.6237 - val_loss: 15.0791\n",
            "Epoch 90/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.7284 - val_loss: 7.9440\n",
            "Epoch 91/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.6271 - val_loss: 21.2038\n",
            "Epoch 92/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.2668 - val_loss: 18.3837\n",
            "Epoch 93/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 8.3436 - val_loss: 28.0624\n",
            "Epoch 94/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 6.8994 - val_loss: 6.3550\n",
            "Epoch 95/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 5.5316 - val_loss: 19.2150\n",
            "Epoch 96/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 5.6416 - val_loss: 18.9135\n",
            "Epoch 97/686\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 6.6718 - val_loss: 9.0728\n",
            "Epoch 98/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.2414 - val_loss: 4.3858\n",
            "Epoch 99/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 6.4183 - val_loss: 17.8480\n",
            "Epoch 100/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.7384 - val_loss: 7.1404\n",
            "Epoch 101/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 5.5246 - val_loss: 11.1339\n",
            "Epoch 102/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 5.9923 - val_loss: 16.2196\n",
            "Epoch 103/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.2138 - val_loss: 21.2394\n",
            "Epoch 104/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.6618 - val_loss: 19.6233\n",
            "Epoch 105/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.6201 - val_loss: 18.8299\n",
            "Epoch 106/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 8.7597 - val_loss: 10.7426\n",
            "Epoch 107/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 8.2092 - val_loss: 18.5689\n",
            "Epoch 108/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 6.9044 - val_loss: 4.1277\n",
            "Epoch 109/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 6.4894 - val_loss: 14.2628\n",
            "Epoch 110/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.1223 - val_loss: 13.8107\n",
            "Epoch 111/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 6.1775 - val_loss: 13.6875\n",
            "Epoch 112/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.1520 - val_loss: 17.0305\n",
            "Epoch 113/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.1831 - val_loss: 22.2403\n",
            "Epoch 114/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 7.1256 - val_loss: 8.5870\n",
            "Epoch 115/686\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 6.4040 - val_loss: 16.0020\n",
            "Epoch 116/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 8.0043 - val_loss: 10.0918\n",
            "Epoch 117/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.5419 - val_loss: 21.7038\n",
            "Epoch 118/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.5355 - val_loss: 21.4467\n",
            "Epoch 119/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.0937 - val_loss: 16.2283\n",
            "Epoch 120/686\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 6.4602 - val_loss: 6.1582\n",
            "Epoch 121/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 8.7513 - val_loss: 25.8685\n",
            "Epoch 122/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 7.3859 - val_loss: 5.7805\n",
            "Epoch 123/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.2554 - val_loss: 16.8370\n",
            "Epoch 124/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.3608 - val_loss: 12.0527\n",
            "Epoch 125/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 6.6329 - val_loss: 9.8694\n",
            "Epoch 126/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 7.6557 - val_loss: 6.3755\n",
            "Epoch 127/686\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 8.1026 - val_loss: 27.6782\n",
            "Epoch 128/686\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 6.9349 - val_loss: 10.6265\n",
            "Epoch 129/686\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 6.2509 - val_loss: 11.7654\n",
            "Epoch 130/686\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.8009 - val_loss: 3.2357\n",
            "Epoch 131/686\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.8947 - val_loss: 19.9059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHpNUpnQy69E"
      },
      "source": [
        "The predictions are very close to what I submitted. Every time I run the model predictions may change a bit. Similarly due to randomness weights are slightly different. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWm5HmmazbWy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d40fa745-f05c-48b0-beed-d3ab24de097a"
      },
      "source": [
        "predictions_encoder_Brazoria = predictionOnPredictionLSTM(initialvalue_Brazoria,look_ahead,encoder_model_Brazoria)\n",
        "predictions_encoder_Brazoria = predictions_encoder_Brazoria.reshape(len(predictions_encoder_Brazoria))\n",
        "print(\"Predictions for second week are:\",predictions_encoder_Brazoria)# 120: is good for window = 7!, encoder\n",
        "#print(test_deaths[3][window:])#loaded weights and it's fine\n",
        "#print(train_deaths[3][-20:])\n",
        "print(\"Test data are:\",test_deaths[3])\n",
        "#trained it with window = 7 for first week, 10 for second\n",
        "#print(mean_absolute_error(predictions_conv_Brazoria,test_deaths[3][window:]))\n",
        "#print(mean_squared_log_error(predictions_conv_Brazoria,test_deaths[3][window:]))\n",
        "#[153.62431 155.44801 156.077   157.16106 158.01569 158.86296 159.82701]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions for second week are: [155.16408 156.25136 157.60457 158.62617 159.08263 160.21729 161.73271]\n",
            "Test data are: [143 145 146 146 146 147 148 148 154 155 155.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYcp86Mu6ks3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6765942-8d14-4402-b7d1-692c414dae96"
      },
      "source": [
        "conv_model_Chambers,conv_history_Chambers = build_conv_model(np.array(X_train[4][20:]),np.array(X_test[4]),np.array(Y_train[4][20:]),np.array(Y_test[4]),window)#100 best\n",
        "encoder_model_Chambers,encoder_history_Chambers = build_encoder_decoder(np.array(X_train[4][20:]),np.array(X_test[4]),np.array(Y_train[4][20:]),np.array(Y_test[4]),window)#120"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.9249 - val_loss: 6.8353\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2722 - val_loss: 3.5331\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7445 - val_loss: 0.0983\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6495 - val_loss: 1.4631\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7711 - val_loss: 0.4470\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5479 - val_loss: 1.1150\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7390 - val_loss: 0.4824\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5240 - val_loss: 1.5999\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5278 - val_loss: 0.9533\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5660 - val_loss: 0.0470\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5823 - val_loss: 0.2173\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6616 - val_loss: 1.7742\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5293 - val_loss: 0.1545\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5029 - val_loss: 1.0646\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5609 - val_loss: 0.0738\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5756 - val_loss: 1.3433\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5296 - val_loss: 0.1204\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4737 - val_loss: 1.1469\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5048 - val_loss: 0.0925\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4330 - val_loss: 1.0949\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4607 - val_loss: 0.1637\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4699 - val_loss: 1.3199\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4122 - val_loss: 0.0476\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3605 - val_loss: 0.3700\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3077 - val_loss: 0.4431\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2726 - val_loss: 0.3236\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2595 - val_loss: 0.1204\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2327 - val_loss: 0.3803\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2080 - val_loss: 0.0324\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2240 - val_loss: 0.3556\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4297 - val_loss: 0.1239\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8402 - val_loss: 2.1938\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2643 - val_loss: 0.0626\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2801 - val_loss: 0.2531\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7433 - val_loss: 1.2684\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3729 - val_loss: 0.8061\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3286 - val_loss: 0.1374\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4899 - val_loss: 1.3618\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2324 - val_loss: 0.1029\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2124 - val_loss: 0.3688\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1940 - val_loss: 0.1631\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3158 - val_loss: 0.0415\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6364 - val_loss: 1.0528\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3896 - val_loss: 0.9212\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2398 - val_loss: 0.3893\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5267 - val_loss: 1.4946\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1804 - val_loss: 0.0560\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2332 - val_loss: 0.1468\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2007 - val_loss: 0.2978\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1910 - val_loss: 0.0887\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2801 - val_loss: 0.1182\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5945 - val_loss: 1.5142\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1927 - val_loss: 0.0515\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2944 - val_loss: 0.1747\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5102 - val_loss: 0.5934\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4029 - val_loss: 1.0764\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2003 - val_loss: 0.0788\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1792 - val_loss: 0.0757\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2222 - val_loss: 0.0794\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1986 - val_loss: 0.2994\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1698 - val_loss: 0.2422\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1971 - val_loss: 0.0241\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2536 - val_loss: 0.2828\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5516 - val_loss: 1.4400\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1761 - val_loss: 0.0522\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1926 - val_loss: 0.2112\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3442 - val_loss: 0.2891\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4365 - val_loss: 0.5748\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3879 - val_loss: 0.8403\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2102 - val_loss: 0.2619\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4777 - val_loss: 1.1642\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1750 - val_loss: 0.0440\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1718 - val_loss: 0.0140\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2014 - val_loss: 0.1657\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1871 - val_loss: 0.0889\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2521 - val_loss: 0.1983\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5398 - val_loss: 1.4226\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1758 - val_loss: 0.0312\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2380 - val_loss: 0.0445\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5445 - val_loss: 0.8119\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3346 - val_loss: 0.7379\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2361 - val_loss: 0.2760\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4577 - val_loss: 1.2491\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1635 - val_loss: 0.0216\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1995 - val_loss: 0.1656\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1709 - val_loss: 0.3967\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1972 - val_loss: 0.1992\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2101 - val_loss: 0.2029\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1796 - val_loss: 0.1083\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1975 - val_loss: 0.2648\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5532 - val_loss: 1.4040\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1746 - val_loss: 0.0925\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2413 - val_loss: 0.0012\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4778 - val_loss: 0.6704\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3309 - val_loss: 0.6706\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2328 - val_loss: 0.2505\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4601 - val_loss: 1.2494\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1477 - val_loss: 0.1293\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2594 - val_loss: 0.1356\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4521 - val_loss: 0.6196\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2972 - val_loss: 0.5810\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2566 - val_loss: 0.1716\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4221 - val_loss: 1.1214\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1597 - val_loss: 0.0297\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1732 - val_loss: 0.0975\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2106 - val_loss: 0.2044\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5445 - val_loss: 1.3381\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1804 - val_loss: 0.2571\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1668 - val_loss: 0.0928\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1742 - val_loss: 0.0774\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3290 - val_loss: 0.1596\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4171 - val_loss: 1.0085\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1560 - val_loss: 0.0661\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1651 - val_loss: 0.1084\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1894 - val_loss: 0.2357\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5427 - val_loss: 1.3324\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1784 - val_loss: 0.3156\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1688 - val_loss: 0.0316\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1587 - val_loss: 0.0278\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1612 - val_loss: 0.1704\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3677 - val_loss: 0.3897\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3720 - val_loss: 0.7236\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1893 - val_loss: 0.1344\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3885 - val_loss: 0.8293\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1852 - val_loss: 0.0199\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1388 - val_loss: 0.0568\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2060 - val_loss: 0.1952\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4988 - val_loss: 0.9128\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2512 - val_loss: 0.3080\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2772 - val_loss: 0.0671\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3835 - val_loss: 0.8659\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1558 - val_loss: 0.0877\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1348 - val_loss: 0.0017\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1889 - val_loss: 0.2673\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5104 - val_loss: 1.0052\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2292 - val_loss: 0.2066\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2943 - val_loss: 0.1665\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3633 - val_loss: 0.7589\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1703 - val_loss: 0.0277\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1342 - val_loss: 0.0293\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1731 - val_loss: 0.0588\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1776 - val_loss: 0.1951\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1579 - val_loss: 0.0104\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1923 - val_loss: 0.1681\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4936 - val_loss: 1.1123\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1795 - val_loss: 0.1619\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1999 - val_loss: 0.0926\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4491 - val_loss: 0.7011\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2503 - val_loss: 0.3359\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2759 - val_loss: 0.0380\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3605 - val_loss: 0.8465\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1536 - val_loss: 0.0953\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1398 - val_loss: 0.0898\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1298 - val_loss: 0.0961\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2075 - val_loss: 0.2768\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4828 - val_loss: 1.2943\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1553 - val_loss: 0.2256\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1889 - val_loss: 0.0599\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2453 - val_loss: 0.1519\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4337 - val_loss: 1.0936\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1542 - val_loss: 0.0722\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2473 - val_loss: 0.2509\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3634 - val_loss: 0.3414\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2760 - val_loss: 0.5830\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2178 - val_loss: 0.2456\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3883 - val_loss: 0.9903\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1505 - val_loss: 0.1509\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3276 - val_loss: 0.2899\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3450 - val_loss: 0.6566\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1788 - val_loss: 0.1796\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3731 - val_loss: 0.7995\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1670 - val_loss: 0.0701\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1326 - val_loss: 8.0872e-04\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1525 - val_loss: 0.1543\n",
            "Epoch 175/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2904 - val_loss: 0.2015\n",
            "Epoch 176/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3186 - val_loss: 0.4289\n",
            "Epoch 177/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2833 - val_loss: 0.3704\n",
            "Epoch 178/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2417 - val_loss: 0.0520\n",
            "Epoch 179/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3465 - val_loss: 0.6916\n",
            "Epoch 180/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1754 - val_loss: 0.0071\n",
            "Epoch 181/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1315 - val_loss: 0.1581\n",
            "Epoch 182/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2873 - val_loss: 0.3565\n",
            "Epoch 183/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3049 - val_loss: 0.1987\n",
            "Epoch 184/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3075 - val_loss: 0.6470\n",
            "Epoch 185/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1822 - val_loss: 0.0282\n",
            "Epoch 186/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1340 - val_loss: 0.0263\n",
            "Epoch 187/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1954 - val_loss: 0.1440\n",
            "Epoch 188/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4276 - val_loss: 0.7845\n",
            "Epoch 189/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2142 - val_loss: 0.1974\n",
            "Epoch 190/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2666 - val_loss: 0.1093\n",
            "Epoch 191/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3394 - val_loss: 0.6718\n",
            "Epoch 192/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1757 - val_loss: 0.2375\n",
            "Epoch 193/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3743 - val_loss: 0.8864\n",
            "Epoch 194/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1444 - val_loss: 0.0587\n",
            "Epoch 195/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1388 - val_loss: 0.0240\n",
            "Epoch 196/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1491 - val_loss: 0.0127\n",
            "Epoch 197/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1450 - val_loss: 0.2790\n",
            "Epoch 198/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4774 - val_loss: 0.8861\n",
            "Epoch 199/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1948 - val_loss: 0.1904\n",
            "Epoch 200/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2731 - val_loss: 0.0834\n",
            "Epoch 201/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3261 - val_loss: 0.6891\n",
            "Epoch 202/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1762 - val_loss: 0.0405\n",
            "Epoch 203/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1340 - val_loss: 0.1120\n",
            "Epoch 204/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2257 - val_loss: 0.0151\n",
            "Epoch 205/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4100 - val_loss: 0.8853\n",
            "Epoch 206/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1541 - val_loss: 0.0453\n",
            "Epoch 207/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2210 - val_loss: 0.1696\n",
            "Epoch 208/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3549 - val_loss: 0.3738\n",
            "Epoch 209/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2476 - val_loss: 0.4557\n",
            "Epoch 210/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2344 - val_loss: 0.1037\n",
            "Epoch 211/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3338 - val_loss: 0.8037\n",
            "Epoch 212/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1588 - val_loss: 0.0920\n",
            "Epoch 213/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2389 - val_loss: 0.0438\n",
            "Epoch 214/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3955 - val_loss: 0.8983\n",
            "Epoch 215/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1561 - val_loss: 0.0195\n",
            "Epoch 216/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2189 - val_loss: 0.1565\n",
            "Epoch 217/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3506 - val_loss: 0.3922\n",
            "Epoch 218/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2360 - val_loss: 0.4114\n",
            "Epoch 219/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2397 - val_loss: 0.0637\n",
            "Epoch 220/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3203 - val_loss: 0.7462\n",
            "Epoch 221/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1664 - val_loss: 0.0917\n",
            "Epoch 222/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1357 - val_loss: 0.1000\n",
            "Epoch 223/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1359 - val_loss: 0.0209\n",
            "Epoch 224/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1346 - val_loss: 0.0106\n",
            "Epoch 225/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1644 - val_loss: 0.1411\n",
            "Epoch 226/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1548 - val_loss: 0.0156\n",
            "Epoch 227/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1558 - val_loss: 0.2364\n",
            "Epoch 228/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4331 - val_loss: 0.8332\n",
            "Epoch 229/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1899 - val_loss: 0.1650\n",
            "Epoch 230/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2483 - val_loss: 0.0737\n",
            "Epoch 231/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3252 - val_loss: 0.6539\n",
            "Epoch 232/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1617 - val_loss: 0.0259\n",
            "Epoch 233/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1339 - val_loss: 0.0693\n",
            "Epoch 234/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2023 - val_loss: 0.0080\n",
            "Epoch 235/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3747 - val_loss: 0.5893\n",
            "Epoch 236/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2047 - val_loss: 0.1698\n",
            "Epoch 237/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2890 - val_loss: 0.2044\n",
            "Epoch 238/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2736 - val_loss: 0.4934\n",
            "Epoch 239/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2145 - val_loss: 0.1051\n",
            "Epoch 240/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3171 - val_loss: 0.7269\n",
            "Epoch 241/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1639 - val_loss: 0.0792\n",
            "Epoch 242/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1405 - val_loss: 0.0088\n",
            "Epoch 243/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1350 - val_loss: 0.0112\n",
            "Epoch 244/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1611 - val_loss: 0.1180\n",
            "Epoch 245/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1624 - val_loss: 0.2179\n",
            "Epoch 246/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1600 - val_loss: 0.1480\n",
            "Epoch 247/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1663 - val_loss: 0.2418\n",
            "Epoch 248/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1906 - val_loss: 0.0871\n",
            "Epoch 249/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1696 - val_loss: 0.0896\n",
            "Epoch 250/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1502 - val_loss: 0.0054\n",
            "Epoch 251/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1732 - val_loss: 0.2148\n",
            "Epoch 252/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4128 - val_loss: 0.9904\n",
            "Epoch 253/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1430 - val_loss: 0.0108\n",
            "Epoch 254/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2019 - val_loss: 0.2048\n",
            "Epoch 255/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2860 - val_loss: 0.1767\n",
            "Epoch 256/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2742 - val_loss: 0.5490\n",
            "Epoch 257/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1884 - val_loss: 0.2224\n",
            "Epoch 258/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3468 - val_loss: 0.8176\n",
            "Epoch 259/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1399 - val_loss: 0.0689\n",
            "Epoch 260/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2403 - val_loss: 0.0328\n",
            "Epoch 261/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3750 - val_loss: 0.7384\n",
            "Epoch 262/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1475 - val_loss: 0.1819\n",
            "Epoch 263/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2954 - val_loss: 0.5551\n",
            "Epoch 264/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2202 - val_loss: 0.1039\n",
            "Epoch 265/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3027 - val_loss: 0.7549\n",
            "Epoch 266/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1547 - val_loss: 0.0283\n",
            "Epoch 267/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2213 - val_loss: 0.0818\n",
            "Epoch 268/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3734 - val_loss: 0.6860\n",
            "Epoch 269/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1990 - val_loss: 0.1169\n",
            "Epoch 270/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1444 - val_loss: 0.1034\n",
            "Epoch 271/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2557 - val_loss: 0.3045\n",
            "Epoch 272/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2919 - val_loss: 0.2360\n",
            "Epoch 273/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2559 - val_loss: 0.4129\n",
            "Epoch 274/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2317 - val_loss: 0.0323\n",
            "Epoch 275/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2937 - val_loss: 0.6331\n",
            "Epoch 276/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1757 - val_loss: 0.0580\n",
            "Epoch 277/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1358 - val_loss: 0.0869\n",
            "Epoch 278/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1319 - val_loss: 0.0328\n",
            "Epoch 279/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1308 - val_loss: 0.0120\n",
            "Epoch 280/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1751 - val_loss: 0.1033\n",
            "Epoch 281/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1545 - val_loss: 0.0227\n",
            "Epoch 282/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1427 - val_loss: 0.0170\n",
            "Epoch 283/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1613 - val_loss: 0.0269\n",
            "Epoch 284/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2143 - val_loss: 0.0765\n",
            "Epoch 285/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3716 - val_loss: 0.7896\n",
            "Epoch 286/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1404 - val_loss: 0.0092\n",
            "Epoch 287/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1504 - val_loss: 0.0171\n",
            "Epoch 288/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1552 - val_loss: 0.1097\n",
            "Epoch 289/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4187 - val_loss: 0.7263\n",
            "Epoch 290/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1385 - val_loss: 0.0910\n",
            "Epoch 291/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2716 - val_loss: 0.4611\n",
            "Epoch 292/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2338 - val_loss: 0.0303\n",
            "Epoch 293/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2881 - val_loss: 0.6653\n",
            "Epoch 294/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1561 - val_loss: 0.1069\n",
            "Epoch 295/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1302 - val_loss: 0.0022\n",
            "Epoch 296/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1764 - val_loss: 0.1797\n",
            "Epoch 297/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4013 - val_loss: 0.8238\n",
            "Epoch 298/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1784 - val_loss: 0.1622\n",
            "Epoch 299/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2076 - val_loss: 0.0395\n",
            "Epoch 300/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3326 - val_loss: 0.6040\n",
            "Epoch 301/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1488 - val_loss: 0.1632\n",
            "Epoch 302/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3210 - val_loss: 0.6425\n",
            "Epoch 303/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1596 - val_loss: 0.0439\n",
            "Epoch 304/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1293 - val_loss: 0.0661\n",
            "Epoch 305/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1897 - val_loss: 0.0104\n",
            "Epoch 306/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3651 - val_loss: 0.5694\n",
            "Epoch 307/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1869 - val_loss: 0.2033\n",
            "Epoch 308/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2307 - val_loss: 0.0563\n",
            "Epoch 309/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3063 - val_loss: 0.5454\n",
            "Epoch 310/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1770 - val_loss: 0.1569\n",
            "Epoch 311/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3034 - val_loss: 0.6688\n",
            "Epoch 312/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1585 - val_loss: 0.0747\n",
            "Epoch 313/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1329 - val_loss: 0.0314\n",
            "Epoch 314/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1248 - val_loss: 0.0284\n",
            "Epoch 315/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1714 - val_loss: 0.0489\n",
            "Epoch 316/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1546 - val_loss: 0.1827\n",
            "Epoch 317/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1488 - val_loss: 0.1502\n",
            "Epoch 318/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1738 - val_loss: 0.1813\n",
            "Epoch 319/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1694 - val_loss: 0.0810\n",
            "Epoch 320/686\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1553 - val_loss: 0.2126\n",
            "Epoch 321/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1788 - val_loss: 0.0930\n",
            "Epoch 322/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1557 - val_loss: 0.2060\n",
            "Epoch 323/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1817 - val_loss: 0.0778\n",
            "Epoch 324/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1522 - val_loss: 0.1807\n",
            "Epoch 325/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1727 - val_loss: 0.1203\n",
            "Epoch 326/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1548 - val_loss: 0.1673\n",
            "Epoch 327/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1673 - val_loss: 0.0834\n",
            "Epoch 328/686\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1458 - val_loss: 0.1621\n",
            "Epoch 329/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1615 - val_loss: 0.1742\n",
            "Epoch 330/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1506 - val_loss: 0.2077\n",
            "Epoch 331/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1875 - val_loss: 0.0729\n",
            "Epoch 332/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1496 - val_loss: 0.1907\n",
            "Epoch 333/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1757 - val_loss: 0.1088\n",
            "(161, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.0144 - val_loss: 7.5852\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.7029 - val_loss: 4.2420\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0579 - val_loss: 2.9179\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.6009 - val_loss: 6.3367\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.6490 - val_loss: 6.2541\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.5370 - val_loss: 5.5450\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.2411 - val_loss: 3.0807\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.9985 - val_loss: 1.4734\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.7332 - val_loss: 0.0973\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.7377 - val_loss: 1.1582\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.5070 - val_loss: 4.9594\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.1059 - val_loss: 3.2800\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.6009 - val_loss: 0.5759\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.3650 - val_loss: 0.7145\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.1433 - val_loss: 4.8691\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.2263 - val_loss: 4.7551\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.9827 - val_loss: 3.3886\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.5269 - val_loss: 0.4910\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.6186 - val_loss: 0.7195\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.8197 - val_loss: 3.1292\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.5828 - val_loss: 1.3268\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.6282 - val_loss: 0.3338\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5002 - val_loss: 1.6519\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3877 - val_loss: 0.5307\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4343 - val_loss: 1.3592\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3692 - val_loss: 0.8170\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.4319 - val_loss: 1.2917\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.4563 - val_loss: 0.1188\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4445 - val_loss: 0.2912\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6534 - val_loss: 1.7160\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3773 - val_loss: 0.3859\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.5045 - val_loss: 0.1945\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4380 - val_loss: 0.0315\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4060 - val_loss: 0.3674\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5053 - val_loss: 0.9888\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4454 - val_loss: 0.0880\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.4291 - val_loss: 1.0532\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.4060 - val_loss: 0.1731\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4704 - val_loss: 1.4288\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3900 - val_loss: 0.1202\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.5099 - val_loss: 0.8411\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4154 - val_loss: 0.0262\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.5571 - val_loss: 0.9129\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3875 - val_loss: 0.0308\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4194 - val_loss: 1.4920\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3710 - val_loss: 0.2267\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3818 - val_loss: 0.9711\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3535 - val_loss: 0.1152\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6735 - val_loss: 1.3376\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.3744 - val_loss: 0.2336\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4607 - val_loss: 1.3744\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3468 - val_loss: 0.5284\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3723 - val_loss: 1.1015\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3397 - val_loss: 0.3783\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3379 - val_loss: 1.1953\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3716 - val_loss: 0.5170\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3901 - val_loss: 0.9429\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3996 - val_loss: 0.1126\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3667 - val_loss: 0.1144\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4761 - val_loss: 1.4306\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.4458 - val_loss: 1.2113\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.3293 - val_loss: 0.3395\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3261 - val_loss: 1.3624\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4192 - val_loss: 1.6041\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3339 - val_loss: 0.6666\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3817 - val_loss: 1.2396\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3722 - val_loss: 0.0893\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4816 - val_loss: 0.0938\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.5654 - val_loss: 1.1876\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3238 - val_loss: 0.1115\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.4293 - val_loss: 0.1697\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3739 - val_loss: 0.3595\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4257 - val_loss: 1.1454\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.2992 - val_loss: 1.0490e-05\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3060 - val_loss: 0.9108\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3345 - val_loss: 0.1962\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3681 - val_loss: 0.0297\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3786 - val_loss: 1.2401\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3369 - val_loss: 0.0675\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3959 - val_loss: 1.0129\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.4014 - val_loss: 0.2320\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.5277 - val_loss: 1.2525\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3244 - val_loss: 0.2914\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3386 - val_loss: 0.5385\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.3599 - val_loss: 1.0694\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3033 - val_loss: 0.3631\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3600 - val_loss: 0.8954\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3531 - val_loss: 0.0761\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3709 - val_loss: 0.2124\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.4247 - val_loss: 1.3737\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3348 - val_loss: 0.1308\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4071 - val_loss: 0.6517\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3449 - val_loss: 0.0705\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4585 - val_loss: 0.9742\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3227 - val_loss: 0.2697\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4288 - val_loss: 0.6756\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3519 - val_loss: 0.5925\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3626 - val_loss: 0.1453\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3130 - val_loss: 0.8042\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4827 - val_loss: 1.3532\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3227 - val_loss: 0.2406\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3914 - val_loss: 0.1180\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3511 - val_loss: 0.8508\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3212 - val_loss: 0.2751\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3561 - val_loss: 0.8801\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3205 - val_loss: 0.1682\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3114 - val_loss: 0.6752\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.3180 - val_loss: 0.1051\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3090 - val_loss: 0.1397\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3486 - val_loss: 0.6584\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3396 - val_loss: 0.5148\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3438 - val_loss: 0.6679\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3379 - val_loss: 0.7213\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3763 - val_loss: 0.7999\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.2860 - val_loss: 0.1967\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3358 - val_loss: 0.7528\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.2884 - val_loss: 0.4773\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3309 - val_loss: 0.0595\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3582 - val_loss: 0.8791\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.2866 - val_loss: 0.0414\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3491 - val_loss: 0.6945\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3341 - val_loss: 0.5670\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3585 - val_loss: 0.1885\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3339 - val_loss: 0.6445\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3022 - val_loss: 0.0122\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3020 - val_loss: 0.3881\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3509 - val_loss: 0.6597\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3250 - val_loss: 0.1064\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3286 - val_loss: 0.5076\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2943 - val_loss: 0.0293\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3280 - val_loss: 0.6234\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.2456 - val_loss: 0.0299\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.3027 - val_loss: 0.3777\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3720 - val_loss: 0.1428\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3070 - val_loss: 0.8395\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.2587 - val_loss: 0.0541\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4294 - val_loss: 0.4621\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3539 - val_loss: 0.8710\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3934 - val_loss: 1.0040\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.2785 - val_loss: 0.1256\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3966 - val_loss: 0.3595\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3436 - val_loss: 0.8346\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3103 - val_loss: 1.8835e-04\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3706 - val_loss: 0.4921\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3175 - val_loss: 0.6579\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.2933 - val_loss: 0.0490\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2857 - val_loss: 0.8821\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3713 - val_loss: 0.8196\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4197 - val_loss: 0.5775\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3776 - val_loss: 0.9748\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.3304 - val_loss: 0.8117\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3488 - val_loss: 0.0212\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3357 - val_loss: 0.8581\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.2758 - val_loss: 0.1659\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3011 - val_loss: 0.6190\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.2774 - val_loss: 0.0253\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3198 - val_loss: 0.2472\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.2944 - val_loss: 0.5035\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.2461 - val_loss: 0.4024\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3690 - val_loss: 0.5376\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3334 - val_loss: 0.6869\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3357 - val_loss: 0.7143\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.2972 - val_loss: 0.0768\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.2806 - val_loss: 0.1057\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3749 - val_loss: 0.9806\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.2739 - val_loss: 0.0726\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3186 - val_loss: 0.4345\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3147 - val_loss: 0.5490\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.2725 - val_loss: 0.3414\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3995 - val_loss: 0.7280\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3039 - val_loss: 0.6876\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3084 - val_loss: 0.2822\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.3288 - val_loss: 0.5249\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.2865 - val_loss: 0.4199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWu6aMJR0XWj"
      },
      "source": [
        "First week's data are reproduced if you run the model for \n",
        "X_train[0:-7] ,Y_train[0:-7].\n",
        "\n",
        "\n",
        "Again predictions are almost identical to submission file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2whwgPG5OKh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "caac0a62-a17f-42f0-f689-c52b22804cbe"
      },
      "source": [
        "predictions_Chambers = predictionOnPredictionLSTM(initialvalue_Chambers,look_ahead,conv_model_Chambers)#+difference_Brazoria[-1]#,encoder_model_Brazoria)#0.5=bias due to stationarity\n",
        "predictions_Chambers = predictions_Chambers.reshape(len(predictions_Chambers))\n",
        "print(\"Second week prediction is\",predictions_Chambers)\n",
        "#print(mean_absolute_error(predictions_Chambers,test_deaths[4][window:]))\n",
        "#print(mean_squared_log_error(predictions_Chambers,test_deaths[4][window:]))\n",
        "#[8.0012865  8.324205   8.627693   8.991761   9.381204   9.81089,10.276717 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Second week prediction is [ 8.000809  8.311843  8.614     8.892143  9.214599  9.637418 10.08719 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nrAHyYjOjem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "191c9a47-6324-4ec6-db37-f3bbcf2c0957"
      },
      "source": [
        "conv_model_Fort,conv_history_Fort = build_conv_model(np.array(X_train[5][20:]),np.array(X_test[5]),np.array(Y_train[5][20:]),np.array(Y_test[5]),window)#100 best\n",
        "encoder_model_Fort,encoder_history_Fort = build_encoder_decoder(np.array(X_train[5][20:]),np.array(X_test[5]),np.array(Y_train[5][20:]),np.array(Y_test[5]),window)#120"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(161, 10, 1)\n",
            "(161, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 57.8640 - val_loss: 102.6817\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.1132 - val_loss: 6.6718\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.1545 - val_loss: 20.2940\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 22.3229 - val_loss: 42.4408\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7842 - val_loss: 16.9062\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2354 - val_loss: 5.4453\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.1094 - val_loss: 14.1972\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 20.3898 - val_loss: 37.7426\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0648 - val_loss: 15.1844\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9928 - val_loss: 5.9352\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4439 - val_loss: 11.8915\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.4926 - val_loss: 16.8448\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6646 - val_loss: 7.6818\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4568 - val_loss: 10.4876\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1354 - val_loss: 12.6605\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.1804 - val_loss: 49.9754\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4368 - val_loss: 10.9985\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1652 - val_loss: 10.6662\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.7663 - val_loss: 33.2500\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9338 - val_loss: 16.3530\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.3366 - val_loss: 3.3473\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5887 - val_loss: 14.6030\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4620 - val_loss: 13.7984\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8650 - val_loss: 7.7948\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2535 - val_loss: 14.7002\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.1502 - val_loss: 7.1210\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.1839 - val_loss: 13.3035\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.6836 - val_loss: 16.0681\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6252 - val_loss: 7.8383\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.2875 - val_loss: 10.7458\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8772 - val_loss: 12.0852\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6426 - val_loss: 9.7566\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.8716 - val_loss: 12.9004\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5548 - val_loss: 10.4354\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2297 - val_loss: 10.0971\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8882 - val_loss: 10.8730\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2308 - val_loss: 10.6086\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.7598 - val_loss: 11.5367\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6584 - val_loss: 8.6692\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1866 - val_loss: 13.6140\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7676 - val_loss: 5.4336\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5627 - val_loss: 7.9018\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1247 - val_loss: 12.0302\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.4178 - val_loss: 14.7624\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7364 - val_loss: 5.1384\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7686 - val_loss: 15.2081\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4074 - val_loss: 4.5978\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7576 - val_loss: 15.5842\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3611 - val_loss: 4.9944\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.5435 - val_loss: 15.1764\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1741 - val_loss: 5.2394\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1135 - val_loss: 13.6492\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4784 - val_loss: 5.3299\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8816 - val_loss: 8.2620\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3540 - val_loss: 12.1115\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8796 - val_loss: 16.9834\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1617 - val_loss: 3.1320\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8471 - val_loss: 14.8088\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7669 - val_loss: 5.7813\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.6774 - val_loss: 15.9113\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1678 - val_loss: 4.2542\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.7083 - val_loss: 15.3518\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3241 - val_loss: 4.0962\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.6408 - val_loss: 15.4481\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2831 - val_loss: 4.8278\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1347 - val_loss: 10.9798\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1913 - val_loss: 9.7943\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.4097 - val_loss: 15.3277\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3660 - val_loss: 4.4560\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5992 - val_loss: 15.5271\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2150 - val_loss: 4.4082\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5319 - val_loss: 15.8031\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9775 - val_loss: 5.4192\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.5381 - val_loss: 11.8924\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9017 - val_loss: 7.0511\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.8879 - val_loss: 14.3666\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0846 - val_loss: 5.4904\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5479 - val_loss: 12.6716\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3407 - val_loss: 5.2451\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9518 - val_loss: 14.7691\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8943 - val_loss: 5.7401\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0285 - val_loss: 10.8766\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6890 - val_loss: 6.7463\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5437 - val_loss: 13.7243\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9891 - val_loss: 6.2960\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8989 - val_loss: 11.1615\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5189 - val_loss: 6.4453\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.4145 - val_loss: 13.4569\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9134 - val_loss: 6.1845\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8283 - val_loss: 11.1642\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2410 - val_loss: 5.4968\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.4086 - val_loss: 13.5064\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8755 - val_loss: 6.2915\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.7034 - val_loss: 11.0518\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1602 - val_loss: 6.0288\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0268 - val_loss: 12.2928\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0543 - val_loss: 6.8911\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5142 - val_loss: 10.5787\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1539 - val_loss: 5.5014\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.2395 - val_loss: 13.3802\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6976 - val_loss: 5.8473\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5563 - val_loss: 10.8451\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0347 - val_loss: 6.4702\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6515 - val_loss: 11.5745\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0308 - val_loss: 7.2812\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2752 - val_loss: 10.2310\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1971 - val_loss: 6.0768\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9709 - val_loss: 12.8879\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5416 - val_loss: 5.3777\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5173 - val_loss: 11.0376\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0032 - val_loss: 7.1272\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2844 - val_loss: 10.5994\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9216 - val_loss: 6.4152\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4280 - val_loss: 11.0785\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9768 - val_loss: 7.4503\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2318 - val_loss: 10.8075\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7822 - val_loss: 6.4174\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2766 - val_loss: 10.5042\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9571 - val_loss: 6.8929\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2355 - val_loss: 10.6086\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7304 - val_loss: 6.2761\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1551 - val_loss: 10.1638\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0140 - val_loss: 7.3410\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1452 - val_loss: 10.6647\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5515 - val_loss: 5.6488\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1798 - val_loss: 10.2805\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9410 - val_loss: 7.2557\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1503 - val_loss: 10.9151\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3963 - val_loss: 5.1142\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1749 - val_loss: 10.2503\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9268 - val_loss: 7.3759\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0800 - val_loss: 10.9397\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2611 - val_loss: 4.9230\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8045 - val_loss: 8.1693\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7876 - val_loss: 9.1516\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1388 - val_loss: 11.4579\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3952 - val_loss: 5.6313\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9856 - val_loss: 10.1302\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3310 - val_loss: 4.9664\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7022 - val_loss: 8.1818\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6185 - val_loss: 9.0881\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.8026 - val_loss: 10.3088\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6370 - val_loss: 6.6502\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6748 - val_loss: 9.1166\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9096 - val_loss: 7.3578\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7538 - val_loss: 9.6438\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8054 - val_loss: 7.5597\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5756 - val_loss: 8.9992\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8971 - val_loss: 7.6855\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6270 - val_loss: 9.3785\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7713 - val_loss: 7.5602\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5520 - val_loss: 9.0918\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7609 - val_loss: 7.3265\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5756 - val_loss: 9.1717\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7324 - val_loss: 7.3236\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6182 - val_loss: 9.4819\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6073 - val_loss: 7.0985\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5392 - val_loss: 9.1873\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4656 - val_loss: 6.3681\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5942 - val_loss: 9.5453\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6448 - val_loss: 2.4382\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0888 - val_loss: 2.9265\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2126 - val_loss: 1.1067\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5580 - val_loss: 15.4742\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2163 - val_loss: 10.0978\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0347 - val_loss: 4.8562\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4265 - val_loss: 8.1588\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8511 - val_loss: 7.1433\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5373 - val_loss: 9.2113\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6605 - val_loss: 7.3161\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2960 - val_loss: 8.3399\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7935 - val_loss: 7.9502\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2345 - val_loss: 8.1420\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7802 - val_loss: 7.9515\n",
            "Epoch 175/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1638 - val_loss: 7.9051\n",
            "Epoch 176/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7995 - val_loss: 7.5038\n",
            "Epoch 177/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3253 - val_loss: 8.4547\n",
            "Epoch 178/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6984 - val_loss: 7.7246\n",
            "Epoch 179/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1806 - val_loss: 8.1370\n",
            "Epoch 180/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7532 - val_loss: 8.0259\n",
            "Epoch 181/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0861 - val_loss: 7.5686\n",
            "Epoch 182/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8680 - val_loss: 6.7429\n",
            "Epoch 183/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6307 - val_loss: 9.5428\n",
            "Epoch 184/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5214 - val_loss: 7.5560\n",
            "Epoch 185/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1703 - val_loss: 8.3823\n",
            "Epoch 186/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5938 - val_loss: 7.3447\n",
            "Epoch 187/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1200 - val_loss: 7.9547\n",
            "Epoch 188/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6369 - val_loss: 6.1623\n",
            "Epoch 189/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.7671 - val_loss: 2.8907\n",
            "Epoch 190/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.5950 - val_loss: 32.3704\n",
            "Epoch 191/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7742 - val_loss: 7.7281\n",
            "Epoch 192/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6490 - val_loss: 4.6328\n",
            "Epoch 193/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1279 - val_loss: 11.2490\n",
            "Epoch 194/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.5736 - val_loss: 30.1040\n",
            "Epoch 195/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0087 - val_loss: 18.2947\n",
            "Epoch 196/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.9950 - val_loss: 1.5517\n",
            "Epoch 197/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3983 - val_loss: 1.8870\n",
            "Epoch 198/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4858 - val_loss: 4.1369\n",
            "Epoch 199/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5442 - val_loss: 4.4349\n",
            "Epoch 200/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6370 - val_loss: 0.5024\n",
            "Epoch 201/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0320 - val_loss: 22.2777\n",
            "Epoch 202/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3348 - val_loss: 15.1736\n",
            "Epoch 203/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3583 - val_loss: 0.4719\n",
            "Epoch 204/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8940 - val_loss: 7.1814\n",
            "Epoch 205/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2179 - val_loss: 10.1016\n",
            "Epoch 206/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8306 - val_loss: 9.8677\n",
            "Epoch 207/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0482 - val_loss: 4.0598\n",
            "Epoch 208/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0552 - val_loss: 14.4974\n",
            "Epoch 209/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0442 - val_loss: 4.7303\n",
            "Epoch 210/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5861 - val_loss: 9.2816\n",
            "Epoch 211/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7303 - val_loss: 5.2208\n",
            "Epoch 212/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1381 - val_loss: 12.0031\n",
            "Epoch 213/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0685 - val_loss: 5.1241\n",
            "Epoch 214/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4196 - val_loss: 9.3552\n",
            "Epoch 215/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6097 - val_loss: 7.1777\n",
            "Epoch 216/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2736 - val_loss: 9.6079\n",
            "Epoch 217/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2793 - val_loss: 5.7666\n",
            "Epoch 218/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3079 - val_loss: 9.4327\n",
            "Epoch 219/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3918 - val_loss: 6.5116\n",
            "Epoch 220/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2756 - val_loss: 9.7906\n",
            "Epoch 221/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1675 - val_loss: 5.6969\n",
            "Epoch 222/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2054 - val_loss: 9.2414\n",
            "Epoch 223/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2678 - val_loss: 6.1397\n",
            "Epoch 224/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2447 - val_loss: 9.7231\n",
            "Epoch 225/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1677 - val_loss: 6.1657\n",
            "Epoch 226/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0081 - val_loss: 8.6902\n",
            "Epoch 227/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3027 - val_loss: 6.4037\n",
            "Epoch 228/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1361 - val_loss: 9.4698\n",
            "Epoch 229/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1418 - val_loss: 6.1886\n",
            "Epoch 230/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9351 - val_loss: 8.4889\n",
            "Epoch 231/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2883 - val_loss: 6.5098\n",
            "Epoch 232/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0750 - val_loss: 9.3246\n",
            "Epoch 233/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1049 - val_loss: 6.1908\n",
            "Epoch 234/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8192 - val_loss: 7.9816\n",
            "Epoch 235/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3843 - val_loss: 7.1407\n",
            "Epoch 236/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7055 - val_loss: 7.5685\n",
            "Epoch 237/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4352 - val_loss: 7.3829\n",
            "Epoch 238/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.6574 - val_loss: 7.4069\n",
            "Epoch 239/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4452 - val_loss: 7.4791\n",
            "Epoch 240/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7620 - val_loss: 8.1224\n",
            "Epoch 241/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2537 - val_loss: 6.8777\n",
            "Epoch 242/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5875 - val_loss: 6.8717\n",
            "Epoch 243/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5209 - val_loss: 7.7775\n",
            "Epoch 244/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6858 - val_loss: 8.1055\n",
            "Epoch 245/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2162 - val_loss: 6.6627\n",
            "Epoch 246/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6300 - val_loss: 7.4771\n",
            "Epoch 247/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3569 - val_loss: 7.3610\n",
            "Epoch 248/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5129 - val_loss: 6.7773\n",
            "Epoch 249/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5236 - val_loss: 7.6371\n",
            "Epoch 250/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7338 - val_loss: 8.3875\n",
            "Epoch 251/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0780 - val_loss: 6.2489\n",
            "Epoch 252/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6932 - val_loss: 7.8418\n",
            "Epoch 253/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2417 - val_loss: 7.1393\n",
            "Epoch 254/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5110 - val_loss: 6.8603\n",
            "Epoch 255/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4550 - val_loss: 7.5070\n",
            "Epoch 256/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6882 - val_loss: 8.2769\n",
            "Epoch 257/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0536 - val_loss: 6.2940\n",
            "Epoch 258/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6274 - val_loss: 7.6577\n",
            "Epoch 259/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1657 - val_loss: 6.9085\n",
            "Epoch 260/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3026 - val_loss: 5.8073\n",
            "Epoch 261/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6317 - val_loss: 7.5229\n",
            "Epoch 262/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8977 - val_loss: 9.5025\n",
            "Epoch 263/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6971 - val_loss: 5.4884\n",
            "Epoch 264/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4893 - val_loss: 7.0710\n",
            "Epoch 265/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3272 - val_loss: 7.5544\n",
            "Epoch 266/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4517 - val_loss: 7.3503\n",
            "Epoch 267/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.2542 - val_loss: 7.3181\n",
            "Epoch 268/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1772 - val_loss: 5.3833\n",
            "Epoch 269/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6439 - val_loss: 7.1605\n",
            "Epoch 270/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0823 - val_loss: 10.3878\n",
            "Epoch 271/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4488 - val_loss: 4.5957\n",
            "Epoch 272/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5129 - val_loss: 7.1512\n",
            "Epoch 273/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2778 - val_loss: 7.4647\n",
            "Epoch 274/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4199 - val_loss: 7.4445\n",
            "Epoch 275/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1452 - val_loss: 6.9560\n",
            "Epoch 276/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3847 - val_loss: 7.2204\n",
            "Epoch 277/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1705 - val_loss: 7.1805\n",
            "Epoch 278/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4146 - val_loss: 7.2677\n",
            "Epoch 279/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1490 - val_loss: 7.2529\n",
            "Epoch 280/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0174 - val_loss: 4.7744\n",
            "Epoch 281/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6572 - val_loss: 7.3366\n",
            "Epoch 282/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8761 - val_loss: 9.7643\n",
            "Epoch 283/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4969 - val_loss: 4.9547\n",
            "Epoch 284/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3758 - val_loss: 6.8195\n",
            "Epoch 285/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1848 - val_loss: 6.7608\n",
            "Epoch 286/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5767 - val_loss: 8.2978\n",
            "Epoch 287/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8763 - val_loss: 6.2641\n",
            "Epoch 288/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3607 - val_loss: 7.1625\n",
            "Epoch 289/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1113 - val_loss: 6.7436\n",
            "Epoch 290/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5368 - val_loss: 8.1530\n",
            "Epoch 291/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8597 - val_loss: 6.3232\n",
            "Epoch 292/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3543 - val_loss: 7.1976\n",
            "Epoch 293/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0852 - val_loss: 6.6298\n",
            "Epoch 294/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4423 - val_loss: 7.6459\n",
            "Epoch 295/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9250 - val_loss: 6.5896\n",
            "Epoch 296/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1960 - val_loss: 6.1980\n",
            "Epoch 297/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2419 - val_loss: 7.4073\n",
            "Epoch 298/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2333 - val_loss: 6.8983\n",
            "Epoch 299/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0650 - val_loss: 6.8432\n",
            "Epoch 300/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1607 - val_loss: 6.0403\n",
            "Epoch 301/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2383 - val_loss: 7.3241\n",
            "Epoch 302/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3206 - val_loss: 7.4189\n",
            "Epoch 303/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9193 - val_loss: 6.5995\n",
            "Epoch 304/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1653 - val_loss: 6.4385\n",
            "Epoch 305/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0937 - val_loss: 7.0518\n",
            "Epoch 306/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9353 - val_loss: 6.7714\n",
            "Epoch 307/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1843 - val_loss: 3.3304\n",
            "Epoch 308/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7057 - val_loss: 13.6477\n",
            "Epoch 309/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2274 - val_loss: 7.7330\n",
            "Epoch 310/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6350 - val_loss: 7.0878\n",
            "Epoch 311/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4151 - val_loss: 7.4337\n",
            "Epoch 312/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6485 - val_loss: 7.7643\n",
            "Epoch 313/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2240 - val_loss: 7.0085\n",
            "Epoch 314/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6394 - val_loss: 7.9843\n",
            "Epoch 315/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0657 - val_loss: 6.4566\n",
            "Epoch 316/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6518 - val_loss: 7.9273\n",
            "Epoch 317/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0612 - val_loss: 6.6353\n",
            "Epoch 318/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5736 - val_loss: 7.8872\n",
            "Epoch 319/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9573 - val_loss: 6.0639\n",
            "Epoch 320/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5872 - val_loss: 7.8170\n",
            "Epoch 321/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9676 - val_loss: 6.3743\n",
            "Epoch 322/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5071 - val_loss: 7.7348\n",
            "Epoch 323/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9484 - val_loss: 6.3232\n",
            "Epoch 324/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4602 - val_loss: 7.5694\n",
            "Epoch 325/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9262 - val_loss: 6.3081\n",
            "Epoch 326/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3347 - val_loss: 6.8218\n",
            "Epoch 327/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1746 - val_loss: 7.1285\n",
            "Epoch 328/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2415 - val_loss: 6.6606\n",
            "Epoch 329/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1377 - val_loss: 7.3199\n",
            "Epoch 330/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0300 - val_loss: 5.5286\n",
            "Epoch 331/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4614 - val_loss: 8.2717\n",
            "Epoch 332/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1171 - val_loss: 6.6479\n",
            "Epoch 333/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0261 - val_loss: 6.9282\n",
            "Epoch 334/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9876 - val_loss: 5.4474\n",
            "Epoch 335/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2273 - val_loss: 7.5264\n",
            "Epoch 336/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0507 - val_loss: 6.2680\n",
            "Epoch 337/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1396 - val_loss: 7.5520\n",
            "Epoch 338/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8753 - val_loss: 5.0833\n",
            "Epoch 339/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3525 - val_loss: 7.8302\n",
            "Epoch 340/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0543 - val_loss: 6.3654\n",
            "Epoch 341/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0669 - val_loss: 7.3183\n",
            "Epoch 342/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8645 - val_loss: 5.1310\n",
            "Epoch 343/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2216 - val_loss: 7.5968\n",
            "Epoch 344/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0146 - val_loss: 6.3552\n",
            "Epoch 345/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0349 - val_loss: 7.2636\n",
            "Epoch 346/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9093 - val_loss: 5.5296\n",
            "Epoch 347/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1824 - val_loss: 7.9337\n",
            "Epoch 348/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7997 - val_loss: 5.1789\n",
            "Epoch 349/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2463 - val_loss: 8.1851\n",
            "Epoch 350/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8168 - val_loss: 5.6951\n",
            "Epoch 351/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0009 - val_loss: 7.1964\n",
            "Epoch 352/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4329 - val_loss: 2.6899\n",
            "Epoch 353/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9478 - val_loss: 9.0605\n",
            "Epoch 354/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2282 - val_loss: 8.1131\n",
            "Epoch 355/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4724 - val_loss: 5.9281\n",
            "Epoch 356/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7577 - val_loss: 5.1500\n",
            "Epoch 357/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2219 - val_loss: 7.9228\n",
            "Epoch 358/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9033 - val_loss: 6.3491\n",
            "Epoch 359/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8401 - val_loss: 6.5827\n",
            "Epoch 360/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0971 - val_loss: 6.9544\n",
            "Epoch 361/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6711 - val_loss: 5.9970\n",
            "Epoch 362/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1100 - val_loss: 6.8683\n",
            "Epoch 363/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7760 - val_loss: 6.4057\n",
            "(161, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 66.3347 - val_loss: 106.7687\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 25.5175 - val_loss: 16.4217\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 16.9225 - val_loss: 19.1697\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 16.1121 - val_loss: 4.4772\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 19.4360 - val_loss: 4.1741\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 17.8395 - val_loss: 36.1095\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.3643 - val_loss: 64.9761\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 18.1245 - val_loss: 247.2400\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 54.3196 - val_loss: 25.5750\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 20.2487 - val_loss: 18.3623\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 21.4019 - val_loss: 3.8953\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 19.3181 - val_loss: 167.5614\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 29.9729 - val_loss: 36.8992\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 20.2751 - val_loss: 13.0649\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 15.1268 - val_loss: 42.7268\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 21.7711 - val_loss: 30.1659\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 29.5427 - val_loss: 64.8010\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 41.4986 - val_loss: 102.2917\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 20.5653 - val_loss: 54.5900\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 30.1719 - val_loss: 12.6594\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 21.7696 - val_loss: 45.2518\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 19.3672 - val_loss: 16.0989\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 17.9341 - val_loss: 0.6706\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 19.8352 - val_loss: 27.4171\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 17.6848 - val_loss: 11.4367\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 15.1525 - val_loss: 18.9060\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 15.8184 - val_loss: 12.9331\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 19.1164 - val_loss: 5.9869\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 24.1703 - val_loss: 67.8963\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 13.2823 - val_loss: 14.8395\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 15.7000 - val_loss: 22.1623\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 15.2149 - val_loss: 3.1684\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 13.4681 - val_loss: 3.3679\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 13.6948 - val_loss: 10.9062\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 15.1277 - val_loss: 13.1207\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 18.0924 - val_loss: 41.5689\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.3743 - val_loss: 17.1781\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 15.7673 - val_loss: 46.3813\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 19.0021 - val_loss: 42.0659\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 18.0637 - val_loss: 24.4717\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 18.0936 - val_loss: 6.2083\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 21.0731 - val_loss: 56.5439\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 13.8242 - val_loss: 11.1680\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.2418 - val_loss: 29.5871\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 15.0439 - val_loss: 12.4242\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 16.5000 - val_loss: 52.7444\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 12.6411 - val_loss: 11.3313\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 11.3877 - val_loss: 32.1614\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 10.8569 - val_loss: 5.0779\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 16.4496 - val_loss: 10.4597\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 16.3329 - val_loss: 51.2646\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 12.6089 - val_loss: 15.4952\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.5936 - val_loss: 41.4067\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.7312 - val_loss: 11.6017\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 14.1713 - val_loss: 10.4606\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 15.0313 - val_loss: 34.4232\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.1322 - val_loss: 16.6611\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 14.9896 - val_loss: 36.6931\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.2958 - val_loss: 17.4046\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.7062 - val_loss: 46.7284\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 13.5829 - val_loss: 36.5101\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 16.2781 - val_loss: 9.6036\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.8219 - val_loss: 45.2276\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 12.2776 - val_loss: 36.7878\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.5097 - val_loss: 13.4998\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 14.0202 - val_loss: 17.1280\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 14.2430 - val_loss: 9.7942\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 14.5049 - val_loss: 105.5804\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 35.3662 - val_loss: 100.7979\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 15.2176 - val_loss: 4.7926\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 17.2425 - val_loss: 24.5905\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.1427 - val_loss: 26.1277\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.6083 - val_loss: 15.3421\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.0072 - val_loss: 50.2465\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.1259 - val_loss: 40.8540\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.3907 - val_loss: 9.6581\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 13.0447 - val_loss: 29.3434\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 17.3082 - val_loss: 62.8637\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.7830 - val_loss: 38.1855\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.4400 - val_loss: 19.0576\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 14.5685 - val_loss: 54.2841\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 15.6741 - val_loss: 56.5103\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.0686 - val_loss: 32.1385\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 16.8069 - val_loss: 13.8363\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.0321 - val_loss: 49.3487\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 12.9548 - val_loss: 33.1991\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 14.0679 - val_loss: 39.5244\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 12.0790 - val_loss: 17.9818\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.3674 - val_loss: 50.1979\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 12.3384 - val_loss: 27.4265\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 14.8808 - val_loss: 17.2588\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.2547 - val_loss: 43.8417\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.1741 - val_loss: 13.3545\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 13.1853 - val_loss: 2.3235\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 11.6492 - val_loss: 35.9600\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.2633 - val_loss: 41.4919\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.2213 - val_loss: 20.7915\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 12.3688 - val_loss: 54.4637\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 12.2149 - val_loss: 54.3006\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 14.0429 - val_loss: 38.5667\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 12.3630 - val_loss: 16.7252\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.6078 - val_loss: 42.9664\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 11.3679 - val_loss: 22.7580\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 12.1866 - val_loss: 60.3763\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 15.4339 - val_loss: 50.6591\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 12.8130 - val_loss: 15.6999\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 13.5574 - val_loss: 51.2532\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 11.0363 - val_loss: 24.9865\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 12.0865 - val_loss: 24.1279\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 11.9321 - val_loss: 47.9516\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 14.7038 - val_loss: 55.1173\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 10.9036 - val_loss: 14.6668\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 12.7672 - val_loss: 22.6914\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 14.8323 - val_loss: 57.1895\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 10.7107 - val_loss: 17.7342\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 13.8767 - val_loss: 7.5891\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 11.6821 - val_loss: 30.8917\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 16.1895 - val_loss: 54.1454\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 11.1690 - val_loss: 6.5602\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 16.1923 - val_loss: 18.1036\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 14.7721 - val_loss: 56.5640\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 10.3839 - val_loss: 26.2801\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 12.1066 - val_loss: 49.1870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II-F1b291Mrv"
      },
      "source": [
        "This cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Il0-GY7Qv-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e3f7fc72-85fe-4b31-8f99-09487ccd8ba1"
      },
      "source": [
        "predictions_Fort = predictionOnPredictionLSTM(initialvalue_Fort_Bend,look_ahead,encoder_model_Fort)\n",
        "predictions_Fort = predictions_Fort.reshape(len(predictions_Fort))\n",
        "print(predictions_Fort)\n",
        "print(test_deaths[5][window:])\n",
        "print(train_deaths[5][160:]) \n",
        "#print(mean_absolute_error(predictions_Fort,test_deaths[5][window:]))\n",
        "#print(mean_squared_log_error(predictions_Fort,test_deaths[5][window:]))\n",
        "#[246.77965 247.47505 248.43849 248.72125 249.26256 249.62228 250.13065] 1st week\n",
        "#[268.51748 272.66992 275.28616 278.30945 280.80664 283.64792 286.3341 ] \n",
        "#[267.47186 271.59134 274.0211  277.9578  281.1139  284.804   288.48596]\n",
        "#[267.67062 270.18558 272.92804 275.56403 278.72568 281.89233 285.80176]2nd week"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[267.67062 270.18558 272.92804 275.56403 278.72568 281.89233 285.80176]\n",
            "[267.0]\n",
            "[189 192 194 194 194 198 204 211 214 216 216 220 226 230 231 231 234 237\n",
            " 239 240 243 244 247 247 248 249 255 255 263 266 267.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R73JIFBRKjI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ef775f2-bfc4-4069-a4fd-932eaa0ecf79"
      },
      "source": [
        "conv_model_Austin,conv_history_Austin = build_conv_model(np.array(X_train[7][-30:]),np.array(X_test[7]),np.array(Y_train[7][-30:]),np.array(Y_test[7]),window)#100 best\n",
        "encoder_model_Austin,encoder_history_Austin = build_encoder_decoder(np.array(X_train[7][-30:]),np.array(X_test[7]),np.array(Y_train[7][-30:]),np.array(Y_test[7]),window)#120"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 5.5274 - val_loss: 8.5842\n",
            "Epoch 2/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.1724 - val_loss: 8.0987\n",
            "Epoch 3/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 4.8171 - val_loss: 7.5358\n",
            "Epoch 4/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 4.4044 - val_loss: 6.8531\n",
            "Epoch 5/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.9050 - val_loss: 5.9854\n",
            "Epoch 6/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3.2765 - val_loss: 4.8957\n",
            "Epoch 7/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4957 - val_loss: 3.5514\n",
            "Epoch 8/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.5321 - val_loss: 1.9055\n",
            "Epoch 9/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7734 - val_loss: 0.2321\n",
            "Epoch 10/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9086 - val_loss: 0.7906\n",
            "Epoch 11/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2011 - val_loss: 0.7836\n",
            "Epoch 12/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0549 - val_loss: 0.1474\n",
            "Epoch 13/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6580 - val_loss: 0.7063\n",
            "Epoch 14/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4442 - val_loss: 1.4592\n",
            "Epoch 15/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5993 - val_loss: 1.8755\n",
            "Epoch 16/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7470 - val_loss: 1.9288\n",
            "Epoch 17/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7411 - val_loss: 1.7032\n",
            "Epoch 18/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6358 - val_loss: 1.2694\n",
            "Epoch 19/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5715 - val_loss: 0.7753\n",
            "Epoch 20/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5793 - val_loss: 0.5055\n",
            "Epoch 21/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5884 - val_loss: 0.5156\n",
            "Epoch 22/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5448 - val_loss: 0.7467\n",
            "Epoch 23/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4870 - val_loss: 1.0598\n",
            "Epoch 24/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4605 - val_loss: 1.3545\n",
            "Epoch 25/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5163 - val_loss: 1.4543\n",
            "Epoch 26/686\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5424 - val_loss: 1.3602\n",
            "Epoch 27/686\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5319 - val_loss: 1.1486\n",
            "Epoch 28/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5087 - val_loss: 0.9190\n",
            "Epoch 29/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5098 - val_loss: 0.8202\n",
            "Epoch 30/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5071 - val_loss: 0.8506\n",
            "Epoch 31/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4862 - val_loss: 0.9837\n",
            "Epoch 32/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4629 - val_loss: 1.1792\n",
            "Epoch 33/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4626 - val_loss: 1.2757\n",
            "Epoch 34/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4830 - val_loss: 1.2572\n",
            "Epoch 35/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4822 - val_loss: 1.1639\n",
            "Epoch 36/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4662 - val_loss: 1.1320\n",
            "Epoch 37/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4616 - val_loss: 1.1510\n",
            "Epoch 38/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4556 - val_loss: 1.2115\n",
            "Epoch 39/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4495 - val_loss: 1.2854\n",
            "Epoch 40/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4648 - val_loss: 1.2441\n",
            "Epoch 41/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4630 - val_loss: 1.1280\n",
            "Epoch 42/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4600 - val_loss: 1.0786\n",
            "Epoch 43/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4557 - val_loss: 1.0849\n",
            "Epoch 44/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4498 - val_loss: 1.1366\n",
            "Epoch 45/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4426 - val_loss: 1.2250\n",
            "Epoch 46/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4353 - val_loss: 1.3216\n",
            "Epoch 47/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4463 - val_loss: 1.2938\n",
            "Epoch 48/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4389 - val_loss: 1.2769\n",
            "Epoch 49/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4363 - val_loss: 1.2901\n",
            "Epoch 50/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4318 - val_loss: 1.3259\n",
            "Epoch 51/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4302 - val_loss: 1.3605\n",
            "Epoch 52/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4401 - val_loss: 1.2785\n",
            "Epoch 53/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4339 - val_loss: 1.2387\n",
            "Epoch 54/686\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4290 - val_loss: 1.2538\n",
            "Epoch 55/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4227 - val_loss: 1.3138\n",
            "Epoch 56/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4178 - val_loss: 1.3876\n",
            "Epoch 57/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4264 - val_loss: 1.3338\n",
            "Epoch 58/686\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4206 - val_loss: 1.2944\n",
            "Epoch 59/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4192 - val_loss: 1.2899\n",
            "Epoch 60/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4132 - val_loss: 1.3347\n",
            "Epoch 61/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4083 - val_loss: 1.3963\n",
            "Epoch 62/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4136 - val_loss: 1.3962\n",
            "Epoch 63/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4113 - val_loss: 1.2945\n",
            "Epoch 64/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4183 - val_loss: 1.1878\n",
            "Epoch 65/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4148 - val_loss: 1.1515\n",
            "Epoch 66/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4093 - val_loss: 1.1738\n",
            "Epoch 67/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4024 - val_loss: 1.2435\n",
            "Epoch 68/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3943 - val_loss: 1.3507\n",
            "Epoch 69/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3962 - val_loss: 1.4054\n",
            "Epoch 70/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4011 - val_loss: 1.3425\n",
            "Epoch 71/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4000 - val_loss: 1.2659\n",
            "Epoch 72/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3955 - val_loss: 1.2554\n",
            "Epoch 73/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3892 - val_loss: 1.2992\n",
            "Epoch 74/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3817 - val_loss: 1.3865\n",
            "Epoch 75/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3910 - val_loss: 1.4230\n",
            "Epoch 76/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3935 - val_loss: 1.3396\n",
            "Epoch 77/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3894 - val_loss: 1.2439\n",
            "Epoch 78/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3851 - val_loss: 1.2196\n",
            "Epoch 79/686\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3789 - val_loss: 1.2543\n",
            "Epoch 80/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3713 - val_loss: 1.3363\n",
            "Epoch 81/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3741 - val_loss: 1.3656\n",
            "Epoch 82/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3758 - val_loss: 1.2961\n",
            "Epoch 83/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3752 - val_loss: 1.2346\n",
            "Epoch 84/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3697 - val_loss: 1.2399\n",
            "Epoch 85/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3627 - val_loss: 1.2997\n",
            "Epoch 86/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3613 - val_loss: 1.3367\n",
            "Epoch 87/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3642 - val_loss: 1.2940\n",
            "Epoch 88/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3621 - val_loss: 1.2536\n",
            "Epoch 89/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3560 - val_loss: 1.2772\n",
            "Epoch 90/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3528 - val_loss: 1.2835\n",
            "Epoch 91/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3531 - val_loss: 1.2117\n",
            "Epoch 92/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3593 - val_loss: 1.2374\n",
            "Epoch 93/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3440 - val_loss: 1.3330\n",
            "Epoch 94/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3507 - val_loss: 1.3327\n",
            "Epoch 95/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3507 - val_loss: 1.2530\n",
            "Epoch 96/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3451 - val_loss: 1.2735\n",
            "Epoch 97/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3404 - val_loss: 1.3036\n",
            "Epoch 98/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3432 - val_loss: 1.2461\n",
            "Epoch 99/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3393 - val_loss: 1.2112\n",
            "Epoch 100/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3363 - val_loss: 1.2236\n",
            "Epoch 101/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3322 - val_loss: 1.2748\n",
            "Epoch 102/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3343 - val_loss: 1.2593\n",
            "Epoch 103/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3352 - val_loss: 1.1921\n",
            "Epoch 104/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3302 - val_loss: 1.1793\n",
            "Epoch 105/686\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3264 - val_loss: 1.2115\n",
            "Epoch 106/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3262 - val_loss: 1.2108\n",
            "Epoch 107/686\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3261 - val_loss: 1.1829\n",
            "Epoch 108/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3248 - val_loss: 1.1321\n",
            "Epoch 109/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3229 - val_loss: 1.2174\n",
            "Epoch 110/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3175 - val_loss: 1.3000\n",
            "Epoch 111/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3345 - val_loss: 1.1302\n",
            "Epoch 112/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3267 - val_loss: 1.1179\n",
            "Epoch 113/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3096 - val_loss: 1.2276\n",
            "Epoch 114/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3133 - val_loss: 1.2532\n",
            "Epoch 115/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3162 - val_loss: 1.2139\n",
            "Epoch 116/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3142 - val_loss: 1.1519\n",
            "Epoch 117/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3112 - val_loss: 1.0702\n",
            "Epoch 118/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3127 - val_loss: 1.1356\n",
            "Epoch 119/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2991 - val_loss: 1.2376\n",
            "Epoch 120/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3150 - val_loss: 1.1028\n",
            "Epoch 121/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3058 - val_loss: 1.1233\n",
            "Epoch 122/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2923 - val_loss: 1.2621\n",
            "Epoch 123/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3143 - val_loss: 1.1573\n",
            "Epoch 124/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3014 - val_loss: 1.0388\n",
            "Epoch 125/686\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3049 - val_loss: 1.0752\n",
            "Epoch 126/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2865 - val_loss: 1.2285\n",
            "Epoch 127/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3011 - val_loss: 1.1311\n",
            "Epoch 128/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2904 - val_loss: 1.0928\n",
            "Epoch 129/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2873 - val_loss: 1.1037\n",
            "Epoch 130/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2833 - val_loss: 1.1548\n",
            "Epoch 131/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2834 - val_loss: 1.1619\n",
            "Epoch 132/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2836 - val_loss: 1.1327\n",
            "Epoch 133/686\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2821 - val_loss: 1.0730\n",
            "Epoch 134/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2778 - val_loss: 1.0667\n",
            "Epoch 135/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2735 - val_loss: 1.1047\n",
            "Epoch 136/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2733 - val_loss: 1.0979\n",
            "Epoch 137/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2729 - val_loss: 1.0544\n",
            "Epoch 138/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2676 - val_loss: 1.0629\n",
            "Epoch 139/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2673 - val_loss: 1.0308\n",
            "Epoch 140/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2624 - val_loss: 1.0486\n",
            "Epoch 141/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2627 - val_loss: 1.0218\n",
            "Epoch 142/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2614 - val_loss: 0.9579\n",
            "Epoch 143/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2567 - val_loss: 0.9508\n",
            "Epoch 144/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2519 - val_loss: 0.9917\n",
            "Epoch 145/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2700 - val_loss: 0.8691\n",
            "Epoch 146/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2474 - val_loss: 1.0327\n",
            "Epoch 147/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2626 - val_loss: 0.8970\n",
            "Epoch 148/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2459 - val_loss: 0.9505\n",
            "Epoch 149/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2380 - val_loss: 1.0390\n",
            "Epoch 150/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2644 - val_loss: 0.8310\n",
            "Epoch 151/686\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2544 - val_loss: 0.9414\n",
            "Epoch 152/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2292 - val_loss: 1.0868\n",
            "Epoch 153/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2680 - val_loss: 0.9294\n",
            "Epoch 154/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2309 - val_loss: 0.9627\n",
            "Epoch 155/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2491 - val_loss: 0.8221\n",
            "Epoch 156/686\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2330 - val_loss: 0.9752\n",
            "Epoch 157/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2377 - val_loss: 0.8193\n",
            "Epoch 158/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2342 - val_loss: 0.9002\n",
            "Epoch 159/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2181 - val_loss: 1.1274\n",
            "Epoch 160/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2670 - val_loss: 0.8874\n",
            "Epoch 161/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2359 - val_loss: 0.8347\n",
            "Epoch 162/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2159 - val_loss: 1.1039\n",
            "Epoch 163/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2660 - val_loss: 0.8014\n",
            "Epoch 164/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2557 - val_loss: 0.6560\n",
            "Epoch 165/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2342 - val_loss: 0.9990\n",
            "Epoch 166/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2385 - val_loss: 0.8504\n",
            "Epoch 167/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2195 - val_loss: 0.8693\n",
            "Epoch 168/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2160 - val_loss: 0.8241\n",
            "Epoch 169/686\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2086 - val_loss: 0.9463\n",
            "Epoch 170/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2298 - val_loss: 0.7675\n",
            "Epoch 171/686\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2134 - val_loss: 0.9374\n",
            "Epoch 172/686\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2290 - val_loss: 0.7752\n",
            "(30, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "2/2 [==============================] - 0s 196ms/step - loss: 5.5573 - val_loss: 8.8804\n",
            "Epoch 2/686\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 5.4720 - val_loss: 8.7036\n",
            "Epoch 3/686\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 5.3198 - val_loss: 8.4799\n",
            "Epoch 4/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.1322 - val_loss: 8.1349\n",
            "Epoch 5/686\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.9057 - val_loss: 7.5007\n",
            "Epoch 6/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.4258 - val_loss: 6.0758\n",
            "Epoch 7/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.4215 - val_loss: 2.4030\n",
            "Epoch 8/686\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2784 - val_loss: 2.1282\n",
            "Epoch 9/686\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4644 - val_loss: 1.6972\n",
            "Epoch 10/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6870 - val_loss: 0.6507\n",
            "Epoch 11/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.6226 - val_loss: 1.4545\n",
            "Epoch 12/686\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.8503 - val_loss: 1.4245\n",
            "Epoch 13/686\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.6257 - val_loss: 1.0916\n",
            "Epoch 14/686\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1.5717 - val_loss: 0.5278\n",
            "Epoch 15/686\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.4229 - val_loss: 0.2066\n",
            "Epoch 16/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.5399 - val_loss: 0.3363\n",
            "Epoch 17/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.4200 - val_loss: 0.4568\n",
            "Epoch 18/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.3014 - val_loss: 1.3379\n",
            "Epoch 19/686\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.6462 - val_loss: 1.4695\n",
            "Epoch 20/686\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.2420 - val_loss: 0.8271\n",
            "Epoch 21/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.2402 - val_loss: 0.1162\n",
            "Epoch 22/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.4220 - val_loss: 0.5489\n",
            "Epoch 23/686\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.9818 - val_loss: 0.2028\n",
            "Epoch 24/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0434 - val_loss: 0.8637\n",
            "Epoch 25/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.2302 - val_loss: 1.5075\n",
            "Epoch 26/686\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.0126 - val_loss: 1.7229\n",
            "Epoch 27/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9978 - val_loss: 1.5036\n",
            "Epoch 28/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8036 - val_loss: 1.2187\n",
            "Epoch 29/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7943 - val_loss: 1.0038\n",
            "Epoch 30/686\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8574 - val_loss: 0.9220\n",
            "Epoch 31/686\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8499 - val_loss: 1.0289\n",
            "Epoch 32/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0886 - val_loss: 1.2373\n",
            "Epoch 33/686\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5396 - val_loss: 1.7464\n",
            "Epoch 34/686\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7730 - val_loss: 1.6042\n",
            "Epoch 35/686\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7900 - val_loss: 1.7041\n",
            "Epoch 36/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6981 - val_loss: 2.3445\n",
            "Epoch 37/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7581 - val_loss: 2.3868\n",
            "Epoch 38/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8196 - val_loss: 1.9715\n",
            "Epoch 39/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6941 - val_loss: 1.6933\n",
            "Epoch 40/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6593 - val_loss: 1.6710\n",
            "Epoch 41/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5065 - val_loss: 1.7762\n",
            "Epoch 42/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8110 - val_loss: 1.8751\n",
            "Epoch 43/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9164 - val_loss: 2.2228\n",
            "Epoch 44/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6588 - val_loss: 2.2233\n",
            "Epoch 45/686\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8878 - val_loss: 1.6020\n",
            "Epoch 46/686\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7832 - val_loss: 0.6548\n",
            "Epoch 47/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9265 - val_loss: 0.6967\n",
            "Epoch 48/686\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.9333 - val_loss: 1.8204\n",
            "Epoch 49/686\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7540 - val_loss: 2.3873\n",
            "Epoch 50/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8156 - val_loss: 2.1732\n",
            "Epoch 51/686\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5869 - val_loss: 1.6469\n",
            "Epoch 52/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7432 - val_loss: 1.1830\n",
            "Epoch 53/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9601 - val_loss: 1.4956\n",
            "Epoch 54/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7177 - val_loss: 1.8530\n",
            "Epoch 55/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6282 - val_loss: 1.8672\n",
            "Epoch 56/686\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.6982 - val_loss: 1.8860\n",
            "Epoch 57/686\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7752 - val_loss: 1.7794\n",
            "Epoch 58/686\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7353 - val_loss: 1.5657\n",
            "Epoch 59/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6688 - val_loss: 1.6827\n",
            "Epoch 60/686\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6743 - val_loss: 1.8186\n",
            "Epoch 61/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8545 - val_loss: 1.9790\n",
            "Epoch 62/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6374 - val_loss: 1.8887\n",
            "Epoch 63/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6895 - val_loss: 1.9877\n",
            "Epoch 64/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6217 - val_loss: 2.1667\n",
            "Epoch 65/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7511 - val_loss: 2.1682\n",
            "Epoch 66/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8485 - val_loss: 2.0765\n",
            "Epoch 67/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7089 - val_loss: 1.7494\n",
            "Epoch 68/686\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7628 - val_loss: 1.8478\n",
            "Epoch 69/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5918 - val_loss: 2.0745\n",
            "Epoch 70/686\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7089 - val_loss: 1.9493\n",
            "Epoch 71/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6828 - val_loss: 1.7966\n",
            "Epoch 72/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5861 - val_loss: 1.7274\n",
            "Epoch 73/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8791 - val_loss: 1.8587\n",
            "Epoch 74/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6675 - val_loss: 1.9650\n",
            "Epoch 75/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6440 - val_loss: 1.9663\n",
            "Epoch 76/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5609 - val_loss: 1.8865\n",
            "Epoch 77/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5603 - val_loss: 1.3640\n",
            "Epoch 78/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7177 - val_loss: 1.5056\n",
            "Epoch 79/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6968 - val_loss: 1.8798\n",
            "Epoch 80/686\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.6031 - val_loss: 2.0655\n",
            "Epoch 81/686\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6448 - val_loss: 1.6606\n",
            "Epoch 82/686\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8020 - val_loss: 1.1111\n",
            "Epoch 83/686\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7263 - val_loss: 1.3336\n",
            "Epoch 84/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7549 - val_loss: 1.7739\n",
            "Epoch 85/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6119 - val_loss: 2.0625\n",
            "Epoch 86/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5958 - val_loss: 2.0127\n",
            "Epoch 87/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6691 - val_loss: 1.8036\n",
            "Epoch 88/686\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6038 - val_loss: 1.2825\n",
            "Epoch 89/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7258 - val_loss: 1.2491\n",
            "Epoch 90/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8202 - val_loss: 1.7590\n",
            "Epoch 91/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6190 - val_loss: 2.2561\n",
            "Epoch 92/686\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8179 - val_loss: 2.4610\n",
            "Epoch 93/686\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.9186 - val_loss: 2.3392\n",
            "Epoch 94/686\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6411 - val_loss: 1.8779\n",
            "Epoch 95/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7745 - val_loss: 1.4191\n",
            "Epoch 96/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7138 - val_loss: 1.6077\n",
            "Epoch 97/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7075 - val_loss: 1.8587\n",
            "Epoch 98/686\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6698 - val_loss: 2.0866\n",
            "Epoch 99/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7230 - val_loss: 1.9490\n",
            "Epoch 100/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5197 - val_loss: 1.5176\n",
            "Epoch 101/686\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6441 - val_loss: 1.6041\n",
            "Epoch 102/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6486 - val_loss: 1.9674\n",
            "Epoch 103/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6503 - val_loss: 2.1758\n",
            "Epoch 104/686\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7586 - val_loss: 2.0863\n",
            "Epoch 105/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6216 - val_loss: 2.1705\n",
            "Epoch 106/686\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5489 - val_loss: 2.1830\n",
            "Epoch 107/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4691 - val_loss: 1.9761\n",
            "Epoch 108/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5895 - val_loss: 1.8646\n",
            "Epoch 109/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5309 - val_loss: 2.0718\n",
            "Epoch 110/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7771 - val_loss: 2.1387\n",
            "Epoch 111/686\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7891 - val_loss: 1.9201\n",
            "Epoch 112/686\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6820 - val_loss: 1.8413\n",
            "Epoch 113/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6017 - val_loss: 1.8134\n",
            "Epoch 114/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7205 - val_loss: 1.9599\n",
            "Epoch 115/686\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5439 - val_loss: 2.0632\n",
            "Epoch 116/686\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7245 - val_loss: 1.6154\n",
            "Epoch 117/686\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7975 - val_loss: 1.3787\n",
            "Epoch 118/686\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5282 - val_loss: 1.5111\n",
            "Epoch 119/686\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6945 - val_loss: 1.6590\n",
            "Epoch 120/686\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7204 - val_loss: 2.1985\n",
            "Epoch 121/686\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6297 - val_loss: 2.5049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pemUmRKsTru0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ae9098f4-f1c1-4667-f426-3df069c64f2e"
      },
      "source": [
        "predictions_Austin = predictionOnPredictionLSTM(initialvalue_Austin,look_ahead,conv_model_Austin)#+3#+difference_Brazoria[-1]#,encoder_model_Brazoria)#0.5=bias due to stationarity\n",
        "predictions_Austin = predictions_Austin.reshape(len(predictions_Austin))\n",
        "#print(predictions_Austin)# 20: use window = 2 here!!!\n",
        "#print(test_deaths[7][window:])#loaded weights and it's fine\n",
        "#print(train_deaths[7][160:]) #make predictions integers, 0.00037\n",
        "#print(mean_absolute_error(predictions_Austin,test_deaths[7][window:]))\n",
        "#print(mean_squared_log_error(predictions_Austin,test_deaths[7][window:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 9.147432   9.953366  10.628498  11.7541895 12.876578  14.358517\n",
            " 16.112059 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t1_AyaSUQk2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "debd4423-cf02-4660-ac35-ea130fc54bba"
      },
      "source": [
        "conv_model_Galveston,conv_history_Galveston = build_conv_model(np.array(X_train[6][30:]),np.array(X_test[6]),np.array(Y_train[6][30:]),np.array(Y_test[6]),window)#100 best\n",
        "encoder_model_Galveston,encoder_history_Galveston = build_encoder_decoder(np.array(X_train[6][30:]),np.array(X_test[6]),np.array(Y_train[6][30:]),np.array(Y_test[6]),window)#120"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 44.8519 - val_loss: 71.4986\n",
            "Epoch 2/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.7163 - val_loss: 21.5248\n",
            "Epoch 3/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.3202 - val_loss: 1.0956\n",
            "Epoch 4/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.5035 - val_loss: 4.0017\n",
            "Epoch 5/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1885 - val_loss: 1.7984\n",
            "Epoch 6/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.3862 - val_loss: 13.2034\n",
            "Epoch 7/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.1014 - val_loss: 7.4647\n",
            "Epoch 8/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9615 - val_loss: 4.7630\n",
            "Epoch 9/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.3408 - val_loss: 0.0706\n",
            "Epoch 10/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0591 - val_loss: 8.8709\n",
            "Epoch 11/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.0487 - val_loss: 3.0510\n",
            "Epoch 12/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1618 - val_loss: 7.2059\n",
            "Epoch 13/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8733 - val_loss: 2.1631\n",
            "Epoch 14/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4703 - val_loss: 8.3950\n",
            "Epoch 15/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.7258 - val_loss: 2.4879\n",
            "Epoch 16/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.0699 - val_loss: 7.3318\n",
            "Epoch 17/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6752 - val_loss: 2.0520\n",
            "Epoch 18/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.2097 - val_loss: 7.9467\n",
            "Epoch 19/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6394 - val_loss: 2.5181\n",
            "Epoch 20/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8546 - val_loss: 7.0376\n",
            "Epoch 21/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5507 - val_loss: 1.9449\n",
            "Epoch 22/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.0038 - val_loss: 7.3417\n",
            "Epoch 23/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5081 - val_loss: 8.1230\n",
            "Epoch 24/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4362 - val_loss: 1.9078\n",
            "Epoch 25/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1262 - val_loss: 12.2964\n",
            "Epoch 26/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0482 - val_loss: 0.6937\n",
            "Epoch 27/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7963 - val_loss: 3.9169\n",
            "Epoch 28/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4563 - val_loss: 0.6046\n",
            "Epoch 29/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3993 - val_loss: 5.7576\n",
            "Epoch 30/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.7923 - val_loss: 11.2298\n",
            "Epoch 31/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2450 - val_loss: 8.4980\n",
            "Epoch 32/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8335 - val_loss: 5.9009\n",
            "Epoch 33/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9376 - val_loss: 1.2442\n",
            "Epoch 34/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.1599 - val_loss: 2.3374\n",
            "Epoch 35/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.1604 - val_loss: 2.0864\n",
            "Epoch 36/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.1456 - val_loss: 0.1650\n",
            "Epoch 37/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3234 - val_loss: 1.6749\n",
            "Epoch 38/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2646 - val_loss: 0.4360\n",
            "Epoch 39/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.5390 - val_loss: 5.1978\n",
            "Epoch 40/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8843 - val_loss: 5.2475\n",
            "Epoch 41/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0294 - val_loss: 1.6776\n",
            "Epoch 42/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.6650 - val_loss: 10.8339\n",
            "Epoch 43/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4987 - val_loss: 6.6606\n",
            "Epoch 44/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7042 - val_loss: 6.4387\n",
            "Epoch 45/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2695 - val_loss: 2.2184\n",
            "Epoch 46/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3631 - val_loss: 5.5255\n",
            "Epoch 47/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.7531 - val_loss: 2.3878\n",
            "Epoch 48/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6641 - val_loss: 6.9153\n",
            "Epoch 49/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.5509 - val_loss: 2.4735\n",
            "Epoch 50/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.5476 - val_loss: 7.0647\n",
            "Epoch 51/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4755 - val_loss: 1.6521\n",
            "Epoch 52/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3303 - val_loss: 6.2750\n",
            "Epoch 53/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9474 - val_loss: 1.8351\n",
            "Epoch 54/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0830 - val_loss: 5.6226\n",
            "Epoch 55/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6915 - val_loss: 3.3168\n",
            "Epoch 56/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7458 - val_loss: 6.2051\n",
            "Epoch 57/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.9175 - val_loss: 41.6961\n",
            "Epoch 58/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4820 - val_loss: 4.9232\n",
            "Epoch 59/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8573 - val_loss: 6.2030\n",
            "Epoch 60/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.1943 - val_loss: 12.3836\n",
            "Epoch 61/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.2396 - val_loss: 7.3708\n",
            "Epoch 62/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0499 - val_loss: 7.2143\n",
            "Epoch 63/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3171 - val_loss: 0.1733\n",
            "Epoch 64/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8023 - val_loss: 6.3118\n",
            "Epoch 65/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4016 - val_loss: 0.7996\n",
            "Epoch 66/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2457 - val_loss: 6.1328\n",
            "Epoch 67/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5726 - val_loss: 3.3629\n",
            "Epoch 68/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6040 - val_loss: 6.2923\n",
            "Epoch 69/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2185 - val_loss: 2.2068\n",
            "Epoch 70/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0164 - val_loss: 6.8415\n",
            "Epoch 71/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.2527 - val_loss: 2.7187\n",
            "Epoch 72/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6534 - val_loss: 6.7949\n",
            "Epoch 73/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0543 - val_loss: 1.8685\n",
            "Epoch 74/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0034 - val_loss: 6.9337\n",
            "Epoch 75/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9497 - val_loss: 1.7016\n",
            "Epoch 76/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7449 - val_loss: 6.2894\n",
            "Epoch 77/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4349 - val_loss: 3.2461\n",
            "Epoch 78/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7582 - val_loss: 7.7512\n",
            "Epoch 79/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0872 - val_loss: 3.8717\n",
            "Epoch 80/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1671 - val_loss: 6.9556\n",
            "Epoch 81/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.9629 - val_loss: 3.0428\n",
            "Epoch 82/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3924 - val_loss: 6.9376\n",
            "Epoch 83/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0419 - val_loss: 3.6717\n",
            "Epoch 84/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0446 - val_loss: 7.3038\n",
            "Epoch 85/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2627 - val_loss: 0.2403\n",
            "Epoch 86/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9697 - val_loss: 7.0536\n",
            "Epoch 87/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6771 - val_loss: 0.8027\n",
            "Epoch 88/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8825 - val_loss: 7.4464\n",
            "Epoch 89/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1236 - val_loss: 2.6221\n",
            "Epoch 90/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5806 - val_loss: 7.7838\n",
            "Epoch 91/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9898 - val_loss: 3.8361\n",
            "Epoch 92/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0324 - val_loss: 7.4934\n",
            "Epoch 93/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.4886 - val_loss: 1.2940\n",
            "Epoch 94/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5180 - val_loss: 7.4913\n",
            "Epoch 95/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4130 - val_loss: 0.3146\n",
            "Epoch 96/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8436 - val_loss: 7.6947\n",
            "Epoch 97/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8817 - val_loss: 1.8837\n",
            "Epoch 98/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5922 - val_loss: 7.9015\n",
            "Epoch 99/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4554 - val_loss: 0.6411\n",
            "Epoch 100/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7317 - val_loss: 7.7493\n",
            "Epoch 101/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5195 - val_loss: 0.5952\n",
            "Epoch 102/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8634 - val_loss: 8.3651\n",
            "Epoch 103/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4640 - val_loss: 0.9115\n",
            "Epoch 104/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.6673 - val_loss: 8.2987\n",
            "Epoch 105/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.4272 - val_loss: 0.5850\n",
            "Epoch 106/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7121 - val_loss: 8.1163\n",
            "Epoch 107/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3840 - val_loss: 0.5799\n",
            "Epoch 108/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.6153 - val_loss: 7.8676\n",
            "Epoch 109/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3460 - val_loss: 0.0039\n",
            "Epoch 110/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7931 - val_loss: 8.3317\n",
            "Epoch 111/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3586 - val_loss: 0.6378\n",
            "Epoch 112/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6214 - val_loss: 8.4376\n",
            "Epoch 113/686\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.2739 - val_loss: 0.1818\n",
            "Epoch 114/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.7079 - val_loss: 8.3831\n",
            "Epoch 115/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2041 - val_loss: 0.0735\n",
            "Epoch 116/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6220 - val_loss: 8.1419\n",
            "Epoch 117/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2900 - val_loss: 0.1820\n",
            "Epoch 118/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7042 - val_loss: 8.5321\n",
            "Epoch 119/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6675 - val_loss: 3.1434\n",
            "Epoch 120/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9713 - val_loss: 7.8006\n",
            "Epoch 121/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3148 - val_loss: 1.2901\n",
            "Epoch 122/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3414 - val_loss: 8.8810\n",
            "Epoch 123/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3435 - val_loss: 1.7471\n",
            "Epoch 124/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2916 - val_loss: 8.7148\n",
            "Epoch 125/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1878 - val_loss: 1.1873\n",
            "Epoch 126/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2477 - val_loss: 8.5869\n",
            "Epoch 127/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3181 - val_loss: 1.4737\n",
            "Epoch 128/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3115 - val_loss: 9.0577\n",
            "Epoch 129/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1792 - val_loss: 1.1503\n",
            "Epoch 130/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3903 - val_loss: 9.3720\n",
            "Epoch 131/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0735 - val_loss: 0.7169\n",
            "Epoch 132/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3521 - val_loss: 9.1637\n",
            "Epoch 133/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1088 - val_loss: 0.9109\n",
            "Epoch 134/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3919 - val_loss: 9.5019\n",
            "Epoch 135/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9402 - val_loss: 0.2120\n",
            "Epoch 136/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0849 - val_loss: 7.7938\n",
            "Epoch 137/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3560 - val_loss: 2.6169\n",
            "Epoch 138/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3963 - val_loss: 7.6407\n",
            "Epoch 139/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8016 - val_loss: 1.7306\n",
            "Epoch 140/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4037 - val_loss: 8.0091\n",
            "Epoch 141/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0370 - val_loss: 0.2103\n",
            "Epoch 142/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2961 - val_loss: 8.5987\n",
            "Epoch 143/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1776 - val_loss: 1.3698\n",
            "Epoch 144/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1193 - val_loss: 8.8071\n",
            "Epoch 145/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0970 - val_loss: 0.7633\n",
            "Epoch 146/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2650 - val_loss: 9.5245\n",
            "Epoch 147/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8960 - val_loss: 0.0353\n",
            "Epoch 148/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4087 - val_loss: 9.7899\n",
            "Epoch 149/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8468 - val_loss: 0.0925\n",
            "Epoch 150/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4203 - val_loss: 9.8338\n",
            "Epoch 151/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0437 - val_loss: 1.0625\n",
            "Epoch 152/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0292 - val_loss: 8.7405\n",
            "Epoch 153/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7587 - val_loss: 0.3383\n",
            "Epoch 154/686\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.0819 - val_loss: 8.5403\n",
            "Epoch 155/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0097 - val_loss: 0.3991\n",
            "Epoch 156/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3303 - val_loss: 9.7112\n",
            "Epoch 157/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7786 - val_loss: 0.2091\n",
            "Epoch 158/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8183 - val_loss: 7.7947\n",
            "Epoch 159/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7093 - val_loss: 0.8113\n",
            "Epoch 160/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1032 - val_loss: 8.7857\n",
            "Epoch 161/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9749 - val_loss: 0.2123\n",
            "Epoch 162/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3004 - val_loss: 9.7977\n",
            "Epoch 163/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7551 - val_loss: 0.0492\n",
            "Epoch 164/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8071 - val_loss: 7.9009\n",
            "Epoch 165/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4197 - val_loss: 2.7307\n",
            "Epoch 166/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4366 - val_loss: 8.7454\n",
            "Epoch 167/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.6325 - val_loss: 1.5052\n",
            "Epoch 168/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2053 - val_loss: 8.9546\n",
            "Epoch 169/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0107 - val_loss: 0.6226\n",
            "Epoch 170/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1718 - val_loss: 9.3694\n",
            "Epoch 171/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.6083 - val_loss: 0.5380\n",
            "Epoch 172/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8446 - val_loss: 8.1490\n",
            "Epoch 173/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3020 - val_loss: 3.4899\n",
            "Epoch 174/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6548 - val_loss: 9.5227\n",
            "Epoch 175/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1494 - val_loss: 1.4869\n",
            "Epoch 176/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9245 - val_loss: 9.0546\n",
            "Epoch 177/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.6071 - val_loss: 0.6931\n",
            "Epoch 178/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9461 - val_loss: 8.7196\n",
            "Epoch 179/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7092 - val_loss: 0.4063\n",
            "Epoch 180/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9018 - val_loss: 8.6127\n",
            "Epoch 181/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7927 - val_loss: 0.4416\n",
            "Epoch 182/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3112 - val_loss: 10.2027\n",
            "Epoch 183/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.7276 - val_loss: 0.1635\n",
            "Epoch 184/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0274 - val_loss: 9.0487\n",
            "Epoch 185/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.1681 - val_loss: 3.7467\n",
            "Epoch 186/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5876 - val_loss: 9.6266\n",
            "Epoch 187/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0158 - val_loss: 1.0093\n",
            "Epoch 188/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.9272 - val_loss: 9.2169\n",
            "Epoch 189/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5837 - val_loss: 0.6564\n",
            "Epoch 190/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8364 - val_loss: 8.4018\n",
            "Epoch 191/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7120 - val_loss: 0.2169\n",
            "Epoch 192/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7692 - val_loss: 8.2804\n",
            "Epoch 193/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7616 - val_loss: 0.0799\n",
            "Epoch 194/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7619 - val_loss: 8.3678\n",
            "Epoch 195/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7262 - val_loss: 0.2013\n",
            "Epoch 196/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7319 - val_loss: 8.3264\n",
            "Epoch 197/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.1891 - val_loss: 3.6189\n",
            "Epoch 198/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.5338 - val_loss: 9.9235\n",
            "Epoch 199/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8145 - val_loss: 0.1665\n",
            "Epoch 200/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0211 - val_loss: 9.3980\n",
            "Epoch 201/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4668 - val_loss: 1.1732\n",
            "Epoch 202/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9507 - val_loss: 9.1962\n",
            "Epoch 203/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4848 - val_loss: 1.1346\n",
            "Epoch 204/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9296 - val_loss: 9.1910\n",
            "Epoch 205/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5413 - val_loss: 0.9109\n",
            "Epoch 206/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8359 - val_loss: 8.8457\n",
            "Epoch 207/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5554 - val_loss: 0.8933\n",
            "Epoch 208/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7630 - val_loss: 8.6075\n",
            "Epoch 209/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.0706 - val_loss: 3.1752\n",
            "Epoch 210/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8588 - val_loss: 8.3206\n",
            "Epoch 211/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5450 - val_loss: 0.9247\n",
            "Epoch 212/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.6898 - val_loss: 8.2835\n",
            "Epoch 213/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.0600 - val_loss: 3.3541\n",
            "Epoch 214/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8803 - val_loss: 7.9725\n",
            "Epoch 215/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.0243 - val_loss: 3.6604\n",
            "Epoch 216/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8389 - val_loss: 8.1661\n",
            "Epoch 217/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3719 - val_loss: 1.5963\n",
            "Epoch 218/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9605 - val_loss: 8.9299\n",
            "Epoch 219/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2007 - val_loss: 3.2606\n",
            "Epoch 220/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3539 - val_loss: 9.7809\n",
            "Epoch 221/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.6776 - val_loss: 0.3760\n",
            "Epoch 222/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0902 - val_loss: 10.0025\n",
            "Epoch 223/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.4074 - val_loss: 1.1823\n",
            "Epoch 224/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8044 - val_loss: 8.8813\n",
            "Epoch 225/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5132 - val_loss: 0.9533\n",
            "Epoch 226/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8208 - val_loss: 9.1127\n",
            "Epoch 227/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.5057 - val_loss: 1.0223\n",
            "Epoch 228/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8148 - val_loss: 9.1014\n",
            "Epoch 229/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4624 - val_loss: 1.1642\n",
            "Epoch 230/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7761 - val_loss: 8.9663\n",
            "Epoch 231/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3531 - val_loss: 1.7423\n",
            "Epoch 232/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8925 - val_loss: 9.1296\n",
            "Epoch 233/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4451 - val_loss: 1.2229\n",
            "Epoch 234/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8274 - val_loss: 8.9754\n",
            "Epoch 235/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.0013 - val_loss: 3.3132\n",
            "Epoch 236/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7622 - val_loss: 8.0677\n",
            "Epoch 237/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9789 - val_loss: 3.8009\n",
            "Epoch 238/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.8034 - val_loss: 8.0206\n",
            "Epoch 239/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9429 - val_loss: 3.9600\n",
            "Epoch 240/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8960 - val_loss: 8.2370\n",
            "Epoch 241/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9402 - val_loss: 3.8234\n",
            "Epoch 242/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8085 - val_loss: 7.9898\n",
            "Epoch 243/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.9477 - val_loss: 3.8494\n",
            "Epoch 244/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8269 - val_loss: 8.0954\n",
            "Epoch 245/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3273 - val_loss: 2.0198\n",
            "Epoch 246/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9055 - val_loss: 8.9873\n",
            "Epoch 247/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.2065 - val_loss: 2.9981\n",
            "Epoch 248/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2866 - val_loss: 9.9860\n",
            "Epoch 249/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5042 - val_loss: 0.5269\n",
            "Epoch 250/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7007 - val_loss: 8.9700\n",
            "Epoch 251/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3808 - val_loss: 1.2979\n",
            "Epoch 252/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.6552 - val_loss: 8.6634\n",
            "Epoch 253/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.8222 - val_loss: 3.6185\n",
            "Epoch 254/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5385 - val_loss: 8.1363\n",
            "Epoch 255/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7927 - val_loss: 3.2751\n",
            "Epoch 256/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5133 - val_loss: 8.1644\n",
            "Epoch 257/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.7086 - val_loss: 3.2366\n",
            "Epoch 258/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.4173 - val_loss: 7.9292\n",
            "Epoch 259/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6148 - val_loss: 3.0811\n",
            "Epoch 260/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.0419 - val_loss: 6.7410\n",
            "Epoch 261/686\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6119 - val_loss: 2.6783\n",
            "Epoch 262/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9053 - val_loss: 6.4231\n",
            "Epoch 263/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5643 - val_loss: 2.3017\n",
            "Epoch 264/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.8138 - val_loss: 6.0706\n",
            "Epoch 265/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5979 - val_loss: 2.6711\n",
            "Epoch 266/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.8182 - val_loss: 5.9707\n",
            "Epoch 267/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5135 - val_loss: 2.2167\n",
            "Epoch 268/686\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5226 - val_loss: 4.3180\n",
            "Epoch 269/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5611 - val_loss: 2.8668\n",
            "(151, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 51.7725 - val_loss: 87.5635\n",
            "Epoch 2/686\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 20.5170 - val_loss: 20.4868\n",
            "Epoch 3/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 14.2803 - val_loss: 14.0025\n",
            "Epoch 4/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 13.7409 - val_loss: 5.8405\n",
            "Epoch 5/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 12.2818 - val_loss: 15.1457\n",
            "Epoch 6/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 17.4833 - val_loss: 29.5904\n",
            "Epoch 7/686\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 14.1323 - val_loss: 39.7607\n",
            "Epoch 8/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 14.7676 - val_loss: 9.7650\n",
            "Epoch 9/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 12.5189 - val_loss: 7.4451\n",
            "Epoch 10/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.7249 - val_loss: 2.3453\n",
            "Epoch 11/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 14.7172 - val_loss: 7.7594\n",
            "Epoch 12/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 12.4645 - val_loss: 16.7671\n",
            "Epoch 13/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.5976 - val_loss: 14.4423\n",
            "Epoch 14/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 13.7107 - val_loss: 8.5194\n",
            "Epoch 15/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 12.2091 - val_loss: 38.2559\n",
            "Epoch 16/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 10.3217 - val_loss: 6.9525\n",
            "Epoch 17/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 10.3907 - val_loss: 21.8879\n",
            "Epoch 18/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 10.0157 - val_loss: 20.9731\n",
            "Epoch 19/686\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 10.7380 - val_loss: 8.5188\n",
            "Epoch 20/686\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 12.0533 - val_loss: 15.5919\n",
            "Epoch 21/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.7865 - val_loss: 12.4697\n",
            "Epoch 22/686\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 10.6536 - val_loss: 18.7235\n",
            "Epoch 23/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 13.3570 - val_loss: 32.9615\n",
            "Epoch 24/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 11.2076 - val_loss: 13.7404\n",
            "Epoch 25/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.6526 - val_loss: 32.1485\n",
            "Epoch 26/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 10.0576 - val_loss: 18.4041\n",
            "Epoch 27/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 9.2624 - val_loss: 28.5255\n",
            "Epoch 28/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 7.5538 - val_loss: 19.0665\n",
            "Epoch 29/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.1864 - val_loss: 27.9952\n",
            "Epoch 30/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.2151 - val_loss: 25.7819\n",
            "Epoch 31/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 10.6312 - val_loss: 15.0929\n",
            "Epoch 32/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.7675 - val_loss: 25.5395\n",
            "Epoch 33/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 9.2217 - val_loss: 20.7624\n",
            "Epoch 34/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.1596 - val_loss: 27.8353\n",
            "Epoch 35/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.5272 - val_loss: 20.8564\n",
            "Epoch 36/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 9.8665 - val_loss: 20.9946\n",
            "Epoch 37/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.1721 - val_loss: 25.1393\n",
            "Epoch 38/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.8512 - val_loss: 20.9416\n",
            "Epoch 39/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 10.2292 - val_loss: 18.4868\n",
            "Epoch 40/686\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 9.6632 - val_loss: 32.6207\n",
            "Epoch 41/686\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 8.0448 - val_loss: 19.4860\n",
            "Epoch 42/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.9979 - val_loss: 23.4832\n",
            "Epoch 43/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.3860 - val_loss: 15.1130\n",
            "Epoch 44/686\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 8.5904 - val_loss: 11.4929\n",
            "Epoch 45/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 9.1424 - val_loss: 22.6130\n",
            "Epoch 46/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.7789 - val_loss: 21.2846\n",
            "Epoch 47/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 8.0913 - val_loss: 18.4525\n",
            "Epoch 48/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.4539 - val_loss: 20.6790\n",
            "Epoch 49/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 9.2541 - val_loss: 18.0804\n",
            "Epoch 50/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.3118 - val_loss: 26.8475\n",
            "Epoch 51/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 9.6662 - val_loss: 19.6277\n",
            "Epoch 52/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.6712 - val_loss: 25.6462\n",
            "Epoch 53/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 12.3418 - val_loss: 23.0617\n",
            "Epoch 54/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 18.0671 - val_loss: 53.6430\n",
            "Epoch 55/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 7.8166 - val_loss: 14.2506\n",
            "Epoch 56/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.8150 - val_loss: 25.2701\n",
            "Epoch 57/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 8.3290 - val_loss: 24.1677\n",
            "Epoch 58/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 8.6074 - val_loss: 30.3168\n",
            "Epoch 59/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.0534 - val_loss: 20.6196\n",
            "Epoch 60/686\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 8.4932 - val_loss: 28.2608\n",
            "Epoch 61/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 8.0245 - val_loss: 19.5613\n",
            "Epoch 62/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.4900 - val_loss: 26.8205\n",
            "Epoch 63/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.1091 - val_loss: 28.7142\n",
            "Epoch 64/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 6.7237 - val_loss: 21.7681\n",
            "Epoch 65/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.0539 - val_loss: 24.7884\n",
            "Epoch 66/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.6096 - val_loss: 26.0338\n",
            "Epoch 67/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.8661 - val_loss: 34.6306\n",
            "Epoch 68/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.4393 - val_loss: 23.5638\n",
            "Epoch 69/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.2713 - val_loss: 30.6428\n",
            "Epoch 70/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 11.0208 - val_loss: 25.0636\n",
            "Epoch 71/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 10.6473 - val_loss: 13.6986\n",
            "Epoch 72/686\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 10.0329 - val_loss: 40.6273\n",
            "Epoch 73/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 8.3707 - val_loss: 20.6916\n",
            "Epoch 74/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.7307 - val_loss: 21.7075\n",
            "Epoch 75/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.4148 - val_loss: 25.2088\n",
            "Epoch 76/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 7.7002 - val_loss: 23.5536\n",
            "Epoch 77/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.3182 - val_loss: 27.6876\n",
            "Epoch 78/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.2854 - val_loss: 23.8515\n",
            "Epoch 79/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.4143 - val_loss: 22.8241\n",
            "Epoch 80/686\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 7.1198 - val_loss: 31.7955\n",
            "Epoch 81/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 9.1643 - val_loss: 23.6404\n",
            "Epoch 82/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 8.5343 - val_loss: 25.9816\n",
            "Epoch 83/686\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 9.7490 - val_loss: 33.2659\n",
            "Epoch 84/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.7863 - val_loss: 23.2683\n",
            "Epoch 85/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 7.3096 - val_loss: 25.7300\n",
            "Epoch 86/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.0840 - val_loss: 24.3922\n",
            "Epoch 87/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 6.9498 - val_loss: 32.0064\n",
            "Epoch 88/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.0554 - val_loss: 21.8217\n",
            "Epoch 89/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 8.6650 - val_loss: 18.4391\n",
            "Epoch 90/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 7.6339 - val_loss: 21.3059\n",
            "Epoch 91/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.4428 - val_loss: 24.7437\n",
            "Epoch 92/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 7.5918 - val_loss: 16.8882\n",
            "Epoch 93/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.0679 - val_loss: 21.5668\n",
            "Epoch 94/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 7.0398 - val_loss: 22.1102\n",
            "Epoch 95/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 6.4456 - val_loss: 27.0695\n",
            "Epoch 96/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.0319 - val_loss: 24.8510\n",
            "Epoch 97/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 7.2488 - val_loss: 27.5668\n",
            "Epoch 98/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 6.2648 - val_loss: 27.3381\n",
            "Epoch 99/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 7.7407 - val_loss: 13.7982\n",
            "Epoch 100/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 8.4085 - val_loss: 24.7823\n",
            "Epoch 101/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 8.4680 - val_loss: 24.2747\n",
            "Epoch 102/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 9.8868 - val_loss: 16.9726\n",
            "Epoch 103/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.0718 - val_loss: 29.9953\n",
            "Epoch 104/686\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 7.6744 - val_loss: 16.4398\n",
            "Epoch 105/686\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 7.2700 - val_loss: 24.3185\n",
            "Epoch 106/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 8.6040 - val_loss: 22.4152\n",
            "Epoch 107/686\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 9.4306 - val_loss: 20.2723\n",
            "Epoch 108/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 7.2553 - val_loss: 26.5013\n",
            "Epoch 109/686\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 8.5175 - val_loss: 21.0292\n",
            "Epoch 110/686\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 7.0362 - val_loss: 28.9547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFU4Gw4p6AOy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJrAh8QZq-l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b552f26-2b2e-4958-d021-3f6f3342867e"
      },
      "source": [
        "predictions_Galveston = predictionOnPredictionLSTM(initialvalue_Galveston,look_ahead,conv_model_Galveston)#+difference_Brazoria[-1]#,encoder_model_Brazoria)#0.5=bias due to stationarity\n",
        "predictions_Galveston = predictions_Galveston.reshape(len(predictions_Galveston))\n",
        "print(\"Prediction for second week is:\",predictions_Galveston)# 20: use window = 2!!!\n",
        "#print(test_deaths[6][window:])#loaded weights and it's fine\n",
        "#print(train_deaths[6][160:]) #make predictions integers, 0.00037\n",
        "#print(mean_absolute_error(predictions_Galveston,test_deaths[6][window:]))#Check galveston again, maybe implement diff/bias method!\n",
        "#print(mean_squared_log_error(predictions_Galveston,test_deaths[6][window:]))\n",
        "#164.7857  167.35925 169.55275 171.98668 174.38051 176.82349 179.33896\n",
        "#[165.00296 165.09131 169.01877 170.19328 172.41519 174.02005 174.8002 ] prediction.. 2nd week"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for second week is: [165.0039  165.12003 169.60738 170.824   173.59613 175.36617 176.14713]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzcM5lzud4jV"
      },
      "source": [
        "Hospitalization starts here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4fd3uXM5uUw"
      },
      "source": [
        "I import from my drive the 8 files containing county hospitalization data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBj3jmSmd8TF"
      },
      "source": [
        "#insert data\n",
        "import xlrd\n",
        "#files can be imported by any available method, I import them from my drive using google colab\n",
        "harris_hosp = pd.read_excel('/content/drive/My Drive/Hospitalizationdata/harris_hosp_0913.xlsx',usecols=[2,3])\n",
        "liberty_hosp=pd.read_excel('/content/drive/My Drive/Hospitalizationdata/liberty_hosp_0913.xlsx',usecols=[2,3])\n",
        "montgomery_hosp = pd.read_excel('/content/drive/My Drive/Hospitalizationdata/montgomery_hosp_0913.xlsx',usecols=[2,3])\n",
        "brazoria_hosp  = pd.read_excel('/content/drive/My Drive/Hospitalizationdata/brazoria_hosp_0913.xlsx',usecols=[2,3])\n",
        "chambers_hosp  = pd.read_excel('/content/drive/My Drive/Hospitalizationdata/chambers_hosp_0913.xlsx',usecols=[2,3])\n",
        "fortbend_hosp  = pd.read_excel('/content/drive/My Drive/Hospitalizationdata/fortbend_hosp_0913.xlsx',usecols=[2,3])\n",
        "galveston_hosp  = pd.read_excel('/content/drive/My Drive/Hospitalizationdata/galveston_hosp_0913.xlsx',usecols=[2,3])\n",
        "austin_hosp  = pd.read_excel('/content/drive/My Drive/Hospitalizationdata/austin_hosp_0913.xlsx',usecols=[2,3])\n",
        "\n",
        "#harris_hosp_0904.xlsx\n",
        "all_names = [\"harris_hosp_0913\",\"liberty_hosp_0913\",\"montgomery_hosp_0913\",\"brazoria_hosp_0913\",\"chambers_hosp_0913\",\"fortbend_hosp_09_13\",\"galveston_hosp_09_13\",\"austin_hosp_09_13\"]\n",
        "#all = [harris_hosp_0904,liberty_hosp_0904,montgomery_hosp_0904,brazoria_hosp_0904,chambers_hosp_0904,fortbend_hosp_09_04,galveston_hosp_09_04,austin_hosp_09_04]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_n83fnhgr2N"
      },
      "source": [
        "harris_hosp['Total'] = harris_hosp['CovidBed']+harris_hosp['ICUCovidBed']\n",
        "harris_hosp.index = datetime_object_hosp\n",
        "liberty_hosp['Total'] = liberty_hosp['CovidBed']+liberty_hosp['ICUCovidBed']\n",
        "liberty_hosp.index = datetime_object_hosp\n",
        "montgomery_hosp['Total'] = montgomery_hosp['CovidBed']+montgomery_hosp['ICUCovidBed']\n",
        "montgomery_hosp.index = datetime_object_hosp\n",
        "brazoria_hosp['Total'] = brazoria_hosp['CovidBed']+brazoria_hosp['ICUCovidBed']\n",
        "brazoria_hosp.index = datetime_object_hosp\n",
        "chambers_hosp['Total'] = chambers_hosp['CovidBed']+chambers_hosp['ICUCovidBed']\n",
        "chambers_hosp.index = datetime_object_hosp\n",
        "fortbend_hosp['Total'] = fortbend_hosp['CovidBed']+fortbend_hosp['ICUCovidBed']\n",
        "fortbend_hosp.index = datetime_object_hosp\n",
        "galveston_hosp['Total'] = galveston_hosp['CovidBed']+galveston_hosp['ICUCovidBed']\n",
        "galveston_hosp.index = datetime_object_hosp\n",
        "austin_hosp['Total'] = austin_hosp['CovidBed']+austin_hosp['ICUCovidBed']\n",
        "austin_hosp.index = datetime_object_hosp\n",
        "all_hosp = [harris_hosp['Total'],liberty_hosp['Total'],montgomery_hosp['Total'],brazoria_hosp['Total'],chambers_hosp['Total'],fortbend_hosp['Total'],galveston_hosp['Total'],austin_hosp['Total']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HCkqIjIiYLQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b80092f5-5b10-422f-aae6-d59393323445"
      },
      "source": [
        "print(harris_hosp.iloc[-10:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            CovidBed  ICUCovidBed  Total\n",
            "09/04/2020       526          259    785\n",
            "09/05/2020       517          250    767\n",
            "09/06/2020       415          245    660\n",
            "09/07/2020       438          227    665\n",
            "09/08/2020       449          222    671\n",
            "09/09/2020       482          223    705\n",
            "09/10/2020       495          217    712\n",
            "09/11/2020       472          234    706\n",
            "09/12/2020       461          206    667\n",
            "09/13/2020       412          195    607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo_tn7ESZlUt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3raTm7qjwvW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "5a114df5-79d4-4e80-cc10-b50713a2bcd1"
      },
      "source": [
        "all_dataframe_hosp = pd.concat(all_hosp, axis=1,names = all_names)\n",
        "all_dataframe_hosp.columns = all_names\n",
        "print(all_dataframe_hosp)\n",
        "rolling_means_hosp = []\n",
        "exp_means_hosp = []\n",
        "for i in range(0,len(all_dataframe_hosp.columns)):\n",
        "  rolling_mean_hosp = all_dataframe_hosp.iloc[:,i].rolling(window=7).mean()\n",
        "  rolling_mean_hosp = rolling_mean_hosp.fillna(0)\n",
        "  rolling_means_hosp.append(rolling_mean_hosp)\n",
        "  exp_mean = all_dataframe_hosp.iloc[:,i].ewm(span=7, adjust=False).mean()\n",
        "  exp_mean = exp_mean.fillna(0)\n",
        "  exp_means_hosp.append(exp_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            harris_hosp_0913  ...  austin_hosp_09_13\n",
            "04/01/2020               248  ...                  0\n",
            "04/02/2020               235  ...                  0\n",
            "04/03/2020               545  ...                  0\n",
            "04/04/2020               616  ...                  0\n",
            "04/05/2020               584  ...                  0\n",
            "...                      ...  ...                ...\n",
            "09/09/2020               705  ...                  0\n",
            "09/10/2020               712  ...                  0\n",
            "09/11/2020               706  ...                  0\n",
            "09/12/2020               667  ...                  0\n",
            "09/13/2020               607  ...                  0\n",
            "\n",
            "[166 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMNoyax3p9QC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ffd4c5ad-4f15-4096-9575-e208b4bc3c8d"
      },
      "source": [
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "i = 0\n",
        "for k in range(0,len(all_hosp)):\n",
        "  fig, ax = plt.subplots()\n",
        "  sns.scatterplot(list(all_hosp[k].index),list(all_hosp[k].values),ax=ax)\n",
        "  plt.plot(all_hosp[k].index,rolling_means_hosp[i],color='r')\n",
        "  plt.plot(all_hosp[k].index,exp_means_hosp[i],color='g')\n",
        "\n",
        "# set the frequency for labelling the xaxis\n",
        "  freq = int(15)\n",
        "  plt.title(all_names[i])\n",
        "  plt.ylabel(\"Daily hospitalizations\")\n",
        "  plt.xlabel(\"Date\")\n",
        "# set the xlabels as the datetime data for the given labelling frequency,\n",
        "# also use only the date for the label\n",
        "  ax.set_xticklabels(all_hosp[k].iloc[::freq].index)\n",
        "# set the xticks at the same frequency as the xlabels\n",
        "  xtix = ax.get_xticks()\n",
        "  ax.set_xticks(xtix[::freq])\n",
        "# nicer label format for dates\n",
        "  fig.autofmt_xdate()\n",
        "  plt.tight_layout()\n",
        "  i = i +1\n",
        "  plt.show()\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMnfatrJrsqy"
      },
      "source": [
        "tr = 100#was 96.5 # percent.#change it when you change the data so the test set contains 9 value, in the split it will contain 7, exactly one week!\n",
        "window_2 = 5 #was 3,10 best\n",
        "train_deaths_hosp=[]\n",
        "test_deaths_hosp= []\n",
        "\n",
        "for i in all_hosp:\n",
        "\t tempp = i.values.reshape(len(i.values),)\n",
        "\t temp_train,temp_test = split_train_test(tempp,tr,window_2)\n",
        "\t #temp_train,temp_test = split_train_test(temp_value,tr,window)\n",
        "\t train_deaths_hosp.append(temp_train)\n",
        "\t test_deaths_hosp.append(temp_test)\n",
        "X_train_hosp,Y_train_hosp = [],[]\n",
        "X_test_hosp, Y_test_hosp = [],[]\n",
        "for i in train_deaths_hosp:\n",
        "\ttemp_X, temp_Y = split_sequence(i,window_2)\n",
        "\tX_train_hosp.append(temp_X)\n",
        "\tY_train_hosp.append(temp_Y)\n",
        "  \n",
        "for i in test_deaths_hosp:\n",
        "\ttemp_Xx, temp_Yy = split_sequence(i,window_2)\n",
        "\tX_test_hosp.append(temp_Xx)\n",
        "\tY_test_hosp.append(temp_Yy)\n",
        " \n",
        "\n",
        "#print(X_train_hosp[0],X_test_hosp[0])\n",
        "#print(len(X_test_hosp[0]))\n",
        "#X_test must be 7!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8THhGE4_fE"
      },
      "source": [
        "X_train_hosp_expma = []\n",
        "Y_train_hosp_expma = []\n",
        "for i in exp_means_hosp:\n",
        "  temp_X, temp_Y = split_sequence(i.values,window_2)\n",
        "  #temp_X = np.array(temp_X)\n",
        "  #temp_Y = np.array(temp_Y)\n",
        "  X_train_hosp_expma.append(temp_X)\n",
        "  Y_train_hosp_expma.append(temp_Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU5YBCHDugki"
      },
      "source": [
        "look_ahead = 7\n",
        "value_Harris_hosp = X_test_hosp[0][0].reshape(1, window_2, 1)\n",
        "value_Liberty_hosp = X_test_hosp[1][0].reshape(1, window_2, 1)\n",
        "value_Montgomery_hosp = X_test_hosp[2][0].reshape(1, window_2, 1)\n",
        "value_Brazoria_hosp = X_test_hosp[3][0].reshape(1, window_2, 1)\n",
        "value_Chambers_hosp = X_test_hosp[4][0].reshape(1, window_2, 1)\n",
        "value_Fort_Bend_hosp = X_test_hosp[5][0].reshape(1, window_2, 1)\n",
        "value_Galveston_hosp = X_test_hosp[6][0].reshape(1, window_2, 1)\n",
        "value_Austin_hosp = X_test_hosp[7][0].reshape(1, window_2, 1)\n",
        "initialvalue_Harris_hosp = tf.convert_to_tensor(list(value_Harris_hosp), dtype=tf.float32)\n",
        "initialvalue_Liberty_hosp = tf.convert_to_tensor(list(value_Liberty_hosp),dtype=tf.float32)\n",
        "initialvalue_Montgomery_hosp = tf.convert_to_tensor(list(value_Montgomery_hosp),dtype=tf.float32)\n",
        "initialvalue_Brazoria_hosp = tf.convert_to_tensor(list(value_Brazoria_hosp), dtype=tf.float32)\n",
        "initialvalue_Chambers_hosp = tf.convert_to_tensor(list(value_Chambers_hosp),dtype=tf.float32)\n",
        "initialvalue_Fort_Bend_hosp = tf.convert_to_tensor(list(value_Fort_Bend_hosp),dtype=tf.float32)\n",
        "initialvalue_Galveston_hosp = tf.convert_to_tensor(list(value_Galveston_hosp), dtype=tf.float32)\n",
        "initialvalue_Austin_hosp = tf.convert_to_tensor(list(value_Austin_hosp),dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN9DoSN6vod_"
      },
      "source": [
        "\n",
        "def build_encoder_decoder_h(train_X,test_X,train_Y,test_Y,window):\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed = 42\n",
        "  temp_Y_train = np.array(train_Y)\n",
        "  temp_Y_test = np.array(test_Y)\n",
        "  n_steps_out = 1\n",
        "  Y_train_encoder = temp_Y_train.reshape((temp_Y_train.shape[0],1,1))\n",
        "  Y_test_encoder = temp_Y_test.reshape((temp_Y_test.shape[0],1,1))\n",
        "  verbose, epochs, batch_size = 0, 686, 16 #8.8 best, 386\n",
        "  n_features = 1\n",
        "  train_X = train_X.reshape((train_X.shape[0],train_X.shape[1],n_features))\n",
        "  print(train_X.shape)\n",
        "  test_X = test_X.reshape((test_X.shape[0],test_X.shape[1],n_features))\n",
        "  train_X = tf.convert_to_tensor(list(train_X), dtype=tf.float32)\n",
        "  test_X = tf.convert_to_tensor(list(test_X), dtype=tf.float32)\n",
        "  model = Sequential() \n",
        "  model.add(LSTM(100 ,activation='relu',recurrent_activation ='sigmoid',input_shape=(window, n_features)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(RepeatVector(n_steps_out))\n",
        "  model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(TimeDistributed(Dense(1)))\n",
        "  model.compile(loss='mae',optimizer='adam')\n",
        "  from tensorflow.keras.callbacks import EarlyStopping \n",
        "  early_stopping = EarlyStopping(patience = 160, restore_best_weights = True,monitor='val_loss')#150 good\n",
        "  history = model.fit(train_X, Y_train_encoder, epochs=epochs, batch_size=batch_size, shuffle = False,validation_data = (test_X, Y_test_encoder),callbacks = [early_stopping])\n",
        "  return model,history "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcpS6DTJv-kK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHVq1dXRv0yu"
      },
      "source": [
        "def build_conv_model_h(train_X,test_X,train_Y,test_Y,window):\n",
        "\t# prepare data\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed = 42\n",
        "  temp_Y_train = np.array(train_Y)\n",
        "  temp_Y_test = np.array(test_Y)\n",
        "  Y_train_conv = temp_Y_train.reshape((temp_Y_train.shape[0],1,1))\n",
        "  Y_test_conv = temp_Y_test.reshape((temp_Y_test.shape[0],1,1))\n",
        "  verbose, epochs, batch_size = 0, 686, 16 #was 16\n",
        "  n_features = 1\n",
        "  train_X = train_X.reshape((train_X.shape[0],train_X.shape[1],n_features))\n",
        "  test_X = test_X.reshape((test_X.shape[0],test_X.shape[1],n_features))\n",
        "  train_X = tf.convert_to_tensor(list(train_X), dtype=tf.float32)\n",
        "  test_X = tf.convert_to_tensor(list(test_X), dtype=tf.float32)\n",
        "  n_outputs=1\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=32, kernel_size=window_2-1, activation='relu', input_shape=(window,n_features)))#kernel_size=2 for window = 3\n",
        "  model.add(MaxPooling1D())#pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(RepeatVector(n_outputs))\n",
        "  model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(50, activation='relu')))\n",
        "  model.add(TimeDistributed(Dense(1)))\n",
        "  model.compile(loss='mae', optimizer='adam')\n",
        "  from tensorflow.keras.callbacks import EarlyStopping \n",
        "  early_stopping = EarlyStopping(patience = 160, restore_best_weights = True,monitor='val_loss')#150 good\n",
        "\t# fit network\n",
        "  history = model.fit(train_X, Y_train_conv, epochs=epochs, batch_size=batch_size, shuffle = False,validation_data = (test_X, Y_test_conv),callbacks = [early_stopping])\n",
        "  return model,history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Ct-KMpv0XU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22d48e05-2688-4047-ac3e-c2763f298a82"
      },
      "source": [
        "encoder_model_Harris,encoder_history_Harris = build_encoder_decoder_h(np.array(X_train_hosp_expma[0][70:]),np.array(X_test_hosp[0]),np.array(Y_train_hosp_expma[0][70:]),np.array(Y_test_hosp[0]),window_2)\n",
        "conv_model_Harris,conv_history_Harris = build_conv_model_h(np.array(X_train_hosp_expma[0][70:]),np.array(X_test_hosp[0]),np.array(Y_train_hosp_expma[0][70:]),np.array(Y_test_hosp[0]),window_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(93, 3, 1)\n",
            "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 1579.4316 - val_loss: 575.7552\n",
            "Epoch 2/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1531.1794 - val_loss: 536.6180\n",
            "Epoch 3/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1445.8508 - val_loss: 491.6672\n",
            "Epoch 4/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1353.4413 - val_loss: 432.1930\n",
            "Epoch 5/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1184.0901 - val_loss: 345.3907\n",
            "Epoch 6/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 904.2183 - val_loss: 168.9793\n",
            "Epoch 7/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 509.3490 - val_loss: 64.4606\n",
            "Epoch 8/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 359.4446 - val_loss: 153.2858\n",
            "Epoch 9/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 284.8084 - val_loss: 107.3446\n",
            "Epoch 10/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 248.3799 - val_loss: 33.8610\n",
            "Epoch 11/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 254.7874 - val_loss: 2.3811\n",
            "Epoch 12/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 272.8656 - val_loss: 30.9955\n",
            "Epoch 13/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 262.5428 - val_loss: 93.2587\n",
            "Epoch 14/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 264.8257 - val_loss: 80.9370\n",
            "Epoch 15/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 251.2928 - val_loss: 45.8138\n",
            "Epoch 16/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 201.4880 - val_loss: 60.2830\n",
            "Epoch 17/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 247.7743 - val_loss: 53.3229\n",
            "Epoch 18/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 218.2112 - val_loss: 42.5035\n",
            "Epoch 19/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 210.8772 - val_loss: 42.2286\n",
            "Epoch 20/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 226.6164 - val_loss: 45.3964\n",
            "Epoch 21/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 229.2988 - val_loss: 17.9509\n",
            "Epoch 22/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 238.4919 - val_loss: 45.0583\n",
            "Epoch 23/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 176.5013 - val_loss: 42.6121\n",
            "Epoch 24/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 228.4273 - val_loss: 8.8354\n",
            "Epoch 25/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 249.9437 - val_loss: 10.7009\n",
            "Epoch 26/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 228.5028 - val_loss: 54.0019\n",
            "Epoch 27/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 224.8947 - val_loss: 62.8807\n",
            "Epoch 28/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 215.9867 - val_loss: 26.6975\n",
            "Epoch 29/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 206.9616 - val_loss: 19.1429\n",
            "Epoch 30/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 200.9072 - val_loss: 64.1595\n",
            "Epoch 31/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 252.7152 - val_loss: 55.4086\n",
            "Epoch 32/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 209.9234 - val_loss: 0.2615\n",
            "Epoch 33/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 252.5181 - val_loss: 52.9624\n",
            "Epoch 34/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 235.9183 - val_loss: 106.8684\n",
            "Epoch 35/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 209.1297 - val_loss: 33.5829\n",
            "Epoch 36/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 206.3622 - val_loss: 1.2478\n",
            "Epoch 37/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 193.6133 - val_loss: 43.7896\n",
            "Epoch 38/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 248.4215 - val_loss: 40.0819\n",
            "Epoch 39/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 249.4065 - val_loss: 29.9289\n",
            "Epoch 40/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 208.2468 - val_loss: 16.5353\n",
            "Epoch 41/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 201.7583 - val_loss: 55.2670\n",
            "Epoch 42/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 213.9197 - val_loss: 52.1067\n",
            "Epoch 43/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 212.9705 - val_loss: 34.8148\n",
            "Epoch 44/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 208.6652 - val_loss: 39.1517\n",
            "Epoch 45/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 191.0493 - val_loss: 34.1779\n",
            "Epoch 46/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 242.5818 - val_loss: 32.8054\n",
            "Epoch 47/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 224.2486 - val_loss: 23.2927\n",
            "Epoch 48/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 214.3474 - val_loss: 78.7393\n",
            "Epoch 49/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 189.8170 - val_loss: 78.1848\n",
            "Epoch 50/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 206.6485 - val_loss: 26.9837\n",
            "Epoch 51/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 212.3829 - val_loss: 6.2075\n",
            "Epoch 52/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 211.1612 - val_loss: 19.7916\n",
            "Epoch 53/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 216.7186 - val_loss: 47.0065\n",
            "Epoch 54/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 231.8499 - val_loss: 43.5020\n",
            "Epoch 55/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 194.9396 - val_loss: 22.7039\n",
            "Epoch 56/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 222.3720 - val_loss: 32.4980\n",
            "Epoch 57/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 226.1088 - val_loss: 20.8348\n",
            "Epoch 58/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 197.4022 - val_loss: 0.6113\n",
            "Epoch 59/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 179.0034 - val_loss: 15.5032\n",
            "Epoch 60/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 200.0166 - val_loss: 7.4566\n",
            "Epoch 61/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 202.2908 - val_loss: 54.4298\n",
            "Epoch 62/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 234.5464 - val_loss: 0.2259\n",
            "Epoch 63/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 191.4508 - val_loss: 1.2689\n",
            "Epoch 64/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 213.7053 - val_loss: 81.1948\n",
            "Epoch 65/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 222.2263 - val_loss: 85.7217\n",
            "Epoch 66/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 211.8400 - val_loss: 25.0924\n",
            "Epoch 67/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 231.5508 - val_loss: 34.9726\n",
            "Epoch 68/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 234.2788 - val_loss: 48.0077\n",
            "Epoch 69/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 223.7360 - val_loss: 89.7153\n",
            "Epoch 70/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 191.3779 - val_loss: 46.6652\n",
            "Epoch 71/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 219.9044 - val_loss: 14.7711\n",
            "Epoch 72/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 202.6980 - val_loss: 18.1832\n",
            "Epoch 73/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 222.1572 - val_loss: 72.1867\n",
            "Epoch 74/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 203.9467 - val_loss: 55.6685\n",
            "Epoch 75/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 240.1021 - val_loss: 46.5712\n",
            "Epoch 76/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 195.4473 - val_loss: 40.1790\n",
            "Epoch 77/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 216.4700 - val_loss: 70.3033\n",
            "Epoch 78/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 206.5858 - val_loss: 37.6891\n",
            "Epoch 79/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 220.1739 - val_loss: 28.1650\n",
            "Epoch 80/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 227.8870 - val_loss: 54.7396\n",
            "Epoch 81/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 191.3689 - val_loss: 33.2943\n",
            "Epoch 82/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 221.2535 - val_loss: 32.5034\n",
            "Epoch 83/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 226.7833 - val_loss: 3.0715\n",
            "Epoch 84/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 216.0907 - val_loss: 15.3412\n",
            "Epoch 85/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 234.9080 - val_loss: 37.4548\n",
            "Epoch 86/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 240.3597 - val_loss: 72.4985\n",
            "Epoch 87/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 231.2409 - val_loss: 25.8881\n",
            "Epoch 88/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 202.5806 - val_loss: 2.1132\n",
            "Epoch 89/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 213.4569 - val_loss: 42.0471\n",
            "Epoch 90/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 249.8242 - val_loss: 75.7468\n",
            "Epoch 91/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 196.0783 - val_loss: 2.5652\n",
            "Epoch 92/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 212.3353 - val_loss: 21.2527\n",
            "Epoch 93/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 209.2897 - val_loss: 37.7566\n",
            "Epoch 94/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 192.5444 - val_loss: 22.1735\n",
            "Epoch 95/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 190.4486 - val_loss: 15.6848\n",
            "Epoch 96/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 212.6037 - val_loss: 37.3613\n",
            "Epoch 97/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 182.3528 - val_loss: 49.8384\n",
            "Epoch 98/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 223.7245 - val_loss: 58.4521\n",
            "Epoch 99/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 214.5888 - val_loss: 44.1697\n",
            "Epoch 100/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 213.3339 - val_loss: 41.0891\n",
            "Epoch 101/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 233.2217 - val_loss: 52.4523\n",
            "Epoch 102/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 191.0275 - val_loss: 11.6524\n",
            "Epoch 103/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 208.9198 - val_loss: 7.9907\n",
            "Epoch 104/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 211.4125 - val_loss: 20.8799\n",
            "Epoch 105/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 237.6795 - val_loss: 64.5889\n",
            "Epoch 106/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 191.2116 - val_loss: 84.2311\n",
            "Epoch 107/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 252.1418 - val_loss: 76.5416\n",
            "Epoch 108/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 196.0780 - val_loss: 13.3278\n",
            "Epoch 109/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 186.5276 - val_loss: 21.2456\n",
            "Epoch 110/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 211.1131 - val_loss: 21.8558\n",
            "Epoch 111/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 209.6920 - val_loss: 81.1897\n",
            "Epoch 112/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 226.5243 - val_loss: 70.7289\n",
            "Epoch 113/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 180.0150 - val_loss: 19.9955\n",
            "Epoch 114/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 206.6001 - val_loss: 26.9115\n",
            "Epoch 115/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 204.2731 - val_loss: 45.7487\n",
            "Epoch 116/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 188.0781 - val_loss: 47.8966\n",
            "Epoch 117/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 223.1326 - val_loss: 28.5800\n",
            "Epoch 118/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 206.2665 - val_loss: 30.9688\n",
            "Epoch 119/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 195.2719 - val_loss: 34.6043\n",
            "Epoch 120/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 198.2174 - val_loss: 17.8725\n",
            "Epoch 121/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 182.3055 - val_loss: 28.6507\n",
            "Epoch 122/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 195.3710 - val_loss: 53.1832\n",
            "Epoch 123/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 177.9392 - val_loss: 68.6786\n",
            "Epoch 124/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 201.8588 - val_loss: 45.8965\n",
            "Epoch 125/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 213.7329 - val_loss: 22.2104\n",
            "Epoch 126/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 172.9582 - val_loss: 23.1217\n",
            "Epoch 127/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 185.5710 - val_loss: 34.9771\n",
            "Epoch 128/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 210.0849 - val_loss: 43.1828\n",
            "Epoch 129/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 181.7242 - val_loss: 9.8784\n",
            "Epoch 130/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 204.0611 - val_loss: 21.9788\n",
            "Epoch 131/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 220.0316 - val_loss: 45.5779\n",
            "Epoch 132/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 227.1560 - val_loss: 54.8284\n",
            "Epoch 133/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 201.3036 - val_loss: 24.9382\n",
            "Epoch 134/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 204.5737 - val_loss: 46.0980\n",
            "Epoch 135/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 215.5098 - val_loss: 33.3978\n",
            "Epoch 136/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 251.9930 - val_loss: 27.5660\n",
            "Epoch 137/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 180.1560 - val_loss: 1.7360\n",
            "Epoch 138/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 199.5032 - val_loss: 21.5142\n",
            "Epoch 139/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 192.7663 - val_loss: 58.6078\n",
            "Epoch 140/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 187.9121 - val_loss: 24.2465\n",
            "Epoch 141/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 184.3949 - val_loss: 7.8774\n",
            "Epoch 142/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 213.1218 - val_loss: 7.0616\n",
            "Epoch 143/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 226.4006 - val_loss: 47.2593\n",
            "Epoch 144/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 211.3645 - val_loss: 31.7769\n",
            "Epoch 145/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 196.0288 - val_loss: 4.3998\n",
            "Epoch 146/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 202.8575 - val_loss: 2.3615\n",
            "Epoch 147/686\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 193.3834 - val_loss: 23.4217\n",
            "Epoch 148/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 192.3913 - val_loss: 42.9276\n",
            "Epoch 149/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 172.9474 - val_loss: 28.2733\n",
            "Epoch 150/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 191.9125 - val_loss: 7.6240\n",
            "Epoch 151/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 197.7433 - val_loss: 28.8190\n",
            "Epoch 152/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 213.6169 - val_loss: 40.2119\n",
            "Epoch 153/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 193.4385 - val_loss: 19.9750\n",
            "Epoch 154/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 174.8980 - val_loss: 20.0974\n",
            "Epoch 155/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 195.3777 - val_loss: 8.9390\n",
            "Epoch 156/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 198.0894 - val_loss: 4.5782\n",
            "Epoch 157/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 186.8400 - val_loss: 24.6569\n",
            "Epoch 158/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 215.6918 - val_loss: 32.1675\n",
            "Epoch 159/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 203.2350 - val_loss: 26.2091\n",
            "Epoch 160/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 182.3260 - val_loss: 40.7396\n",
            "Epoch 161/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 222.9703 - val_loss: 20.6715\n",
            "Epoch 162/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 188.0214 - val_loss: 27.5353\n",
            "Epoch 163/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 219.1645 - val_loss: 20.7341\n",
            "Epoch 164/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 188.7906 - val_loss: 4.4884\n",
            "Epoch 165/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 218.2183 - val_loss: 11.7050\n",
            "Epoch 166/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 245.6777 - val_loss: 64.9545\n",
            "Epoch 167/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 185.0301 - val_loss: 32.9954\n",
            "Epoch 168/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 191.2935 - val_loss: 15.5583\n",
            "Epoch 169/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 187.5819 - val_loss: 5.8964\n",
            "Epoch 170/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 206.4826 - val_loss: 4.8577\n",
            "Epoch 171/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 204.3421 - val_loss: 19.3167\n",
            "Epoch 172/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 193.1858 - val_loss: 4.3729\n",
            "Epoch 173/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 201.4182 - val_loss: 72.4993\n",
            "Epoch 174/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 209.8628 - val_loss: 19.8617\n",
            "Epoch 175/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 178.2538 - val_loss: 6.9164\n",
            "Epoch 176/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 178.8810 - val_loss: 32.7024\n",
            "Epoch 177/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 187.3609 - val_loss: 2.6800\n",
            "Epoch 178/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 228.4498 - val_loss: 22.5417\n",
            "Epoch 179/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 209.5873 - val_loss: 55.3131\n",
            "Epoch 180/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 194.2805 - val_loss: 7.9022\n",
            "Epoch 181/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 205.5171 - val_loss: 14.1346\n",
            "Epoch 182/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 195.3276 - val_loss: 44.3116\n",
            "Epoch 183/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 204.7102 - val_loss: 59.0319\n",
            "Epoch 184/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 165.3989 - val_loss: 28.1625\n",
            "Epoch 185/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 179.1449 - val_loss: 11.5096\n",
            "Epoch 186/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 184.4174 - val_loss: 24.7981\n",
            "Epoch 187/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 192.0568 - val_loss: 45.6545\n",
            "Epoch 188/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 208.8690 - val_loss: 6.8533\n",
            "Epoch 189/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 196.3042 - val_loss: 6.7350\n",
            "Epoch 190/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 175.0759 - val_loss: 45.2075\n",
            "Epoch 191/686\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 182.9948 - val_loss: 30.2477\n",
            "Epoch 192/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 182.5678 - val_loss: 18.2445\n",
            "Epoch 193/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 168.8655 - val_loss: 18.8555\n",
            "Epoch 194/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 221.5141 - val_loss: 11.0464\n",
            "Epoch 195/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 188.2048 - val_loss: 8.6379\n",
            "Epoch 196/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 208.6926 - val_loss: 28.2431\n",
            "Epoch 197/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 193.4920 - val_loss: 22.1468\n",
            "Epoch 198/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 156.9349 - val_loss: 4.0288\n",
            "Epoch 199/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 180.8815 - val_loss: 11.2001\n",
            "Epoch 200/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 177.5855 - val_loss: 40.0451\n",
            "Epoch 201/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 179.1550 - val_loss: 17.7151\n",
            "Epoch 202/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 149.5911 - val_loss: 11.5901\n",
            "Epoch 203/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 210.7492 - val_loss: 26.1925\n",
            "Epoch 204/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 174.1710 - val_loss: 5.6365\n",
            "Epoch 205/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 188.7700 - val_loss: 11.5353\n",
            "Epoch 206/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 186.7023 - val_loss: 14.0783\n",
            "Epoch 207/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 192.9520 - val_loss: 15.7993\n",
            "Epoch 208/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 191.2673 - val_loss: 27.3326\n",
            "Epoch 209/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 158.7775 - val_loss: 28.6188\n",
            "Epoch 210/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 216.7441 - val_loss: 52.6193\n",
            "Epoch 211/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 180.7426 - val_loss: 13.2524\n",
            "Epoch 212/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 166.5673 - val_loss: 5.7259\n",
            "Epoch 213/686\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 184.4282 - val_loss: 13.3923\n",
            "Epoch 214/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 187.8134 - val_loss: 37.4014\n",
            "Epoch 215/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 185.4731 - val_loss: 36.7619\n",
            "Epoch 216/686\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 192.8236 - val_loss: 11.5444\n",
            "Epoch 217/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 179.0825 - val_loss: 0.4201\n",
            "Epoch 218/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 157.1483 - val_loss: 31.6677\n",
            "Epoch 219/686\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 173.4836 - val_loss: 11.7610\n",
            "Epoch 220/686\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 176.9447 - val_loss: 13.3014\n",
            "Epoch 221/686\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 190.1333 - val_loss: 8.8762\n",
            "Epoch 222/686\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 202.9426 - val_loss: 13.2723\n",
            "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 1606.0902 - val_loss: 577.5063\n",
            "Epoch 2/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1524.3964 - val_loss: 540.3525\n",
            "Epoch 3/686\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1434.9635 - val_loss: 499.0165\n",
            "Epoch 4/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1326.8156 - val_loss: 441.4622\n",
            "Epoch 5/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1178.4484 - val_loss: 363.4225\n",
            "Epoch 6/686\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 976.5849 - val_loss: 257.4295\n",
            "Epoch 7/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 703.2104 - val_loss: 114.7025\n",
            "Epoch 8/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 333.5205 - val_loss: 77.6802\n",
            "Epoch 9/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 188.9669 - val_loss: 204.6987\n",
            "Epoch 10/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 224.9143 - val_loss: 132.9508\n",
            "Epoch 11/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 63.5106 - val_loss: 51.0212\n",
            "Epoch 12/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 124.3781 - val_loss: 57.0961\n",
            "Epoch 13/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 103.9340 - val_loss: 101.4543\n",
            "Epoch 14/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 99.2047 - val_loss: 101.6644\n",
            "Epoch 15/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 79.0984 - val_loss: 76.4438\n",
            "Epoch 16/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 80.8898 - val_loss: 69.2400\n",
            "Epoch 17/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.4483 - val_loss: 78.5660\n",
            "Epoch 18/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.6863 - val_loss: 83.7063\n",
            "Epoch 19/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 81.5448 - val_loss: 79.0497\n",
            "Epoch 20/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 81.3583 - val_loss: 75.5856\n",
            "Epoch 21/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 82.2091 - val_loss: 74.6492\n",
            "Epoch 22/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.0037 - val_loss: 75.8009\n",
            "Epoch 23/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 82.8900 - val_loss: 77.0406\n",
            "Epoch 24/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.7626 - val_loss: 78.3317\n",
            "Epoch 25/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.6286 - val_loss: 79.6544\n",
            "Epoch 26/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 82.5006 - val_loss: 80.7058\n",
            "Epoch 27/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.8807 - val_loss: 80.5425\n",
            "Epoch 28/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 81.5038 - val_loss: 80.0283\n",
            "Epoch 29/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 81.7490 - val_loss: 80.4030\n",
            "Epoch 30/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.8307 - val_loss: 80.9616\n",
            "Epoch 31/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 81.3128 - val_loss: 80.5458\n",
            "Epoch 32/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 80.9982 - val_loss: 79.9077\n",
            "Epoch 33/686\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 81.2770 - val_loss: 80.2274\n",
            "Epoch 34/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 81.3698 - val_loss: 80.7670\n",
            "Epoch 35/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 80.8639 - val_loss: 80.6437\n",
            "Epoch 36/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 81.0553 - val_loss: 80.9537\n",
            "Epoch 37/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.5940 - val_loss: 80.7126\n",
            "Epoch 38/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 80.1308 - val_loss: 79.2061\n",
            "Epoch 39/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 80.1612 - val_loss: 78.3298\n",
            "Epoch 40/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.5002 - val_loss: 78.5408\n",
            "Epoch 41/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 80.6178 - val_loss: 79.3335\n",
            "Epoch 42/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.6181 - val_loss: 80.4404\n",
            "Epoch 43/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 79.8901 - val_loss: 79.6575\n",
            "Epoch 44/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 79.7710 - val_loss: 79.1782\n",
            "Epoch 45/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.0354 - val_loss: 79.6168\n",
            "Epoch 46/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.1130 - val_loss: 80.5477\n",
            "Epoch 47/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 79.4322 - val_loss: 79.6766\n",
            "Epoch 48/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 79.3259 - val_loss: 79.1602\n",
            "Epoch 49/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 79.6025 - val_loss: 79.5914\n",
            "Epoch 50/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 79.6860 - val_loss: 80.5311\n",
            "Epoch 51/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 79.0084 - val_loss: 79.6697\n",
            "Epoch 52/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 78.8999 - val_loss: 79.1684\n",
            "Epoch 53/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 79.1778 - val_loss: 79.6204\n",
            "Epoch 54/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 79.2611 - val_loss: 80.5839\n",
            "Epoch 55/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.8018 - val_loss: 77.3083\n",
            "Epoch 56/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.6628 - val_loss: 74.6483\n",
            "Epoch 57/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 79.1544 - val_loss: 76.0764\n",
            "Epoch 58/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 79.4133 - val_loss: 78.3423\n",
            "Epoch 59/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 79.1295 - val_loss: 80.2881\n",
            "Epoch 60/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 77.4713 - val_loss: 77.5283\n",
            "Epoch 61/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 77.2212 - val_loss: 75.1478\n",
            "Epoch 62/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 78.6257 - val_loss: 76.7493\n",
            "Epoch 63/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 78.8927 - val_loss: 79.1310\n",
            "Epoch 64/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 78.5893 - val_loss: 81.1567\n",
            "Epoch 65/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.0599 - val_loss: 78.4231\n",
            "Epoch 66/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 76.6510 - val_loss: 76.0624\n",
            "Epoch 67/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.3262 - val_loss: 75.5723\n",
            "Epoch 68/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 77.6201 - val_loss: 76.0893\n",
            "Epoch 69/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 77.7079 - val_loss: 77.1450\n",
            "Epoch 70/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 77.6808 - val_loss: 78.4832\n",
            "Epoch 71/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 77.5970 - val_loss: 79.9779\n",
            "Epoch 72/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.0036 - val_loss: 76.9556\n",
            "Epoch 73/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 75.8243 - val_loss: 74.4577\n",
            "Epoch 74/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.3383 - val_loss: 76.0805\n",
            "Epoch 75/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.5566 - val_loss: 78.5264\n",
            "Epoch 76/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.2492 - val_loss: 80.6316\n",
            "Epoch 77/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 75.6598 - val_loss: 77.9136\n",
            "Epoch 78/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 75.2754 - val_loss: 75.5822\n",
            "Epoch 79/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 76.6887 - val_loss: 77.3370\n",
            "Epoch 80/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.9682 - val_loss: 79.8848\n",
            "Epoch 81/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 75.2011 - val_loss: 77.3943\n",
            "Epoch 82/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 74.8504 - val_loss: 75.1897\n",
            "Epoch 83/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.2737 - val_loss: 77.0407\n",
            "Epoch 84/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.5098 - val_loss: 79.6592\n",
            "Epoch 85/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 74.7064 - val_loss: 77.1935\n",
            "Epoch 86/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 74.3630 - val_loss: 75.0071\n",
            "Epoch 87/686\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 75.8063 - val_loss: 76.8992\n",
            "Epoch 88/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.0237 - val_loss: 79.5608\n",
            "Epoch 89/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 74.2072 - val_loss: 77.1024\n",
            "Epoch 90/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 73.8551 - val_loss: 74.9247\n",
            "Epoch 91/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 75.3140 - val_loss: 76.8548\n",
            "Epoch 92/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 75.5204 - val_loss: 79.5592\n",
            "Epoch 93/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 73.7051 - val_loss: 77.1053\n",
            "Epoch 94/686\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 73.3288 - val_loss: 74.9346\n",
            "Epoch 95/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 74.7976 - val_loss: 76.9044\n",
            "Epoch 96/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 74.9995 - val_loss: 79.6536\n",
            "Epoch 97/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 73.1990 - val_loss: 77.2028\n",
            "Epoch 98/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 72.7829 - val_loss: 75.0375\n",
            "Epoch 99/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 74.2557 - val_loss: 77.0489\n",
            "Epoch 100/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 74.4595 - val_loss: 79.8453\n",
            "Epoch 101/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 72.6877 - val_loss: 77.3964\n",
            "Epoch 102/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 72.2156 - val_loss: 75.2355\n",
            "Epoch 103/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 73.6867 - val_loss: 77.2903\n",
            "Epoch 104/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 73.8988 - val_loss: 80.1364\n",
            "Epoch 105/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 72.1698 - val_loss: 77.6880\n",
            "Epoch 106/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 71.6254 - val_loss: 75.5304\n",
            "Epoch 107/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 73.0887 - val_loss: 77.6309\n",
            "Epoch 108/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 73.3159 - val_loss: 80.5291\n",
            "Epoch 109/686\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 71.6442 - val_loss: 78.0798\n",
            "Epoch 110/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 71.0107 - val_loss: 75.9245\n",
            "Epoch 111/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 72.4601 - val_loss: 78.0726\n",
            "Epoch 112/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 71.8596 - val_loss: 78.3477\n",
            "Epoch 113/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 71.4354 - val_loss: 78.4743\n",
            "Epoch 114/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 70.7523 - val_loss: 76.8203\n",
            "Epoch 115/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 70.7528 - val_loss: 75.9329\n",
            "Epoch 116/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 71.1745 - val_loss: 76.4780\n",
            "Epoch 117/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 71.2988 - val_loss: 77.7844\n",
            "Epoch 118/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 71.2473 - val_loss: 79.4670\n",
            "Epoch 119/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 69.6493 - val_loss: 76.3023\n",
            "Epoch 120/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 70.1258 - val_loss: 76.1540\n",
            "Epoch 121/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 70.8553 - val_loss: 78.0435\n",
            "Epoch 122/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 69.8462 - val_loss: 77.3672\n",
            "Epoch 123/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 69.6055 - val_loss: 77.0277\n",
            "Epoch 124/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 69.9256 - val_loss: 77.9176\n",
            "Epoch 125/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 69.0761 - val_loss: 76.6745\n",
            "Epoch 126/686\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 69.0147 - val_loss: 76.1481\n",
            "Epoch 127/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 69.3948 - val_loss: 77.0119\n",
            "Epoch 128/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 69.4673 - val_loss: 78.5703\n",
            "Epoch 129/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 67.7818 - val_loss: 75.2823\n",
            "Epoch 130/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 68.4880 - val_loss: 75.2347\n",
            "Epoch 131/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 69.9500 - val_loss: 79.6716\n",
            "Epoch 132/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 67.6096 - val_loss: 74.6516\n",
            "Epoch 133/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 67.3828 - val_loss: 74.6725\n",
            "Epoch 134/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 69.1949 - val_loss: 78.4853\n",
            "Epoch 135/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 67.6027 - val_loss: 77.2413\n",
            "Epoch 136/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 66.7609 - val_loss: 75.8274\n",
            "Epoch 137/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 68.1803 - val_loss: 78.7712\n",
            "Epoch 138/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 66.8471 - val_loss: 77.0425\n",
            "Epoch 139/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 66.8846 - val_loss: 77.8671\n",
            "Epoch 140/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 65.8596 - val_loss: 75.0828\n",
            "Epoch 141/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 66.4896 - val_loss: 75.4221\n",
            "Epoch 142/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 67.9045 - val_loss: 80.3052\n",
            "Epoch 143/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 64.7743 - val_loss: 73.7976\n",
            "Epoch 144/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 64.8033 - val_loss: 71.7904\n",
            "Epoch 145/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 67.6630 - val_loss: 76.7603\n",
            "Epoch 146/686\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 66.2878 - val_loss: 78.5619\n",
            "Epoch 147/686\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 63.7973 - val_loss: 74.1559\n",
            "Epoch 148/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 64.7893 - val_loss: 73.6429\n",
            "Epoch 149/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 66.4621 - val_loss: 78.1926\n",
            "Epoch 150/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 63.7126 - val_loss: 74.2625\n",
            "Epoch 151/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 63.8171 - val_loss: 72.9429\n",
            "Epoch 152/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 65.7180 - val_loss: 77.1158\n",
            "Epoch 153/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 63.7884 - val_loss: 75.9401\n",
            "Epoch 154/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 63.8987 - val_loss: 77.1823\n",
            "Epoch 155/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 63.4798 - val_loss: 76.9920\n",
            "Epoch 156/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 62.0389 - val_loss: 74.0055\n",
            "Epoch 157/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 63.4118 - val_loss: 75.3639\n",
            "Epoch 158/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 63.6536 - val_loss: 78.0768\n",
            "Epoch 159/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 61.6895 - val_loss: 75.0283\n",
            "Epoch 160/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 62.2129 - val_loss: 75.3727\n",
            "Epoch 161/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 62.7359 - val_loss: 77.5800\n",
            "Epoch 162/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 60.7781 - val_loss: 74.2474\n",
            "Epoch 163/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 61.5266 - val_loss: 74.5450\n",
            "Epoch 164/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 63.0830 - val_loss: 79.5641\n",
            "Epoch 165/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 59.0709 - val_loss: 71.3831\n",
            "Epoch 166/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 62.5135 - val_loss: 77.1624\n",
            "Epoch 167/686\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 61.0458 - val_loss: 75.0096\n",
            "Epoch 168/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 59.5463 - val_loss: 73.6165\n",
            "Epoch 169/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 61.5764 - val_loss: 78.1352\n",
            "Epoch 170/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 58.9088 - val_loss: 73.7988\n",
            "Epoch 171/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 58.8758 - val_loss: 72.4048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA1BPRi9wmyv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d06e8c14-c391-4948-9301-c8d8d4d2df22"
      },
      "source": [
        "\n",
        "predictions_hosp_Harris = predictionOnPredictionLSTM(initialvalue_Harris_hosp,look_ahead,conv_model_Harris)\n",
        "predictions_hosp_Harris = predictions_hosp_Harris.reshape(len(predictions_hosp_Harris))\n",
        "print(predictions_hosp_Harris)\n",
        "print(train_deaths_hosp[0][-20:])\n",
        "print(test_deaths_hosp[0])\n",
        "#print(mean_absolute_error(predictions_hosp_Harris,test_deaths_hosp[0][window_2:]))\n",
        "#print(mean_squared_log_error(predictions_hosp_Harris,test_deaths_hosp[0][window_2:]))\n",
        "#[721.77356 712.42664 673.3252  635.06647 610.22815 581.2126  551.75415] 1st week\n",
        "#[ 636.788   626.026   618.71826 623.69507 614.1832  600.37854 585.93115] \n",
        "#[648.8522  630.1971  616.67267 613.0903  600.22144 589.7575  580.5178 ], \n",
        "#[636.788 ,  626.026 ,  618.71826, 623.69507 ,600.22144,589.7575 , 580.5178] #final 2nd week"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[658.02124 636.5361  613.6591  599.67267 579.2134  561.867   546.1658 ]\n",
            "[1010  889  898  865  789  821  805  904  826  789  785  767  660  665\n",
            "  671  705  712  706  667  607]\n",
            "[712 706 667 607]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgMSxZnZwEio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de99a5b1-d0d7-4a2d-9ad1-9fe10977e8a1"
      },
      "source": [
        "encoder_model_Liberty,encoder_history_Liberty = build_encoder_decoder_h(np.array(X_train_hosp_expma[1][:]),np.array(X_test_hosp[1]),np.array(Y_train_hosp_expma[1][:]),np.array(Y_test_hosp[1]),window_2)\n",
        "conv_model_Liberty,conv_history_Liberty = build_conv_model_h(np.array(X_train_hosp_expma[1][:]),np.array(X_test_hosp[1]),np.array(Y_train_hosp_expma[1][:]),np.array(Y_test_hosp[1]),window_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(129, 30, 1)\n",
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.4750 - val_loss: 0.0350\n",
            "Epoch 2/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.3990 - val_loss: 0.1022\n",
            "Epoch 3/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.5163 - val_loss: 0.0937\n",
            "Epoch 4/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.3642 - val_loss: 0.0679\n",
            "Epoch 5/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.3836 - val_loss: 0.0693\n",
            "Epoch 6/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.3774 - val_loss: 0.0783\n",
            "Epoch 7/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.3693 - val_loss: 0.0897\n",
            "Epoch 8/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.3558 - val_loss: 0.1016\n",
            "Epoch 9/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.3357 - val_loss: 0.1099\n",
            "Epoch 10/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.3260 - val_loss: 0.1114\n",
            "Epoch 11/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.3022 - val_loss: 0.1050\n",
            "Epoch 12/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.2900 - val_loss: 0.0895\n",
            "Epoch 13/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.2750 - val_loss: 0.0785\n",
            "Epoch 14/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.2589 - val_loss: 0.0538\n",
            "Epoch 15/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.2440 - val_loss: 0.0731\n",
            "Epoch 16/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.2469 - val_loss: 0.0520\n",
            "Epoch 17/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.2482 - val_loss: 0.0368\n",
            "Epoch 18/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.2172 - val_loss: 0.0479\n",
            "Epoch 19/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.2227 - val_loss: 0.0412\n",
            "Epoch 20/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.2256 - val_loss: 0.0372\n",
            "Epoch 21/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.2008 - val_loss: 0.0304\n",
            "Epoch 22/686\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.2163 - val_loss: 0.0257\n",
            "Epoch 23/686\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1867 - val_loss: 0.0225\n",
            "Epoch 24/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1987 - val_loss: 0.0312\n",
            "Epoch 25/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1850 - val_loss: 0.0147\n",
            "Epoch 26/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1831 - val_loss: 0.0016\n",
            "Epoch 27/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.2148 - val_loss: 0.0301\n",
            "Epoch 28/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.2195 - val_loss: 0.0293\n",
            "Epoch 29/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.2016 - val_loss: 0.0086\n",
            "Epoch 30/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1953 - val_loss: 0.0122\n",
            "Epoch 31/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1881 - val_loss: 0.0014\n",
            "Epoch 32/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1765 - val_loss: 7.0713e-04\n",
            "Epoch 33/686\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1741 - val_loss: 0.0108\n",
            "Epoch 34/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1622 - val_loss: 0.0113\n",
            "Epoch 35/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1654 - val_loss: 0.0182\n",
            "Epoch 36/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1692 - val_loss: 0.0262\n",
            "Epoch 37/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1612 - val_loss: 0.0290\n",
            "Epoch 38/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1769 - val_loss: 0.0133\n",
            "Epoch 39/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1553 - val_loss: 0.0262\n",
            "Epoch 40/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1576 - val_loss: 0.0225\n",
            "Epoch 41/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1575 - val_loss: 0.0154\n",
            "Epoch 42/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1380 - val_loss: 0.0191\n",
            "Epoch 43/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1578 - val_loss: 0.0263\n",
            "Epoch 44/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1625 - val_loss: 0.0560\n",
            "Epoch 45/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1493 - val_loss: 0.0318\n",
            "Epoch 46/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1710 - val_loss: 0.0044\n",
            "Epoch 47/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1564 - val_loss: 0.0174\n",
            "Epoch 48/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1500 - val_loss: 0.0533\n",
            "Epoch 49/686\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1393 - val_loss: 0.0220\n",
            "Epoch 50/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1571 - val_loss: 0.0126\n",
            "Epoch 51/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1465 - val_loss: 0.0372\n",
            "Epoch 52/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1357 - val_loss: 0.0318\n",
            "Epoch 53/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1381 - val_loss: 0.0219\n",
            "Epoch 54/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1354 - val_loss: 0.0203\n",
            "Epoch 55/686\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.1445 - val_loss: 0.0562\n",
            "Epoch 56/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1483 - val_loss: 0.0406\n",
            "Epoch 57/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1282 - val_loss: 0.0285\n",
            "Epoch 58/686\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.1333 - val_loss: 0.0327\n",
            "Epoch 59/686\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.1416 - val_loss: 0.0279\n",
            "Epoch 60/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1332 - val_loss: 0.0572\n",
            "Epoch 61/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1285 - val_loss: 0.0255\n",
            "Epoch 62/686\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.1354 - val_loss: 0.0333\n",
            "Epoch 63/686\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.1430 - val_loss: 0.0526\n",
            "Epoch 64/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1344 - val_loss: 0.0313\n",
            "Epoch 65/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1366 - val_loss: 0.0375\n",
            "Epoch 66/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1587 - val_loss: 0.0365\n",
            "Epoch 67/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1427 - val_loss: 0.0393\n",
            "Epoch 68/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1166 - val_loss: 0.0490\n",
            "Epoch 69/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1419 - val_loss: 0.0127\n",
            "Epoch 70/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1483 - val_loss: 0.0262\n",
            "Epoch 71/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1377 - val_loss: 0.0403\n",
            "Epoch 72/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1351 - val_loss: 0.0212\n",
            "Epoch 73/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1364 - val_loss: 0.0274\n",
            "Epoch 74/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1313 - val_loss: 0.0411\n",
            "Epoch 75/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1190 - val_loss: 0.0489\n",
            "Epoch 76/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1242 - val_loss: 0.0374\n",
            "Epoch 77/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1228 - val_loss: 0.0333\n",
            "Epoch 78/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1364 - val_loss: 0.0395\n",
            "Epoch 79/686\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.1252 - val_loss: 0.0257\n",
            "Epoch 80/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1355 - val_loss: 0.0440\n",
            "Epoch 81/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1261 - val_loss: 0.0608\n",
            "Epoch 82/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1296 - val_loss: 0.0323\n",
            "Epoch 83/686\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.1343 - val_loss: 0.0326\n",
            "Epoch 84/686\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1330 - val_loss: 0.0369\n",
            "Epoch 85/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1226 - val_loss: 0.0297\n",
            "Epoch 86/686\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.1125 - val_loss: 0.0329\n",
            "Epoch 87/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1178 - val_loss: 0.0375\n",
            "Epoch 88/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1170 - val_loss: 0.0301\n",
            "Epoch 89/686\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.1276 - val_loss: 0.0364\n",
            "Epoch 90/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1291 - val_loss: 0.0197\n",
            "Epoch 91/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1233 - val_loss: 0.0261\n",
            "Epoch 92/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1238 - val_loss: 0.0368\n",
            "Epoch 93/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1190 - val_loss: 0.0423\n",
            "Epoch 94/686\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1254 - val_loss: 0.0386\n",
            "Epoch 95/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1306 - val_loss: 0.0415\n",
            "Epoch 96/686\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.1319 - val_loss: 0.0194\n",
            "Epoch 97/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1249 - val_loss: 0.0433\n",
            "Epoch 98/686\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.1153 - val_loss: 0.0337\n",
            "Epoch 99/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1239 - val_loss: 0.0287\n",
            "Epoch 100/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1242 - val_loss: 0.0477\n",
            "Epoch 101/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1195 - val_loss: 0.0288\n",
            "Epoch 102/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1252 - val_loss: 0.0577\n",
            "Epoch 103/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1254 - val_loss: 0.0322\n",
            "Epoch 104/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1263 - val_loss: 0.0202\n",
            "Epoch 105/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1206 - val_loss: 0.0503\n",
            "Epoch 106/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1179 - val_loss: 0.0424\n",
            "Epoch 107/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1240 - val_loss: 0.0428\n",
            "Epoch 108/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1053 - val_loss: 0.0453\n",
            "Epoch 109/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1313 - val_loss: 0.0311\n",
            "Epoch 110/686\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.1261 - val_loss: 0.0447\n",
            "Epoch 111/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1204 - val_loss: 0.0357\n",
            "Epoch 112/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1179 - val_loss: 0.0327\n",
            "Epoch 113/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1151 - val_loss: 0.0358\n",
            "Epoch 114/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1141 - val_loss: 0.0278\n",
            "Epoch 115/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1102 - val_loss: 0.0386\n",
            "Epoch 116/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1177 - val_loss: 0.0466\n",
            "Epoch 117/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1232 - val_loss: 0.0368\n",
            "Epoch 118/686\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1081 - val_loss: 0.0415\n",
            "Epoch 119/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1128 - val_loss: 0.0339\n",
            "Epoch 120/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1145 - val_loss: 0.0297\n",
            "Epoch 121/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1115 - val_loss: 0.0347\n",
            "Epoch 122/686\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1131 - val_loss: 0.0397\n",
            "Epoch 123/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1174 - val_loss: 0.0430\n",
            "Epoch 124/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1173 - val_loss: 0.0437\n",
            "Epoch 125/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1129 - val_loss: 0.0554\n",
            "Epoch 126/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1187 - val_loss: 0.0245\n",
            "Epoch 127/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1247 - val_loss: 0.0376\n",
            "Epoch 128/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1216 - val_loss: 0.0366\n",
            "Epoch 129/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1243 - val_loss: 0.0176\n",
            "Epoch 130/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1172 - val_loss: 0.0674\n",
            "Epoch 131/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1039 - val_loss: 0.0451\n",
            "Epoch 132/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1130 - val_loss: 0.0241\n",
            "Epoch 133/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1152 - val_loss: 0.0408\n",
            "Epoch 134/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1053 - val_loss: 0.0392\n",
            "Epoch 135/686\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1194 - val_loss: 0.0435\n",
            "Epoch 136/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1197 - val_loss: 0.0352\n",
            "Epoch 137/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1093 - val_loss: 0.0650\n",
            "Epoch 138/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1099 - val_loss: 0.0364\n",
            "Epoch 139/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1202 - val_loss: 0.0326\n",
            "Epoch 140/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1142 - val_loss: 0.0395\n",
            "Epoch 141/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1026 - val_loss: 0.0404\n",
            "Epoch 142/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1220 - val_loss: 0.0313\n",
            "Epoch 143/686\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.1052 - val_loss: 0.0445\n",
            "Epoch 144/686\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.1067 - val_loss: 0.0353\n",
            "Epoch 145/686\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.1154 - val_loss: 0.0247\n",
            "Epoch 146/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1200 - val_loss: 0.0572\n",
            "Epoch 147/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1044 - val_loss: 0.0296\n",
            "Epoch 148/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1072 - val_loss: 0.0340\n",
            "Epoch 149/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1021 - val_loss: 0.0508\n",
            "Epoch 150/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1058 - val_loss: 0.0361\n",
            "Epoch 151/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1065 - val_loss: 0.0330\n",
            "Epoch 152/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1168 - val_loss: 0.0596\n",
            "Epoch 153/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1010 - val_loss: 0.0391\n",
            "Epoch 154/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.0986 - val_loss: 0.0508\n",
            "Epoch 155/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1167 - val_loss: 0.0442\n",
            "Epoch 156/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1076 - val_loss: 0.0521\n",
            "Epoch 157/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1070 - val_loss: 0.0421\n",
            "Epoch 158/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1184 - val_loss: 0.0389\n",
            "Epoch 159/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.0966 - val_loss: 0.0364\n",
            "Epoch 160/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1245 - val_loss: 0.0358\n",
            "Epoch 161/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1051 - val_loss: 0.0483\n",
            "Epoch 162/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1042 - val_loss: 0.0576\n",
            "Epoch 163/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1066 - val_loss: 0.0598\n",
            "Epoch 164/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1027 - val_loss: 0.0696\n",
            "Epoch 165/686\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.1089 - val_loss: 0.0495\n",
            "Epoch 166/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1029 - val_loss: 0.0569\n",
            "Epoch 167/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1063 - val_loss: 0.0590\n",
            "Epoch 168/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1128 - val_loss: 0.0314\n",
            "Epoch 169/686\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.0991 - val_loss: 0.0766\n",
            "Epoch 170/686\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.1078 - val_loss: 0.0729\n",
            "Epoch 171/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.0988 - val_loss: 0.0395\n",
            "Epoch 172/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1044 - val_loss: 0.0576\n",
            "Epoch 173/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1059 - val_loss: 0.0729\n",
            "Epoch 174/686\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.1044 - val_loss: 0.0399\n",
            "Epoch 175/686\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1021 - val_loss: 0.0669\n",
            "Epoch 176/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1043 - val_loss: 0.0491\n",
            "Epoch 177/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1022 - val_loss: 0.0288\n",
            "Epoch 178/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1132 - val_loss: 0.0324\n",
            "Epoch 179/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1044 - val_loss: 0.0601\n",
            "Epoch 180/686\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1060 - val_loss: 0.0492\n",
            "Epoch 181/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1145 - val_loss: 0.0401\n",
            "Epoch 182/686\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.1159 - val_loss: 0.0950\n",
            "Epoch 183/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1074 - val_loss: 0.0486\n",
            "Epoch 184/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1038 - val_loss: 0.0573\n",
            "Epoch 185/686\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.1056 - val_loss: 0.0592\n",
            "Epoch 186/686\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.0891 - val_loss: 0.0632\n",
            "Epoch 187/686\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.0878 - val_loss: 0.0779\n",
            "Epoch 188/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1055 - val_loss: 0.0633\n",
            "Epoch 189/686\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1057 - val_loss: 0.0439\n",
            "Epoch 190/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.1117 - val_loss: 0.0755\n",
            "Epoch 191/686\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.1027 - val_loss: 0.0627\n",
            "Epoch 192/686\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.0988 - val_loss: 0.0565\n",
            "(129, 30, 1)\n",
            "(129, 30, 1)\n",
            "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.4737 - val_loss: 0.0668\n",
            "Epoch 2/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4263 - val_loss: 0.1211\n",
            "Epoch 3/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3887 - val_loss: 0.1609\n",
            "Epoch 4/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3585 - val_loss: 0.1763\n",
            "Epoch 5/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3336 - val_loss: 0.1708\n",
            "Epoch 6/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3087 - val_loss: 0.1614\n",
            "Epoch 7/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2849 - val_loss: 0.1530\n",
            "Epoch 8/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2698 - val_loss: 0.1237\n",
            "Epoch 9/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2598 - val_loss: 0.1031\n",
            "Epoch 10/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2464 - val_loss: 0.0906\n",
            "Epoch 11/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2317 - val_loss: 0.0739\n",
            "Epoch 12/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2212 - val_loss: 0.0671\n",
            "Epoch 13/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2080 - val_loss: 0.0520\n",
            "Epoch 14/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2016 - val_loss: 0.0533\n",
            "Epoch 15/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2061 - val_loss: 0.0316\n",
            "Epoch 16/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2494 - val_loss: 0.0381\n",
            "Epoch 17/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1862 - val_loss: 0.0402\n",
            "Epoch 18/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1851 - val_loss: 0.0389\n",
            "Epoch 19/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1696 - val_loss: 0.0320\n",
            "Epoch 20/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1662 - val_loss: 0.0482\n",
            "Epoch 21/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2133 - val_loss: 0.0106\n",
            "Epoch 22/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2163 - val_loss: 0.0297\n",
            "Epoch 23/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1634 - val_loss: 0.0485\n",
            "Epoch 24/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1554 - val_loss: 0.0447\n",
            "Epoch 25/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1427 - val_loss: 0.0327\n",
            "Epoch 26/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1499 - val_loss: 0.0448\n",
            "Epoch 27/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1769 - val_loss: 0.0171\n",
            "Epoch 28/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1735 - val_loss: 0.0371\n",
            "Epoch 29/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1655 - val_loss: 0.0308\n",
            "Epoch 30/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1483 - val_loss: 0.0429\n",
            "Epoch 31/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1512 - val_loss: 0.0295\n",
            "Epoch 32/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1421 - val_loss: 0.0460\n",
            "Epoch 33/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1518 - val_loss: 0.0296\n",
            "Epoch 34/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1484 - val_loss: 0.0479\n",
            "Epoch 35/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1607 - val_loss: 0.0347\n",
            "Epoch 36/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1586 - val_loss: 0.0476\n",
            "Epoch 37/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1381 - val_loss: 0.0390\n",
            "Epoch 38/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1282 - val_loss: 0.0443\n",
            "Epoch 39/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1426 - val_loss: 0.0304\n",
            "Epoch 40/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1456 - val_loss: 0.0530\n",
            "Epoch 41/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1437 - val_loss: 0.0347\n",
            "Epoch 42/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1460 - val_loss: 0.0462\n",
            "Epoch 43/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1368 - val_loss: 0.0375\n",
            "Epoch 44/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1337 - val_loss: 0.0525\n",
            "Epoch 45/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1296 - val_loss: 0.0347\n",
            "Epoch 46/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1300 - val_loss: 0.0528\n",
            "Epoch 47/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1414 - val_loss: 0.0328\n",
            "Epoch 48/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1396 - val_loss: 0.0494\n",
            "Epoch 49/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1346 - val_loss: 0.0399\n",
            "Epoch 50/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1278 - val_loss: 0.0498\n",
            "Epoch 51/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1353 - val_loss: 0.0351\n",
            "Epoch 52/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1303 - val_loss: 0.0504\n",
            "Epoch 53/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1304 - val_loss: 0.0394\n",
            "Epoch 54/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1222 - val_loss: 0.0543\n",
            "Epoch 55/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1314 - val_loss: 0.0329\n",
            "Epoch 56/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1312 - val_loss: 0.0440\n",
            "Epoch 57/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1358 - val_loss: 0.0340\n",
            "Epoch 58/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1180 - val_loss: 0.0470\n",
            "Epoch 59/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1226 - val_loss: 0.0359\n",
            "Epoch 60/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1222 - val_loss: 0.0537\n",
            "Epoch 61/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1283 - val_loss: 0.0353\n",
            "Epoch 62/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1217 - val_loss: 0.0464\n",
            "Epoch 63/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1327 - val_loss: 0.0328\n",
            "Epoch 64/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1204 - val_loss: 0.0503\n",
            "Epoch 65/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1254 - val_loss: 0.0341\n",
            "Epoch 66/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1179 - val_loss: 0.0465\n",
            "Epoch 67/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1246 - val_loss: 0.0328\n",
            "Epoch 68/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1194 - val_loss: 0.0494\n",
            "Epoch 69/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1289 - val_loss: 0.0347\n",
            "Epoch 70/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1265 - val_loss: 0.0469\n",
            "Epoch 71/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1183 - val_loss: 0.0393\n",
            "Epoch 72/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1113 - val_loss: 0.0494\n",
            "Epoch 73/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1213 - val_loss: 0.0374\n",
            "Epoch 74/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1103 - val_loss: 0.0537\n",
            "Epoch 75/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1186 - val_loss: 0.0335\n",
            "Epoch 76/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1057 - val_loss: 0.0493\n",
            "Epoch 77/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1156 - val_loss: 0.0307\n",
            "Epoch 78/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1275 - val_loss: 0.0554\n",
            "Epoch 79/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1174 - val_loss: 0.0388\n",
            "Epoch 80/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1184 - val_loss: 0.0560\n",
            "Epoch 81/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1177 - val_loss: 0.0360\n",
            "Epoch 82/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1091 - val_loss: 0.0459\n",
            "Epoch 83/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1120 - val_loss: 0.0403\n",
            "Epoch 84/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1074 - val_loss: 0.0595\n",
            "Epoch 85/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1153 - val_loss: 0.0299\n",
            "Epoch 86/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1125 - val_loss: 0.0645\n",
            "Epoch 87/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1202 - val_loss: 0.0312\n",
            "Epoch 88/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1196 - val_loss: 0.0567\n",
            "Epoch 89/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1104 - val_loss: 0.0440\n",
            "Epoch 90/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1037 - val_loss: 0.0531\n",
            "Epoch 91/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1164 - val_loss: 0.0440\n",
            "Epoch 92/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1044 - val_loss: 0.0621\n",
            "Epoch 93/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1036 - val_loss: 0.0397\n",
            "Epoch 94/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1052 - val_loss: 0.0627\n",
            "Epoch 95/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1125 - val_loss: 0.0310\n",
            "Epoch 96/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1096 - val_loss: 0.0624\n",
            "Epoch 97/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1110 - val_loss: 0.0355\n",
            "Epoch 98/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1025 - val_loss: 0.0595\n",
            "Epoch 99/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1082 - val_loss: 0.0354\n",
            "Epoch 100/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1061 - val_loss: 0.0629\n",
            "Epoch 101/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.0414\n",
            "Epoch 102/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0984 - val_loss: 0.0587\n",
            "Epoch 103/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1002 - val_loss: 0.0402\n",
            "Epoch 104/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1016 - val_loss: 0.0616\n",
            "Epoch 105/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1071 - val_loss: 0.0307\n",
            "Epoch 106/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1039 - val_loss: 0.0694\n",
            "Epoch 107/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1219 - val_loss: 0.0320\n",
            "Epoch 108/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1132 - val_loss: 0.0622\n",
            "Epoch 109/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0998 - val_loss: 0.0367\n",
            "Epoch 110/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0990 - val_loss: 0.0571\n",
            "Epoch 111/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0994 - val_loss: 0.0419\n",
            "Epoch 112/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0965 - val_loss: 0.0738\n",
            "Epoch 113/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0999 - val_loss: 0.0348\n",
            "Epoch 114/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0995 - val_loss: 0.0690\n",
            "Epoch 115/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0975 - val_loss: 0.0468\n",
            "Epoch 116/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0933 - val_loss: 0.0616\n",
            "Epoch 117/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1011 - val_loss: 0.0326\n",
            "Epoch 118/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0852 - val_loss: 0.0639\n",
            "Epoch 119/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0922 - val_loss: 0.0388\n",
            "Epoch 120/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0797 - val_loss: 0.0672\n",
            "Epoch 121/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0805 - val_loss: 0.0354\n",
            "Epoch 122/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0905 - val_loss: 0.0709\n",
            "Epoch 123/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1000 - val_loss: 0.0414\n",
            "Epoch 124/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0943 - val_loss: 0.0833\n",
            "Epoch 125/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0993 - val_loss: 0.0216\n",
            "Epoch 126/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0993 - val_loss: 0.0664\n",
            "Epoch 127/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1021 - val_loss: 0.0280\n",
            "Epoch 128/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0995 - val_loss: 0.0582\n",
            "Epoch 129/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1013 - val_loss: 0.0393\n",
            "Epoch 130/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0890 - val_loss: 0.0669\n",
            "Epoch 131/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0906 - val_loss: 0.0420\n",
            "Epoch 132/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0857 - val_loss: 0.0708\n",
            "Epoch 133/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0833 - val_loss: 0.0341\n",
            "Epoch 134/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0741 - val_loss: 0.0707\n",
            "Epoch 135/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0863 - val_loss: 0.0304\n",
            "Epoch 136/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0759 - val_loss: 0.0726\n",
            "Epoch 137/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0876 - val_loss: 0.0280\n",
            "Epoch 138/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0840 - val_loss: 0.0835\n",
            "Epoch 139/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1065 - val_loss: 0.0274\n",
            "Epoch 140/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1147 - val_loss: 0.0588\n",
            "Epoch 141/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0804 - val_loss: 0.0704\n",
            "Epoch 142/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0753 - val_loss: 0.0717\n",
            "Epoch 143/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0762 - val_loss: 0.0227\n",
            "Epoch 144/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0734 - val_loss: 0.0860\n",
            "Epoch 145/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1041 - val_loss: 0.0346\n",
            "Epoch 146/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1025 - val_loss: 0.0679\n",
            "Epoch 147/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0744 - val_loss: 0.0581\n",
            "Epoch 148/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0803 - val_loss: 0.0763\n",
            "Epoch 149/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0829 - val_loss: 0.0226\n",
            "Epoch 150/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0957 - val_loss: 0.0727\n",
            "Epoch 151/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0787 - val_loss: 0.0346\n",
            "Epoch 152/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0776 - val_loss: 0.0727\n",
            "Epoch 153/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0830 - val_loss: 0.0339\n",
            "Epoch 154/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0851 - val_loss: 0.0599\n",
            "Epoch 155/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0716 - val_loss: 0.0374\n",
            "Epoch 156/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0652 - val_loss: 0.0639\n",
            "Epoch 157/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0728 - val_loss: 0.0271\n",
            "Epoch 158/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0750 - val_loss: 0.0796\n",
            "Epoch 159/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0813 - val_loss: 0.0246\n",
            "Epoch 160/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0938 - val_loss: 0.0629\n",
            "Epoch 161/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0699 - val_loss: 0.0361\n",
            "Epoch 162/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0777 - val_loss: 0.0625\n",
            "Epoch 163/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0810 - val_loss: 0.0269\n",
            "Epoch 164/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0830 - val_loss: 0.0630\n",
            "Epoch 165/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0718 - val_loss: 0.0317\n",
            "Epoch 166/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0790 - val_loss: 0.0597\n",
            "Epoch 167/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0685 - val_loss: 0.0255\n",
            "Epoch 168/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0666 - val_loss: 0.0572\n",
            "Epoch 169/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0781 - val_loss: 0.0209\n",
            "Epoch 170/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0863 - val_loss: 0.0526\n",
            "Epoch 171/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0705 - val_loss: 0.0273\n",
            "Epoch 172/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0815 - val_loss: 0.0575\n",
            "Epoch 173/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0643 - val_loss: 0.0252\n",
            "Epoch 174/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0556 - val_loss: 0.0441\n",
            "Epoch 175/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0706 - val_loss: 0.0210\n",
            "Epoch 176/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0848 - val_loss: 0.0590\n",
            "Epoch 177/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0630 - val_loss: 0.0228\n",
            "Epoch 178/686\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0670 - val_loss: 0.0371\n",
            "Epoch 179/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0704 - val_loss: 0.0233\n",
            "Epoch 180/686\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0830 - val_loss: 0.0402\n",
            "Epoch 181/686\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0584 - val_loss: 0.0257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeCUvqJTBQeB"
      },
      "source": [
        "Predictions for both first and second week for Liberty hospitalization county"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCqbgI6_R7k4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9f80bf1e-832c-45c6-8b97-ca54c9d238bb"
      },
      "source": [
        "\n",
        "predictions_hosp_Liberty = predictionOnPredictionLSTM(initialvalue_Liberty_hosp,look_ahead,encoder_model_Liberty)\n",
        "predictions_hosp_Liberty = predictions_hosp_Liberty.reshape(len(predictions_hosp_Liberty))\n",
        "print(predictions_hosp_Liberty)\n",
        "print(test_deaths_hosp[1][window:])\n",
        "print(train_deaths_hosp[1][-20:])\n",
        "#print(train_deaths_hosp[0][150:])\n",
        "#conv model best 0.019 window = 3\n",
        "#print(mean_absolute_error(predictions_hosp_Liberty,test_deaths_hosp[1][window_2:]))\n",
        "#print(mean_squared_log_error(predictions_hosp_Liberty,test_deaths_hosp[1][window_2:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00070713 0.00133595 0.00234038 0.00352938 0.0047998  0.00600645\n",
            " 0.0071775 ]\n",
            "[0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuPqDULbSVdK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1e36716-28be-420c-a759-73e01f0f6314"
      },
      "source": [
        "encoder_model_Montgomery,encoder_history_Montgomery = build_encoder_decoder_h(np.array(X_train_hosp[2][30:]),np.array(X_test_hosp[2]),np.array(Y_train_hosp[2][30:]),np.array(Y_test_hosp[2]),window_2)\n",
        "conv_model_Montgomery,conv_history_Montgomery = build_conv_model_h(np.array(X_train_hosp[2][30:]),np.array(X_test_hosp[2]),np.array(Y_train_hosp[2][30:]),np.array(Y_test_hosp[2]),window_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(131, 5, 1)\n",
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 112.2556 - val_loss: 45.5113\n",
            "Epoch 2/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 80.2254 - val_loss: 4.1668\n",
            "Epoch 3/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 40.6427 - val_loss: 4.3827\n",
            "Epoch 4/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 36.3764 - val_loss: 3.3421\n",
            "Epoch 5/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 27.3717 - val_loss: 8.8929\n",
            "Epoch 6/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 24.8235 - val_loss: 9.1138\n",
            "Epoch 7/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 24.0210 - val_loss: 7.1093\n",
            "Epoch 8/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 23.7526 - val_loss: 10.6381\n",
            "Epoch 9/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 22.0608 - val_loss: 6.5235\n",
            "Epoch 10/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 21.8331 - val_loss: 6.6121\n",
            "Epoch 11/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.8124 - val_loss: 8.9264\n",
            "Epoch 12/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 19.5766 - val_loss: 11.0098\n",
            "Epoch 13/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 21.8348 - val_loss: 3.6280\n",
            "Epoch 14/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 21.0381 - val_loss: 0.8492\n",
            "Epoch 15/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 20.4141 - val_loss: 6.7187\n",
            "Epoch 16/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 22.6751 - val_loss: 6.9511\n",
            "Epoch 17/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 23.3071 - val_loss: 9.5120\n",
            "Epoch 18/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 19.7951 - val_loss: 11.2281\n",
            "Epoch 19/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 20.9148 - val_loss: 14.5110\n",
            "Epoch 20/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 18.8526 - val_loss: 5.9514\n",
            "Epoch 21/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 22.0193 - val_loss: 8.4484\n",
            "Epoch 22/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 21.3495 - val_loss: 11.0666\n",
            "Epoch 23/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 20.9590 - val_loss: 5.4529\n",
            "Epoch 24/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 22.2172 - val_loss: 10.1060\n",
            "Epoch 25/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 21.0975 - val_loss: 10.4048\n",
            "Epoch 26/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.9277 - val_loss: 7.2385\n",
            "Epoch 27/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.8478 - val_loss: 11.5472\n",
            "Epoch 28/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.5522 - val_loss: 12.4782\n",
            "Epoch 29/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.1098 - val_loss: 9.1487\n",
            "Epoch 30/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.7040 - val_loss: 8.8885\n",
            "Epoch 31/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 19.1756 - val_loss: 10.5083\n",
            "Epoch 32/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 21.8694 - val_loss: 7.6654\n",
            "Epoch 33/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 22.0853 - val_loss: 10.2841\n",
            "Epoch 34/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 23.6364 - val_loss: 16.1352\n",
            "Epoch 35/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 21.0930 - val_loss: 9.3053\n",
            "Epoch 36/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 20.0443 - val_loss: 9.1588\n",
            "Epoch 37/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 21.2087 - val_loss: 9.1894\n",
            "Epoch 38/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 17.9224 - val_loss: 9.6856\n",
            "Epoch 39/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 19.2408 - val_loss: 5.6338\n",
            "Epoch 40/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 23.7366 - val_loss: 12.6162\n",
            "Epoch 41/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 22.9543 - val_loss: 5.2317\n",
            "Epoch 42/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 24.8351 - val_loss: 6.9626\n",
            "Epoch 43/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.8511 - val_loss: 7.2239\n",
            "Epoch 44/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.6908 - val_loss: 11.3068\n",
            "Epoch 45/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.6075 - val_loss: 4.1637\n",
            "Epoch 46/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 22.2310 - val_loss: 7.7817\n",
            "Epoch 47/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 20.9336 - val_loss: 7.4281\n",
            "Epoch 48/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 19.3274 - val_loss: 11.5066\n",
            "Epoch 49/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 21.0045 - val_loss: 7.4344\n",
            "Epoch 50/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.0229 - val_loss: 3.2108\n",
            "Epoch 51/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.3000 - val_loss: 11.7673\n",
            "Epoch 52/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.5899 - val_loss: 6.8654\n",
            "Epoch 53/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.7954 - val_loss: 13.3935\n",
            "Epoch 54/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 16.2681 - val_loss: 4.3777\n",
            "Epoch 55/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 20.6744 - val_loss: 10.8492\n",
            "Epoch 56/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.2164 - val_loss: 2.8122\n",
            "Epoch 57/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 22.3280 - val_loss: 6.9862\n",
            "Epoch 58/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 19.3532 - val_loss: 1.0461\n",
            "Epoch 59/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 23.9171 - val_loss: 9.9256\n",
            "Epoch 60/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.5738 - val_loss: 0.2649\n",
            "Epoch 61/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 28.6245 - val_loss: 4.4135\n",
            "Epoch 62/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 22.1134 - val_loss: 15.6825\n",
            "Epoch 63/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 20.0442 - val_loss: 0.9915\n",
            "Epoch 64/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 24.4288 - val_loss: 5.5868\n",
            "Epoch 65/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 23.2607 - val_loss: 8.5924\n",
            "Epoch 66/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.3269 - val_loss: 2.2574\n",
            "Epoch 67/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.0105 - val_loss: 6.3456\n",
            "Epoch 68/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 19.5657 - val_loss: 9.3656\n",
            "Epoch 69/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.4912 - val_loss: 3.9602\n",
            "Epoch 70/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.3131 - val_loss: 7.1132\n",
            "Epoch 71/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 16.5922 - val_loss: 10.8135\n",
            "Epoch 72/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 20.9530 - val_loss: 0.1878\n",
            "Epoch 73/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 22.9851 - val_loss: 5.6209\n",
            "Epoch 74/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 17.3738 - val_loss: 6.4953\n",
            "Epoch 75/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.5089 - val_loss: 3.8880\n",
            "Epoch 76/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.5392 - val_loss: 6.4246\n",
            "Epoch 77/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.9114 - val_loss: 8.0381\n",
            "Epoch 78/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.2940 - val_loss: 7.7428\n",
            "Epoch 79/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 18.4540 - val_loss: 7.2995\n",
            "Epoch 80/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 16.2978 - val_loss: 8.4712\n",
            "Epoch 81/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 20.3806 - val_loss: 6.1354\n",
            "Epoch 82/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 17.1960 - val_loss: 5.7826\n",
            "Epoch 83/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.4981 - val_loss: 6.6187\n",
            "Epoch 84/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 19.7178 - val_loss: 4.3735\n",
            "Epoch 85/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 18.6222 - val_loss: 6.4958\n",
            "Epoch 86/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.7649 - val_loss: 7.8467\n",
            "Epoch 87/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.1132 - val_loss: 7.1338\n",
            "Epoch 88/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.9665 - val_loss: 2.7652\n",
            "Epoch 89/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 20.9128 - val_loss: 15.0190\n",
            "Epoch 90/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 23.1523 - val_loss: 0.1495\n",
            "Epoch 91/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 31.3443 - val_loss: 1.2776\n",
            "Epoch 92/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.1583 - val_loss: 11.1945\n",
            "Epoch 93/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 16.8656 - val_loss: 4.9765\n",
            "Epoch 94/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.4926 - val_loss: 8.8545\n",
            "Epoch 95/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 22.4446 - val_loss: 6.6763\n",
            "Epoch 96/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.6432 - val_loss: 5.5225\n",
            "Epoch 97/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.6755 - val_loss: 4.8327\n",
            "Epoch 98/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.9925 - val_loss: 8.6989\n",
            "Epoch 99/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 19.4582 - val_loss: 4.2069\n",
            "Epoch 100/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.0305 - val_loss: 7.8736\n",
            "Epoch 101/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 20.8897 - val_loss: 9.0954\n",
            "Epoch 102/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 17.8265 - val_loss: 3.1112\n",
            "Epoch 103/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.3012 - val_loss: 3.2827\n",
            "Epoch 104/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.0416 - val_loss: 2.8194\n",
            "Epoch 105/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.8386 - val_loss: 10.6371\n",
            "Epoch 106/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 19.3341 - val_loss: 3.2074\n",
            "Epoch 107/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 23.0948 - val_loss: 5.0263\n",
            "Epoch 108/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.9998 - val_loss: 10.2354\n",
            "Epoch 109/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.8700 - val_loss: 5.4210\n",
            "Epoch 110/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.5292 - val_loss: 10.7329\n",
            "Epoch 111/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 19.1706 - val_loss: 10.3472\n",
            "Epoch 112/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.5660 - val_loss: 2.8685\n",
            "Epoch 113/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 22.0746 - val_loss: 6.3658\n",
            "Epoch 114/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 17.3742 - val_loss: 7.6005\n",
            "Epoch 115/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 17.5833 - val_loss: 8.3982\n",
            "Epoch 116/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.2499 - val_loss: 5.8392\n",
            "Epoch 117/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.1220 - val_loss: 3.3373\n",
            "Epoch 118/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 19.3133 - val_loss: 8.8487\n",
            "Epoch 119/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.9575 - val_loss: 7.2878\n",
            "Epoch 120/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.2692 - val_loss: 3.8072\n",
            "Epoch 121/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 17.1149 - val_loss: 3.0106\n",
            "Epoch 122/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.9363 - val_loss: 8.0133\n",
            "Epoch 123/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.4780 - val_loss: 3.2526\n",
            "Epoch 124/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 20.3215 - val_loss: 12.1321\n",
            "Epoch 125/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.6846 - val_loss: 2.7469\n",
            "Epoch 126/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 22.7273 - val_loss: 6.3405\n",
            "Epoch 127/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 19.5087 - val_loss: 10.0288\n",
            "Epoch 128/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.7761 - val_loss: 4.7509\n",
            "Epoch 129/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.2079 - val_loss: 4.4796\n",
            "Epoch 130/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.0592 - val_loss: 6.9778\n",
            "Epoch 131/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 19.0691 - val_loss: 3.5321\n",
            "Epoch 132/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 17.7971 - val_loss: 4.4372\n",
            "Epoch 133/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 19.3382 - val_loss: 6.6870\n",
            "Epoch 134/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.0073 - val_loss: 8.3796\n",
            "Epoch 135/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 20.6321 - val_loss: 4.9564\n",
            "Epoch 136/686\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 18.4147 - val_loss: 9.4814\n",
            "Epoch 137/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 19.8737 - val_loss: 5.5111\n",
            "Epoch 138/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 19.2029 - val_loss: 9.7444\n",
            "Epoch 139/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 22.9179 - val_loss: 3.7556\n",
            "Epoch 140/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 20.2761 - val_loss: 7.2752\n",
            "Epoch 141/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.8151 - val_loss: 10.9828\n",
            "Epoch 142/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 15.2818 - val_loss: 5.7954\n",
            "Epoch 143/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 16.5684 - val_loss: 7.9527\n",
            "Epoch 144/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.1813 - val_loss: 9.6503\n",
            "Epoch 145/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.2502 - val_loss: 6.9081\n",
            "Epoch 146/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 17.7325 - val_loss: 4.0309\n",
            "Epoch 147/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 17.1237 - val_loss: 8.8378\n",
            "Epoch 148/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.0678 - val_loss: 4.2255\n",
            "Epoch 149/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 18.2660 - val_loss: 7.4728\n",
            "Epoch 150/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 19.8158 - val_loss: 4.8132\n",
            "Epoch 151/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.8079 - val_loss: 3.1317\n",
            "Epoch 152/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.7646 - val_loss: 6.8843\n",
            "Epoch 153/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 16.9020 - val_loss: 6.3626\n",
            "Epoch 154/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 17.0703 - val_loss: 6.7509\n",
            "Epoch 155/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.2628 - val_loss: 6.6083\n",
            "Epoch 156/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 18.2064 - val_loss: 12.2842\n",
            "Epoch 157/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.1802 - val_loss: 4.7721\n",
            "Epoch 158/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.9052 - val_loss: 4.6800\n",
            "Epoch 159/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 16.8241 - val_loss: 6.7915\n",
            "Epoch 160/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.3806 - val_loss: 6.6859\n",
            "Epoch 161/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 17.7959 - val_loss: 9.2560\n",
            "Epoch 162/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 16.9539 - val_loss: 7.4559\n",
            "Epoch 163/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.0518 - val_loss: 2.4786\n",
            "Epoch 164/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.1416 - val_loss: 6.2011\n",
            "Epoch 165/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 17.8496 - val_loss: 7.4714\n",
            "Epoch 166/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.9124 - val_loss: 4.1014\n",
            "Epoch 167/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.4098 - val_loss: 8.8693\n",
            "Epoch 168/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 17.1040 - val_loss: 6.4022\n",
            "Epoch 169/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.0429 - val_loss: 4.9376\n",
            "Epoch 170/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.0719 - val_loss: 11.2759\n",
            "Epoch 171/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.2925 - val_loss: 2.8753\n",
            "Epoch 172/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 21.3520 - val_loss: 4.8994\n",
            "Epoch 173/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 20.3515 - val_loss: 7.8771\n",
            "Epoch 174/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.1720 - val_loss: 5.4493\n",
            "Epoch 175/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 16.8556 - val_loss: 10.7703\n",
            "Epoch 176/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.1010 - val_loss: 9.2433\n",
            "Epoch 177/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 19.0517 - val_loss: 4.7757\n",
            "Epoch 178/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.8060 - val_loss: 9.5704\n",
            "Epoch 179/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 14.3943 - val_loss: 8.8909\n",
            "Epoch 180/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.0127 - val_loss: 5.5887\n",
            "Epoch 181/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.2656 - val_loss: 6.5102\n",
            "Epoch 182/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 18.3415 - val_loss: 9.8052\n",
            "Epoch 183/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 16.9236 - val_loss: 7.5122\n",
            "Epoch 184/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.2942 - val_loss: 8.7152\n",
            "Epoch 185/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.7145 - val_loss: 8.3168\n",
            "Epoch 186/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 16.9915 - val_loss: 3.7483\n",
            "Epoch 187/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 15.7011 - val_loss: 2.9473\n",
            "Epoch 188/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.2973 - val_loss: 2.0963\n",
            "Epoch 189/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 15.9689 - val_loss: 8.0463\n",
            "Epoch 190/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.7881 - val_loss: 3.7855\n",
            "Epoch 191/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.7968 - val_loss: 5.9027\n",
            "Epoch 192/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.0702 - val_loss: 1.2786\n",
            "Epoch 193/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 18.6991 - val_loss: 5.6413\n",
            "Epoch 194/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 20.3935 - val_loss: 5.8701\n",
            "Epoch 195/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 20.1385 - val_loss: 9.9702\n",
            "Epoch 196/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 19.7115 - val_loss: 6.8372\n",
            "Epoch 197/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 19.8789 - val_loss: 8.0845\n",
            "Epoch 198/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.8357 - val_loss: 4.8547\n",
            "Epoch 199/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 18.0120 - val_loss: 5.5418\n",
            "Epoch 200/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.1052 - val_loss: 6.9771\n",
            "Epoch 201/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 18.9289 - val_loss: 7.9101\n",
            "Epoch 202/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.1146 - val_loss: 8.7032\n",
            "Epoch 203/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.6794 - val_loss: 4.7847\n",
            "Epoch 204/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.1229 - val_loss: 7.4391\n",
            "Epoch 205/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 16.2942 - val_loss: 10.5126\n",
            "Epoch 206/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.9118 - val_loss: 5.6819\n",
            "Epoch 207/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.4271 - val_loss: 7.1473\n",
            "Epoch 208/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.2068 - val_loss: 2.9941\n",
            "Epoch 209/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.2140 - val_loss: 4.3164\n",
            "Epoch 210/686\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 19.2058 - val_loss: 1.9998\n",
            "Epoch 211/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 19.6539 - val_loss: 6.7063\n",
            "Epoch 212/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 19.6236 - val_loss: 5.9232\n",
            "Epoch 213/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.9207 - val_loss: 4.1952\n",
            "Epoch 214/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 19.5499 - val_loss: 2.4220\n",
            "Epoch 215/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 18.8854 - val_loss: 2.4182\n",
            "Epoch 216/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 16.8750 - val_loss: 5.5014\n",
            "Epoch 217/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.2042 - val_loss: 4.9094\n",
            "Epoch 218/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.4919 - val_loss: 4.3195\n",
            "Epoch 219/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 15.6395 - val_loss: 6.1713\n",
            "Epoch 220/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.1323 - val_loss: 6.0814\n",
            "Epoch 221/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.7607 - val_loss: 4.7573\n",
            "Epoch 222/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.5870 - val_loss: 7.1917\n",
            "Epoch 223/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.3452 - val_loss: 3.8072\n",
            "Epoch 224/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 15.8160 - val_loss: 3.5670\n",
            "Epoch 225/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 18.0144 - val_loss: 6.4305\n",
            "Epoch 226/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.3764 - val_loss: 7.2503\n",
            "Epoch 227/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.0245 - val_loss: 1.1921\n",
            "Epoch 228/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 17.8301 - val_loss: 10.8964\n",
            "Epoch 229/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.6626 - val_loss: 3.2817\n",
            "Epoch 230/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 17.6922 - val_loss: 7.2609\n",
            "Epoch 231/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 17.5675 - val_loss: 5.8116\n",
            "Epoch 232/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 15.1442 - val_loss: 3.6820\n",
            "Epoch 233/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 16.3832 - val_loss: 7.4909\n",
            "Epoch 234/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 16.3714 - val_loss: 4.0590\n",
            "Epoch 235/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 16.4830 - val_loss: 8.2804\n",
            "Epoch 236/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 21.2583 - val_loss: 7.1885\n",
            "Epoch 237/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 18.9198 - val_loss: 5.5858\n",
            "Epoch 238/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 15.1797 - val_loss: 0.7647\n",
            "Epoch 239/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 19.6019 - val_loss: 5.6150\n",
            "Epoch 240/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 17.5486 - val_loss: 5.7003\n",
            "Epoch 241/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 15.3875 - val_loss: 5.6787\n",
            "Epoch 242/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 15.6145 - val_loss: 4.8244\n",
            "Epoch 243/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 15.2311 - val_loss: 2.0755\n",
            "Epoch 244/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.4314 - val_loss: 4.6231\n",
            "Epoch 245/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 16.1775 - val_loss: 6.8007\n",
            "Epoch 246/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.1611 - val_loss: 3.2984\n",
            "Epoch 247/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.2484 - val_loss: 5.2267\n",
            "Epoch 248/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 17.3727 - val_loss: 3.0620\n",
            "Epoch 249/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 15.9298 - val_loss: 3.8971\n",
            "Epoch 250/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 12.9634 - val_loss: 2.2454\n",
            "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 107.7640 - val_loss: 43.3397\n",
            "Epoch 2/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 92.0252 - val_loss: 31.4736\n",
            "Epoch 3/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.5269 - val_loss: 12.5235\n",
            "Epoch 4/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 26.0138 - val_loss: 17.2037\n",
            "Epoch 5/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26.4058 - val_loss: 21.4789\n",
            "Epoch 6/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.3325 - val_loss: 8.2446\n",
            "Epoch 7/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.9966 - val_loss: 7.7396\n",
            "Epoch 8/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.6108 - val_loss: 15.3340\n",
            "Epoch 9/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.5156 - val_loss: 12.2709\n",
            "Epoch 10/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.8927 - val_loss: 10.5358\n",
            "Epoch 11/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.9409 - val_loss: 13.7169\n",
            "Epoch 12/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.3252 - val_loss: 13.3884\n",
            "Epoch 13/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.2659 - val_loss: 12.8998\n",
            "Epoch 14/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.3242 - val_loss: 13.7266\n",
            "Epoch 15/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.0005 - val_loss: 12.6199\n",
            "Epoch 16/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.3616 - val_loss: 13.0574\n",
            "Epoch 17/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.1132 - val_loss: 13.1553\n",
            "Epoch 18/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.2116 - val_loss: 13.5138\n",
            "Epoch 19/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.0036 - val_loss: 12.9868\n",
            "Epoch 20/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.2156 - val_loss: 13.4148\n",
            "Epoch 21/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.0158 - val_loss: 13.2371\n",
            "Epoch 22/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.0398 - val_loss: 13.1667\n",
            "Epoch 23/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.9774 - val_loss: 13.1000\n",
            "Epoch 24/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.0209 - val_loss: 13.3190\n",
            "Epoch 25/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8575 - val_loss: 12.8202\n",
            "Epoch 26/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.1653 - val_loss: 13.4139\n",
            "Epoch 27/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.0568 - val_loss: 13.6257\n",
            "Epoch 28/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.9656 - val_loss: 13.5825\n",
            "Epoch 29/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8171 - val_loss: 13.3428\n",
            "Epoch 30/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9249 - val_loss: 13.8560\n",
            "Epoch 31/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7468 - val_loss: 13.2770\n",
            "Epoch 32/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9641 - val_loss: 14.0009\n",
            "Epoch 33/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.6569 - val_loss: 13.6313\n",
            "Epoch 34/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.0759 - val_loss: 15.7107\n",
            "Epoch 35/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2069 - val_loss: 11.6795\n",
            "Epoch 36/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.4767 - val_loss: 12.7029\n",
            "Epoch 37/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8118 - val_loss: 13.1969\n",
            "Epoch 38/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7982 - val_loss: 13.5273\n",
            "Epoch 39/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.6261 - val_loss: 12.6703\n",
            "Epoch 40/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.0223 - val_loss: 13.8044\n",
            "Epoch 41/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.7918 - val_loss: 13.5310\n",
            "Epoch 42/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.6674 - val_loss: 13.1581\n",
            "Epoch 43/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.5217 - val_loss: 12.6349\n",
            "Epoch 44/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7752 - val_loss: 13.1986\n",
            "Epoch 45/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.5062 - val_loss: 12.4990\n",
            "Epoch 46/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8513 - val_loss: 13.2650\n",
            "Epoch 47/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.5547 - val_loss: 12.7324\n",
            "Epoch 48/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.7737 - val_loss: 13.1390\n",
            "Epoch 49/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4965 - val_loss: 12.4781\n",
            "Epoch 50/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.6891 - val_loss: 13.1012\n",
            "Epoch 51/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4456 - val_loss: 12.5857\n",
            "Epoch 52/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.7178 - val_loss: 13.3765\n",
            "Epoch 53/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.4970 - val_loss: 12.8180\n",
            "Epoch 54/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.6472 - val_loss: 13.4473\n",
            "Epoch 55/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4119 - val_loss: 12.7924\n",
            "Epoch 56/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.5197 - val_loss: 12.8709\n",
            "Epoch 57/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.3763 - val_loss: 12.6790\n",
            "Epoch 58/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.3565 - val_loss: 12.2639\n",
            "Epoch 59/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4817 - val_loss: 12.8221\n",
            "Epoch 60/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.2929 - val_loss: 12.3616\n",
            "Epoch 61/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4103 - val_loss: 12.5077\n",
            "Epoch 62/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2565 - val_loss: 12.2428\n",
            "Epoch 63/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.3239 - val_loss: 12.1867\n",
            "Epoch 64/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.3092 - val_loss: 12.3453\n",
            "Epoch 65/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1641 - val_loss: 11.7442\n",
            "Epoch 66/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.5142 - val_loss: 13.1321\n",
            "Epoch 67/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1587 - val_loss: 12.3486\n",
            "Epoch 68/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.4506 - val_loss: 13.0213\n",
            "Epoch 69/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.1621 - val_loss: 12.5160\n",
            "Epoch 70/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.3712 - val_loss: 13.3379\n",
            "Epoch 71/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.9889 - val_loss: 12.5330\n",
            "Epoch 72/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.4136 - val_loss: 14.4154\n",
            "Epoch 73/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0286 - val_loss: 14.0629\n",
            "Epoch 74/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7524 - val_loss: 12.1663\n",
            "Epoch 75/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4782 - val_loss: 14.9907\n",
            "Epoch 76/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6934 - val_loss: 12.0875\n",
            "Epoch 77/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.6024 - val_loss: 12.8539\n",
            "Epoch 78/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1677 - val_loss: 12.9806\n",
            "Epoch 79/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8801 - val_loss: 11.6733\n",
            "Epoch 80/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.3418 - val_loss: 12.7881\n",
            "Epoch 81/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0547 - val_loss: 12.2038\n",
            "Epoch 82/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.1171 - val_loss: 12.4254\n",
            "Epoch 83/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.0416 - val_loss: 13.6097\n",
            "Epoch 84/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7416 - val_loss: 13.8806\n",
            "Epoch 85/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8283 - val_loss: 12.8495\n",
            "Epoch 86/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9015 - val_loss: 12.8311\n",
            "Epoch 87/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8832 - val_loss: 12.6602\n",
            "Epoch 88/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8682 - val_loss: 12.9439\n",
            "Epoch 89/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6836 - val_loss: 12.5018\n",
            "Epoch 90/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0331 - val_loss: 16.6087\n",
            "Epoch 91/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.9751 - val_loss: 10.7304\n",
            "Epoch 92/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.0527 - val_loss: 13.7847\n",
            "Epoch 93/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.4821 - val_loss: 13.6746\n",
            "Epoch 94/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.8516 - val_loss: 10.8594\n",
            "Epoch 95/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.4033 - val_loss: 12.2518\n",
            "Epoch 96/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0933 - val_loss: 11.3828\n",
            "Epoch 97/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1617 - val_loss: 11.2831\n",
            "Epoch 98/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.0067 - val_loss: 11.3861\n",
            "Epoch 99/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1506 - val_loss: 12.1500\n",
            "Epoch 100/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.9485 - val_loss: 11.9833\n",
            "Epoch 101/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8609 - val_loss: 11.3880\n",
            "Epoch 102/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.0136 - val_loss: 11.2193\n",
            "Epoch 103/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8615 - val_loss: 10.8970\n",
            "Epoch 104/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9309 - val_loss: 11.0935\n",
            "Epoch 105/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8069 - val_loss: 11.1233\n",
            "Epoch 106/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.1641 - val_loss: 12.4704\n",
            "Epoch 107/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9806 - val_loss: 12.3229\n",
            "Epoch 108/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7860 - val_loss: 11.1392\n",
            "Epoch 109/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.0145 - val_loss: 11.9243\n",
            "Epoch 110/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7236 - val_loss: 11.3256\n",
            "Epoch 111/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.2550 - val_loss: 13.1042\n",
            "Epoch 112/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1486 - val_loss: 13.0236\n",
            "Epoch 113/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6682 - val_loss: 10.6761\n",
            "Epoch 114/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.1200 - val_loss: 12.3261\n",
            "Epoch 115/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.8881 - val_loss: 12.1510\n",
            "Epoch 116/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7305 - val_loss: 11.6407\n",
            "Epoch 117/686\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 12.7188 - val_loss: 11.7784\n",
            "Epoch 118/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7950 - val_loss: 12.2141\n",
            "Epoch 119/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7496 - val_loss: 11.8798\n",
            "Epoch 120/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6090 - val_loss: 11.1449\n",
            "Epoch 121/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9126 - val_loss: 12.2701\n",
            "Epoch 122/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7016 - val_loss: 11.7852\n",
            "Epoch 123/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6643 - val_loss: 11.5163\n",
            "Epoch 124/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8783 - val_loss: 12.6631\n",
            "Epoch 125/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.8938 - val_loss: 12.3963\n",
            "Epoch 126/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6708 - val_loss: 11.3529\n",
            "Epoch 127/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7091 - val_loss: 11.6524\n",
            "Epoch 128/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6121 - val_loss: 11.5544\n",
            "Epoch 129/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7785 - val_loss: 12.5838\n",
            "Epoch 130/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7024 - val_loss: 12.0035\n",
            "Epoch 131/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7374 - val_loss: 12.4150\n",
            "Epoch 132/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6191 - val_loss: 11.9916\n",
            "Epoch 133/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.7423 - val_loss: 12.0321\n",
            "Epoch 134/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7743 - val_loss: 10.8923\n",
            "Epoch 135/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.5519 - val_loss: 13.7087\n",
            "Epoch 136/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.2705 - val_loss: 14.1702\n",
            "Epoch 137/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.3721 - val_loss: 10.8404\n",
            "Epoch 138/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0943 - val_loss: 13.9573\n",
            "Epoch 139/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8406 - val_loss: 12.3787\n",
            "Epoch 140/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7985 - val_loss: 12.5774\n",
            "Epoch 141/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7713 - val_loss: 13.0570\n",
            "Epoch 142/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.4756 - val_loss: 10.8520\n",
            "Epoch 143/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6991 - val_loss: 12.0469\n",
            "Epoch 144/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.5593 - val_loss: 11.9699\n",
            "Epoch 145/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.6102 - val_loss: 12.2494\n",
            "Epoch 146/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.5506 - val_loss: 11.6938\n",
            "Epoch 147/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6413 - val_loss: 11.7590\n",
            "Epoch 148/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.5799 - val_loss: 11.7057\n",
            "Epoch 149/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6069 - val_loss: 12.2331\n",
            "Epoch 150/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.4286 - val_loss: 11.5242\n",
            "Epoch 151/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7490 - val_loss: 12.3352\n",
            "Epoch 152/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.6825 - val_loss: 12.5184\n",
            "Epoch 153/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3319 - val_loss: 10.8129\n",
            "Epoch 154/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7768 - val_loss: 12.9194\n",
            "Epoch 155/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.5181 - val_loss: 11.4759\n",
            "Epoch 156/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.5041 - val_loss: 10.9637\n",
            "Epoch 157/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.4861 - val_loss: 11.2913\n",
            "Epoch 158/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.5608 - val_loss: 12.4071\n",
            "Epoch 159/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7924 - val_loss: 12.3601\n",
            "Epoch 160/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.4215 - val_loss: 11.1821\n",
            "Epoch 161/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.4912 - val_loss: 11.5442\n",
            "Epoch 162/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.3466 - val_loss: 11.1872\n",
            "Epoch 163/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.5101 - val_loss: 11.8502\n",
            "Epoch 164/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.5807 - val_loss: 11.9795\n",
            "Epoch 165/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.2697 - val_loss: 10.5408\n",
            "Epoch 166/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.5657 - val_loss: 12.5490\n",
            "Epoch 167/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.4162 - val_loss: 11.4330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mt1dZc_U-LW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4613e1fa-a725-44f3-ff8b-0b72a0b12ef8"
      },
      "source": [
        "\n",
        "predictions_hosp_Montgomery = predictionOnPredictionLSTM(initialvalue_Montgomery_hosp,look_ahead,conv_model_Montgomery)\n",
        "predictions_hosp_Montgomery = predictions_hosp_Montgomery.reshape(len(predictions_hosp_Montgomery))\n",
        "print(\"Predictions for second week is\",predictions_hosp_Montgomery)\n",
        "#print(test_deaths_hosp[2][window:])\n",
        "#print(mean_absolute_error(predictions_hosp_Montgomery,test_deaths_hosp[2][window_2:]))\n",
        "#print(mean_squared_log_error(predictions_hosp_Montgomery,test_deaths_hosp[2][window_2:]))\n",
        "#[66.97783 68.46707 67.36516 66.63943 64.96595 66.45057 62.30796]1st week\n",
        "#[59.950928 55.185307 52.84615  50.147797 50.81942  50.982178 49.417046] 2nd week\n",
        "#[59.92499  54.64683  53.495754 49.320377 49.55309  45.013844 43.299374]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions for second week is [61.739635 60.86918  60.03604  57.474285 53.708492 52.73098  50.78721 ]\n",
            "[61 77 61 54]\n",
            "[108  96  92  84  74  84  83  62  65  68  68  82  67  77  63  64  61  77\n",
            "  61  54]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjwEBjHLVhXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "884d30b1-a518-41d9-c0c7-b9c2521a1db1"
      },
      "source": [
        "encoder_model_Brazoria,encoder_history_Brazoria = build_encoder_decoder_h(np.array(X_train_hosp[3][30:]),np.array(X_test_hosp[3]),np.array(Y_train_hosp[3][30:]),np.array(Y_test_hosp[3]),window_2)\n",
        "conv_model_Brazoria,conv_history_Brazoria = build_conv_model_h(np.array(X_train_hosp[3][30:]),np.array(X_test_hosp[3]),np.array(Y_train_hosp[3][30:]),np.array(Y_test_hosp[3]),window_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(131, 5, 1)\n",
            "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 42.2378 - val_loss: 24.6246\n",
            "Epoch 2/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 23.1174 - val_loss: 8.6619\n",
            "Epoch 3/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 29.8052 - val_loss: 0.9414\n",
            "Epoch 4/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 16.2252 - val_loss: 6.8244\n",
            "Epoch 5/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 13.0362 - val_loss: 2.9533\n",
            "Epoch 6/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 14.0778 - val_loss: 1.8643\n",
            "Epoch 7/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 11.2014 - val_loss: 0.2853\n",
            "Epoch 8/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 11.5836 - val_loss: 4.2244\n",
            "Epoch 9/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 11.9115 - val_loss: 0.5136\n",
            "Epoch 10/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 11.6318 - val_loss: 2.2861\n",
            "Epoch 11/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 11.2817 - val_loss: 0.9902\n",
            "Epoch 12/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 10.9859 - val_loss: 5.8479\n",
            "Epoch 13/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 10.1752 - val_loss: 2.3899\n",
            "Epoch 14/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 9.9796 - val_loss: 7.4995\n",
            "Epoch 15/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.0662 - val_loss: 5.0422\n",
            "Epoch 16/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 9.4520 - val_loss: 10.2706\n",
            "Epoch 17/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 10.7165 - val_loss: 0.1322\n",
            "Epoch 18/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 11.1869 - val_loss: 4.5781\n",
            "Epoch 19/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 10.0143 - val_loss: 7.1958\n",
            "Epoch 20/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.1876 - val_loss: 3.1478\n",
            "Epoch 21/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.5356 - val_loss: 7.1583\n",
            "Epoch 22/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.6116 - val_loss: 4.9803\n",
            "Epoch 23/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 9.5291 - val_loss: 5.1615\n",
            "Epoch 24/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.5912 - val_loss: 3.6837\n",
            "Epoch 25/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.5508 - val_loss: 6.3446\n",
            "Epoch 26/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.1168 - val_loss: 2.0244\n",
            "Epoch 27/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 10.9893 - val_loss: 5.7247\n",
            "Epoch 28/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.9447 - val_loss: 4.4963\n",
            "Epoch 29/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 9.7794 - val_loss: 4.0586\n",
            "Epoch 30/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.6261 - val_loss: 9.6681\n",
            "Epoch 31/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.7315 - val_loss: 2.5795\n",
            "Epoch 32/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 10.6108 - val_loss: 5.5988\n",
            "Epoch 33/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.9852 - val_loss: 4.3550\n",
            "Epoch 34/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.3433 - val_loss: 6.2430\n",
            "Epoch 35/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 8.7372 - val_loss: 7.7661\n",
            "Epoch 36/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.4972 - val_loss: 4.2610\n",
            "Epoch 37/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 9.0385 - val_loss: 9.0695\n",
            "Epoch 38/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.2718 - val_loss: 4.7619\n",
            "Epoch 39/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.3298 - val_loss: 5.6993\n",
            "Epoch 40/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.9860 - val_loss: 6.9802\n",
            "Epoch 41/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.4290 - val_loss: 1.1448\n",
            "Epoch 42/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 9.3702 - val_loss: 8.2735\n",
            "Epoch 43/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 10.0988 - val_loss: 2.7404\n",
            "Epoch 44/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 9.0255 - val_loss: 6.9503\n",
            "Epoch 45/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 10.1906 - val_loss: 3.7857\n",
            "Epoch 46/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.7598 - val_loss: 4.5903\n",
            "Epoch 47/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.9872 - val_loss: 3.5365\n",
            "Epoch 48/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 9.7300 - val_loss: 2.2068\n",
            "Epoch 49/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.7801 - val_loss: 6.2082\n",
            "Epoch 50/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.1533 - val_loss: 1.1231\n",
            "Epoch 51/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 10.3611 - val_loss: 4.8942\n",
            "Epoch 52/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.8233 - val_loss: 4.3141\n",
            "Epoch 53/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.5777 - val_loss: 3.4498\n",
            "Epoch 54/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.4065 - val_loss: 4.4479\n",
            "Epoch 55/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.5981 - val_loss: 6.3132\n",
            "Epoch 56/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.9977 - val_loss: 4.3476\n",
            "Epoch 57/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 8.3228 - val_loss: 6.9822\n",
            "Epoch 58/686\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 9.1411 - val_loss: 1.0584\n",
            "Epoch 59/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.3950 - val_loss: 5.7503\n",
            "Epoch 60/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 9.1496 - val_loss: 2.2440\n",
            "Epoch 61/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.3424 - val_loss: 7.7753\n",
            "Epoch 62/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 9.1536 - val_loss: 0.3417\n",
            "Epoch 63/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 10.1573 - val_loss: 1.5278\n",
            "Epoch 64/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.2685 - val_loss: 4.8752\n",
            "Epoch 65/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 9.2464 - val_loss: 2.3095\n",
            "Epoch 66/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.3089 - val_loss: 5.4118\n",
            "Epoch 67/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.3968 - val_loss: 1.7899\n",
            "Epoch 68/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.5695 - val_loss: 5.5381\n",
            "Epoch 69/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.0772 - val_loss: 5.0420\n",
            "Epoch 70/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.2934 - val_loss: 3.5114\n",
            "Epoch 71/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.4146 - val_loss: 6.9640\n",
            "Epoch 72/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.7294 - val_loss: 3.2107\n",
            "Epoch 73/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.3850 - val_loss: 3.4671\n",
            "Epoch 74/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.5543 - val_loss: 2.0838\n",
            "Epoch 75/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.5606 - val_loss: 3.9622\n",
            "Epoch 76/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.5655 - val_loss: 3.6928\n",
            "Epoch 77/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.5573 - val_loss: 3.4976\n",
            "Epoch 78/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.7556 - val_loss: 6.8372\n",
            "Epoch 79/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 9.0647 - val_loss: 0.2144\n",
            "Epoch 80/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 9.7434 - val_loss: 3.6453\n",
            "Epoch 81/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 9.5799 - val_loss: 4.4943\n",
            "Epoch 82/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.8661 - val_loss: 4.6938\n",
            "Epoch 83/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.5319 - val_loss: 0.6916\n",
            "Epoch 84/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 9.2299 - val_loss: 5.3419\n",
            "Epoch 85/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.4588 - val_loss: 2.2908\n",
            "Epoch 86/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.0202 - val_loss: 4.4418\n",
            "Epoch 87/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.6196 - val_loss: 4.3920\n",
            "Epoch 88/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.2303 - val_loss: 6.0418\n",
            "Epoch 89/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.8995 - val_loss: 5.9632\n",
            "Epoch 90/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 8.6756 - val_loss: 5.1474\n",
            "Epoch 91/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.8532 - val_loss: 3.2680\n",
            "Epoch 92/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.5844 - val_loss: 5.3630\n",
            "Epoch 93/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.4890 - val_loss: 2.2886\n",
            "Epoch 94/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.2902 - val_loss: 4.9340\n",
            "Epoch 95/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.8433 - val_loss: 4.6177\n",
            "Epoch 96/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.6088 - val_loss: 2.4666\n",
            "Epoch 97/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.6967 - val_loss: 3.0177\n",
            "Epoch 98/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.9481 - val_loss: 1.6093\n",
            "Epoch 99/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.6315 - val_loss: 1.1416\n",
            "Epoch 100/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.5648 - val_loss: 4.9301\n",
            "Epoch 101/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 9.4671 - val_loss: 2.1338\n",
            "Epoch 102/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.1682 - val_loss: 4.8317\n",
            "Epoch 103/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 8.4902 - val_loss: 1.0612\n",
            "Epoch 104/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.0337 - val_loss: 3.4178\n",
            "Epoch 105/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.2607 - val_loss: 4.7809\n",
            "Epoch 106/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.0842 - val_loss: 1.9550\n",
            "Epoch 107/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.2230 - val_loss: 5.6883\n",
            "Epoch 108/686\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 8.6756 - val_loss: 0.2915\n",
            "Epoch 109/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 9.3002 - val_loss: 4.0736\n",
            "Epoch 110/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.7481 - val_loss: 0.8257\n",
            "Epoch 111/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 9.5129 - val_loss: 3.9926\n",
            "Epoch 112/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.0218 - val_loss: 1.2164\n",
            "Epoch 113/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.8206 - val_loss: 4.1405\n",
            "Epoch 114/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.5471 - val_loss: 5.2536\n",
            "Epoch 115/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.9546 - val_loss: 1.8165\n",
            "Epoch 116/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.3244 - val_loss: 3.1119\n",
            "Epoch 117/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.0206 - val_loss: 0.7805\n",
            "Epoch 118/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.3581 - val_loss: 2.4489\n",
            "Epoch 119/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.4429 - val_loss: 0.2070\n",
            "Epoch 120/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 9.3251 - val_loss: 2.3612\n",
            "Epoch 121/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 9.1562 - val_loss: 4.2449\n",
            "Epoch 122/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.8084 - val_loss: 3.9268\n",
            "Epoch 123/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 7.4688 - val_loss: 3.6895\n",
            "Epoch 124/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.2908 - val_loss: 2.1999\n",
            "Epoch 125/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.0705 - val_loss: 2.4852\n",
            "Epoch 126/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4701 - val_loss: 0.8377\n",
            "Epoch 127/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.3190 - val_loss: 1.9033\n",
            "Epoch 128/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.5786 - val_loss: 0.8865\n",
            "Epoch 129/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.8373 - val_loss: 1.3350\n",
            "Epoch 130/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.5762 - val_loss: 0.4309\n",
            "Epoch 131/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.8213 - val_loss: 1.7965\n",
            "Epoch 132/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.4599 - val_loss: 3.2926\n",
            "Epoch 133/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.2984 - val_loss: 0.8932\n",
            "Epoch 134/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.7111 - val_loss: 4.2025\n",
            "Epoch 135/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.3017 - val_loss: 2.3490\n",
            "Epoch 136/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.5837 - val_loss: 2.4277\n",
            "Epoch 137/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.2081 - val_loss: 1.9481\n",
            "Epoch 138/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.9012 - val_loss: 1.9673\n",
            "Epoch 139/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.9081 - val_loss: 4.5459\n",
            "Epoch 140/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.7539 - val_loss: 0.6273\n",
            "Epoch 141/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.1696 - val_loss: 3.0158\n",
            "Epoch 142/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.1403 - val_loss: 0.6578\n",
            "Epoch 143/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.8534 - val_loss: 4.5389\n",
            "Epoch 144/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.1276 - val_loss: 3.1098\n",
            "Epoch 145/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.8274 - val_loss: 0.2801\n",
            "Epoch 146/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.4774 - val_loss: 5.2875\n",
            "Epoch 147/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 9.1682 - val_loss: 3.2840\n",
            "Epoch 148/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 11.9480 - val_loss: 1.2622\n",
            "Epoch 149/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.8764 - val_loss: 5.4795\n",
            "Epoch 150/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.7013 - val_loss: 1.6108\n",
            "Epoch 151/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.8169 - val_loss: 3.5597\n",
            "Epoch 152/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.0243 - val_loss: 2.6508\n",
            "Epoch 153/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.6764 - val_loss: 2.0583\n",
            "Epoch 154/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4774 - val_loss: 0.2569\n",
            "Epoch 155/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.1516 - val_loss: 1.8091\n",
            "Epoch 156/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.1283 - val_loss: 0.7802\n",
            "Epoch 157/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.3819 - val_loss: 2.7091\n",
            "Epoch 158/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 7.6120 - val_loss: 1.6211\n",
            "Epoch 159/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.8379 - val_loss: 5.1149\n",
            "Epoch 160/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.1049 - val_loss: 0.5063\n",
            "Epoch 161/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.3054 - val_loss: 2.1808\n",
            "Epoch 162/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.6797 - val_loss: 0.5728\n",
            "Epoch 163/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.9296 - val_loss: 2.2633\n",
            "Epoch 164/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.3048 - val_loss: 0.6023\n",
            "Epoch 165/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.8333 - val_loss: 2.8128\n",
            "Epoch 166/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.7617 - val_loss: 3.0020\n",
            "Epoch 167/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.0313 - val_loss: 3.0200\n",
            "Epoch 168/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.4467 - val_loss: 1.2053\n",
            "Epoch 169/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.6513 - val_loss: 3.2490\n",
            "Epoch 170/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.0362 - val_loss: 2.4496\n",
            "Epoch 171/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.2304 - val_loss: 2.3097\n",
            "Epoch 172/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.9161 - val_loss: 0.1119\n",
            "Epoch 173/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.9523 - val_loss: 2.6885\n",
            "Epoch 174/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.1023 - val_loss: 1.0895\n",
            "Epoch 175/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.2928 - val_loss: 0.9558\n",
            "Epoch 176/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.5801 - val_loss: 2.5289\n",
            "Epoch 177/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.5402 - val_loss: 1.9585\n",
            "Epoch 178/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 7.4565 - val_loss: 0.5658\n",
            "Epoch 179/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.1954 - val_loss: 2.7348\n",
            "Epoch 180/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.3694 - val_loss: 0.3538\n",
            "Epoch 181/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.2489 - val_loss: 2.8015\n",
            "Epoch 182/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 9.0666 - val_loss: 2.2914\n",
            "Epoch 183/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.1074 - val_loss: 3.1058\n",
            "Epoch 184/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.9670 - val_loss: 0.6267\n",
            "Epoch 185/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 9.0990 - val_loss: 2.2253\n",
            "Epoch 186/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.5260 - val_loss: 0.0249\n",
            "Epoch 187/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.0149 - val_loss: 1.4538\n",
            "Epoch 188/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.5544 - val_loss: 2.4262\n",
            "Epoch 189/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.8450 - val_loss: 2.2686\n",
            "Epoch 190/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.1605 - val_loss: 4.3456\n",
            "Epoch 191/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7.9618 - val_loss: 1.8496\n",
            "Epoch 192/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.2412 - val_loss: 0.4109\n",
            "Epoch 193/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.2933 - val_loss: 1.6874\n",
            "Epoch 194/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.9073 - val_loss: 0.5956\n",
            "Epoch 195/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.6881 - val_loss: 3.4918\n",
            "Epoch 196/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.7758 - val_loss: 1.7837\n",
            "Epoch 197/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.8029 - val_loss: 2.9263\n",
            "Epoch 198/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.9030 - val_loss: 0.4756\n",
            "Epoch 199/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4888 - val_loss: 1.1703\n",
            "Epoch 200/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.4392 - val_loss: 1.8380\n",
            "Epoch 201/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.5810 - val_loss: 2.5460\n",
            "Epoch 202/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.9945 - val_loss: 0.1523\n",
            "Epoch 203/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.8917 - val_loss: 1.9354\n",
            "Epoch 204/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.8001 - val_loss: 0.7998\n",
            "Epoch 205/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.2460 - val_loss: 2.6253\n",
            "Epoch 206/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.3959 - val_loss: 1.2509\n",
            "Epoch 207/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.7095 - val_loss: 1.5281\n",
            "Epoch 208/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.7345 - val_loss: 0.0636\n",
            "Epoch 209/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 7.5482 - val_loss: 1.3083\n",
            "Epoch 210/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.4683 - val_loss: 0.2250\n",
            "Epoch 211/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.3421 - val_loss: 1.9253\n",
            "Epoch 212/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.8388 - val_loss: 1.3354\n",
            "Epoch 213/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.3378 - val_loss: 0.7452\n",
            "Epoch 214/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.3872 - val_loss: 1.6958\n",
            "Epoch 215/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.9956 - val_loss: 1.1371\n",
            "Epoch 216/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.6495 - val_loss: 1.1340\n",
            "Epoch 217/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.3586 - val_loss: 2.0355\n",
            "Epoch 218/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.4463 - val_loss: 0.7005\n",
            "Epoch 219/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.4680 - val_loss: 0.9625\n",
            "Epoch 220/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 7.4715 - val_loss: 1.2682\n",
            "Epoch 221/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.4371 - val_loss: 2.0844\n",
            "Epoch 222/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.5737 - val_loss: 0.5931\n",
            "Epoch 223/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 8.3288 - val_loss: 1.4516\n",
            "Epoch 224/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.3975 - val_loss: 1.5785\n",
            "Epoch 225/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.4788 - val_loss: 1.6855\n",
            "Epoch 226/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.1578 - val_loss: 1.8523\n",
            "Epoch 227/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.8064 - val_loss: 0.4195\n",
            "Epoch 228/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.3805 - val_loss: 1.4078\n",
            "Epoch 229/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.9485 - val_loss: 2.7364\n",
            "Epoch 230/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.2404 - val_loss: 2.6721\n",
            "Epoch 231/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.7802 - val_loss: 4.8594\n",
            "Epoch 232/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.6674 - val_loss: 1.4371\n",
            "Epoch 233/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.1226 - val_loss: 1.1833\n",
            "Epoch 234/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.3833 - val_loss: 0.9155\n",
            "Epoch 235/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.3301 - val_loss: 1.3637\n",
            "Epoch 236/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.6542 - val_loss: 3.9971\n",
            "Epoch 237/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.8113 - val_loss: 2.2003\n",
            "Epoch 238/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.1668 - val_loss: 4.2552\n",
            "Epoch 239/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.2665 - val_loss: 0.2456\n",
            "Epoch 240/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.3379 - val_loss: 2.1600\n",
            "Epoch 241/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.0203 - val_loss: 1.9578\n",
            "Epoch 242/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.5746 - val_loss: 2.5009\n",
            "Epoch 243/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.5633 - val_loss: 0.6995\n",
            "Epoch 244/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.8206 - val_loss: 0.0453\n",
            "Epoch 245/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4144 - val_loss: 0.0357\n",
            "Epoch 246/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.2235 - val_loss: 2.0243\n",
            "Epoch 247/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.5086 - val_loss: 0.8020\n",
            "Epoch 248/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 7.8511 - val_loss: 0.3126\n",
            "Epoch 249/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.0716 - val_loss: 0.5541\n",
            "Epoch 250/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.9732 - val_loss: 0.0050\n",
            "Epoch 251/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.3809 - val_loss: 0.5347\n",
            "Epoch 252/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7.8339 - val_loss: 0.0917\n",
            "Epoch 253/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.5561 - val_loss: 1.3721\n",
            "Epoch 254/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.5379 - val_loss: 2.3415\n",
            "Epoch 255/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 6.8791 - val_loss: 0.9673\n",
            "Epoch 256/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.2177 - val_loss: 2.9540\n",
            "Epoch 257/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6.8879 - val_loss: 0.6362\n",
            "Epoch 258/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.3796 - val_loss: 2.9923\n",
            "Epoch 259/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.7212 - val_loss: 0.1944\n",
            "Epoch 260/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.7044 - val_loss: 1.2049\n",
            "Epoch 261/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.5732 - val_loss: 2.6015\n",
            "Epoch 262/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.0134 - val_loss: 3.8473\n",
            "Epoch 263/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.7216 - val_loss: 1.0611\n",
            "Epoch 264/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.7451 - val_loss: 1.8675\n",
            "Epoch 265/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6.8083 - val_loss: 1.3239\n",
            "Epoch 266/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 9.7863 - val_loss: 0.4690\n",
            "Epoch 267/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7.2834 - val_loss: 1.5828\n",
            "Epoch 268/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.6527 - val_loss: 2.2258\n",
            "Epoch 269/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.7723 - val_loss: 1.3852\n",
            "Epoch 270/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.1384 - val_loss: 1.5249\n",
            "Epoch 271/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.1191 - val_loss: 3.9345\n",
            "Epoch 272/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.9230 - val_loss: 1.9827\n",
            "Epoch 273/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.5725 - val_loss: 0.0459\n",
            "Epoch 274/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.4991 - val_loss: 0.9062\n",
            "Epoch 275/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.6018 - val_loss: 0.9209\n",
            "Epoch 276/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 6.9731 - val_loss: 2.1248\n",
            "Epoch 277/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.2072 - val_loss: 2.1887\n",
            "Epoch 278/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.9670 - val_loss: 0.3735\n",
            "Epoch 279/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.6100 - val_loss: 1.2682\n",
            "Epoch 280/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.2924 - val_loss: 2.1739\n",
            "Epoch 281/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.0462 - val_loss: 2.2927\n",
            "Epoch 282/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.9047 - val_loss: 1.5645\n",
            "Epoch 283/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.1986 - val_loss: 0.3149\n",
            "Epoch 284/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.0827 - val_loss: 0.7755\n",
            "Epoch 285/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.9206 - val_loss: 1.2476\n",
            "Epoch 286/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.2003 - val_loss: 0.2789\n",
            "Epoch 287/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.7159 - val_loss: 1.7747\n",
            "Epoch 288/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.0294 - val_loss: 0.0304\n",
            "Epoch 289/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.6413 - val_loss: 0.7468\n",
            "Epoch 290/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.0582 - val_loss: 2.5098\n",
            "Epoch 291/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.1327 - val_loss: 3.4519\n",
            "Epoch 292/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.8581 - val_loss: 2.3287\n",
            "Epoch 293/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.7868 - val_loss: 0.1870\n",
            "Epoch 294/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.8470 - val_loss: 0.3240\n",
            "Epoch 295/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.1822 - val_loss: 1.2168\n",
            "Epoch 296/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.4816 - val_loss: 0.6036\n",
            "Epoch 297/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.7890 - val_loss: 0.7868\n",
            "Epoch 298/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.0009 - val_loss: 1.8893\n",
            "Epoch 299/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.4138 - val_loss: 2.0386\n",
            "Epoch 300/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.3081 - val_loss: 1.3265\n",
            "Epoch 301/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.7660 - val_loss: 1.1089\n",
            "Epoch 302/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.7158 - val_loss: 0.1013\n",
            "Epoch 303/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.4666 - val_loss: 0.6791\n",
            "Epoch 304/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.3312 - val_loss: 2.2415\n",
            "Epoch 305/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.7256 - val_loss: 1.4062\n",
            "Epoch 306/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.0922 - val_loss: 5.3336\n",
            "Epoch 307/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.9075 - val_loss: 0.2267\n",
            "Epoch 308/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.0023 - val_loss: 1.1961\n",
            "Epoch 309/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.7954 - val_loss: 0.8244\n",
            "Epoch 310/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.4768 - val_loss: 2.0253\n",
            "Epoch 311/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.1513 - val_loss: 1.1811\n",
            "Epoch 312/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.4815 - val_loss: 1.0403\n",
            "Epoch 313/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 6.7187 - val_loss: 1.5535\n",
            "Epoch 314/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.4997 - val_loss: 1.8623\n",
            "Epoch 315/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.7774 - val_loss: 0.3044\n",
            "Epoch 316/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.2247 - val_loss: 2.1476\n",
            "Epoch 317/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.4045 - val_loss: 1.2562\n",
            "Epoch 318/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.8103 - val_loss: 2.1148\n",
            "Epoch 319/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.0822 - val_loss: 1.9201\n",
            "Epoch 320/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.6825 - val_loss: 4.8862\n",
            "Epoch 321/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.3742 - val_loss: 1.2674\n",
            "Epoch 322/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.0480 - val_loss: 2.7342\n",
            "Epoch 323/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.2994 - val_loss: 0.7640\n",
            "Epoch 324/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.0666 - val_loss: 2.0162\n",
            "Epoch 325/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.0730 - val_loss: 0.4391\n",
            "Epoch 326/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.4045 - val_loss: 2.4301\n",
            "Epoch 327/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.7080 - val_loss: 0.4485\n",
            "Epoch 328/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.6892 - val_loss: 0.5944\n",
            "Epoch 329/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.1568 - val_loss: 0.9164\n",
            "Epoch 330/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.9507 - val_loss: 1.5182\n",
            "Epoch 331/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.2439 - val_loss: 1.1357\n",
            "Epoch 332/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.4884 - val_loss: 0.6542\n",
            "Epoch 333/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.5871 - val_loss: 2.3933\n",
            "Epoch 334/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.3852 - val_loss: 0.8479\n",
            "Epoch 335/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4724 - val_loss: 0.0683\n",
            "Epoch 336/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.5475 - val_loss: 1.6762\n",
            "Epoch 337/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.5709 - val_loss: 1.2431\n",
            "Epoch 338/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.6839 - val_loss: 2.3373\n",
            "Epoch 339/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.3862 - val_loss: 2.8464\n",
            "Epoch 340/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.7210 - val_loss: 3.4764\n",
            "Epoch 341/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.6464 - val_loss: 0.7391\n",
            "Epoch 342/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.9142 - val_loss: 5.0390\n",
            "Epoch 343/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 9.0181 - val_loss: 4.3250\n",
            "Epoch 344/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.0480 - val_loss: 2.3601\n",
            "Epoch 345/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.6919 - val_loss: 0.4838\n",
            "Epoch 346/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.4124 - val_loss: 2.1246\n",
            "Epoch 347/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.6418 - val_loss: 1.7672\n",
            "Epoch 348/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.7185 - val_loss: 0.5704\n",
            "Epoch 349/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.2841 - val_loss: 1.6370\n",
            "Epoch 350/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 5.7354 - val_loss: 0.8121\n",
            "Epoch 351/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.3230 - val_loss: 2.5142\n",
            "Epoch 352/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.4380 - val_loss: 1.8369\n",
            "Epoch 353/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.5045 - val_loss: 2.0079\n",
            "Epoch 354/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.0155 - val_loss: 1.0914\n",
            "Epoch 355/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6.7729 - val_loss: 1.9828\n",
            "Epoch 356/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.5303 - val_loss: 4.5417\n",
            "Epoch 357/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.8458 - val_loss: 3.7820\n",
            "Epoch 358/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 6.9246 - val_loss: 1.7848\n",
            "Epoch 359/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.8299 - val_loss: 3.7079\n",
            "Epoch 360/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.4622 - val_loss: 0.7687\n",
            "Epoch 361/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.4795 - val_loss: 1.4558\n",
            "Epoch 362/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.5921 - val_loss: 1.3739\n",
            "Epoch 363/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 6.5427 - val_loss: 2.2732\n",
            "Epoch 364/686\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 6.8478 - val_loss: 2.0246\n",
            "Epoch 365/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 6.2402 - val_loss: 0.8616\n",
            "Epoch 366/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4459 - val_loss: 0.3584\n",
            "Epoch 367/686\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.3123 - val_loss: 1.3658\n",
            "Epoch 368/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.4122 - val_loss: 1.7711\n",
            "Epoch 369/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 6.4275 - val_loss: 4.8510\n",
            "Epoch 370/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.7549 - val_loss: 3.5904\n",
            "Epoch 371/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.0693 - val_loss: 1.3184\n",
            "Epoch 372/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 7.1276 - val_loss: 0.1585\n",
            "Epoch 373/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.8587 - val_loss: 0.6262\n",
            "Epoch 374/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.0944 - val_loss: 1.5117\n",
            "Epoch 375/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.3185 - val_loss: 0.5681\n",
            "Epoch 376/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.3667 - val_loss: 1.1176\n",
            "Epoch 377/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.4850 - val_loss: 1.5463\n",
            "Epoch 378/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.4975 - val_loss: 3.1915\n",
            "Epoch 379/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4845 - val_loss: 5.4499\n",
            "Epoch 380/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.7669 - val_loss: 3.4658\n",
            "Epoch 381/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.5328 - val_loss: 4.1764\n",
            "Epoch 382/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.9729 - val_loss: 1.5210\n",
            "Epoch 383/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.5503 - val_loss: 1.3582\n",
            "Epoch 384/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4859 - val_loss: 1.0828\n",
            "Epoch 385/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.3436 - val_loss: 1.6815\n",
            "Epoch 386/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.0410 - val_loss: 4.4624\n",
            "Epoch 387/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.0518 - val_loss: 3.0171\n",
            "Epoch 388/686\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 6.2830 - val_loss: 0.9121\n",
            "Epoch 389/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.2424 - val_loss: 2.1896\n",
            "Epoch 390/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 5.7276 - val_loss: 2.2499\n",
            "Epoch 391/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 5.8276 - val_loss: 0.0449\n",
            "Epoch 392/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.5118 - val_loss: 1.3661\n",
            "Epoch 393/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.0769 - val_loss: 1.3660\n",
            "Epoch 394/686\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 7.1060 - val_loss: 3.5050\n",
            "Epoch 395/686\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7.3220 - val_loss: 3.6168\n",
            "Epoch 396/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.5639 - val_loss: 1.5104\n",
            "Epoch 397/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.0993 - val_loss: 2.8796\n",
            "Epoch 398/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.6577 - val_loss: 2.0366\n",
            "Epoch 399/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.2105 - val_loss: 2.8686\n",
            "Epoch 400/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.0107 - val_loss: 2.4947\n",
            "Epoch 401/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.2197 - val_loss: 2.0448\n",
            "Epoch 402/686\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 6.1926 - val_loss: 0.3467\n",
            "Epoch 403/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.5284 - val_loss: 1.1466\n",
            "Epoch 404/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.7690 - val_loss: 1.1572\n",
            "Epoch 405/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4659 - val_loss: 0.0400\n",
            "Epoch 406/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.5132 - val_loss: 0.1663\n",
            "Epoch 407/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.3501 - val_loss: 2.1708\n",
            "Epoch 408/686\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.0529 - val_loss: 0.1798\n",
            "Epoch 409/686\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.9520 - val_loss: 0.3771\n",
            "Epoch 410/686\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6.0471 - val_loss: 2.6609\n",
            "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 41.0590 - val_loss: 24.3490\n",
            "Epoch 2/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 34.1045 - val_loss: 16.6597\n",
            "Epoch 3/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 22.7898 - val_loss: 3.2624\n",
            "Epoch 4/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.3457 - val_loss: 11.9853\n",
            "Epoch 5/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.0136 - val_loss: 7.4856\n",
            "Epoch 6/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8494 - val_loss: 4.2302\n",
            "Epoch 7/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.4998 - val_loss: 7.2580\n",
            "Epoch 8/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.5299 - val_loss: 7.0097\n",
            "Epoch 9/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.2814 - val_loss: 5.8339\n",
            "Epoch 10/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.2279 - val_loss: 6.7595\n",
            "Epoch 11/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0499 - val_loss: 7.8017\n",
            "Epoch 12/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.8857 - val_loss: 8.2299\n",
            "Epoch 13/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7872 - val_loss: 8.6252\n",
            "Epoch 14/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.5426 - val_loss: 9.0862\n",
            "Epoch 15/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.3381 - val_loss: 8.6604\n",
            "Epoch 16/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1607 - val_loss: 9.0315\n",
            "Epoch 17/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.9104 - val_loss: 7.5864\n",
            "Epoch 18/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2233 - val_loss: 11.2191\n",
            "Epoch 19/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1895 - val_loss: 2.4425\n",
            "Epoch 20/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7327 - val_loss: 12.6259\n",
            "Epoch 21/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.3821 - val_loss: 6.5339\n",
            "Epoch 22/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.3706 - val_loss: 4.9993\n",
            "Epoch 23/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.0335 - val_loss: 8.6135\n",
            "Epoch 24/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8651 - val_loss: 6.8622\n",
            "Epoch 25/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.9159 - val_loss: 7.7016\n",
            "Epoch 26/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.5914 - val_loss: 8.5719\n",
            "Epoch 27/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4941 - val_loss: 7.7699\n",
            "Epoch 28/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3590 - val_loss: 7.7208\n",
            "Epoch 29/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4289 - val_loss: 8.7304\n",
            "Epoch 30/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1488 - val_loss: 6.0896\n",
            "Epoch 31/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.8231 - val_loss: 10.8554\n",
            "Epoch 32/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8285 - val_loss: 2.3652\n",
            "Epoch 33/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8722 - val_loss: 10.1035\n",
            "Epoch 34/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.1765 - val_loss: 6.9813\n",
            "Epoch 35/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.3294 - val_loss: 5.5943\n",
            "Epoch 36/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4478 - val_loss: 7.3377\n",
            "Epoch 37/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3403 - val_loss: 6.4203\n",
            "Epoch 38/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3847 - val_loss: 7.1947\n",
            "Epoch 39/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2124 - val_loss: 7.0102\n",
            "Epoch 40/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2127 - val_loss: 7.3497\n",
            "Epoch 41/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1103 - val_loss: 6.9681\n",
            "Epoch 42/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1992 - val_loss: 7.5795\n",
            "Epoch 43/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0076 - val_loss: 5.9512\n",
            "Epoch 44/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1728 - val_loss: 6.8690\n",
            "Epoch 45/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9795 - val_loss: 5.1943\n",
            "Epoch 46/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6633 - val_loss: 9.5472\n",
            "Epoch 47/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7162 - val_loss: 3.8169\n",
            "Epoch 48/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.1044 - val_loss: 7.8828\n",
            "Epoch 49/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0666 - val_loss: 4.9237\n",
            "Epoch 50/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.9761 - val_loss: 6.3225\n",
            "Epoch 51/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3464 - val_loss: 6.5797\n",
            "Epoch 52/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1633 - val_loss: 6.8552\n",
            "Epoch 53/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9070 - val_loss: 6.2507\n",
            "Epoch 54/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2081 - val_loss: 7.5055\n",
            "Epoch 55/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8827 - val_loss: 6.3837\n",
            "Epoch 56/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9240 - val_loss: 6.6819\n",
            "Epoch 57/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8618 - val_loss: 6.5833\n",
            "Epoch 58/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8616 - val_loss: 6.2591\n",
            "Epoch 59/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8735 - val_loss: 6.4159\n",
            "Epoch 60/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7850 - val_loss: 4.8082\n",
            "Epoch 61/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2031 - val_loss: 8.2755\n",
            "Epoch 62/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9555 - val_loss: 3.1166\n",
            "Epoch 63/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8679 - val_loss: 8.9157\n",
            "Epoch 64/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1997 - val_loss: 3.9991\n",
            "Epoch 65/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6953 - val_loss: 5.7032\n",
            "Epoch 66/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.4006 - val_loss: 6.1000\n",
            "Epoch 67/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2376 - val_loss: 5.8268\n",
            "Epoch 68/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.9515 - val_loss: 6.1722\n",
            "Epoch 69/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9413 - val_loss: 6.6286\n",
            "Epoch 70/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9029 - val_loss: 6.1545\n",
            "Epoch 71/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8470 - val_loss: 6.2461\n",
            "Epoch 72/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9642 - val_loss: 6.8371\n",
            "Epoch 73/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9429 - val_loss: 4.3647\n",
            "Epoch 74/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9845 - val_loss: 5.8567\n",
            "Epoch 75/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7642 - val_loss: 4.1152\n",
            "Epoch 76/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7299 - val_loss: 10.5928\n",
            "Epoch 77/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.4307 - val_loss: 2.2071\n",
            "Epoch 78/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6524 - val_loss: 6.7243\n",
            "Epoch 79/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.0730 - val_loss: 5.3118\n",
            "Epoch 80/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6275 - val_loss: 5.1428\n",
            "Epoch 81/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0097 - val_loss: 6.4712\n",
            "Epoch 82/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9287 - val_loss: 5.8474\n",
            "Epoch 83/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9267 - val_loss: 6.7420\n",
            "Epoch 84/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8629 - val_loss: 5.4667\n",
            "Epoch 85/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8442 - val_loss: 6.0055\n",
            "Epoch 86/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7749 - val_loss: 6.1704\n",
            "Epoch 87/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8639 - val_loss: 6.9787\n",
            "Epoch 88/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6996 - val_loss: 4.3909\n",
            "Epoch 89/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1068 - val_loss: 7.6077\n",
            "Epoch 90/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.7338 - val_loss: 3.4777\n",
            "Epoch 91/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4486 - val_loss: 7.6983\n",
            "Epoch 92/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2466 - val_loss: 3.4043\n",
            "Epoch 93/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8701 - val_loss: 6.5065\n",
            "Epoch 94/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4860 - val_loss: 4.3627\n",
            "Epoch 95/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6233 - val_loss: 5.3697\n",
            "Epoch 96/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0362 - val_loss: 4.6222\n",
            "Epoch 97/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2628 - val_loss: 6.2737\n",
            "Epoch 98/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7954 - val_loss: 4.5091\n",
            "Epoch 99/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9595 - val_loss: 6.0445\n",
            "Epoch 100/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7321 - val_loss: 3.9820\n",
            "Epoch 101/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3186 - val_loss: 7.8940\n",
            "Epoch 102/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1002 - val_loss: 3.0898\n",
            "Epoch 103/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.7675 - val_loss: 6.6997\n",
            "Epoch 104/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6159 - val_loss: 3.8917\n",
            "Epoch 105/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6324 - val_loss: 5.1196\n",
            "Epoch 106/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0938 - val_loss: 4.6161\n",
            "Epoch 107/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0071 - val_loss: 4.9330\n",
            "Epoch 108/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6827 - val_loss: 4.7018\n",
            "Epoch 109/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0719 - val_loss: 6.5205\n",
            "Epoch 110/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7532 - val_loss: 2.4495\n",
            "Epoch 111/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.3077 - val_loss: 5.6954\n",
            "Epoch 112/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.9925 - val_loss: 3.1834\n",
            "Epoch 113/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6682 - val_loss: 7.2792\n",
            "Epoch 114/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0666 - val_loss: 2.4031\n",
            "Epoch 115/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6395 - val_loss: 4.1947\n",
            "Epoch 116/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9621 - val_loss: 3.9909\n",
            "Epoch 117/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0501 - val_loss: 4.9707\n",
            "Epoch 118/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7122 - val_loss: 4.2072\n",
            "Epoch 119/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7615 - val_loss: 4.7817\n",
            "Epoch 120/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6553 - val_loss: 3.5845\n",
            "Epoch 121/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8019 - val_loss: 5.7049\n",
            "Epoch 122/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6365 - val_loss: 2.4101\n",
            "Epoch 123/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9858 - val_loss: 5.9258\n",
            "Epoch 124/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.7806 - val_loss: 0.5444\n",
            "Epoch 125/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1196 - val_loss: 5.5997\n",
            "Epoch 126/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8362 - val_loss: 3.1143\n",
            "Epoch 127/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9458 - val_loss: 6.1088\n",
            "Epoch 128/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8274 - val_loss: 1.8368\n",
            "Epoch 129/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3909 - val_loss: 5.1059\n",
            "Epoch 130/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8164 - val_loss: 2.8270\n",
            "Epoch 131/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0839 - val_loss: 5.6983\n",
            "Epoch 132/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7334 - val_loss: 1.8299\n",
            "Epoch 133/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2199 - val_loss: 4.9729\n",
            "Epoch 134/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.6833 - val_loss: 2.2050\n",
            "Epoch 135/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0326 - val_loss: 5.5637\n",
            "Epoch 136/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7178 - val_loss: 0.9817\n",
            "Epoch 137/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2674 - val_loss: 4.9024\n",
            "Epoch 138/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8699 - val_loss: 1.8706\n",
            "Epoch 139/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6540 - val_loss: 6.7420\n",
            "Epoch 140/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3402 - val_loss: 1.3695\n",
            "Epoch 141/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6281 - val_loss: 4.3138\n",
            "Epoch 142/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9847 - val_loss: 3.8560\n",
            "Epoch 143/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0092 - val_loss: 4.2624\n",
            "Epoch 144/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8271 - val_loss: 4.2493\n",
            "Epoch 145/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8073 - val_loss: 5.1252\n",
            "Epoch 146/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6980 - val_loss: 2.3684\n",
            "Epoch 147/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0127 - val_loss: 5.3815\n",
            "Epoch 148/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5726 - val_loss: 2.1440\n",
            "Epoch 149/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8896 - val_loss: 4.6797\n",
            "Epoch 150/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5450 - val_loss: 1.5074\n",
            "Epoch 151/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7581 - val_loss: 3.6796\n",
            "Epoch 152/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4309 - val_loss: 0.8258\n",
            "Epoch 153/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1267 - val_loss: 3.9305\n",
            "Epoch 154/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5328 - val_loss: 0.8637\n",
            "Epoch 155/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6490 - val_loss: 2.9812\n",
            "Epoch 156/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6672 - val_loss: 1.4143\n",
            "Epoch 157/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.5353 - val_loss: 1.7710\n",
            "Epoch 158/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2361 - val_loss: 5.9259\n",
            "Epoch 159/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.4858 - val_loss: 0.0424\n",
            "Epoch 160/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.5597 - val_loss: 4.1855\n",
            "Epoch 161/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1081 - val_loss: 3.6244\n",
            "Epoch 162/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0641 - val_loss: 3.7485\n",
            "Epoch 163/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7229 - val_loss: 3.4398\n",
            "Epoch 164/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6140 - val_loss: 3.8345\n",
            "Epoch 165/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4835 - val_loss: 1.1057\n",
            "Epoch 166/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.6553 - val_loss: 3.6619\n",
            "Epoch 167/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5363 - val_loss: 3.2694\n",
            "Epoch 168/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.4491 - val_loss: 1.9302\n",
            "Epoch 169/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6856 - val_loss: 4.2105\n",
            "Epoch 170/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7457 - val_loss: 0.2003\n",
            "Epoch 171/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6672 - val_loss: 3.5376\n",
            "Epoch 172/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4831 - val_loss: 2.1627\n",
            "Epoch 173/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4273 - val_loss: 2.4426\n",
            "Epoch 174/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3803 - val_loss: 0.9184\n",
            "Epoch 175/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6907 - val_loss: 2.8813\n",
            "Epoch 176/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7312 - val_loss: 0.3178\n",
            "Epoch 177/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5975 - val_loss: 2.8380\n",
            "Epoch 178/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9983 - val_loss: 5.4390\n",
            "Epoch 179/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8336 - val_loss: 0.9722\n",
            "Epoch 180/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.3307 - val_loss: 5.2143\n",
            "Epoch 181/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1415 - val_loss: 0.0708\n",
            "Epoch 182/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7825 - val_loss: 4.6346\n",
            "Epoch 183/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3436 - val_loss: 0.9581\n",
            "Epoch 184/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6965 - val_loss: 3.7712\n",
            "Epoch 185/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0775 - val_loss: 1.7017\n",
            "Epoch 186/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0839 - val_loss: 2.6776\n",
            "Epoch 187/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5002 - val_loss: 0.5761\n",
            "Epoch 188/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0155 - val_loss: 3.5799\n",
            "Epoch 189/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6510 - val_loss: 0.1723\n",
            "Epoch 190/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0950 - val_loss: 3.8867\n",
            "Epoch 191/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8531 - val_loss: 0.4216\n",
            "Epoch 192/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3546 - val_loss: 3.7750\n",
            "Epoch 193/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1534 - val_loss: 0.1293\n",
            "Epoch 194/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9976 - val_loss: 3.2527\n",
            "Epoch 195/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7011 - val_loss: 0.9154\n",
            "Epoch 196/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0708 - val_loss: 3.4969\n",
            "Epoch 197/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9186 - val_loss: 0.1031\n",
            "Epoch 198/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9260 - val_loss: 3.3941\n",
            "Epoch 199/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5394 - val_loss: 0.1476\n",
            "Epoch 200/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5278 - val_loss: 2.4278\n",
            "Epoch 201/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.2926 - val_loss: 0.0135\n",
            "Epoch 202/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.8408 - val_loss: 3.3141\n",
            "Epoch 203/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.5520 - val_loss: 0.0478\n",
            "Epoch 204/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.4089 - val_loss: 2.7203\n",
            "Epoch 205/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4107 - val_loss: 2.7905\n",
            "Epoch 206/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2877 - val_loss: 0.2837\n",
            "Epoch 207/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7689 - val_loss: 2.1472\n",
            "Epoch 208/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3929 - val_loss: 0.3696\n",
            "Epoch 209/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3313 - val_loss: 0.3431\n",
            "Epoch 210/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4322 - val_loss: 1.0640\n",
            "Epoch 211/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4904 - val_loss: 0.4082\n",
            "Epoch 212/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6868 - val_loss: 0.7981\n",
            "Epoch 213/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8694 - val_loss: 3.0394\n",
            "Epoch 214/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.6211 - val_loss: 1.0544\n",
            "Epoch 215/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5839 - val_loss: 2.6627\n",
            "Epoch 216/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4591 - val_loss: 0.5830\n",
            "Epoch 217/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4069 - val_loss: 1.9604\n",
            "Epoch 218/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3359 - val_loss: 1.7698\n",
            "Epoch 219/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2349 - val_loss: 0.3975\n",
            "Epoch 220/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5180 - val_loss: 0.6930\n",
            "Epoch 221/686\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6.4887 - val_loss: 1.0014\n",
            "Epoch 222/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7637 - val_loss: 0.0111\n",
            "Epoch 223/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7861 - val_loss: 3.0487\n",
            "Epoch 224/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3899 - val_loss: 0.1138\n",
            "Epoch 225/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7505 - val_loss: 2.4921\n",
            "Epoch 226/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4068 - val_loss: 0.6372\n",
            "Epoch 227/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1270 - val_loss: 0.9851\n",
            "Epoch 228/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2394 - val_loss: 2.4019\n",
            "Epoch 229/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0605 - val_loss: 0.3107\n",
            "Epoch 230/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2856 - val_loss: 1.3623\n",
            "Epoch 231/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1908 - val_loss: 0.4785\n",
            "Epoch 232/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1210 - val_loss: 0.1586\n",
            "Epoch 233/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5499 - val_loss: 2.2149\n",
            "Epoch 234/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2881 - val_loss: 0.6311\n",
            "Epoch 235/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.1656 - val_loss: 0.1201\n",
            "Epoch 236/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5498 - val_loss: 3.5312\n",
            "Epoch 237/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2730 - val_loss: 0.2114\n",
            "Epoch 238/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1690 - val_loss: 1.8895\n",
            "Epoch 239/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0037 - val_loss: 0.6435\n",
            "Epoch 240/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0918 - val_loss: 0.4101\n",
            "Epoch 241/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0714 - val_loss: 0.3023\n",
            "Epoch 242/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1522 - val_loss: 0.7611\n",
            "Epoch 243/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.4757 - val_loss: 0.9076\n",
            "Epoch 244/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2176 - val_loss: 2.5866\n",
            "Epoch 245/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4872 - val_loss: 4.1129\n",
            "Epoch 246/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8856 - val_loss: 0.4986\n",
            "Epoch 247/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.6892 - val_loss: 3.9614\n",
            "Epoch 248/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.2082 - val_loss: 0.4135\n",
            "Epoch 249/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8886 - val_loss: 2.6690\n",
            "Epoch 250/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4004 - val_loss: 2.7558\n",
            "Epoch 251/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4092 - val_loss: 1.4205\n",
            "Epoch 252/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0429 - val_loss: 2.6394\n",
            "Epoch 253/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0622 - val_loss: 1.6574\n",
            "Epoch 254/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9568 - val_loss: 1.3199\n",
            "Epoch 255/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9328 - val_loss: 0.2648\n",
            "Epoch 256/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9831 - val_loss: 0.7154\n",
            "Epoch 257/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9690 - val_loss: 0.2642\n",
            "Epoch 258/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.3520 - val_loss: 2.5062\n",
            "Epoch 259/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8379 - val_loss: 1.3940\n",
            "Epoch 260/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4405 - val_loss: 2.2850\n",
            "Epoch 261/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2802 - val_loss: 1.1733\n",
            "Epoch 262/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1343 - val_loss: 1.3437\n",
            "Epoch 263/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0597 - val_loss: 1.9453\n",
            "Epoch 264/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2363 - val_loss: 1.1776\n",
            "Epoch 265/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1333 - val_loss: 1.0862\n",
            "Epoch 266/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.9297 - val_loss: 0.2218\n",
            "Epoch 267/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2969 - val_loss: 2.2204\n",
            "Epoch 268/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1442 - val_loss: 0.0145\n",
            "Epoch 269/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.3353 - val_loss: 0.4728\n",
            "Epoch 270/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1113 - val_loss: 2.8973\n",
            "Epoch 271/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9888 - val_loss: 0.8233\n",
            "Epoch 272/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.9802 - val_loss: 0.5386\n",
            "Epoch 273/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2419 - val_loss: 1.2167\n",
            "Epoch 274/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0112 - val_loss: 0.9649\n",
            "Epoch 275/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2271 - val_loss: 0.6398\n",
            "Epoch 276/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5542 - val_loss: 2.2040\n",
            "Epoch 277/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9648 - val_loss: 0.5087\n",
            "Epoch 278/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.8842 - val_loss: 0.0583\n",
            "Epoch 279/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9701 - val_loss: 2.9075\n",
            "Epoch 280/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.1337 - val_loss: 1.1793\n",
            "Epoch 281/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0085 - val_loss: 0.2639\n",
            "Epoch 282/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1187 - val_loss: 4.8871\n",
            "Epoch 283/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.5881 - val_loss: 1.9465\n",
            "Epoch 284/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1899 - val_loss: 3.0847\n",
            "Epoch 285/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3753 - val_loss: 0.7322\n",
            "Epoch 286/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7777 - val_loss: 3.7087\n",
            "Epoch 287/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2983 - val_loss: 1.4873\n",
            "Epoch 288/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1165 - val_loss: 2.9332\n",
            "Epoch 289/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8893 - val_loss: 0.8493\n",
            "Epoch 290/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8598 - val_loss: 1.2096\n",
            "Epoch 291/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.7745 - val_loss: 0.4051\n",
            "Epoch 292/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8006 - val_loss: 0.4286\n",
            "Epoch 293/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9579 - val_loss: 1.4233\n",
            "Epoch 294/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0594 - val_loss: 1.3670\n",
            "Epoch 295/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.1437 - val_loss: 1.1776\n",
            "Epoch 296/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9041 - val_loss: 2.5915\n",
            "Epoch 297/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9316 - val_loss: 1.2288\n",
            "Epoch 298/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7852 - val_loss: 1.0656\n",
            "Epoch 299/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9863 - val_loss: 0.3405\n",
            "Epoch 300/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2016 - val_loss: 2.4214\n",
            "Epoch 301/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2388 - val_loss: 2.9052\n",
            "Epoch 302/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.1824 - val_loss: 3.8897\n",
            "Epoch 303/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0685 - val_loss: 0.2548\n",
            "Epoch 304/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1761 - val_loss: 1.8623\n",
            "Epoch 305/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9276 - val_loss: 1.7325\n",
            "Epoch 306/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2341 - val_loss: 1.9272\n",
            "Epoch 307/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9469 - val_loss: 2.7299\n",
            "Epoch 308/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0545 - val_loss: 0.2910\n",
            "Epoch 309/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0725 - val_loss: 0.6556\n",
            "Epoch 310/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7787 - val_loss: 2.0444\n",
            "Epoch 311/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0695 - val_loss: 1.8962\n",
            "Epoch 312/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9087 - val_loss: 0.3486\n",
            "Epoch 313/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.0090 - val_loss: 0.6095\n",
            "Epoch 314/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0465 - val_loss: 2.6641\n",
            "Epoch 315/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8589 - val_loss: 0.0975\n",
            "Epoch 316/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7788 - val_loss: 1.0117\n",
            "Epoch 317/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7064 - val_loss: 1.1051\n",
            "Epoch 318/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9515 - val_loss: 2.7792\n",
            "Epoch 319/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2044 - val_loss: 2.0833\n",
            "Epoch 320/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0695 - val_loss: 2.1540\n",
            "Epoch 321/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8077 - val_loss: 0.5956\n",
            "Epoch 322/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7847 - val_loss: 0.7655\n",
            "Epoch 323/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6851 - val_loss: 2.1866\n",
            "Epoch 324/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9424 - val_loss: 0.5045\n",
            "Epoch 325/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.9266 - val_loss: 0.8385\n",
            "Epoch 326/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.6932 - val_loss: 0.5710\n",
            "Epoch 327/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3350 - val_loss: 4.0509\n",
            "Epoch 328/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7567 - val_loss: 0.8813\n",
            "Epoch 329/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1411 - val_loss: 4.4795\n",
            "Epoch 330/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1625 - val_loss: 1.3262\n",
            "Epoch 331/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5243 - val_loss: 1.7461\n",
            "Epoch 332/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8683 - val_loss: 0.8141\n",
            "Epoch 333/686\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.8586 - val_loss: 1.3683\n",
            "Epoch 334/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5913 - val_loss: 0.8940\n",
            "Epoch 335/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8227 - val_loss: 1.1300\n",
            "Epoch 336/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.8243 - val_loss: 1.8528\n",
            "Epoch 337/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9405 - val_loss: 2.0938\n",
            "Epoch 338/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9004 - val_loss: 2.3620\n",
            "Epoch 339/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8506 - val_loss: 0.8881\n",
            "Epoch 340/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9188 - val_loss: 1.1153\n",
            "Epoch 341/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6338 - val_loss: 2.0007\n",
            "Epoch 342/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7413 - val_loss: 0.2660\n",
            "Epoch 343/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5509 - val_loss: 0.4274\n",
            "Epoch 344/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6504 - val_loss: 0.5912\n",
            "Epoch 345/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0965 - val_loss: 7.3125\n",
            "Epoch 346/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7776 - val_loss: 0.9034\n",
            "Epoch 347/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.1691 - val_loss: 3.8392\n",
            "Epoch 348/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3683 - val_loss: 2.8412\n",
            "Epoch 349/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0826 - val_loss: 1.0933\n",
            "Epoch 350/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.8271 - val_loss: 0.6177\n",
            "Epoch 351/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7276 - val_loss: 1.3915\n",
            "Epoch 352/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5885 - val_loss: 0.2527\n",
            "Epoch 353/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9199 - val_loss: 1.6294\n",
            "Epoch 354/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7571 - val_loss: 0.0010\n",
            "Epoch 355/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9134 - val_loss: 0.4408\n",
            "Epoch 356/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6783 - val_loss: 1.7941\n",
            "Epoch 357/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7036 - val_loss: 2.8543\n",
            "Epoch 358/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.8402 - val_loss: 1.2978\n",
            "Epoch 359/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6391 - val_loss: 1.5259\n",
            "Epoch 360/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7681 - val_loss: 1.4749\n",
            "Epoch 361/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7856 - val_loss: 1.6973\n",
            "Epoch 362/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7870 - val_loss: 1.6330\n",
            "Epoch 363/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9371 - val_loss: 3.3955\n",
            "Epoch 364/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4202 - val_loss: 2.2323\n",
            "Epoch 365/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1777 - val_loss: 3.5367\n",
            "Epoch 366/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0847 - val_loss: 1.5345\n",
            "Epoch 367/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1428 - val_loss: 3.0859\n",
            "Epoch 368/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9616 - val_loss: 1.5554\n",
            "Epoch 369/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5312 - val_loss: 0.5663\n",
            "Epoch 370/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.4255 - val_loss: 1.1751\n",
            "Epoch 371/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5648 - val_loss: 0.2355\n",
            "Epoch 372/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6034 - val_loss: 0.0424\n",
            "Epoch 373/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5044 - val_loss: 0.0629\n",
            "Epoch 374/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4214 - val_loss: 0.1348\n",
            "Epoch 375/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4729 - val_loss: 0.0297\n",
            "Epoch 376/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7847 - val_loss: 1.9759\n",
            "Epoch 377/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7479 - val_loss: 1.7128\n",
            "Epoch 378/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4353 - val_loss: 1.3483\n",
            "Epoch 379/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7334 - val_loss: 3.2213\n",
            "Epoch 380/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0492 - val_loss: 2.3861\n",
            "Epoch 381/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.0398 - val_loss: 2.3019\n",
            "Epoch 382/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5922 - val_loss: 0.0763\n",
            "Epoch 383/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5358 - val_loss: 0.1509\n",
            "Epoch 384/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.5680 - val_loss: 0.8318\n",
            "Epoch 385/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5650 - val_loss: 0.5442\n",
            "Epoch 386/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5238 - val_loss: 0.8233\n",
            "Epoch 387/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4767 - val_loss: 0.7284\n",
            "Epoch 388/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6255 - val_loss: 2.8574\n",
            "Epoch 389/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1562 - val_loss: 3.8561\n",
            "Epoch 390/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2209 - val_loss: 2.3915\n",
            "Epoch 391/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8985 - val_loss: 0.1181\n",
            "Epoch 392/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7851 - val_loss: 0.4571\n",
            "Epoch 393/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7231 - val_loss: 1.6471\n",
            "Epoch 394/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6488 - val_loss: 1.3484\n",
            "Epoch 395/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4598 - val_loss: 1.3253\n",
            "Epoch 396/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6610 - val_loss: 1.0558\n",
            "Epoch 397/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8863 - val_loss: 0.5239\n",
            "Epoch 398/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5692 - val_loss: 3.0054\n",
            "Epoch 399/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6632 - val_loss: 0.3661\n",
            "Epoch 400/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7255 - val_loss: 1.6091\n",
            "Epoch 401/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4403 - val_loss: 0.1116\n",
            "Epoch 402/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.9508 - val_loss: 3.5261\n",
            "Epoch 403/686\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.4123 - val_loss: 2.5947\n",
            "Epoch 404/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0155 - val_loss: 3.1152\n",
            "Epoch 405/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6627 - val_loss: 0.1381\n",
            "Epoch 406/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4843 - val_loss: 0.3962\n",
            "Epoch 407/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6436 - val_loss: 1.0999\n",
            "Epoch 408/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5260 - val_loss: 0.7091\n",
            "Epoch 409/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4129 - val_loss: 0.5818\n",
            "Epoch 410/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3644 - val_loss: 0.6607\n",
            "Epoch 411/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3820 - val_loss: 0.2572\n",
            "Epoch 412/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.4053 - val_loss: 0.4500\n",
            "Epoch 413/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6272 - val_loss: 1.4964\n",
            "Epoch 414/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3911 - val_loss: 1.2246\n",
            "Epoch 415/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4619 - val_loss: 2.2123\n",
            "Epoch 416/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5675 - val_loss: 1.8538\n",
            "Epoch 417/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3594 - val_loss: 0.8190\n",
            "Epoch 418/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8976 - val_loss: 1.5417\n",
            "Epoch 419/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5962 - val_loss: 1.5853\n",
            "Epoch 420/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2962 - val_loss: 0.1274\n",
            "Epoch 421/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3944 - val_loss: 0.7277\n",
            "Epoch 422/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3186 - val_loss: 0.0477\n",
            "Epoch 423/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4333 - val_loss: 1.3173\n",
            "Epoch 424/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7101 - val_loss: 2.7578\n",
            "Epoch 425/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7758 - val_loss: 0.3115\n",
            "Epoch 426/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7147 - val_loss: 0.2512\n",
            "Epoch 427/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2415 - val_loss: 0.8101\n",
            "Epoch 428/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3111 - val_loss: 0.2907\n",
            "Epoch 429/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2352 - val_loss: 0.1652\n",
            "Epoch 430/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1865 - val_loss: 0.7607\n",
            "Epoch 431/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7724 - val_loss: 3.6804\n",
            "Epoch 432/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0292 - val_loss: 3.3202\n",
            "Epoch 433/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7634 - val_loss: 3.6718\n",
            "Epoch 434/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6782 - val_loss: 1.3688\n",
            "Epoch 435/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6633 - val_loss: 1.8705\n",
            "Epoch 436/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.5208 - val_loss: 0.1206\n",
            "Epoch 437/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8103 - val_loss: 1.5538\n",
            "Epoch 438/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5364 - val_loss: 1.8621\n",
            "Epoch 439/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7515 - val_loss: 3.9465\n",
            "Epoch 440/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9200 - val_loss: 1.9434\n",
            "Epoch 441/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8588 - val_loss: 3.4314\n",
            "Epoch 442/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5155 - val_loss: 0.7851\n",
            "Epoch 443/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2315 - val_loss: 0.8072\n",
            "Epoch 444/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.1727 - val_loss: 1.2534\n",
            "Epoch 445/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3226 - val_loss: 0.9080\n",
            "Epoch 446/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3747 - val_loss: 0.9621\n",
            "Epoch 447/686\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.6098 - val_loss: 4.7494\n",
            "Epoch 448/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8749 - val_loss: 2.6312\n",
            "Epoch 449/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7989 - val_loss: 3.5784\n",
            "Epoch 450/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5480 - val_loss: 0.5662\n",
            "Epoch 451/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3700 - val_loss: 3.1642\n",
            "Epoch 452/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4510 - val_loss: 0.9315\n",
            "Epoch 453/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5726 - val_loss: 0.4264\n",
            "Epoch 454/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7918 - val_loss: 2.2080\n",
            "Epoch 455/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3677 - val_loss: 0.9789\n",
            "Epoch 456/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0842 - val_loss: 0.7558\n",
            "Epoch 457/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3782 - val_loss: 1.5379\n",
            "Epoch 458/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2611 - val_loss: 0.1480\n",
            "Epoch 459/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3373 - val_loss: 1.3307\n",
            "Epoch 460/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0915 - val_loss: 1.0782\n",
            "Epoch 461/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2793 - val_loss: 0.1825\n",
            "Epoch 462/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5590 - val_loss: 0.8875\n",
            "Epoch 463/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2009 - val_loss: 0.5636\n",
            "Epoch 464/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1534 - val_loss: 0.0448\n",
            "Epoch 465/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0974 - val_loss: 0.0537\n",
            "Epoch 466/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1199 - val_loss: 1.2353\n",
            "Epoch 467/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2138 - val_loss: 1.5566\n",
            "Epoch 468/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8686 - val_loss: 6.3887\n",
            "Epoch 469/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7172 - val_loss: 2.2435\n",
            "Epoch 470/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1810 - val_loss: 4.7439\n",
            "Epoch 471/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3582 - val_loss: 0.8490\n",
            "Epoch 472/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.1294 - val_loss: 3.5489\n",
            "Epoch 473/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0757 - val_loss: 1.4166\n",
            "Epoch 474/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6668 - val_loss: 3.1594\n",
            "Epoch 475/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5249 - val_loss: 1.4502\n",
            "Epoch 476/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1720 - val_loss: 1.9370\n",
            "Epoch 477/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5015 - val_loss: 0.4273\n",
            "Epoch 478/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1849 - val_loss: 0.1993\n",
            "Epoch 479/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0921 - val_loss: 0.4636\n",
            "Epoch 480/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1564 - val_loss: 0.5522\n",
            "Epoch 481/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2159 - val_loss: 0.6726\n",
            "Epoch 482/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5968 - val_loss: 1.3028\n",
            "Epoch 483/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.3054 - val_loss: 1.1905\n",
            "Epoch 484/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7811 - val_loss: 2.5505\n",
            "Epoch 485/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9823 - val_loss: 2.8779\n",
            "Epoch 486/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7192 - val_loss: 2.4317\n",
            "Epoch 487/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2656 - val_loss: 0.0850\n",
            "Epoch 488/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2337 - val_loss: 1.5487\n",
            "Epoch 489/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3443 - val_loss: 1.7676\n",
            "Epoch 490/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4445 - val_loss: 1.2191\n",
            "Epoch 491/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3228 - val_loss: 1.8851\n",
            "Epoch 492/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2295 - val_loss: 0.6148\n",
            "Epoch 493/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7900 - val_loss: 2.0572\n",
            "Epoch 494/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4970 - val_loss: 1.9405\n",
            "Epoch 495/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4292 - val_loss: 2.0955\n",
            "Epoch 496/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3966 - val_loss: 0.2652\n",
            "Epoch 497/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.1632 - val_loss: 2.0761\n",
            "Epoch 498/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0392 - val_loss: 0.1058\n",
            "Epoch 499/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0830 - val_loss: 4.9005\n",
            "Epoch 500/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6940 - val_loss: 2.0020\n",
            "Epoch 501/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9632 - val_loss: 1.7246\n",
            "Epoch 502/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2680 - val_loss: 1.1463\n",
            "Epoch 503/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9047 - val_loss: 1.1147\n",
            "Epoch 504/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0692 - val_loss: 0.4134\n",
            "Epoch 505/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1368 - val_loss: 1.6811\n",
            "Epoch 506/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0855 - val_loss: 0.0773\n",
            "Epoch 507/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9729 - val_loss: 1.4290\n",
            "Epoch 508/686\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.1389 - val_loss: 0.4910\n",
            "Epoch 509/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0655 - val_loss: 1.5220\n",
            "Epoch 510/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1119 - val_loss: 2.0449\n",
            "Epoch 511/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2163 - val_loss: 2.6560\n",
            "Epoch 512/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2566 - val_loss: 1.1504\n",
            "Epoch 513/686\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1355 - val_loss: 1.7142\n",
            "Epoch 514/686\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0318 - val_loss: 2.6007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2JnjQLmb6nu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b2f98837-a586-430a-996b-b64888600d89"
      },
      "source": [
        "\n",
        "predictions_hosp_Brazoria = predictionOnPredictionLSTM(initialvalue_Brazoria_hosp,look_ahead,conv_model_Brazoria)\n",
        "predictions_hosp_Brazoria = predictions_hosp_Brazoria.reshape(len(predictions_hosp_Brazoria))\n",
        "#print(predictions_hosp_Brazoria)\n",
        "#print(test_deaths_hosp[3][window:])\n",
        "#print(train_deaths_hosp[3][-20:]) # put smaller window (e.g.4)\n",
        "#conv with 50: best (2.79) window = 2, or 2.75 with 20:\n",
        "#print(mean_absolute_error(predictions_hosp_Brazoria,test_deaths_hosp[3][window_2:]))\n",
        "#print(mean_squared_log_error(predictions_hosp_Brazoria,test_deaths_hosp[3][window_2:]))\n",
        "#[21.998697 19.482649 18.963905 19.884718 19.096195 17.927074 17.467596]\n",
        "print(\"Prediction of first week is :\",[22.021269 ,20.658545, 19.740294 ,19.015366, 18.47681 , 18.032284 ,17.736917] )#1st week\n",
        "#[26.206995 26.850891 27.842733 28.7694   28.969711 28.849827 28.510479]\n",
        "#[29.990364 37.636543 46.50364  31.085344 27.497902 27.020609 21.223059] \n",
        "#[29.993618 36.97773  36.9332   33.374626 36.494392 39.635876 38.17873 ]\n",
        "print(\"Prediction of second week is :\",[29.993618 ,36.97773 , 36.9332 ,  33.374626,27.497902 ,27.497902,27.020609 ,21.223059] )#2nd week"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of first week is : [22.021269, 20.658545, 19.740294, 19.015366, 18.47681, 18.032284, 17.736917]\n",
            "Prediction of second week is : [29.993618, 36.97773, 36.9332, 33.374626, 27.497902, 27.497902, 27.020609, 21.223059]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLGNQ0bVePo6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0696b57f-993f-42da-ce37-14bd5efd192a"
      },
      "source": [
        "encoder_model_Chambers,encoder_history_Chambers = build_encoder_decoder_h(np.array(X_train_hosp_expma[4][:]),np.array(X_test_hosp[4]),np.array(Y_train_hosp_expma[4][:]),np.array(Y_test_hosp[4]),window_2)\n",
        "conv_model_Chambers,conv_history_Chambers = build_conv_model_h(np.array(X_train_hosp_expma[4][:]),np.array(X_test_hosp[4]),np.array(Y_train_hosp_expma[4][:]),np.array(Y_test_hosp[4]),window_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.4544 - val_loss: 0.0507\n",
            "Epoch 2/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3831 - val_loss: 0.1435\n",
            "Epoch 3/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2692 - val_loss: 0.2504\n",
            "Epoch 4/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2701 - val_loss: 0.2462\n",
            "Epoch 5/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2653 - val_loss: 0.2282\n",
            "Epoch 6/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2659 - val_loss: 0.2027\n",
            "Epoch 7/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2455 - val_loss: 0.2099\n",
            "Epoch 8/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2287 - val_loss: 0.2058\n",
            "Epoch 9/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2239 - val_loss: 0.1729\n",
            "Epoch 10/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2336 - val_loss: 0.1869\n",
            "Epoch 11/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2375 - val_loss: 0.1577\n",
            "Epoch 12/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2828 - val_loss: 0.1198\n",
            "Epoch 13/686\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2607 - val_loss: 0.1850\n",
            "Epoch 14/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2160 - val_loss: 0.2502\n",
            "Epoch 15/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2307 - val_loss: 0.2276\n",
            "Epoch 16/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2121 - val_loss: 0.1914\n",
            "Epoch 17/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1954 - val_loss: 0.1792\n",
            "Epoch 18/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1746 - val_loss: 0.1821\n",
            "Epoch 19/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1836 - val_loss: 0.2030\n",
            "Epoch 20/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1864 - val_loss: 0.1562\n",
            "Epoch 21/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1902 - val_loss: 0.2115\n",
            "Epoch 22/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2043 - val_loss: 0.1907\n",
            "Epoch 23/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2046 - val_loss: 0.1504\n",
            "Epoch 24/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1788 - val_loss: 0.1850\n",
            "Epoch 25/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1737 - val_loss: 0.1764\n",
            "Epoch 26/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1610 - val_loss: 0.1639\n",
            "Epoch 27/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1659 - val_loss: 0.1713\n",
            "Epoch 28/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1636 - val_loss: 0.1841\n",
            "Epoch 29/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1745 - val_loss: 0.1631\n",
            "Epoch 30/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1627 - val_loss: 0.1704\n",
            "Epoch 31/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1599 - val_loss: 0.1540\n",
            "Epoch 32/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1720 - val_loss: 0.1511\n",
            "Epoch 33/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1536 - val_loss: 0.1728\n",
            "Epoch 34/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1540 - val_loss: 0.1506\n",
            "Epoch 35/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1568 - val_loss: 0.1468\n",
            "Epoch 36/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1434 - val_loss: 0.1535\n",
            "Epoch 37/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1395 - val_loss: 0.1450\n",
            "Epoch 38/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1537 - val_loss: 0.1538\n",
            "Epoch 39/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1391 - val_loss: 0.1344\n",
            "Epoch 40/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1518 - val_loss: 0.1816\n",
            "Epoch 41/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1602 - val_loss: 0.1549\n",
            "Epoch 42/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1526 - val_loss: 0.1281\n",
            "Epoch 43/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1423 - val_loss: 0.1634\n",
            "Epoch 44/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1405 - val_loss: 0.1458\n",
            "Epoch 45/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1338 - val_loss: 0.1384\n",
            "Epoch 46/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1427 - val_loss: 0.1574\n",
            "Epoch 47/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1424 - val_loss: 0.1247\n",
            "Epoch 48/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1478 - val_loss: 0.1442\n",
            "Epoch 49/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1418 - val_loss: 0.1523\n",
            "Epoch 50/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1396 - val_loss: 0.1394\n",
            "Epoch 51/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1362 - val_loss: 0.1478\n",
            "Epoch 52/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1294 - val_loss: 0.1411\n",
            "Epoch 53/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1324 - val_loss: 0.1568\n",
            "Epoch 54/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1337 - val_loss: 0.1507\n",
            "Epoch 55/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1371 - val_loss: 0.1332\n",
            "Epoch 56/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1363 - val_loss: 0.1564\n",
            "Epoch 57/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1383 - val_loss: 0.1479\n",
            "Epoch 58/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1291 - val_loss: 0.1509\n",
            "Epoch 59/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1293 - val_loss: 0.1494\n",
            "Epoch 60/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1323 - val_loss: 0.1415\n",
            "Epoch 61/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1312 - val_loss: 0.1588\n",
            "Epoch 62/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1313 - val_loss: 0.1336\n",
            "Epoch 63/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1245 - val_loss: 0.1568\n",
            "Epoch 64/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1352 - val_loss: 0.1404\n",
            "Epoch 65/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1339 - val_loss: 0.1319\n",
            "Epoch 66/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1392 - val_loss: 0.1545\n",
            "Epoch 67/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1262 - val_loss: 0.1726\n",
            "Epoch 68/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1261 - val_loss: 0.1429\n",
            "Epoch 69/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1276 - val_loss: 0.1425\n",
            "Epoch 70/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1223 - val_loss: 0.1628\n",
            "Epoch 71/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1277 - val_loss: 0.1412\n",
            "Epoch 72/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1263 - val_loss: 0.1452\n",
            "Epoch 73/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1209 - val_loss: 0.1645\n",
            "Epoch 74/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1194 - val_loss: 0.1476\n",
            "Epoch 75/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1172 - val_loss: 0.1674\n",
            "Epoch 76/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1281 - val_loss: 0.1506\n",
            "Epoch 77/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1275 - val_loss: 0.1617\n",
            "Epoch 78/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1292 - val_loss: 0.1516\n",
            "Epoch 79/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1157 - val_loss: 0.1457\n",
            "Epoch 80/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1201 - val_loss: 0.1624\n",
            "Epoch 81/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1215 - val_loss: 0.1408\n",
            "Epoch 82/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1150 - val_loss: 0.1644\n",
            "Epoch 83/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1191 - val_loss: 0.1508\n",
            "Epoch 84/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1205 - val_loss: 0.1673\n",
            "Epoch 85/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1178 - val_loss: 0.1548\n",
            "Epoch 86/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1168 - val_loss: 0.1758\n",
            "Epoch 87/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1131 - val_loss: 0.1620\n",
            "Epoch 88/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1097 - val_loss: 0.1569\n",
            "Epoch 89/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1198 - val_loss: 0.1723\n",
            "Epoch 90/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1127 - val_loss: 0.1663\n",
            "Epoch 91/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1097 - val_loss: 0.1608\n",
            "Epoch 92/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1152 - val_loss: 0.1763\n",
            "Epoch 93/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1115 - val_loss: 0.1645\n",
            "Epoch 94/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1272 - val_loss: 0.1711\n",
            "Epoch 95/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1091 - val_loss: 0.1802\n",
            "Epoch 96/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1106 - val_loss: 0.1731\n",
            "Epoch 97/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1125 - val_loss: 0.1751\n",
            "Epoch 98/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1107 - val_loss: 0.1701\n",
            "Epoch 99/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1164 - val_loss: 0.1731\n",
            "Epoch 100/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1136 - val_loss: 0.1749\n",
            "Epoch 101/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1180 - val_loss: 0.1735\n",
            "Epoch 102/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1154 - val_loss: 0.1689\n",
            "Epoch 103/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1177 - val_loss: 0.1913\n",
            "Epoch 104/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1118 - val_loss: 0.1756\n",
            "Epoch 105/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1243 - val_loss: 0.1753\n",
            "Epoch 106/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1146 - val_loss: 0.1976\n",
            "Epoch 107/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1130 - val_loss: 0.1594\n",
            "Epoch 108/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1209 - val_loss: 0.1742\n",
            "Epoch 109/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1070 - val_loss: 0.1811\n",
            "Epoch 110/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1106 - val_loss: 0.1583\n",
            "Epoch 111/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1022 - val_loss: 0.1838\n",
            "Epoch 112/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1128 - val_loss: 0.1657\n",
            "Epoch 113/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1106 - val_loss: 0.1706\n",
            "Epoch 114/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1150 - val_loss: 0.1795\n",
            "Epoch 115/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1094 - val_loss: 0.1767\n",
            "Epoch 116/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1166 - val_loss: 0.1845\n",
            "Epoch 117/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1146 - val_loss: 0.1820\n",
            "Epoch 118/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1167 - val_loss: 0.1909\n",
            "Epoch 119/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1045 - val_loss: 0.1912\n",
            "Epoch 120/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1143 - val_loss: 0.1753\n",
            "Epoch 121/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1121 - val_loss: 0.1861\n",
            "Epoch 122/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1160 - val_loss: 0.1761\n",
            "Epoch 123/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1047 - val_loss: 0.1761\n",
            "Epoch 124/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1194 - val_loss: 0.1734\n",
            "Epoch 125/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1046 - val_loss: 0.1826\n",
            "Epoch 126/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1036 - val_loss: 0.1779\n",
            "Epoch 127/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1140 - val_loss: 0.1961\n",
            "Epoch 128/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1205 - val_loss: 0.1665\n",
            "Epoch 129/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1255 - val_loss: 0.1913\n",
            "Epoch 130/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1033 - val_loss: 0.1905\n",
            "Epoch 131/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1069 - val_loss: 0.1875\n",
            "Epoch 132/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1140 - val_loss: 0.1832\n",
            "Epoch 133/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1130 - val_loss: 0.1888\n",
            "Epoch 134/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1160 - val_loss: 0.1852\n",
            "Epoch 135/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0937 - val_loss: 0.1969\n",
            "Epoch 136/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1106 - val_loss: 0.1834\n",
            "Epoch 137/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1033 - val_loss: 0.1861\n",
            "Epoch 138/686\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.1121 - val_loss: 0.1901\n",
            "Epoch 139/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1038 - val_loss: 0.1973\n",
            "Epoch 140/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1025 - val_loss: 0.1966\n",
            "Epoch 141/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1100 - val_loss: 0.2060\n",
            "Epoch 142/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1018 - val_loss: 0.1841\n",
            "Epoch 143/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1026 - val_loss: 0.1983\n",
            "Epoch 144/686\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1099 - val_loss: 0.1909\n",
            "Epoch 145/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1028 - val_loss: 0.2156\n",
            "Epoch 146/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1151 - val_loss: 0.1893\n",
            "Epoch 147/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1021 - val_loss: 0.1894\n",
            "Epoch 148/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1077 - val_loss: 0.1890\n",
            "Epoch 149/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1051 - val_loss: 0.1823\n",
            "Epoch 150/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1042 - val_loss: 0.2000\n",
            "Epoch 151/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1043 - val_loss: 0.1981\n",
            "Epoch 152/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1116 - val_loss: 0.1972\n",
            "Epoch 153/686\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1120 - val_loss: 0.1786\n",
            "Epoch 154/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1039 - val_loss: 0.1970\n",
            "Epoch 155/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1011 - val_loss: 0.1995\n",
            "Epoch 156/686\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1154 - val_loss: 0.1755\n",
            "Epoch 157/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1217 - val_loss: 0.1980\n",
            "Epoch 158/686\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1054 - val_loss: 0.1859\n",
            "Epoch 159/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1078 - val_loss: 0.1823\n",
            "Epoch 160/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1047 - val_loss: 0.1839\n",
            "Epoch 161/686\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1045 - val_loss: 0.2024\n",
            "(149, 10, 1)\n",
            "(149, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4478 - val_loss: 0.0734\n",
            "Epoch 2/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3894 - val_loss: 0.1612\n",
            "Epoch 3/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3315 - val_loss: 0.2701\n",
            "Epoch 4/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2844 - val_loss: 0.3690\n",
            "Epoch 5/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2543 - val_loss: 0.4168\n",
            "Epoch 6/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2321 - val_loss: 0.3813\n",
            "Epoch 7/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2126 - val_loss: 0.3354\n",
            "Epoch 8/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1818 - val_loss: 0.3080\n",
            "Epoch 9/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1619 - val_loss: 0.2638\n",
            "Epoch 10/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1472 - val_loss: 0.2639\n",
            "Epoch 11/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1316 - val_loss: 0.2226\n",
            "Epoch 12/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1494 - val_loss: 0.2908\n",
            "Epoch 13/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1531 - val_loss: 0.1861\n",
            "Epoch 14/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2135\n",
            "Epoch 15/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1470 - val_loss: 0.2355\n",
            "Epoch 16/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1434 - val_loss: 0.2044\n",
            "Epoch 17/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1261 - val_loss: 0.2167\n",
            "Epoch 18/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1246 - val_loss: 0.2146\n",
            "Epoch 19/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1168 - val_loss: 0.1887\n",
            "Epoch 20/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1244 - val_loss: 0.2181\n",
            "Epoch 21/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1227 - val_loss: 0.1679\n",
            "Epoch 22/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1380 - val_loss: 0.2050\n",
            "Epoch 23/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1330 - val_loss: 0.1681\n",
            "Epoch 24/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1450 - val_loss: 0.1781\n",
            "Epoch 25/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1227 - val_loss: 0.1858\n",
            "Epoch 26/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1204 - val_loss: 0.1867\n",
            "Epoch 27/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1105 - val_loss: 0.1678\n",
            "Epoch 28/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1143 - val_loss: 0.1911\n",
            "Epoch 29/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1084 - val_loss: 0.1585\n",
            "Epoch 30/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1116 - val_loss: 0.1777\n",
            "Epoch 31/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1038 - val_loss: 0.1704\n",
            "Epoch 32/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1036 - val_loss: 0.1733\n",
            "Epoch 33/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1019 - val_loss: 0.1752\n",
            "Epoch 34/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0988 - val_loss: 0.1646\n",
            "Epoch 35/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1017 - val_loss: 0.1889\n",
            "Epoch 36/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0976 - val_loss: 0.1657\n",
            "Epoch 37/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0980 - val_loss: 0.1790\n",
            "Epoch 38/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1014 - val_loss: 0.2119\n",
            "Epoch 39/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0990 - val_loss: 0.1512\n",
            "Epoch 40/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1082 - val_loss: 0.2207\n",
            "Epoch 41/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1003 - val_loss: 0.2252\n",
            "Epoch 42/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1120 - val_loss: 0.1341\n",
            "Epoch 43/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1606 - val_loss: 0.2224\n",
            "Epoch 44/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1297 - val_loss: 0.1715\n",
            "Epoch 45/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1344 - val_loss: 0.2056\n",
            "Epoch 46/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1165 - val_loss: 0.1782\n",
            "Epoch 47/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1228 - val_loss: 0.2158\n",
            "Epoch 48/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1064 - val_loss: 0.1827\n",
            "Epoch 49/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1057 - val_loss: 0.2214\n",
            "Epoch 50/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1001 - val_loss: 0.1805\n",
            "Epoch 51/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1004 - val_loss: 0.2221\n",
            "Epoch 52/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0947 - val_loss: 0.1870\n",
            "Epoch 53/686\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0995 - val_loss: 0.2410\n",
            "Epoch 54/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0974 - val_loss: 0.1822\n",
            "Epoch 55/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1003 - val_loss: 0.2313\n",
            "Epoch 56/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0941 - val_loss: 0.2205\n",
            "Epoch 57/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0928 - val_loss: 0.2108\n",
            "Epoch 58/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0957 - val_loss: 0.2399\n",
            "Epoch 59/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0925 - val_loss: 0.2074\n",
            "Epoch 60/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0944 - val_loss: 0.2390\n",
            "Epoch 61/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0922 - val_loss: 0.2291\n",
            "Epoch 62/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0931 - val_loss: 0.2133\n",
            "Epoch 63/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0959 - val_loss: 0.2585\n",
            "Epoch 64/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0927 - val_loss: 0.2145\n",
            "Epoch 65/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0946 - val_loss: 0.2429\n",
            "Epoch 66/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0943 - val_loss: 0.2568\n",
            "Epoch 67/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0940 - val_loss: 0.1973\n",
            "Epoch 68/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1056 - val_loss: 0.2836\n",
            "Epoch 69/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0986 - val_loss: 0.1984\n",
            "Epoch 70/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1159 - val_loss: 0.2978\n",
            "Epoch 71/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1272 - val_loss: 0.1924\n",
            "Epoch 72/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1663 - val_loss: 0.2367\n",
            "Epoch 73/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1149 - val_loss: 0.2525\n",
            "Epoch 74/686\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1182 - val_loss: 0.2581\n",
            "Epoch 75/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1052 - val_loss: 0.2284\n",
            "Epoch 76/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1095 - val_loss: 0.2750\n",
            "Epoch 77/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0987 - val_loss: 0.2265\n",
            "Epoch 78/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1092 - val_loss: 0.2899\n",
            "Epoch 79/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.2246\n",
            "Epoch 80/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1119 - val_loss: 0.2906\n",
            "Epoch 81/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1085 - val_loss: 0.2281\n",
            "Epoch 82/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1266 - val_loss: 0.2763\n",
            "Epoch 83/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1185 - val_loss: 0.2312\n",
            "Epoch 84/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1351 - val_loss: 0.2670\n",
            "Epoch 85/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1058 - val_loss: 0.2543\n",
            "Epoch 86/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1136 - val_loss: 0.2719\n",
            "Epoch 87/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1053 - val_loss: 0.2333\n",
            "Epoch 88/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.2637\n",
            "Epoch 89/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1013 - val_loss: 0.2349\n",
            "Epoch 90/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1071 - val_loss: 0.2838\n",
            "Epoch 91/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1001 - val_loss: 0.2257\n",
            "Epoch 92/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1084 - val_loss: 0.2732\n",
            "Epoch 93/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1034 - val_loss: 0.2287\n",
            "Epoch 94/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1101 - val_loss: 0.2766\n",
            "Epoch 95/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1039 - val_loss: 0.2299\n",
            "Epoch 96/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1117 - val_loss: 0.2781\n",
            "Epoch 97/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1143 - val_loss: 0.2301\n",
            "Epoch 98/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1140 - val_loss: 0.2636\n",
            "Epoch 99/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1058 - val_loss: 0.2508\n",
            "Epoch 100/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1082 - val_loss: 0.2730\n",
            "Epoch 101/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1037 - val_loss: 0.2357\n",
            "Epoch 102/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1039 - val_loss: 0.2634\n",
            "Epoch 103/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0989 - val_loss: 0.2308\n",
            "Epoch 104/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1066 - val_loss: 0.2773\n",
            "Epoch 105/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1007 - val_loss: 0.2267\n",
            "Epoch 106/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1020 - val_loss: 0.2606\n",
            "Epoch 107/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0955 - val_loss: 0.2355\n",
            "Epoch 108/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1014 - val_loss: 0.2651\n",
            "Epoch 109/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0982 - val_loss: 0.2275\n",
            "Epoch 110/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1070 - val_loss: 0.2761\n",
            "Epoch 111/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1008 - val_loss: 0.2212\n",
            "Epoch 112/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1063 - val_loss: 0.2725\n",
            "Epoch 113/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0993 - val_loss: 0.2253\n",
            "Epoch 114/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1085 - val_loss: 0.2730\n",
            "Epoch 115/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1024 - val_loss: 0.2281\n",
            "Epoch 116/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1065 - val_loss: 0.2642\n",
            "Epoch 117/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1007 - val_loss: 0.2377\n",
            "Epoch 118/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1109 - val_loss: 0.2691\n",
            "Epoch 119/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1049 - val_loss: 0.2296\n",
            "Epoch 120/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1066 - val_loss: 0.2595\n",
            "Epoch 121/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0987 - val_loss: 0.2424\n",
            "Epoch 122/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1018 - val_loss: 0.2646\n",
            "Epoch 123/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0970 - val_loss: 0.2352\n",
            "Epoch 124/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0990 - val_loss: 0.2685\n",
            "Epoch 125/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0940 - val_loss: 0.2422\n",
            "Epoch 126/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0974 - val_loss: 0.2602\n",
            "Epoch 127/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0946 - val_loss: 0.2506\n",
            "Epoch 128/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0981 - val_loss: 0.2771\n",
            "Epoch 129/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0955 - val_loss: 0.2231\n",
            "Epoch 130/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1065 - val_loss: 0.2876\n",
            "Epoch 131/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1030 - val_loss: 0.2217\n",
            "Epoch 132/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1142 - val_loss: 0.2835\n",
            "Epoch 133/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1103 - val_loss: 0.2333\n",
            "Epoch 134/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1163 - val_loss: 0.2708\n",
            "Epoch 135/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1074 - val_loss: 0.2505\n",
            "Epoch 136/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1031 - val_loss: 0.2621\n",
            "Epoch 137/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0956 - val_loss: 0.2550\n",
            "Epoch 138/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0963 - val_loss: 0.2642\n",
            "Epoch 139/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0915 - val_loss: 0.2654\n",
            "Epoch 140/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0925 - val_loss: 0.2714\n",
            "Epoch 141/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0909 - val_loss: 0.2627\n",
            "Epoch 142/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0933 - val_loss: 0.2902\n",
            "Epoch 143/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0903 - val_loss: 0.2578\n",
            "Epoch 144/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0893 - val_loss: 0.2787\n",
            "Epoch 145/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0862 - val_loss: 0.2564\n",
            "Epoch 146/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0880 - val_loss: 0.2838\n",
            "Epoch 147/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0874 - val_loss: 0.2437\n",
            "Epoch 148/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0874 - val_loss: 0.2803\n",
            "Epoch 149/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0866 - val_loss: 0.2559\n",
            "Epoch 150/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0878 - val_loss: 0.2566\n",
            "Epoch 151/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0886 - val_loss: 0.2901\n",
            "Epoch 152/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0854 - val_loss: 0.2838\n",
            "Epoch 153/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0865 - val_loss: 0.2501\n",
            "Epoch 154/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0882 - val_loss: 0.2892\n",
            "Epoch 155/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0850 - val_loss: 0.2746\n",
            "Epoch 156/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0857 - val_loss: 0.2650\n",
            "Epoch 157/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0881 - val_loss: 0.3149\n",
            "Epoch 158/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0886 - val_loss: 0.2616\n",
            "Epoch 159/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0869 - val_loss: 0.3085\n",
            "Epoch 160/686\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0845 - val_loss: 0.2733\n",
            "Epoch 161/686\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0854 - val_loss: 0.2997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI1qlzfSLe6d"
      },
      "source": [
        "Predictions are in first print line [0,0,0..,0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spq0iI0DhTNi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e78f2a13-2bf5-4aea-89ba-00ad30841f77"
      },
      "source": [
        "\n",
        "predictions_hosp_Chambers = predictionOnPredictionLSTM(initialvalue_Chambers_hosp,look_ahead,encoder_model_Chambers)\n",
        "predictions_hosp_Chambers = predictions_hosp_Chambers.reshape(len(predictions_hosp_Chambers))\n",
        "print(predictions_hosp_Chambers)\n",
        "print(test_deaths_hosp[4][window_2:])\n",
        "print(train_deaths_hosp[4][-20:])# see again!\n",
        "#conv with 50: best (2.79) window = 2, or 2.75 with 20:\n",
        "#print(mean_absolute_error(predictions_hosp_Chambers,test_deaths_hosp[4][window_2:]))\n",
        "#print(mean_squared_log_error(predictions_hosp_Chambers,test_deaths_hosp[4][window_2:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05070187 0.04806378 0.04554209 0.04329471 0.04131039 0.03653921\n",
            " 0.03240459]\n",
            "[0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dds5LyIh2_t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "027af13f-c903-4e3d-d8ef-259a9a36089a"
      },
      "source": [
        "encoder_model_Fort_Bend,encoder_history_Fort_Bend = build_encoder_decoder_h(np.array(X_train_hosp[5][:]),np.array(X_test_hosp[5]),np.array(Y_train_hosp[5][:]),np.array(Y_test_hosp[5]),window_2)\n",
        "conv_model_Fort_Bend,conv_history_Fort_Bend = build_conv_model_h(np.array(X_train_hosp[5][:]),np.array(X_test_hosp[5]),np.array(Y_train_hosp[5][:]),np.array(Y_test_hosp[5]),window_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(161, 5, 1)\n",
            "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 99.8378 - val_loss: 25.9053\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 44.0867 - val_loss: 23.5899\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 23.2293 - val_loss: 8.3198\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 22.5067 - val_loss: 5.7155\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 21.1181 - val_loss: 9.5256\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 21.4667 - val_loss: 7.1778\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 23.1055 - val_loss: 3.6009\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 26.5583 - val_loss: 14.3114\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.6696 - val_loss: 6.2956\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 22.3335 - val_loss: 10.0705\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.0139 - val_loss: 6.3647\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 22.8456 - val_loss: 11.2254\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 20.0559 - val_loss: 12.2066\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.4080 - val_loss: 4.5575\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 24.7872 - val_loss: 14.9678\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 26.0774 - val_loss: 1.3781\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 29.9686 - val_loss: 7.3655\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.9015 - val_loss: 4.1869\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 22.4830 - val_loss: 9.4229\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.9309 - val_loss: 9.5297\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 21.9981 - val_loss: 5.0822\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.7480 - val_loss: 6.9216\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.9546 - val_loss: 4.8484\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.7799 - val_loss: 9.0055\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.2426 - val_loss: 0.7145\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 21.6765 - val_loss: 11.0737\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.8930 - val_loss: 4.0382\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.1802 - val_loss: 3.8844\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.5051 - val_loss: 3.7904\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.5051 - val_loss: 8.2301\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.9803 - val_loss: 0.1214\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 23.6348 - val_loss: 16.5175\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.4545 - val_loss: 0.4216\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 29.9088 - val_loss: 7.7733\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 21.9557 - val_loss: 8.1084\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 22.3441 - val_loss: 10.8931\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.6415 - val_loss: 5.0543\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 21.1190 - val_loss: 13.1235\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.4104 - val_loss: 1.6084\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 28.8044 - val_loss: 8.4399\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.5584 - val_loss: 5.1258\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 23.7586 - val_loss: 9.0981\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.9984 - val_loss: 7.3795\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.3955 - val_loss: 8.2575\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 18.7127 - val_loss: 9.0808\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.1413 - val_loss: 7.6385\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.4268 - val_loss: 7.2394\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 17.0322 - val_loss: 5.6241\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.1187 - val_loss: 12.7751\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.2228 - val_loss: 0.8775\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 25.8201 - val_loss: 6.0121\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 20.7629 - val_loss: 6.3699\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.2876 - val_loss: 4.1113\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.6233 - val_loss: 6.5830\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.0632 - val_loss: 2.0749\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.9607 - val_loss: 4.6642\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 20.5531 - val_loss: 1.2412\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 20.4319 - val_loss: 8.8925\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.9111 - val_loss: 1.4961\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 22.6183 - val_loss: 5.2795\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.5274 - val_loss: 0.5481\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 23.1551 - val_loss: 7.0675\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.1907 - val_loss: 0.5378\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 22.9793 - val_loss: 4.9068\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 18.9290 - val_loss: 3.6147\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 22.1622 - val_loss: 5.4202\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.7630 - val_loss: 3.1517\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.9519 - val_loss: 6.3847\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.5648 - val_loss: 6.0899\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.7288 - val_loss: 3.5224\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 17.3521 - val_loss: 4.9230\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.8215 - val_loss: 3.6061\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5694 - val_loss: 1.2434\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.4449 - val_loss: 3.8429\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.2595 - val_loss: 0.5930\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.9636 - val_loss: 7.7638\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.1599 - val_loss: 4.8444\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 18.2443 - val_loss: 4.2296\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.4371 - val_loss: 0.0306\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.4196 - val_loss: 5.2660\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.9811 - val_loss: 2.0607\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 26.2039 - val_loss: 3.2961\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.8790 - val_loss: 6.0327\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.7445 - val_loss: 5.4137\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.3444 - val_loss: 5.2927\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.7655 - val_loss: 1.8160\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.2263 - val_loss: 2.0207\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.8904 - val_loss: 1.7844\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.7494 - val_loss: 3.4068\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.5834 - val_loss: 0.0907\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 19.6260 - val_loss: 4.4452\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.7226 - val_loss: 0.7264\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.2776 - val_loss: 0.7406\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.3733 - val_loss: 3.2407\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.7158 - val_loss: 0.7054\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.0637 - val_loss: 5.3464\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.6518 - val_loss: 2.3250\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 19.1405 - val_loss: 4.6225\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.0771 - val_loss: 2.2940\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.5680 - val_loss: 11.4827\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 21.3877 - val_loss: 1.1705\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 22.6196 - val_loss: 1.6042\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.1349 - val_loss: 6.2785\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.5573 - val_loss: 1.7164\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.3386 - val_loss: 5.1856\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.7678 - val_loss: 0.7397\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 21.5849 - val_loss: 6.0007\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.8161 - val_loss: 0.2586\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.7757 - val_loss: 0.2095\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.1106 - val_loss: 3.4427\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 18.2395 - val_loss: 1.9318\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.7880 - val_loss: 6.5485\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.6838 - val_loss: 3.3876\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.5389 - val_loss: 4.9876\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.5879 - val_loss: 2.8123\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.1950 - val_loss: 0.6852\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.4389 - val_loss: 0.0673\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 19.8965 - val_loss: 5.5066\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.8631 - val_loss: 1.5008\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5260 - val_loss: 2.9035\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.8481 - val_loss: 0.8180\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.5312 - val_loss: 3.2193\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.9474 - val_loss: 1.5634\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.5222 - val_loss: 0.1910\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.3614 - val_loss: 1.6839\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.5590 - val_loss: 3.4057\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.8059 - val_loss: 1.3653\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.0824 - val_loss: 2.6811\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.3692 - val_loss: 3.7578\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.4373 - val_loss: 1.0390\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.2903 - val_loss: 1.7368\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5413 - val_loss: 4.8737\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.1374 - val_loss: 0.1562\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.5310 - val_loss: 3.3751\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.4826 - val_loss: 1.3991\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.9742 - val_loss: 1.2974\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 18.3814 - val_loss: 1.6352\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.2957 - val_loss: 1.5268\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.2249 - val_loss: 2.0740\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 17.1103 - val_loss: 0.2929\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.3365 - val_loss: 6.2272\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.9889 - val_loss: 0.3915\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 19.2395 - val_loss: 3.2887\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.2769 - val_loss: 1.2261\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.3221 - val_loss: 2.8843\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 18.9600 - val_loss: 2.0327\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.9245 - val_loss: 6.2849\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.9797 - val_loss: 0.6824\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.9305 - val_loss: 5.2094\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 17.5257 - val_loss: 0.8532\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.0900 - val_loss: 0.4196\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.4192 - val_loss: 1.7210\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.4347 - val_loss: 1.3959\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.9440 - val_loss: 2.8012\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.6165 - val_loss: 1.6637\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 14.9353 - val_loss: 0.1619\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.1462 - val_loss: 5.0139\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.9665 - val_loss: 0.7623\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 19.0660 - val_loss: 3.2450\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5256 - val_loss: 0.5456\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.1557 - val_loss: 1.2911\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.2165 - val_loss: 2.1184\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.5360 - val_loss: 0.0221\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.9058 - val_loss: 0.0704\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 19.1459 - val_loss: 0.6575\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.3359 - val_loss: 1.6078\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.7672 - val_loss: 2.4899\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.9419 - val_loss: 4.9899\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.4309 - val_loss: 2.2189\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 17.1152 - val_loss: 2.6414\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.5155 - val_loss: 0.2650\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.3371 - val_loss: 3.0373\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.5698 - val_loss: 0.6407\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.9865 - val_loss: 3.7614\n",
            "Epoch 175/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.3436 - val_loss: 1.5060\n",
            "Epoch 176/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.5250 - val_loss: 1.0621\n",
            "Epoch 177/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.8283 - val_loss: 0.4438\n",
            "Epoch 178/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.6693 - val_loss: 1.8402\n",
            "Epoch 179/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.5424 - val_loss: 1.9115\n",
            "Epoch 180/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.6771 - val_loss: 1.5549\n",
            "Epoch 181/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.9166 - val_loss: 2.7005\n",
            "Epoch 182/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.9061 - val_loss: 0.2676\n",
            "Epoch 183/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.4385 - val_loss: 4.4677\n",
            "Epoch 184/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.5104 - val_loss: 2.2559\n",
            "Epoch 185/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.5417 - val_loss: 0.4334\n",
            "Epoch 186/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.4217 - val_loss: 0.0314\n",
            "Epoch 187/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.5214 - val_loss: 0.5881\n",
            "Epoch 188/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.1104 - val_loss: 0.6362\n",
            "Epoch 189/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.5697 - val_loss: 1.2410\n",
            "Epoch 190/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.9960 - val_loss: 4.7518\n",
            "Epoch 191/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.4011 - val_loss: 3.6555\n",
            "Epoch 192/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.9857 - val_loss: 0.4613\n",
            "Epoch 193/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.3040 - val_loss: 1.6878\n",
            "Epoch 194/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.5951 - val_loss: 3.0435\n",
            "Epoch 195/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.0664 - val_loss: 1.4879\n",
            "Epoch 196/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.0262 - val_loss: 0.0048\n",
            "Epoch 197/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.5502 - val_loss: 0.7785\n",
            "Epoch 198/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.4942 - val_loss: 1.0886\n",
            "Epoch 199/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.4249 - val_loss: 2.2300\n",
            "Epoch 200/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.5923 - val_loss: 2.8191\n",
            "Epoch 201/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.2603 - val_loss: 1.4697\n",
            "Epoch 202/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.6336 - val_loss: 2.0390\n",
            "Epoch 203/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.7126 - val_loss: 0.5982\n",
            "Epoch 204/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.0083 - val_loss: 0.0802\n",
            "Epoch 205/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.5230 - val_loss: 2.0632\n",
            "Epoch 206/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.8182 - val_loss: 1.3461\n",
            "Epoch 207/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.9525 - val_loss: 0.7824\n",
            "Epoch 208/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.2049 - val_loss: 2.3798\n",
            "Epoch 209/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.1874 - val_loss: 2.9369\n",
            "Epoch 210/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.1467 - val_loss: 2.8410\n",
            "Epoch 211/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.3291 - val_loss: 1.0850\n",
            "Epoch 212/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 17.5517 - val_loss: 2.7527\n",
            "Epoch 213/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.5124 - val_loss: 0.7629\n",
            "Epoch 214/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.6785 - val_loss: 0.4438\n",
            "Epoch 215/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.2571 - val_loss: 1.7372\n",
            "Epoch 216/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.6214 - val_loss: 3.0936\n",
            "Epoch 217/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.2914 - val_loss: 1.4408\n",
            "Epoch 218/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.6104 - val_loss: 1.3677\n",
            "Epoch 219/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.7371 - val_loss: 0.7133\n",
            "Epoch 220/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.2517 - val_loss: 3.3891\n",
            "Epoch 221/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.8833 - val_loss: 2.9729\n",
            "Epoch 222/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.4139 - val_loss: 1.3040\n",
            "Epoch 223/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.8479 - val_loss: 0.4158\n",
            "Epoch 224/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.9053 - val_loss: 0.4800\n",
            "Epoch 225/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.1506 - val_loss: 2.1323\n",
            "Epoch 226/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.9490 - val_loss: 2.2016\n",
            "Epoch 227/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.5693 - val_loss: 1.1594\n",
            "Epoch 228/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5659 - val_loss: 0.8208\n",
            "Epoch 229/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.8443 - val_loss: 1.0616\n",
            "Epoch 230/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.8764 - val_loss: 3.3831\n",
            "Epoch 231/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.3051 - val_loss: 6.0129\n",
            "Epoch 232/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.2683 - val_loss: 1.6153\n",
            "Epoch 233/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.7389 - val_loss: 1.4977\n",
            "Epoch 234/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.4251 - val_loss: 1.5661\n",
            "Epoch 235/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.2860 - val_loss: 0.7004\n",
            "Epoch 236/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.7316 - val_loss: 4.7655\n",
            "Epoch 237/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.3157 - val_loss: 0.0448\n",
            "Epoch 238/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.8357 - val_loss: 1.7180\n",
            "Epoch 239/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 19.0309 - val_loss: 0.0574\n",
            "Epoch 240/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.6255 - val_loss: 2.3686\n",
            "Epoch 241/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.7750 - val_loss: 1.1178\n",
            "Epoch 242/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.7350 - val_loss: 1.0756\n",
            "Epoch 243/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.2611 - val_loss: 1.4619\n",
            "Epoch 244/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.7042 - val_loss: 1.0449\n",
            "Epoch 245/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.3131 - val_loss: 0.1376\n",
            "Epoch 246/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.2488 - val_loss: 0.0351\n",
            "Epoch 247/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.3184 - val_loss: 1.3500\n",
            "Epoch 248/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 13.5234 - val_loss: 1.1821\n",
            "Epoch 249/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 14.6056 - val_loss: 1.9768\n",
            "Epoch 250/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.9443 - val_loss: 0.5155\n",
            "Epoch 251/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.9090 - val_loss: 2.4765\n",
            "Epoch 252/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5422 - val_loss: 2.0697\n",
            "Epoch 253/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.7202 - val_loss: 0.3016\n",
            "Epoch 254/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.2564 - val_loss: 0.7220\n",
            "Epoch 255/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.7388 - val_loss: 2.6178\n",
            "Epoch 256/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.5965 - val_loss: 2.8352\n",
            "Epoch 257/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.6019 - val_loss: 1.2295\n",
            "Epoch 258/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.0902 - val_loss: 0.3357\n",
            "Epoch 259/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.9537 - val_loss: 1.1697\n",
            "Epoch 260/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.3792 - val_loss: 0.4808\n",
            "Epoch 261/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.3144 - val_loss: 0.0185\n",
            "Epoch 262/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.4347 - val_loss: 0.0970\n",
            "Epoch 263/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.8760 - val_loss: 1.4075\n",
            "Epoch 264/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.6424 - val_loss: 2.4512\n",
            "Epoch 265/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.4059 - val_loss: 0.9101\n",
            "Epoch 266/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.1231 - val_loss: 1.4682\n",
            "Epoch 267/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.2998 - val_loss: 0.5364\n",
            "Epoch 268/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.6239 - val_loss: 0.7181\n",
            "Epoch 269/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.6677 - val_loss: 0.6854\n",
            "Epoch 270/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5995 - val_loss: 1.0118\n",
            "Epoch 271/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.2579 - val_loss: 0.3095\n",
            "Epoch 272/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 13.6441 - val_loss: 0.5970\n",
            "Epoch 273/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 13.9039 - val_loss: 1.7459\n",
            "Epoch 274/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 14.0979 - val_loss: 5.2993\n",
            "Epoch 275/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.6823 - val_loss: 3.7998\n",
            "Epoch 276/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.4164 - val_loss: 5.2517\n",
            "Epoch 277/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.5852 - val_loss: 2.2223\n",
            "Epoch 278/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.9967 - val_loss: 2.5516\n",
            "Epoch 279/686\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 19.0568 - val_loss: 2.1560\n",
            "Epoch 280/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.8732 - val_loss: 5.7358\n",
            "Epoch 281/686\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 16.7666 - val_loss: 4.9549\n",
            "Epoch 282/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.3536 - val_loss: 3.4746\n",
            "Epoch 283/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 13.8706 - val_loss: 1.4812\n",
            "Epoch 284/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.5139 - val_loss: 2.2278\n",
            "Epoch 285/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.6972 - val_loss: 7.4262\n",
            "Epoch 286/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.3481 - val_loss: 7.9125\n",
            "Epoch 287/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.2149 - val_loss: 4.6466\n",
            "Epoch 288/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.1867 - val_loss: 2.4868\n",
            "Epoch 289/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.2034 - val_loss: 2.0070\n",
            "Epoch 290/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.0843 - val_loss: 0.1141\n",
            "Epoch 291/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.0346 - val_loss: 2.6553\n",
            "Epoch 292/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.8025 - val_loss: 0.2893\n",
            "Epoch 293/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.6274 - val_loss: 2.3745\n",
            "Epoch 294/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.5004 - val_loss: 3.8105\n",
            "Epoch 295/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.6249 - val_loss: 2.3060\n",
            "Epoch 296/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 13.7299 - val_loss: 7.8900\n",
            "Epoch 297/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 17.7162 - val_loss: 7.5510\n",
            "Epoch 298/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.9186 - val_loss: 4.7242\n",
            "Epoch 299/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.2767 - val_loss: 8.2487\n",
            "Epoch 300/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.0422 - val_loss: 6.0321\n",
            "Epoch 301/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.0981 - val_loss: 3.2616\n",
            "Epoch 302/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 13.4709 - val_loss: 0.0563\n",
            "Epoch 303/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5065 - val_loss: 2.5355\n",
            "Epoch 304/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.8798 - val_loss: 1.1672\n",
            "Epoch 305/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.2755 - val_loss: 0.6580\n",
            "Epoch 306/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.4099 - val_loss: 7.2446\n",
            "Epoch 307/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 20.6641 - val_loss: 4.6527\n",
            "Epoch 308/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.8041 - val_loss: 0.9735\n",
            "Epoch 309/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.2853 - val_loss: 2.6270\n",
            "Epoch 310/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.7205 - val_loss: 2.7288\n",
            "Epoch 311/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.2889 - val_loss: 5.5315\n",
            "Epoch 312/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.2438 - val_loss: 1.4194\n",
            "Epoch 313/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.5727 - val_loss: 3.3317\n",
            "Epoch 314/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.0690 - val_loss: 1.8973\n",
            "Epoch 315/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.9814 - val_loss: 2.7359\n",
            "Epoch 316/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.8624 - val_loss: 3.0033\n",
            "Epoch 317/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.1612 - val_loss: 4.4220\n",
            "Epoch 318/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.4120 - val_loss: 3.0316\n",
            "Epoch 319/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 13.5906 - val_loss: 1.9218\n",
            "Epoch 320/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.2471 - val_loss: 2.6272\n",
            "Epoch 321/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.0876 - val_loss: 0.2306\n",
            "Epoch 322/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.1020 - val_loss: 2.2418\n",
            "Epoch 323/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.4116 - val_loss: 7.1322\n",
            "Epoch 324/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.5217 - val_loss: 4.5916\n",
            "Epoch 325/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.8858 - val_loss: 4.9982\n",
            "Epoch 326/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.6569 - val_loss: 2.6245\n",
            "Epoch 327/686\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 16.2324 - val_loss: 2.3771\n",
            "Epoch 328/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.9545 - val_loss: 0.3434\n",
            "Epoch 329/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.7541 - val_loss: 4.5316\n",
            "Epoch 330/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.7848 - val_loss: 3.2957\n",
            "Epoch 331/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.4104 - val_loss: 4.4575\n",
            "Epoch 332/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.4034 - val_loss: 5.5796\n",
            "Epoch 333/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 15.1334 - val_loss: 0.3381\n",
            "Epoch 334/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.6520 - val_loss: 1.8212\n",
            "Epoch 335/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.1512 - val_loss: 5.1887\n",
            "Epoch 336/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.1076 - val_loss: 7.5188\n",
            "Epoch 337/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.3589 - val_loss: 0.7363\n",
            "Epoch 338/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 13.6281 - val_loss: 3.6040\n",
            "Epoch 339/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.7299 - val_loss: 3.8728\n",
            "Epoch 340/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.7883 - val_loss: 1.7043\n",
            "Epoch 341/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.1347 - val_loss: 5.3044\n",
            "Epoch 342/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 13.8405 - val_loss: 3.4701\n",
            "Epoch 343/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.3552 - val_loss: 3.2225\n",
            "Epoch 344/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 12.9634 - val_loss: 4.4241\n",
            "Epoch 345/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.7410 - val_loss: 4.5064\n",
            "Epoch 346/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 14.5310 - val_loss: 1.2776\n",
            "Epoch 347/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 13.4166 - val_loss: 3.1188\n",
            "Epoch 348/686\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 15.7459 - val_loss: 0.5559\n",
            "Epoch 349/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.2538 - val_loss: 4.1179\n",
            "Epoch 350/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.1478 - val_loss: 2.1542\n",
            "Epoch 351/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.2625 - val_loss: 1.7515\n",
            "Epoch 352/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.6568 - val_loss: 4.0526\n",
            "Epoch 353/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 13.7865 - val_loss: 6.7100\n",
            "Epoch 354/686\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.5640 - val_loss: 6.6810\n",
            "Epoch 355/686\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.0801 - val_loss: 7.3836\n",
            "Epoch 356/686\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 14.5245 - val_loss: 1.5832\n",
            "(161, 5, 1)\n",
            "(161, 5, 1)\n",
            "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 96.8199 - val_loss: 28.8354\n",
            "Epoch 2/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 75.5069 - val_loss: 14.3082\n",
            "Epoch 3/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.6300 - val_loss: 13.2766\n",
            "Epoch 4/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.6229 - val_loss: 14.1120\n",
            "Epoch 5/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.9756 - val_loss: 10.9528\n",
            "Epoch 6/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.8602 - val_loss: 15.4601\n",
            "Epoch 7/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.7332 - val_loss: 14.0013\n",
            "Epoch 8/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.1113 - val_loss: 13.4765\n",
            "Epoch 9/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.5860 - val_loss: 13.4959\n",
            "Epoch 10/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.7223 - val_loss: 12.9760\n",
            "Epoch 11/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.5013 - val_loss: 12.0553\n",
            "Epoch 12/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.7548 - val_loss: 12.8473\n",
            "Epoch 13/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.2893 - val_loss: 11.3591\n",
            "Epoch 14/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.4899 - val_loss: 12.7514\n",
            "Epoch 15/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.5094 - val_loss: 12.8332\n",
            "Epoch 16/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.6678 - val_loss: 12.1859\n",
            "Epoch 17/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.2512 - val_loss: 11.2458\n",
            "Epoch 18/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.9804 - val_loss: 11.9331\n",
            "Epoch 19/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.1999 - val_loss: 11.1048\n",
            "Epoch 20/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.7765 - val_loss: 11.5941\n",
            "Epoch 21/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.0521 - val_loss: 11.2738\n",
            "Epoch 22/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.8274 - val_loss: 11.6389\n",
            "Epoch 23/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.0239 - val_loss: 10.4108\n",
            "Epoch 24/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.7212 - val_loss: 10.3012\n",
            "Epoch 25/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.9934 - val_loss: 10.1999\n",
            "Epoch 26/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4530 - val_loss: 10.2824\n",
            "Epoch 27/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.8251 - val_loss: 8.8344\n",
            "Epoch 28/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.4752 - val_loss: 9.6874\n",
            "Epoch 29/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.7548 - val_loss: 8.1627\n",
            "Epoch 30/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.6457 - val_loss: 8.9926\n",
            "Epoch 31/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.6910 - val_loss: 7.9473\n",
            "Epoch 32/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.1657 - val_loss: 10.2869\n",
            "Epoch 33/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.7283 - val_loss: 9.5640\n",
            "Epoch 34/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.6934 - val_loss: 9.1356\n",
            "Epoch 35/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.8011 - val_loss: 9.6834\n",
            "Epoch 36/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.9264 - val_loss: 8.4735\n",
            "Epoch 37/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4720 - val_loss: 6.5398\n",
            "Epoch 38/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.3781 - val_loss: 8.5283\n",
            "Epoch 39/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.5257 - val_loss: 6.8237\n",
            "Epoch 40/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.3798 - val_loss: 8.4013\n",
            "Epoch 41/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.6561 - val_loss: 6.8386\n",
            "Epoch 42/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.5407 - val_loss: 7.0934\n",
            "Epoch 43/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5656 - val_loss: 5.7630\n",
            "Epoch 44/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0783 - val_loss: 5.0478\n",
            "Epoch 45/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4646 - val_loss: 4.8574\n",
            "Epoch 46/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5985 - val_loss: 4.6509\n",
            "Epoch 47/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.3670 - val_loss: 3.9617\n",
            "Epoch 48/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4378 - val_loss: 4.3204\n",
            "Epoch 49/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2152 - val_loss: 3.1559\n",
            "Epoch 50/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5407 - val_loss: 4.2833\n",
            "Epoch 51/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.2015 - val_loss: 3.8804\n",
            "Epoch 52/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.3159 - val_loss: 2.9606\n",
            "Epoch 53/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1701 - val_loss: 2.5554\n",
            "Epoch 54/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.7287 - val_loss: 4.7957\n",
            "Epoch 55/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9848 - val_loss: 3.1075\n",
            "Epoch 56/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4883 - val_loss: 4.1045\n",
            "Epoch 57/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1224 - val_loss: 2.0053\n",
            "Epoch 58/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.7357 - val_loss: 3.8820\n",
            "Epoch 59/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8256 - val_loss: 0.0775\n",
            "Epoch 60/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.0008 - val_loss: 6.7830\n",
            "Epoch 61/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4234 - val_loss: 3.0572\n",
            "Epoch 62/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.6794 - val_loss: 8.3765\n",
            "Epoch 63/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.6397 - val_loss: 1.5121\n",
            "Epoch 64/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.8319 - val_loss: 6.1264\n",
            "Epoch 65/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.7355 - val_loss: 6.9068\n",
            "Epoch 66/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.1405 - val_loss: 5.7897\n",
            "Epoch 67/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2155 - val_loss: 4.8787\n",
            "Epoch 68/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.3208 - val_loss: 7.1518\n",
            "Epoch 69/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2330 - val_loss: 6.6757\n",
            "Epoch 70/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4450 - val_loss: 6.1742\n",
            "Epoch 71/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2290 - val_loss: 5.5153\n",
            "Epoch 72/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.3088 - val_loss: 5.4966\n",
            "Epoch 73/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.2468 - val_loss: 5.4425\n",
            "Epoch 74/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0395 - val_loss: 4.3949\n",
            "Epoch 75/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0762 - val_loss: 4.5553\n",
            "Epoch 76/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.2831 - val_loss: 4.3487\n",
            "Epoch 77/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9297 - val_loss: 3.8097\n",
            "Epoch 78/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.1416 - val_loss: 4.0491\n",
            "Epoch 79/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8292 - val_loss: 3.2996\n",
            "Epoch 80/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2981 - val_loss: 4.0032\n",
            "Epoch 81/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.1286 - val_loss: 3.3267\n",
            "Epoch 82/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.9732 - val_loss: 2.3624\n",
            "Epoch 83/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0618 - val_loss: 3.0588\n",
            "Epoch 84/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8249 - val_loss: 2.3947\n",
            "Epoch 85/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.1669 - val_loss: 3.3193\n",
            "Epoch 86/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.8108 - val_loss: 1.2253\n",
            "Epoch 87/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.6452 - val_loss: 3.1914\n",
            "Epoch 88/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8388 - val_loss: 2.4403\n",
            "Epoch 89/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1454 - val_loss: 2.5271\n",
            "Epoch 90/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7626 - val_loss: 1.8109\n",
            "Epoch 91/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2004 - val_loss: 3.3820\n",
            "Epoch 92/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8336 - val_loss: 0.6063\n",
            "Epoch 93/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.1785 - val_loss: 1.9568\n",
            "Epoch 94/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7765 - val_loss: 0.5537\n",
            "Epoch 95/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.8338 - val_loss: 0.8824\n",
            "Epoch 96/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7117 - val_loss: 0.1627\n",
            "Epoch 97/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7972 - val_loss: 0.4064\n",
            "Epoch 98/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4034 - val_loss: 0.3157\n",
            "Epoch 99/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.1617 - val_loss: 6.5377\n",
            "Epoch 100/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8738 - val_loss: 0.6188\n",
            "Epoch 101/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.6230 - val_loss: 6.6155\n",
            "Epoch 102/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4104 - val_loss: 4.0211\n",
            "Epoch 103/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.6464 - val_loss: 5.7445\n",
            "Epoch 104/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1399 - val_loss: 5.9665\n",
            "Epoch 105/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.7028 - val_loss: 4.7121\n",
            "Epoch 106/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.0005 - val_loss: 5.0544\n",
            "Epoch 107/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.0879 - val_loss: 3.4416\n",
            "Epoch 108/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.1257 - val_loss: 3.3144\n",
            "Epoch 109/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9042 - val_loss: 2.5457\n",
            "Epoch 110/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.9418 - val_loss: 1.6836\n",
            "Epoch 111/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0927 - val_loss: 0.4690\n",
            "Epoch 112/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8660 - val_loss: 0.2026\n",
            "Epoch 113/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8879 - val_loss: 0.4713\n",
            "Epoch 114/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.7811 - val_loss: 0.1813\n",
            "Epoch 115/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2616 - val_loss: 0.2262\n",
            "Epoch 116/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7835 - val_loss: 0.4524\n",
            "Epoch 117/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8401 - val_loss: 0.0951\n",
            "Epoch 118/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7465 - val_loss: 0.2264\n",
            "Epoch 119/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9238 - val_loss: 0.1910\n",
            "Epoch 120/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7368 - val_loss: 0.4746\n",
            "Epoch 121/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.5958 - val_loss: 0.3996\n",
            "Epoch 122/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.0433 - val_loss: 0.4927\n",
            "Epoch 123/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6876 - val_loss: 0.3265\n",
            "Epoch 124/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.5456 - val_loss: 0.2492\n",
            "Epoch 125/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.5033 - val_loss: 3.2982\n",
            "Epoch 126/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6377 - val_loss: 0.3247\n",
            "Epoch 127/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.0627 - val_loss: 2.4167\n",
            "Epoch 128/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.5420 - val_loss: 2.2828\n",
            "Epoch 129/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7320 - val_loss: 0.3917\n",
            "Epoch 130/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.5871 - val_loss: 0.1448\n",
            "Epoch 131/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6443 - val_loss: 0.0701\n",
            "Epoch 132/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4665 - val_loss: 0.5709\n",
            "Epoch 133/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4185 - val_loss: 0.3277\n",
            "Epoch 134/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.9931 - val_loss: 0.1523\n",
            "Epoch 135/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3883 - val_loss: 0.1708\n",
            "Epoch 136/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3014 - val_loss: 0.0907\n",
            "Epoch 137/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7485 - val_loss: 0.1189\n",
            "Epoch 138/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4267 - val_loss: 0.3607\n",
            "Epoch 139/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2469 - val_loss: 0.5598\n",
            "Epoch 140/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2854 - val_loss: 1.0798\n",
            "Epoch 141/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.4234 - val_loss: 0.1705\n",
            "Epoch 142/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2626 - val_loss: 0.0612\n",
            "Epoch 143/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6467 - val_loss: 0.4007\n",
            "Epoch 144/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.3913 - val_loss: 0.8248\n",
            "Epoch 145/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.6650 - val_loss: 0.2371\n",
            "Epoch 146/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2990 - val_loss: 0.2524\n",
            "Epoch 147/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.2786 - val_loss: 0.1404\n",
            "Epoch 148/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3105 - val_loss: 0.1456\n",
            "Epoch 149/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6471 - val_loss: 0.2807\n",
            "Epoch 150/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1997 - val_loss: 0.2625\n",
            "Epoch 151/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1602 - val_loss: 0.2535\n",
            "Epoch 152/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5437 - val_loss: 0.2020\n",
            "Epoch 153/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1570 - val_loss: 0.3710\n",
            "Epoch 154/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2441 - val_loss: 0.2624\n",
            "Epoch 155/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.7588 - val_loss: 0.2010\n",
            "Epoch 156/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.1004 - val_loss: 0.0397\n",
            "Epoch 157/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0524 - val_loss: 0.2882\n",
            "Epoch 158/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6448 - val_loss: 0.7252\n",
            "Epoch 159/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0077 - val_loss: 0.2085\n",
            "Epoch 160/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.0909 - val_loss: 1.2384\n",
            "Epoch 161/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.0275 - val_loss: 0.9280\n",
            "Epoch 162/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0394 - val_loss: 0.9980\n",
            "Epoch 163/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3774 - val_loss: 0.6330\n",
            "Epoch 164/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8425 - val_loss: 0.4670\n",
            "Epoch 165/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.1902 - val_loss: 3.3608\n",
            "Epoch 166/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1888 - val_loss: 3.3557\n",
            "Epoch 167/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5488 - val_loss: 3.1780\n",
            "Epoch 168/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0160 - val_loss: 0.1663\n",
            "Epoch 169/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.6528 - val_loss: 2.0482\n",
            "Epoch 170/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0153 - val_loss: 2.2381\n",
            "Epoch 171/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6992 - val_loss: 2.3645\n",
            "Epoch 172/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9773 - val_loss: 0.1694\n",
            "Epoch 173/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1077 - val_loss: 2.2909\n",
            "Epoch 174/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0596 - val_loss: 0.3234\n",
            "Epoch 175/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2219 - val_loss: 0.8779\n",
            "Epoch 176/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9342 - val_loss: 0.8866\n",
            "Epoch 177/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9380 - val_loss: 0.3295\n",
            "Epoch 178/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3623 - val_loss: 0.1268\n",
            "Epoch 179/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9010 - val_loss: 0.2329\n",
            "Epoch 180/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8354 - val_loss: 0.0505\n",
            "Epoch 181/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1827 - val_loss: 0.2110\n",
            "Epoch 182/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.8464 - val_loss: 0.5539\n",
            "Epoch 183/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9406 - val_loss: 0.1861\n",
            "Epoch 184/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9256 - val_loss: 0.0293\n",
            "Epoch 185/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2422 - val_loss: 0.6612\n",
            "Epoch 186/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7319 - val_loss: 0.8047\n",
            "Epoch 187/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.6979 - val_loss: 2.5758\n",
            "Epoch 188/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0274 - val_loss: 4.0263\n",
            "Epoch 189/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4597 - val_loss: 2.9583\n",
            "Epoch 190/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8370 - val_loss: 1.4506\n",
            "Epoch 191/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4488 - val_loss: 4.8498\n",
            "Epoch 192/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1102 - val_loss: 0.9889\n",
            "Epoch 193/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8201 - val_loss: 2.9340\n",
            "Epoch 194/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8619 - val_loss: 1.0998\n",
            "Epoch 195/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2902 - val_loss: 1.4459\n",
            "Epoch 196/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7255 - val_loss: 0.2815\n",
            "Epoch 197/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7064 - val_loss: 0.9659\n",
            "Epoch 198/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0803 - val_loss: 0.0847\n",
            "Epoch 199/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6956 - val_loss: 0.4484\n",
            "Epoch 200/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6788 - val_loss: 0.5602\n",
            "Epoch 201/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.8070 - val_loss: 0.3929\n",
            "Epoch 202/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0233 - val_loss: 0.1945\n",
            "Epoch 203/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6844 - val_loss: 0.0560\n",
            "Epoch 204/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5424 - val_loss: 0.5364\n",
            "Epoch 205/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6588 - val_loss: 2.4322\n",
            "Epoch 206/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7366 - val_loss: 0.5014\n",
            "Epoch 207/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6809 - val_loss: 0.7911\n",
            "Epoch 208/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.0716 - val_loss: 1.1976\n",
            "Epoch 209/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7076 - val_loss: 0.0145\n",
            "Epoch 210/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5648 - val_loss: 0.7484\n",
            "Epoch 211/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0290 - val_loss: 0.7977\n",
            "Epoch 212/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5399 - val_loss: 0.3541\n",
            "Epoch 213/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.3998 - val_loss: 0.3606\n",
            "Epoch 214/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.0498 - val_loss: 1.3173\n",
            "Epoch 215/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5487 - val_loss: 0.9879\n",
            "Epoch 216/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4701 - val_loss: 0.6885\n",
            "Epoch 217/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8758 - val_loss: 3.8598\n",
            "Epoch 218/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0382 - val_loss: 4.3773\n",
            "Epoch 219/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2168 - val_loss: 3.6058\n",
            "Epoch 220/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5730 - val_loss: 0.9640\n",
            "Epoch 221/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.0445 - val_loss: 6.2470\n",
            "Epoch 222/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9065 - val_loss: 3.0758\n",
            "Epoch 223/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.9607 - val_loss: 5.1295\n",
            "Epoch 224/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2667 - val_loss: 1.5423\n",
            "Epoch 225/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.5099 - val_loss: 4.8638\n",
            "Epoch 226/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3115 - val_loss: 1.2549\n",
            "Epoch 227/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.2747 - val_loss: 4.1231\n",
            "Epoch 228/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.3583 - val_loss: 3.1590\n",
            "Epoch 229/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.2667 - val_loss: 3.5985\n",
            "Epoch 230/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9775 - val_loss: 2.2959\n",
            "Epoch 231/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8541 - val_loss: 3.0324\n",
            "Epoch 232/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7786 - val_loss: 1.4270\n",
            "Epoch 233/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2400 - val_loss: 2.3754\n",
            "Epoch 234/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7838 - val_loss: 0.2438\n",
            "Epoch 235/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.3436 - val_loss: 1.9636\n",
            "Epoch 236/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7378 - val_loss: 0.1539\n",
            "Epoch 237/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7964 - val_loss: 1.6812\n",
            "Epoch 238/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8469 - val_loss: 0.3594\n",
            "Epoch 239/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8684 - val_loss: 0.1536\n",
            "Epoch 240/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7728 - val_loss: 0.2746\n",
            "Epoch 241/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7447 - val_loss: 1.5939\n",
            "Epoch 242/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.8449 - val_loss: 0.1417\n",
            "Epoch 243/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.6501 - val_loss: 0.9990\n",
            "Epoch 244/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.8612 - val_loss: 0.1989\n",
            "Epoch 245/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5588 - val_loss: 1.0676\n",
            "Epoch 246/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0415 - val_loss: 0.1321\n",
            "Epoch 247/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6056 - val_loss: 0.1613\n",
            "Epoch 248/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5923 - val_loss: 0.8982\n",
            "Epoch 249/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7011 - val_loss: 0.0228\n",
            "Epoch 250/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5384 - val_loss: 0.5025\n",
            "Epoch 251/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7166 - val_loss: 0.0246\n",
            "Epoch 252/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4509 - val_loss: 0.9759\n",
            "Epoch 253/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6754 - val_loss: 0.1397\n",
            "Epoch 254/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.5578 - val_loss: 0.1169\n",
            "Epoch 255/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5706 - val_loss: 0.2991\n",
            "Epoch 256/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.3910 - val_loss: 0.5225\n",
            "Epoch 257/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6658 - val_loss: 0.5029\n",
            "Epoch 258/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4553 - val_loss: 0.2504\n",
            "Epoch 259/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4224 - val_loss: 0.7092\n",
            "Epoch 260/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6384 - val_loss: 0.2758\n",
            "Epoch 261/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.5165 - val_loss: 0.2675\n",
            "Epoch 262/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5928 - val_loss: 0.1807\n",
            "Epoch 263/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.3759 - val_loss: 0.0856\n",
            "Epoch 264/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4709 - val_loss: 1.1510\n",
            "Epoch 265/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7710 - val_loss: 1.6394\n",
            "Epoch 266/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3868 - val_loss: 1.2360\n",
            "Epoch 267/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5883 - val_loss: 1.6780\n",
            "Epoch 268/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.6957 - val_loss: 0.4992\n",
            "Epoch 269/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4020 - val_loss: 0.5047\n",
            "Epoch 270/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.1881 - val_loss: 5.4478\n",
            "Epoch 271/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9254 - val_loss: 0.6347\n",
            "Epoch 272/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4316 - val_loss: 1.9924\n",
            "Epoch 273/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3976 - val_loss: 2.4317\n",
            "Epoch 274/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.3210 - val_loss: 4.0761\n",
            "Epoch 275/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6788 - val_loss: 0.6535\n",
            "Epoch 276/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9938 - val_loss: 0.1181\n",
            "Epoch 277/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3209 - val_loss: 0.3537\n",
            "Epoch 278/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.5450 - val_loss: 0.9653\n",
            "Epoch 279/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.2400 - val_loss: 0.7476\n",
            "Epoch 280/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.3961 - val_loss: 1.8671\n",
            "Epoch 281/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.2745 - val_loss: 0.6503\n",
            "Epoch 282/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2271 - val_loss: 0.1781\n",
            "Epoch 283/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.2926 - val_loss: 0.1632\n",
            "Epoch 284/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0419 - val_loss: 0.2644\n",
            "Epoch 285/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3562 - val_loss: 2.5730\n",
            "Epoch 286/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.3417 - val_loss: 0.3744\n",
            "Epoch 287/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4220 - val_loss: 0.8520\n",
            "Epoch 288/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1341 - val_loss: 0.0111\n",
            "Epoch 289/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0948 - val_loss: 0.3264\n",
            "Epoch 290/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9982 - val_loss: 2.8207\n",
            "Epoch 291/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2965 - val_loss: 3.0192\n",
            "Epoch 292/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.0867 - val_loss: 2.7884\n",
            "Epoch 293/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1021 - val_loss: 0.2383\n",
            "Epoch 294/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8113 - val_loss: 2.5034\n",
            "Epoch 295/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.1867 - val_loss: 2.8865\n",
            "Epoch 296/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8097 - val_loss: 1.8240\n",
            "Epoch 297/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1872 - val_loss: 0.1759\n",
            "Epoch 298/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5932 - val_loss: 1.3471\n",
            "Epoch 299/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0957 - val_loss: 3.3112\n",
            "Epoch 300/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5440 - val_loss: 2.1587\n",
            "Epoch 301/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2083 - val_loss: 0.7683\n",
            "Epoch 302/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2255 - val_loss: 0.1297\n",
            "Epoch 303/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0173 - val_loss: 3.9074\n",
            "Epoch 304/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7024 - val_loss: 4.1727\n",
            "Epoch 305/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4763 - val_loss: 4.9689\n",
            "Epoch 306/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9390 - val_loss: 4.3990\n",
            "Epoch 307/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.5464 - val_loss: 5.7769\n",
            "Epoch 308/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.9909 - val_loss: 1.6615\n",
            "Epoch 309/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.2229 - val_loss: 4.8453\n",
            "Epoch 310/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.7255 - val_loss: 0.5808\n",
            "Epoch 311/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.4839 - val_loss: 1.8305\n",
            "Epoch 312/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.3684 - val_loss: 0.8651\n",
            "Epoch 313/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.1750 - val_loss: 4.5001\n",
            "Epoch 314/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6175 - val_loss: 0.6076\n",
            "Epoch 315/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.3815 - val_loss: 4.4988\n",
            "Epoch 316/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2301 - val_loss: 0.4532\n",
            "Epoch 317/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.3194 - val_loss: 3.1847\n",
            "Epoch 318/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0114 - val_loss: 1.4006\n",
            "Epoch 319/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.9068 - val_loss: 4.9802\n",
            "Epoch 320/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.6070 - val_loss: 0.8831\n",
            "Epoch 321/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.2378 - val_loss: 2.0787\n",
            "Epoch 322/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8987 - val_loss: 1.2679\n",
            "Epoch 323/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5300 - val_loss: 3.2497\n",
            "Epoch 324/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3566 - val_loss: 0.7121\n",
            "Epoch 325/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4394 - val_loss: 2.9638\n",
            "Epoch 326/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.5228 - val_loss: 1.1480\n",
            "Epoch 327/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7351 - val_loss: 4.6088\n",
            "Epoch 328/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2751 - val_loss: 0.8771\n",
            "Epoch 329/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4074 - val_loss: 2.1600\n",
            "Epoch 330/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9171 - val_loss: 1.7374\n",
            "Epoch 331/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.2153 - val_loss: 4.1952\n",
            "Epoch 332/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4713 - val_loss: 0.6378\n",
            "Epoch 333/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3625 - val_loss: 3.5238\n",
            "Epoch 334/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2015 - val_loss: 0.3383\n",
            "Epoch 335/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8470 - val_loss: 2.0920\n",
            "Epoch 336/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.0129 - val_loss: 0.7595\n",
            "Epoch 337/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6276 - val_loss: 2.0880\n",
            "Epoch 338/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.0257 - val_loss: 0.1753\n",
            "Epoch 339/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3856 - val_loss: 0.7053\n",
            "Epoch 340/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.9522 - val_loss: 0.4930\n",
            "Epoch 341/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1519 - val_loss: 0.1613\n",
            "Epoch 342/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8637 - val_loss: 0.2645\n",
            "Epoch 343/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.3590 - val_loss: 3.7099\n",
            "Epoch 344/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9458 - val_loss: 0.2477\n",
            "Epoch 345/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7982 - val_loss: 2.0253\n",
            "Epoch 346/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0347 - val_loss: 0.2868\n",
            "Epoch 347/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8216 - val_loss: 0.2427\n",
            "Epoch 348/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.0023 - val_loss: 1.7203\n",
            "Epoch 349/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.0759 - val_loss: 0.1744\n",
            "Epoch 350/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.9341 - val_loss: 0.5642\n",
            "Epoch 351/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9721 - val_loss: 0.9076\n",
            "Epoch 352/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.2585 - val_loss: 0.2018\n",
            "Epoch 353/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.8468 - val_loss: 0.2698\n",
            "Epoch 354/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7417 - val_loss: 0.0652\n",
            "Epoch 355/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9531 - val_loss: 0.0298\n",
            "Epoch 356/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6731 - val_loss: 0.4039\n",
            "Epoch 357/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9377 - val_loss: 2.1396\n",
            "Epoch 358/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8210 - val_loss: 1.6845\n",
            "Epoch 359/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2035 - val_loss: 2.2546\n",
            "Epoch 360/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8582 - val_loss: 0.0075\n",
            "Epoch 361/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.9948 - val_loss: 0.0114\n",
            "Epoch 362/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9470 - val_loss: 0.2463\n",
            "Epoch 363/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.6834 - val_loss: 1.3740\n",
            "Epoch 364/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4125 - val_loss: 4.2580\n",
            "Epoch 365/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0366 - val_loss: 1.8311\n",
            "Epoch 366/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9831 - val_loss: 2.3863\n",
            "Epoch 367/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.0695 - val_loss: 0.1779\n",
            "Epoch 368/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4349 - val_loss: 1.1579\n",
            "Epoch 369/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7332 - val_loss: 1.4976\n",
            "Epoch 370/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0178 - val_loss: 1.0278\n",
            "Epoch 371/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8707 - val_loss: 0.0662\n",
            "Epoch 372/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.0030 - val_loss: 0.5766\n",
            "Epoch 373/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.6104 - val_loss: 2.3956\n",
            "Epoch 374/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9849 - val_loss: 1.3772\n",
            "Epoch 375/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.9783 - val_loss: 0.0348\n",
            "Epoch 376/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0391 - val_loss: 2.2958\n",
            "Epoch 377/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7607 - val_loss: 5.6035\n",
            "Epoch 378/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.0418 - val_loss: 2.9743\n",
            "Epoch 379/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.5590 - val_loss: 4.7623\n",
            "Epoch 380/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.7468 - val_loss: 1.1706\n",
            "Epoch 381/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 19.3336 - val_loss: 1.5012\n",
            "Epoch 382/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.5344 - val_loss: 0.4739\n",
            "Epoch 383/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.0443 - val_loss: 4.1495\n",
            "Epoch 384/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5398 - val_loss: 1.0125\n",
            "Epoch 385/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.6267 - val_loss: 4.1317\n",
            "Epoch 386/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7744 - val_loss: 1.0089\n",
            "Epoch 387/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.6320 - val_loss: 4.8392\n",
            "Epoch 388/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.6531 - val_loss: 0.7111\n",
            "Epoch 389/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.7043 - val_loss: 1.9188\n",
            "Epoch 390/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4399 - val_loss: 0.3428\n",
            "Epoch 391/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0892 - val_loss: 2.7214\n",
            "Epoch 392/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.9170 - val_loss: 1.0813\n",
            "Epoch 393/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.5896 - val_loss: 2.4343\n",
            "Epoch 394/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8835 - val_loss: 0.1571\n",
            "Epoch 395/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2532 - val_loss: 1.7971\n",
            "Epoch 396/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7844 - val_loss: 0.4569\n",
            "Epoch 397/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8924 - val_loss: 0.6203\n",
            "Epoch 398/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7748 - val_loss: 0.4676\n",
            "Epoch 399/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7065 - val_loss: 0.1053\n",
            "Epoch 400/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6870 - val_loss: 0.3007\n",
            "Epoch 401/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5417 - val_loss: 0.2396\n",
            "Epoch 402/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5946 - val_loss: 0.9990\n",
            "Epoch 403/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8724 - val_loss: 2.0140\n",
            "Epoch 404/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.4719 - val_loss: 0.4653\n",
            "Epoch 405/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7968 - val_loss: 2.3238\n",
            "Epoch 406/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.6118 - val_loss: 0.2829\n",
            "Epoch 407/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.5811 - val_loss: 0.6977\n",
            "Epoch 408/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2711 - val_loss: 1.4964\n",
            "Epoch 409/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5635 - val_loss: 1.8198\n",
            "Epoch 410/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4890 - val_loss: 2.1580\n",
            "Epoch 411/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7109 - val_loss: 0.6292\n",
            "Epoch 412/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3418 - val_loss: 1.3965\n",
            "Epoch 413/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6821 - val_loss: 2.6064\n",
            "Epoch 414/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.1015 - val_loss: 1.8274\n",
            "Epoch 415/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5649 - val_loss: 0.0294\n",
            "Epoch 416/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.5848 - val_loss: 0.4151\n",
            "Epoch 417/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0262 - val_loss: 1.8571\n",
            "Epoch 418/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3931 - val_loss: 1.6151\n",
            "Epoch 419/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1024 - val_loss: 1.9857\n",
            "Epoch 420/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.5460 - val_loss: 0.2053\n",
            "Epoch 421/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6225 - val_loss: 0.1386\n",
            "Epoch 422/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3095 - val_loss: 1.9993\n",
            "Epoch 423/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.6286 - val_loss: 1.4816\n",
            "Epoch 424/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.6402 - val_loss: 0.3983\n",
            "Epoch 425/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4977 - val_loss: 0.2609\n",
            "Epoch 426/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4536 - val_loss: 1.5309\n",
            "Epoch 427/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.8334 - val_loss: 3.5749\n",
            "Epoch 428/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9140 - val_loss: 2.1543\n",
            "Epoch 429/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.8286 - val_loss: 3.7452\n",
            "Epoch 430/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4931 - val_loss: 2.1876\n",
            "Epoch 431/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.2040 - val_loss: 5.0112\n",
            "Epoch 432/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9553 - val_loss: 1.8006\n",
            "Epoch 433/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.0680 - val_loss: 3.9046\n",
            "Epoch 434/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.4358 - val_loss: 1.5595\n",
            "Epoch 435/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.8653 - val_loss: 3.6160\n",
            "Epoch 436/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3098 - val_loss: 0.5924\n",
            "Epoch 437/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.8439 - val_loss: 2.6914\n",
            "Epoch 438/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7598 - val_loss: 0.0982\n",
            "Epoch 439/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.0754 - val_loss: 2.7340\n",
            "Epoch 440/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.2419 - val_loss: 1.3802\n",
            "Epoch 441/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.8530 - val_loss: 2.5360\n",
            "Epoch 442/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4578 - val_loss: 0.9235\n",
            "Epoch 443/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.6382 - val_loss: 3.0187\n",
            "Epoch 444/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0834 - val_loss: 1.3910\n",
            "Epoch 445/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3478 - val_loss: 1.8358\n",
            "Epoch 446/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7042 - val_loss: 0.8635\n",
            "Epoch 447/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9151 - val_loss: 2.8581\n",
            "Epoch 448/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7592 - val_loss: 0.1032\n",
            "Epoch 449/686\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.3888 - val_loss: 1.2996\n",
            "Epoch 450/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6609 - val_loss: 1.2104\n",
            "Epoch 451/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9821 - val_loss: 2.5971\n",
            "Epoch 452/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7186 - val_loss: 0.3992\n",
            "Epoch 453/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7352 - val_loss: 0.8708\n",
            "Epoch 454/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4249 - val_loss: 0.8903\n",
            "Epoch 455/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5380 - val_loss: 0.1330\n",
            "Epoch 456/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.3924 - val_loss: 0.2184\n",
            "Epoch 457/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.3714 - val_loss: 0.3268\n",
            "Epoch 458/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2300 - val_loss: 1.9395\n",
            "Epoch 459/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3124 - val_loss: 0.1449\n",
            "Epoch 460/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4016 - val_loss: 0.1446\n",
            "Epoch 461/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1440 - val_loss: 1.1785\n",
            "Epoch 462/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4019 - val_loss: 0.2365\n",
            "Epoch 463/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.1616 - val_loss: 0.0487\n",
            "Epoch 464/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.0800 - val_loss: 1.0442\n",
            "Epoch 465/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.8014 - val_loss: 1.4344\n",
            "Epoch 466/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8084 - val_loss: 0.1634\n",
            "Epoch 467/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.3769 - val_loss: 0.3037\n",
            "Epoch 468/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.9879 - val_loss: 0.9543\n",
            "Epoch 469/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8679 - val_loss: 2.3156\n",
            "Epoch 470/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2701 - val_loss: 1.5329\n",
            "Epoch 471/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9368 - val_loss: 3.2681\n",
            "Epoch 472/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5425 - val_loss: 2.2840\n",
            "Epoch 473/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9067 - val_loss: 2.9160\n",
            "Epoch 474/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5369 - val_loss: 1.3264\n",
            "Epoch 475/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7428 - val_loss: 3.0412\n",
            "Epoch 476/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7352 - val_loss: 2.2741\n",
            "Epoch 477/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8143 - val_loss: 2.9808\n",
            "Epoch 478/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0297 - val_loss: 2.0727\n",
            "Epoch 479/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.6843 - val_loss: 3.2907\n",
            "Epoch 480/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.6441 - val_loss: 2.4542\n",
            "Epoch 481/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.3763 - val_loss: 3.3334\n",
            "Epoch 482/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.1281 - val_loss: 1.4094\n",
            "Epoch 483/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.7112 - val_loss: 4.3610\n",
            "Epoch 484/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5847 - val_loss: 1.4119\n",
            "Epoch 485/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0236 - val_loss: 3.5707\n",
            "Epoch 486/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.8454 - val_loss: 0.7644\n",
            "Epoch 487/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.2250 - val_loss: 2.9875\n",
            "Epoch 488/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4156 - val_loss: 1.0743\n",
            "Epoch 489/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.3467 - val_loss: 2.1157\n",
            "Epoch 490/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3194 - val_loss: 1.1825\n",
            "Epoch 491/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.2264 - val_loss: 2.0659\n",
            "Epoch 492/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.8075 - val_loss: 1.2592\n",
            "Epoch 493/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8845 - val_loss: 1.7978\n",
            "Epoch 494/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6069 - val_loss: 0.6058\n",
            "Epoch 495/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.2993 - val_loss: 2.9177\n",
            "Epoch 496/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7575 - val_loss: 1.4550\n",
            "Epoch 497/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.3924 - val_loss: 2.6274\n",
            "Epoch 498/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.6487 - val_loss: 1.7934\n",
            "Epoch 499/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.8926 - val_loss: 3.1355\n",
            "Epoch 500/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7354 - val_loss: 1.6681\n",
            "Epoch 501/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9251 - val_loss: 2.7980\n",
            "Epoch 502/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7809 - val_loss: 1.3094\n",
            "Epoch 503/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7698 - val_loss: 3.1531\n",
            "Epoch 504/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7190 - val_loss: 0.5601\n",
            "Epoch 505/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.0729 - val_loss: 2.0487\n",
            "Epoch 506/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.2581 - val_loss: 0.5776\n",
            "Epoch 507/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.6125 - val_loss: 1.9135\n",
            "Epoch 508/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5093 - val_loss: 1.4351\n",
            "Epoch 509/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.0390 - val_loss: 2.3810\n",
            "Epoch 510/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2605 - val_loss: 1.5628\n",
            "Epoch 511/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9274 - val_loss: 1.7842\n",
            "Epoch 512/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1802 - val_loss: 0.8145\n",
            "Epoch 513/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7405 - val_loss: 2.3396\n",
            "Epoch 514/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.2179 - val_loss: 0.7018\n",
            "Epoch 515/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3451 - val_loss: 1.1197\n",
            "Epoch 516/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2242 - val_loss: 0.3205\n",
            "Epoch 517/686\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.0708 - val_loss: 0.0651\n",
            "Epoch 518/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.9586 - val_loss: 0.5022\n",
            "Epoch 519/686\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.6788 - val_loss: 1.3998\n",
            "Epoch 520/686\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3940 - val_loss: 2.8653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC1P34KYlQP8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b57969c6-41cf-4bb6-c30b-3168e622ebcf"
      },
      "source": [
        "\n",
        "predictions_hosp_Fort_Bend = predictionOnPredictionLSTM(initialvalue_Fort_Bend_hosp,look_ahead,conv_model_Fort_Bend)\n",
        "predictions_hosp_Fort_Bend = predictions_hosp_Fort_Bend.reshape(len(predictions_hosp_Fort_Bend))\n",
        "print(predictions_hosp_Fort_Bend)\n",
        "print(test_deaths_hosp[5][window_2:])\n",
        "print(train_deaths_hosp[5][-20:])# see again!\n",
        "#encoder with 50: best (3.5317) window = 25, or 2.75 with 50: with expma, also try window = 15\n",
        "#print(mean_absolute_error(predictions_hosp_Fort_Bend,test_deaths_hosp[5][window_2:]))\n",
        "#print(mean_squared_log_error(predictions_hosp_Fort_Bend,test_deaths_hosp[5][window_2:]))\n",
        "#[51.001987 49.12187  47.398655 44.517857 41.71608  38.55071  36.288105]\n",
        "#[51.975143 52.42597  50.32082  49.313362 46.811794 45.39326  42.778282] 1st week\n",
        "#36.484318 34.11702  32.082085 30.432217 28.57373  26.796574 25.251715 \n",
        "#39.46749  37.984047 36.92402  35.572926 34.42708  33.356216 32.413094 2nd week\n",
        "#[39.00485  37.541004 34.439774 31.94413  30.508825 29.098776 28.484945]2nd week (ensemble)\n",
        "#[38.99247  41.878197 38.14488  37.15999  34.40238  32.872955 31.187769] 2nd week"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[38.99247  41.878197 38.14488  37.15999  34.40238  32.872955 31.187769]\n",
            "[39]\n",
            "[80 77 70 75 67 61 50 71 64 65 61 62 51 54 51 70 52 44 45 39]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8ELd09ElzdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c043e681-ed76-4896-c4ea-4391a78469f8"
      },
      "source": [
        "encoder_model_Austin,encoder_history_Austin = build_encoder_decoder_h(np.array(X_train_hosp[7][50:]),np.array(X_test_hosp[7]),np.array(Y_train_hosp[7][50:]),np.array(Y_test_hosp[7]),window_2)\n",
        "conv_model_Austin,conv_history_Austin = build_conv_model_h(np.array(X_train_hosp[7][50:]),np.array(X_test_hosp[7]),np.array(Y_train_hosp[7][50:]),np.array(Y_test_hosp[7]),window_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(86, 15, 1)\n",
            "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.4205 - val_loss: 5.5732e-04\n",
            "Epoch 2/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4189 - val_loss: 2.3395e-04\n",
            "Epoch 3/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4193 - val_loss: 1.1139e-04\n",
            "Epoch 4/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.4191 - val_loss: 2.6423e-04\n",
            "Epoch 5/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4191 - val_loss: 2.5769e-04\n",
            "Epoch 6/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4191 - val_loss: 0.0012\n",
            "Epoch 7/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4196 - val_loss: 8.8230e-04\n",
            "Epoch 8/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4188 - val_loss: 1.1026e-04\n",
            "Epoch 9/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4194 - val_loss: 4.6096e-04\n",
            "Epoch 10/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4189 - val_loss: 3.1117e-04\n",
            "Epoch 11/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4190 - val_loss: 0.0012\n",
            "Epoch 12/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4189 - val_loss: 8.9910e-04\n",
            "Epoch 13/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4188 - val_loss: 9.1709e-04\n",
            "Epoch 14/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.4187 - val_loss: 2.5330e-04\n",
            "Epoch 15/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.4188 - val_loss: 3.5555e-04\n",
            "Epoch 16/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.4191 - val_loss: 1.5466e-04\n",
            "Epoch 17/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4183 - val_loss: 2.7055e-04\n",
            "Epoch 18/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4184 - val_loss: 2.9811e-04\n",
            "Epoch 19/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4189 - val_loss: 1.0150e-04\n",
            "Epoch 20/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4187 - val_loss: 2.8962e-04\n",
            "Epoch 21/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4190 - val_loss: 3.5317e-05\n",
            "Epoch 22/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4187 - val_loss: 1.0459e-04\n",
            "Epoch 23/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.4189 - val_loss: 4.2133e-05\n",
            "Epoch 24/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.4188 - val_loss: 9.9220e-05\n",
            "Epoch 25/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.4184 - val_loss: 5.4752e-04\n",
            "Epoch 26/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.4189 - val_loss: 3.7733e-05\n",
            "Epoch 27/686\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.4185 - val_loss: 3.3922e-04\n",
            "Epoch 28/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.4187 - val_loss: 1.3221e-04\n",
            "Epoch 29/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.4185 - val_loss: 8.7088e-04\n",
            "Epoch 30/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.4190 - val_loss: 6.8767e-04\n",
            "Epoch 31/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4187 - val_loss: 0.0012\n",
            "Epoch 32/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4186 - val_loss: 2.7295e-04\n",
            "Epoch 33/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4186 - val_loss: 2.4820e-04\n",
            "Epoch 34/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4188 - val_loss: 6.2954e-05\n",
            "Epoch 35/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4183 - val_loss: 4.6011e-05\n",
            "Epoch 36/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4181 - val_loss: 6.1179e-05\n",
            "Epoch 37/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4182 - val_loss: 2.7349e-04\n",
            "Epoch 38/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4185 - val_loss: 1.0226e-04\n",
            "Epoch 39/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4187 - val_loss: 9.7244e-04\n",
            "Epoch 40/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.4184 - val_loss: 5.0685e-04\n",
            "Epoch 41/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4188 - val_loss: 5.4867e-04\n",
            "Epoch 42/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4188 - val_loss: 5.4999e-04\n",
            "Epoch 43/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.4185 - val_loss: 0.0010\n",
            "Epoch 44/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.4185 - val_loss: 1.4530e-04\n",
            "Epoch 45/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.4181 - val_loss: 3.2668e-04\n",
            "Epoch 46/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.4183 - val_loss: 5.0942e-04\n",
            "Epoch 47/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4181 - val_loss: 0.0010\n",
            "Epoch 48/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.4184 - val_loss: 3.1576e-04\n",
            "Epoch 49/686\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.4177 - val_loss: 5.1909e-04\n",
            "Epoch 50/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.4177 - val_loss: 2.7845e-04\n",
            "Epoch 51/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.4173 - val_loss: 8.3425e-04\n",
            "Epoch 52/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.4163 - val_loss: 3.0021e-04\n",
            "Epoch 53/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4167 - val_loss: 7.1237e-04\n",
            "Epoch 54/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4155 - val_loss: 9.2727e-05\n",
            "Epoch 55/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.4163 - val_loss: 6.7743e-04\n",
            "Epoch 56/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4148 - val_loss: 2.9468e-04\n",
            "Epoch 57/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4126 - val_loss: 5.2212e-04\n",
            "Epoch 58/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.4119 - val_loss: 5.7231e-04\n",
            "Epoch 59/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4048 - val_loss: 0.0012\n",
            "Epoch 60/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4029 - val_loss: 0.0011\n",
            "Epoch 61/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4064 - val_loss: 3.4298e-04\n",
            "Epoch 62/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4038 - val_loss: 8.6059e-04\n",
            "Epoch 63/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3941 - val_loss: 5.3324e-04\n",
            "Epoch 64/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4045 - val_loss: 0.0016\n",
            "Epoch 65/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3998 - val_loss: 2.2083e-04\n",
            "Epoch 66/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3899 - val_loss: 9.1888e-05\n",
            "Epoch 67/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3947 - val_loss: 4.7934e-05\n",
            "Epoch 68/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3910 - val_loss: 4.1177e-04\n",
            "Epoch 69/686\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.3948 - val_loss: 4.7158e-04\n",
            "Epoch 70/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3848 - val_loss: 6.6926e-04\n",
            "Epoch 71/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3872 - val_loss: 1.3482e-05\n",
            "Epoch 72/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3906 - val_loss: 3.0840e-04\n",
            "Epoch 73/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3926 - val_loss: 3.4931e-04\n",
            "Epoch 74/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3864 - val_loss: 1.9226e-04\n",
            "Epoch 75/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3811 - val_loss: 6.3982e-04\n",
            "Epoch 76/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3861 - val_loss: 6.1759e-04\n",
            "Epoch 77/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3828 - val_loss: 0.0011\n",
            "Epoch 78/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3845 - val_loss: 4.3415e-05\n",
            "Epoch 79/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3939 - val_loss: 1.6585e-04\n",
            "Epoch 80/686\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.3788 - val_loss: 1.8681e-05\n",
            "Epoch 81/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3843 - val_loss: 2.2213e-04\n",
            "Epoch 82/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3832 - val_loss: 2.9697e-04\n",
            "Epoch 83/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3778 - val_loss: 5.3205e-04\n",
            "Epoch 84/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3680 - val_loss: 7.4276e-04\n",
            "Epoch 85/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.4801 - val_loss: 8.8039e-04\n",
            "Epoch 86/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3769 - val_loss: 0.0030\n",
            "Epoch 87/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3873 - val_loss: 6.2477e-04\n",
            "Epoch 88/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.3861 - val_loss: 5.5387e-04\n",
            "Epoch 89/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.3881 - val_loss: 5.8230e-04\n",
            "Epoch 90/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3884 - val_loss: 6.9428e-04\n",
            "Epoch 91/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.3867 - val_loss: 6.5638e-06\n",
            "Epoch 92/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3767 - val_loss: 7.8877e-05\n",
            "Epoch 93/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.3766 - val_loss: 3.8780e-05\n",
            "Epoch 94/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3749 - val_loss: 2.0256e-04\n",
            "Epoch 95/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.3683 - val_loss: 2.5763e-05\n",
            "Epoch 96/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3736 - val_loss: 5.8520e-04\n",
            "Epoch 97/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.3639 - val_loss: 6.9691e-04\n",
            "Epoch 98/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.5234 - val_loss: 1.2862e-04\n",
            "Epoch 99/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3896 - val_loss: 8.6770e-04\n",
            "Epoch 100/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3995 - val_loss: 1.1237e-04\n",
            "Epoch 101/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3966 - val_loss: 3.4033e-04\n",
            "Epoch 102/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.3951 - val_loss: 2.7290e-04\n",
            "Epoch 103/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3960 - val_loss: 5.2920e-04\n",
            "Epoch 104/686\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.3993 - val_loss: 3.5753e-04\n",
            "Epoch 105/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3903 - val_loss: 7.7988e-04\n",
            "Epoch 106/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3942 - val_loss: 4.1753e-04\n",
            "Epoch 107/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3898 - val_loss: 6.9583e-04\n",
            "Epoch 108/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3855 - val_loss: 1.7407e-04\n",
            "Epoch 109/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3881 - val_loss: 1.7272e-04\n",
            "Epoch 110/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3899 - val_loss: 3.6427e-05\n",
            "Epoch 111/686\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.3811 - val_loss: 2.9533e-04\n",
            "Epoch 112/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3812 - val_loss: 1.3733e-04\n",
            "Epoch 113/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3792 - val_loss: 1.6147e-04\n",
            "Epoch 114/686\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.3779 - val_loss: 7.4296e-04\n",
            "Epoch 115/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3782 - val_loss: 3.9128e-05\n",
            "Epoch 116/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3817 - val_loss: 1.0184e-04\n",
            "Epoch 117/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3738 - val_loss: 3.6648e-04\n",
            "Epoch 118/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3785 - val_loss: 9.0005e-05\n",
            "Epoch 119/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.3735 - val_loss: 2.1444e-04\n",
            "Epoch 120/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3777 - val_loss: 1.2223e-04\n",
            "Epoch 121/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3738 - val_loss: 2.0467e-04\n",
            "Epoch 122/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3816 - val_loss: 1.3701e-04\n",
            "Epoch 123/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3665 - val_loss: 2.2926e-04\n",
            "Epoch 124/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3675 - val_loss: 5.8635e-04\n",
            "Epoch 125/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3485 - val_loss: 4.1655e-04\n",
            "Epoch 126/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.3769 - val_loss: 0.0010\n",
            "Epoch 127/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3984 - val_loss: 7.4397e-05\n",
            "Epoch 128/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3902 - val_loss: 1.4273e-04\n",
            "Epoch 129/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3756 - val_loss: 3.4137e-05\n",
            "Epoch 130/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3743 - val_loss: 2.5134e-04\n",
            "Epoch 131/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3726 - val_loss: 3.4767e-04\n",
            "Epoch 132/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3758 - val_loss: 7.9574e-04\n",
            "Epoch 133/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3630 - val_loss: 4.1458e-04\n",
            "Epoch 134/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3761 - val_loss: 8.8906e-04\n",
            "Epoch 135/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3538 - val_loss: 3.5119e-04\n",
            "Epoch 136/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.3590 - val_loss: 2.2128e-04\n",
            "Epoch 137/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3523 - val_loss: 6.8698e-05\n",
            "Epoch 138/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3373 - val_loss: 5.2262e-04\n",
            "Epoch 139/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3646 - val_loss: 5.8528e-04\n",
            "Epoch 140/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.3729 - val_loss: 0.0010\n",
            "Epoch 141/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.3769 - val_loss: 2.0786e-05\n",
            "Epoch 142/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3655 - val_loss: 2.0531e-05\n",
            "Epoch 143/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3460 - val_loss: 8.7634e-04\n",
            "Epoch 144/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3429 - val_loss: 3.4757e-04\n",
            "Epoch 145/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3388 - val_loss: 7.1981e-04\n",
            "Epoch 146/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3512 - val_loss: 4.3998e-04\n",
            "Epoch 147/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3484 - val_loss: 9.7706e-04\n",
            "Epoch 148/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3204 - val_loss: 1.0260e-04\n",
            "Epoch 149/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3280 - val_loss: 4.6196e-04\n",
            "Epoch 150/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.3650 - val_loss: 8.1509e-04\n",
            "Epoch 151/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3299 - val_loss: 1.6113e-04\n",
            "Epoch 152/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3381 - val_loss: 4.8732e-05\n",
            "Epoch 153/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3342 - val_loss: 1.9137e-04\n",
            "Epoch 154/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3211 - val_loss: 3.4673e-05\n",
            "Epoch 155/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3310 - val_loss: 3.9784e-05\n",
            "Epoch 156/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3236 - val_loss: 2.4540e-04\n",
            "Epoch 157/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3095 - val_loss: 3.1623e-04\n",
            "Epoch 158/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3189 - val_loss: 8.6389e-04\n",
            "Epoch 159/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3330 - val_loss: 1.5706e-04\n",
            "Epoch 160/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3406 - val_loss: 6.9199e-04\n",
            "Epoch 161/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3595 - val_loss: 4.2791e-04\n",
            "Epoch 162/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3226 - val_loss: 5.7873e-04\n",
            "Epoch 163/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3178 - val_loss: 4.5782e-04\n",
            "Epoch 164/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3157 - val_loss: 9.7729e-04\n",
            "Epoch 165/686\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.3240 - val_loss: 2.9564e-04\n",
            "Epoch 166/686\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.3163 - val_loss: 3.4625e-04\n",
            "Epoch 167/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3253 - val_loss: 2.3769e-05\n",
            "Epoch 168/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3022 - val_loss: 1.0464e-04\n",
            "Epoch 169/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3372 - val_loss: 6.1614e-05\n",
            "Epoch 170/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3385 - val_loss: 1.6297e-04\n",
            "Epoch 171/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3206 - val_loss: 4.0012e-04\n",
            "Epoch 172/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3247 - val_loss: 6.6016e-07\n",
            "Epoch 173/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3244 - val_loss: 5.4310e-04\n",
            "Epoch 174/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3293 - val_loss: 1.1824e-04\n",
            "Epoch 175/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3225 - val_loss: 2.4165e-05\n",
            "Epoch 176/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3046 - val_loss: 5.0438e-05\n",
            "Epoch 177/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3169 - val_loss: 7.7072e-05\n",
            "Epoch 178/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2961 - val_loss: 3.3367e-04\n",
            "Epoch 179/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2849 - val_loss: 2.2342e-04\n",
            "Epoch 180/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3038 - val_loss: 8.0340e-04\n",
            "Epoch 181/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3077 - val_loss: 4.4778e-04\n",
            "Epoch 182/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3178 - val_loss: 7.2322e-04\n",
            "Epoch 183/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3095 - val_loss: 7.6010e-05\n",
            "Epoch 184/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3478 - val_loss: 4.1200e-05\n",
            "Epoch 185/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3133 - val_loss: 3.5161e-09\n",
            "Epoch 186/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3026 - val_loss: 2.8633e-04\n",
            "Epoch 187/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3020 - val_loss: 1.6463e-04\n",
            "Epoch 188/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2898 - val_loss: 1.4295e-04\n",
            "Epoch 189/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3219 - val_loss: 1.0040e-04\n",
            "Epoch 190/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3088 - val_loss: 5.2911e-05\n",
            "Epoch 191/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3063 - val_loss: 6.6249e-05\n",
            "Epoch 192/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3208 - val_loss: 2.7117e-04\n",
            "Epoch 193/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2922 - val_loss: 6.3786e-05\n",
            "Epoch 194/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3059 - val_loss: 3.8010e-04\n",
            "Epoch 195/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3099 - val_loss: 3.6533e-04\n",
            "Epoch 196/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3033 - val_loss: 0.0010\n",
            "Epoch 197/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3416 - val_loss: 4.3325e-04\n",
            "Epoch 198/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3056 - val_loss: 1.9130e-04\n",
            "Epoch 199/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3188 - val_loss: 1.6832e-04\n",
            "Epoch 200/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3168 - val_loss: 6.4888e-05\n",
            "Epoch 201/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2939 - val_loss: 2.1218e-05\n",
            "Epoch 202/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.2948 - val_loss: 2.0319e-04\n",
            "Epoch 203/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.2823 - val_loss: 3.2000e-05\n",
            "Epoch 204/686\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.3042 - val_loss: 8.0374e-05\n",
            "Epoch 205/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3084 - val_loss: 2.0066e-04\n",
            "Epoch 206/686\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.3042 - val_loss: 1.3483e-04\n",
            "Epoch 207/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.3041 - val_loss: 8.2393e-05\n",
            "Epoch 208/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2947 - val_loss: 8.2805e-05\n",
            "Epoch 209/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2984 - val_loss: 2.0350e-04\n",
            "Epoch 210/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2963 - val_loss: 1.6965e-04\n",
            "Epoch 211/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3121 - val_loss: 9.8669e-05\n",
            "Epoch 212/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3048 - val_loss: 2.1558e-04\n",
            "Epoch 213/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3148 - val_loss: 3.1004e-05\n",
            "Epoch 214/686\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.2979 - val_loss: 2.6339e-05\n",
            "Epoch 215/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.2883 - val_loss: 1.4626e-04\n",
            "Epoch 216/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2923 - val_loss: 4.9913e-04\n",
            "Epoch 217/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2819 - val_loss: 4.6877e-04\n",
            "Epoch 218/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2936 - val_loss: 7.6506e-04\n",
            "Epoch 219/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3097 - val_loss: 3.6149e-05\n",
            "Epoch 220/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2982 - val_loss: 1.9608e-04\n",
            "Epoch 221/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2997 - val_loss: 4.0574e-05\n",
            "Epoch 222/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2865 - val_loss: 2.4479e-05\n",
            "Epoch 223/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2969 - val_loss: 5.4090e-07\n",
            "Epoch 224/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2992 - val_loss: 8.6378e-05\n",
            "Epoch 225/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2936 - val_loss: 6.1138e-04\n",
            "Epoch 226/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2889 - val_loss: 2.3835e-04\n",
            "Epoch 227/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3135 - val_loss: 3.2911e-04\n",
            "Epoch 228/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2928 - val_loss: 1.3778e-04\n",
            "Epoch 229/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.2849 - val_loss: 5.3238e-04\n",
            "Epoch 230/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3096 - val_loss: 7.3893e-04\n",
            "Epoch 231/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2853 - val_loss: 8.4359e-04\n",
            "Epoch 232/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3009 - val_loss: 2.7889e-04\n",
            "Epoch 233/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2897 - val_loss: 1.4952e-04\n",
            "Epoch 234/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2955 - val_loss: 9.8582e-05\n",
            "Epoch 235/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3105 - val_loss: 1.5902e-04\n",
            "Epoch 236/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2851 - val_loss: 2.3341e-04\n",
            "Epoch 237/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3064 - val_loss: 1.1685e-04\n",
            "Epoch 238/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3161 - val_loss: 5.2439e-04\n",
            "Epoch 239/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2970 - val_loss: 2.0078e-04\n",
            "Epoch 240/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.2849 - val_loss: 2.2060e-05\n",
            "Epoch 241/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2799 - val_loss: 2.6301e-04\n",
            "Epoch 242/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2901 - val_loss: 3.4786e-04\n",
            "Epoch 243/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3044 - val_loss: 4.3749e-04\n",
            "Epoch 244/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2949 - val_loss: 2.2478e-05\n",
            "Epoch 245/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2933 - val_loss: 4.9089e-05\n",
            "Epoch 246/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2886 - val_loss: 1.1363e-04\n",
            "Epoch 247/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2845 - val_loss: 2.2470e-04\n",
            "Epoch 248/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2879 - val_loss: 3.6968e-04\n",
            "Epoch 249/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2909 - val_loss: 9.0787e-04\n",
            "Epoch 250/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2873 - val_loss: 5.9362e-04\n",
            "Epoch 251/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2860 - val_loss: 1.8046e-04\n",
            "Epoch 252/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2760 - val_loss: 3.2871e-05\n",
            "Epoch 253/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2827 - val_loss: 2.0927e-04\n",
            "Epoch 254/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2885 - val_loss: 2.5098e-06\n",
            "Epoch 255/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2968 - val_loss: 4.7856e-05\n",
            "Epoch 256/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2917 - val_loss: 2.5435e-04\n",
            "Epoch 257/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2986 - val_loss: 7.4453e-05\n",
            "Epoch 258/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2979 - val_loss: 2.9871e-04\n",
            "Epoch 259/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.2864 - val_loss: 1.0242e-04\n",
            "Epoch 260/686\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2880 - val_loss: 9.9040e-06\n",
            "Epoch 261/686\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2859 - val_loss: 4.0243e-04\n",
            "Epoch 262/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2770 - val_loss: 1.0693e-04\n",
            "Epoch 263/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2839 - val_loss: 8.6037e-05\n",
            "Epoch 264/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2927 - val_loss: 9.3451e-06\n",
            "Epoch 265/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2884 - val_loss: 1.6431e-04\n",
            "Epoch 266/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2822 - val_loss: 3.2184e-04\n",
            "Epoch 267/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2831 - val_loss: 9.8323e-05\n",
            "Epoch 268/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2855 - val_loss: 5.9020e-05\n",
            "Epoch 269/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2773 - val_loss: 1.8268e-04\n",
            "Epoch 270/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.2803 - val_loss: 1.5803e-04\n",
            "Epoch 271/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2809 - val_loss: 2.7520e-05\n",
            "Epoch 272/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2892 - val_loss: 1.8215e-04\n",
            "Epoch 273/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2986 - val_loss: 2.2948e-05\n",
            "Epoch 274/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2964 - val_loss: 1.7011e-04\n",
            "Epoch 275/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2822 - val_loss: 9.6050e-05\n",
            "Epoch 276/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2937 - val_loss: 6.4447e-05\n",
            "Epoch 277/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2869 - val_loss: 1.8286e-04\n",
            "Epoch 278/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2950 - val_loss: 5.3674e-04\n",
            "Epoch 279/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2883 - val_loss: 2.7748e-04\n",
            "Epoch 280/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2820 - val_loss: 0.0010\n",
            "Epoch 281/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.2812 - val_loss: 4.4286e-04\n",
            "Epoch 282/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3023 - val_loss: 2.4559e-04\n",
            "Epoch 283/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2946 - val_loss: 8.1494e-06\n",
            "Epoch 284/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2698 - val_loss: 1.7440e-05\n",
            "Epoch 285/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2772 - val_loss: 4.2704e-05\n",
            "Epoch 286/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2817 - val_loss: 3.0647e-05\n",
            "Epoch 287/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.2921 - val_loss: 9.6621e-05\n",
            "Epoch 288/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3009 - val_loss: 7.0644e-05\n",
            "Epoch 289/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2926 - val_loss: 6.1058e-05\n",
            "Epoch 290/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2920 - val_loss: 3.1268e-04\n",
            "Epoch 291/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2819 - val_loss: 3.8588e-05\n",
            "Epoch 292/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2827 - val_loss: 1.2117e-04\n",
            "Epoch 293/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2884 - val_loss: 2.9201e-04\n",
            "Epoch 294/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2743 - val_loss: 3.6245e-05\n",
            "Epoch 295/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2825 - val_loss: 8.9410e-05\n",
            "Epoch 296/686\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.2799 - val_loss: 3.5141e-04\n",
            "Epoch 297/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2999 - val_loss: 1.1357e-04\n",
            "Epoch 298/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3033 - val_loss: 1.2135e-04\n",
            "Epoch 299/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2946 - val_loss: 1.4300e-04\n",
            "Epoch 300/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2811 - val_loss: 1.0072e-04\n",
            "Epoch 301/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2753 - val_loss: 5.2570e-05\n",
            "Epoch 302/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2784 - val_loss: 6.8720e-06\n",
            "Epoch 303/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2841 - val_loss: 1.5013e-04\n",
            "Epoch 304/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2776 - val_loss: 8.0422e-05\n",
            "Epoch 305/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3015 - val_loss: 2.0481e-04\n",
            "Epoch 306/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2776 - val_loss: 5.0071e-05\n",
            "Epoch 307/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2878 - val_loss: 1.3356e-04\n",
            "Epoch 308/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2731 - val_loss: 5.9521e-04\n",
            "Epoch 309/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2801 - val_loss: 4.4694e-04\n",
            "Epoch 310/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2694 - val_loss: 9.4749e-04\n",
            "Epoch 311/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2852 - val_loss: 2.5893e-04\n",
            "Epoch 312/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2716 - val_loss: 3.4492e-04\n",
            "Epoch 313/686\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.2718 - val_loss: 2.9215e-04\n",
            "Epoch 314/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3200 - val_loss: 1.4411e-04\n",
            "Epoch 315/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2772 - val_loss: 1.2306e-04\n",
            "Epoch 316/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2839 - val_loss: 8.8144e-05\n",
            "Epoch 317/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2865 - val_loss: 3.2041e-04\n",
            "Epoch 318/686\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2875 - val_loss: 3.1258e-04\n",
            "Epoch 319/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2702 - val_loss: 8.1236e-04\n",
            "Epoch 320/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2958 - val_loss: 1.2956e-04\n",
            "Epoch 321/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2938 - val_loss: 1.8167e-05\n",
            "Epoch 322/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.2938 - val_loss: 3.9606e-05\n",
            "Epoch 323/686\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.2774 - val_loss: 2.4872e-04\n",
            "Epoch 324/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2757 - val_loss: 4.9157e-05\n",
            "Epoch 325/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2841 - val_loss: 1.7749e-04\n",
            "Epoch 326/686\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.2792 - val_loss: 2.3375e-05\n",
            "Epoch 327/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2702 - val_loss: 1.1411e-05\n",
            "Epoch 328/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2735 - val_loss: 3.2403e-05\n",
            "Epoch 329/686\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2784 - val_loss: 9.0068e-05\n",
            "Epoch 330/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2928 - val_loss: 1.2807e-05\n",
            "Epoch 331/686\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.2810 - val_loss: 2.1783e-04\n",
            "Epoch 332/686\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2733 - val_loss: 2.6908e-04\n",
            "Epoch 333/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2876 - val_loss: 2.5833e-04\n",
            "Epoch 334/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.2890 - val_loss: 4.1388e-04\n",
            "Epoch 335/686\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2811 - val_loss: 1.5071e-04\n",
            "Epoch 336/686\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.2696 - val_loss: 2.0869e-04\n",
            "Epoch 337/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2839 - val_loss: 2.4477e-04\n",
            "Epoch 338/686\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2840 - val_loss: 1.8159e-04\n",
            "Epoch 339/686\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2991 - val_loss: 3.5820e-04\n",
            "Epoch 340/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2806 - val_loss: 5.8077e-04\n",
            "Epoch 341/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2957 - val_loss: 8.7836e-04\n",
            "Epoch 342/686\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3049 - val_loss: 8.5356e-05\n",
            "Epoch 343/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2699 - val_loss: 4.7781e-05\n",
            "Epoch 344/686\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2749 - val_loss: 5.8379e-05\n",
            "Epoch 345/686\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2701 - val_loss: 1.8695e-04\n",
            "(86, 15, 1)\n",
            "(86, 15, 1)\n",
            "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 0.4218 - val_loss: 0.0087\n",
            "Epoch 2/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4206 - val_loss: 0.0025\n",
            "Epoch 3/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4185 - val_loss: 0.0031\n",
            "Epoch 4/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4183 - val_loss: 0.0027\n",
            "Epoch 5/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4170 - val_loss: 0.0016\n",
            "Epoch 6/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4164 - val_loss: 0.0037\n",
            "Epoch 7/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4156 - val_loss: 0.0027\n",
            "Epoch 8/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4148 - val_loss: 0.0055\n",
            "Epoch 9/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4151 - val_loss: 0.0054\n",
            "Epoch 10/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4137 - val_loss: 0.0053\n",
            "Epoch 11/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4134 - val_loss: 0.0058\n",
            "Epoch 12/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4111 - val_loss: 0.0082\n",
            "Epoch 13/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4098 - val_loss: 0.0075\n",
            "Epoch 14/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4080 - val_loss: 0.0096\n",
            "Epoch 15/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4067 - val_loss: 0.0147\n",
            "Epoch 16/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4044 - val_loss: 0.0127\n",
            "Epoch 17/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4004 - val_loss: 0.0163\n",
            "Epoch 18/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3949 - val_loss: 0.0174\n",
            "Epoch 19/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3897 - val_loss: 0.0259\n",
            "Epoch 20/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3846 - val_loss: 0.0350\n",
            "Epoch 21/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3836 - val_loss: 0.0341\n",
            "Epoch 22/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3669 - val_loss: 0.0416\n",
            "Epoch 23/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3512 - val_loss: 0.0532\n",
            "Epoch 24/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3362 - val_loss: 0.0685\n",
            "Epoch 25/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3273 - val_loss: 0.0551\n",
            "Epoch 26/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3042 - val_loss: 0.0551\n",
            "Epoch 27/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2967 - val_loss: 0.0742\n",
            "Epoch 28/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2912 - val_loss: 0.0795\n",
            "Epoch 29/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2767 - val_loss: 0.0757\n",
            "Epoch 30/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2742 - val_loss: 0.0888\n",
            "Epoch 31/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2664 - val_loss: 0.1044\n",
            "Epoch 32/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2903 - val_loss: 0.0838\n",
            "Epoch 33/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2568 - val_loss: 0.1058\n",
            "Epoch 34/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2560 - val_loss: 0.0990\n",
            "Epoch 35/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2615 - val_loss: 0.1231\n",
            "Epoch 36/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2530 - val_loss: 0.1022\n",
            "Epoch 37/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2489 - val_loss: 0.1246\n",
            "Epoch 38/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2779 - val_loss: 0.1237\n",
            "Epoch 39/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2378 - val_loss: 0.1190\n",
            "Epoch 40/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2371 - val_loss: 0.1173\n",
            "Epoch 41/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2213 - val_loss: 0.1167\n",
            "Epoch 42/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2131 - val_loss: 0.1329\n",
            "Epoch 43/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2078 - val_loss: 0.1311\n",
            "Epoch 44/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2003 - val_loss: 0.1147\n",
            "Epoch 45/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2077 - val_loss: 0.1380\n",
            "Epoch 46/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1886 - val_loss: 0.1180\n",
            "Epoch 47/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1847 - val_loss: 0.1360\n",
            "Epoch 48/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1755 - val_loss: 0.1187\n",
            "Epoch 49/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1729 - val_loss: 0.1149\n",
            "Epoch 50/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1919 - val_loss: 0.1493\n",
            "Epoch 51/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1824 - val_loss: 0.1172\n",
            "Epoch 52/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2092 - val_loss: 0.1351\n",
            "Epoch 53/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2028 - val_loss: 0.1142\n",
            "Epoch 54/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2102 - val_loss: 0.1084\n",
            "Epoch 55/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1781 - val_loss: 0.1279\n",
            "Epoch 56/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1689 - val_loss: 0.1170\n",
            "Epoch 57/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1684 - val_loss: 0.1128\n",
            "Epoch 58/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1795 - val_loss: 0.1260\n",
            "Epoch 59/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1724 - val_loss: 0.1121\n",
            "Epoch 60/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1883 - val_loss: 0.1143\n",
            "Epoch 61/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1700 - val_loss: 0.1127\n",
            "Epoch 62/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1581 - val_loss: 0.1160\n",
            "Epoch 63/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1539 - val_loss: 0.1071\n",
            "Epoch 64/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1826 - val_loss: 0.1250\n",
            "Epoch 65/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1720 - val_loss: 0.1173\n",
            "Epoch 66/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1612 - val_loss: 0.1209\n",
            "Epoch 67/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1680 - val_loss: 0.1117\n",
            "Epoch 68/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1622 - val_loss: 0.1111\n",
            "Epoch 69/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1589 - val_loss: 0.1109\n",
            "Epoch 70/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1429 - val_loss: 0.1164\n",
            "Epoch 71/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1532 - val_loss: 0.1131\n",
            "Epoch 72/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1428 - val_loss: 0.1260\n",
            "Epoch 73/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1498 - val_loss: 0.1083\n",
            "Epoch 74/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1463 - val_loss: 0.1199\n",
            "Epoch 75/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1902 - val_loss: 0.1058\n",
            "Epoch 76/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1578 - val_loss: 0.0936\n",
            "Epoch 77/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1365 - val_loss: 0.1049\n",
            "Epoch 78/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1342 - val_loss: 0.1137\n",
            "Epoch 79/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1429 - val_loss: 0.1025\n",
            "Epoch 80/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1560 - val_loss: 0.1168\n",
            "Epoch 81/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1428 - val_loss: 0.1089\n",
            "Epoch 82/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1615 - val_loss: 0.1087\n",
            "Epoch 83/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1298 - val_loss: 0.1100\n",
            "Epoch 84/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1398 - val_loss: 0.1195\n",
            "Epoch 85/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1366 - val_loss: 0.1095\n",
            "Epoch 86/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1438 - val_loss: 0.1170\n",
            "Epoch 87/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1484 - val_loss: 0.1069\n",
            "Epoch 88/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1473 - val_loss: 0.1069\n",
            "Epoch 89/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1268 - val_loss: 0.1089\n",
            "Epoch 90/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1289 - val_loss: 0.1121\n",
            "Epoch 91/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1295 - val_loss: 0.1017\n",
            "Epoch 92/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1547 - val_loss: 0.1080\n",
            "Epoch 93/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1338 - val_loss: 0.1094\n",
            "Epoch 94/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1277 - val_loss: 0.1127\n",
            "Epoch 95/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1374 - val_loss: 0.1087\n",
            "Epoch 96/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1284 - val_loss: 0.1199\n",
            "Epoch 97/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1184 - val_loss: 0.1134\n",
            "Epoch 98/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1153 - val_loss: 0.1210\n",
            "Epoch 99/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1378 - val_loss: 0.1074\n",
            "Epoch 100/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1255 - val_loss: 0.1201\n",
            "Epoch 101/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1223 - val_loss: 0.1094\n",
            "Epoch 102/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1321 - val_loss: 0.1157\n",
            "Epoch 103/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1360 - val_loss: 0.1094\n",
            "Epoch 104/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1160 - val_loss: 0.1114\n",
            "Epoch 105/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1151 - val_loss: 0.1053\n",
            "Epoch 106/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1229 - val_loss: 0.1239\n",
            "Epoch 107/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1191 - val_loss: 0.1101\n",
            "Epoch 108/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1341 - val_loss: 0.1223\n",
            "Epoch 109/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1224 - val_loss: 0.1143\n",
            "Epoch 110/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1353 - val_loss: 0.1139\n",
            "Epoch 111/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1077 - val_loss: 0.1145\n",
            "Epoch 112/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1102 - val_loss: 0.1151\n",
            "Epoch 113/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1128 - val_loss: 0.1022\n",
            "Epoch 114/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1229 - val_loss: 0.1156\n",
            "Epoch 115/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1091 - val_loss: 0.1099\n",
            "Epoch 116/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1123 - val_loss: 0.1281\n",
            "Epoch 117/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1190 - val_loss: 0.1051\n",
            "Epoch 118/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1340 - val_loss: 0.1135\n",
            "Epoch 119/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1137 - val_loss: 0.1174\n",
            "Epoch 120/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1078 - val_loss: 0.1204\n",
            "Epoch 121/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1191 - val_loss: 0.1077\n",
            "Epoch 122/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1156 - val_loss: 0.1213\n",
            "Epoch 123/686\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1073 - val_loss: 0.1090\n",
            "Epoch 124/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1209 - val_loss: 0.1241\n",
            "Epoch 125/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1147 - val_loss: 0.1071\n",
            "Epoch 126/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1315 - val_loss: 0.1105\n",
            "Epoch 127/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1106 - val_loss: 0.1144\n",
            "Epoch 128/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1118 - val_loss: 0.1150\n",
            "Epoch 129/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1095 - val_loss: 0.1072\n",
            "Epoch 130/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1222\n",
            "Epoch 131/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1151 - val_loss: 0.1134\n",
            "Epoch 132/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1152 - val_loss: 0.1143\n",
            "Epoch 133/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1162 - val_loss: 0.1036\n",
            "Epoch 134/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1160 - val_loss: 0.1094\n",
            "Epoch 135/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1148 - val_loss: 0.1128\n",
            "Epoch 136/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1057 - val_loss: 0.1220\n",
            "Epoch 137/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1077 - val_loss: 0.1079\n",
            "Epoch 138/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1118 - val_loss: 0.1264\n",
            "Epoch 139/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1156 - val_loss: 0.1160\n",
            "Epoch 140/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1078 - val_loss: 0.1252\n",
            "Epoch 141/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1177 - val_loss: 0.1084\n",
            "Epoch 142/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1232 - val_loss: 0.1115\n",
            "Epoch 143/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1080 - val_loss: 0.1106\n",
            "Epoch 144/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1089 - val_loss: 0.1209\n",
            "Epoch 145/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1049 - val_loss: 0.1099\n",
            "Epoch 146/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1173 - val_loss: 0.1236\n",
            "Epoch 147/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1111 - val_loss: 0.1097\n",
            "Epoch 148/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1189 - val_loss: 0.1158\n",
            "Epoch 149/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1133 - val_loss: 0.1113\n",
            "Epoch 150/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1128 - val_loss: 0.1152\n",
            "Epoch 151/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1037 - val_loss: 0.1072\n",
            "Epoch 152/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1116 - val_loss: 0.1226\n",
            "Epoch 153/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1108 - val_loss: 0.1121\n",
            "Epoch 154/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1089 - val_loss: 0.1221\n",
            "Epoch 155/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1063 - val_loss: 0.1065\n",
            "Epoch 156/686\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1227 - val_loss: 0.1166\n",
            "Epoch 157/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1052 - val_loss: 0.1202\n",
            "Epoch 158/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1103 - val_loss: 0.1193\n",
            "Epoch 159/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0979 - val_loss: 0.1145\n",
            "Epoch 160/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.1110\n",
            "Epoch 161/686\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0999 - val_loss: 0.1157\n",
            "Epoch 162/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1046 - val_loss: 0.1303\n",
            "Epoch 163/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1220 - val_loss: 0.1082\n",
            "Epoch 164/686\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1180 - val_loss: 0.1126\n",
            "Epoch 165/686\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1080 - val_loss: 0.1170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjykKLTWLnsH"
      },
      "source": [
        "Predictions for both first and second week are : [0,0,..,0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8SV3kjJqllt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "8ba2346c-69c6-44ea-fad8-90e4659fc993"
      },
      "source": [
        "\n",
        "predictions_hosp_Austin = predictionOnPredictionLSTM(initialvalue_Austin_hosp,look_ahead,encoder_model_Austin)\n",
        "predictions_hosp_Austin = predictions_hosp_Austin.reshape(len(predictions_hosp_Austin))\n",
        "print(predictions_hosp_Austin)\n",
        "print(test_deaths_hosp[7][window_2:])\n",
        "print(train_deaths_hosp[7][120:])# window 15\n",
        "print(mean_absolute_error(predictions_hosp_Austin,test_deaths_hosp[7][window_2:]))\n",
        "print(mean_squared_log_error(predictions_hosp_Austin,test_deaths_hosp[7][window_2:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.5161065e-09 3.5161065e-09 3.5161065e-09 3.5161065e-09 3.5161065e-09\n",
            " 3.5161065e-09 3.5161065e-09]\n",
            "[0 0 0 0 0 0 0]\n",
            "[2 0 1 2 3 1 1 0 0 0 0 0 0 0 0 0 2 0 0 1 1 0 0 0 0 0 1 0 0 0 0]\n",
            "3.5161065170541406e-09\n",
            "1.23630050392706e-17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wH289xoq4DC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b83a0158-b0b2-437d-cf89-79bc84fa0f66"
      },
      "source": [
        "encoder_model_Galveston,encoder_history_Galveston = build_encoder_decoder_h(np.array(X_train_hosp_expma[6][40:]),np.array(X_test_hosp[6]),np.array(Y_train_hosp_expma[6][40:]),np.array(Y_test_hosp[6]),window_2)\n",
        "conv_model_Galveston,conv_history_Galveston = build_conv_model_h(np.array(X_train_hosp_expma[6][40:]),np.array(X_test_hosp[6]),np.array(Y_train_hosp_expma[6][40:]),np.array(Y_test_hosp[6]),window_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(116, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 122.4484 - val_loss: 35.9855\n",
            "Epoch 2/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 64.1088 - val_loss: 14.5732\n",
            "Epoch 3/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 39.6461 - val_loss: 8.8942\n",
            "Epoch 4/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 29.9848 - val_loss: 8.2946\n",
            "Epoch 5/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 32.7739 - val_loss: 17.1883\n",
            "Epoch 6/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 26.7388 - val_loss: 8.1092\n",
            "Epoch 7/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 30.5970 - val_loss: 8.2212\n",
            "Epoch 8/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 34.7316 - val_loss: 7.8776\n",
            "Epoch 9/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 23.9542 - val_loss: 6.2950\n",
            "Epoch 10/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 25.3818 - val_loss: 7.7929\n",
            "Epoch 11/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 33.7704 - val_loss: 7.3923\n",
            "Epoch 12/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 23.7151 - val_loss: 10.7218\n",
            "Epoch 13/686\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 32.1696 - val_loss: 6.6306\n",
            "Epoch 14/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 26.6627 - val_loss: 6.4854\n",
            "Epoch 15/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 23.2561 - val_loss: 6.3021\n",
            "Epoch 16/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 30.4755 - val_loss: 7.5712\n",
            "Epoch 17/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 30.5956 - val_loss: 7.1823\n",
            "Epoch 18/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 24.4302 - val_loss: 7.1926\n",
            "Epoch 19/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 25.3728 - val_loss: 8.0641\n",
            "Epoch 20/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 23.1980 - val_loss: 8.0344\n",
            "Epoch 21/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 28.7427 - val_loss: 8.2359\n",
            "Epoch 22/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 24.6942 - val_loss: 7.4851\n",
            "Epoch 23/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 27.8170 - val_loss: 6.9460\n",
            "Epoch 24/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 22.9840 - val_loss: 8.2485\n",
            "Epoch 25/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 29.4526 - val_loss: 7.9609\n",
            "Epoch 26/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 25.4237 - val_loss: 7.7566\n",
            "Epoch 27/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 26.9982 - val_loss: 7.6160\n",
            "Epoch 28/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 24.5409 - val_loss: 7.2990\n",
            "Epoch 29/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 25.9908 - val_loss: 7.2114\n",
            "Epoch 30/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 27.9813 - val_loss: 8.0976\n",
            "Epoch 31/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 25.8255 - val_loss: 7.3723\n",
            "Epoch 32/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 25.2069 - val_loss: 7.4695\n",
            "Epoch 33/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 23.0547 - val_loss: 7.6800\n",
            "Epoch 34/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 23.0415 - val_loss: 7.1985\n",
            "Epoch 35/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 22.8730 - val_loss: 7.6797\n",
            "Epoch 36/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 24.1446 - val_loss: 7.6337\n",
            "Epoch 37/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 23.2264 - val_loss: 7.5202\n",
            "Epoch 38/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 22.0488 - val_loss: 7.0955\n",
            "Epoch 39/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 25.2898 - val_loss: 7.4907\n",
            "Epoch 40/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 22.6853 - val_loss: 6.7977\n",
            "Epoch 41/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 23.4887 - val_loss: 7.5954\n",
            "Epoch 42/686\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 27.1841 - val_loss: 6.8857\n",
            "Epoch 43/686\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 24.5033 - val_loss: 7.3220\n",
            "Epoch 44/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 22.8904 - val_loss: 7.7234\n",
            "Epoch 45/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 22.2776 - val_loss: 7.0272\n",
            "Epoch 46/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 22.9964 - val_loss: 6.9528\n",
            "Epoch 47/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 21.4222 - val_loss: 7.0168\n",
            "Epoch 48/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 20.1230 - val_loss: 8.0456\n",
            "Epoch 49/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 20.8665 - val_loss: 7.3762\n",
            "Epoch 50/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 21.4151 - val_loss: 7.0027\n",
            "Epoch 51/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 18.8452 - val_loss: 7.0402\n",
            "Epoch 52/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 23.9457 - val_loss: 7.0408\n",
            "Epoch 53/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 21.7771 - val_loss: 7.2865\n",
            "Epoch 54/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 20.5343 - val_loss: 6.9703\n",
            "Epoch 55/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.1509 - val_loss: 6.7904\n",
            "Epoch 56/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 18.8389 - val_loss: 7.3498\n",
            "Epoch 57/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 21.4814 - val_loss: 6.8405\n",
            "Epoch 58/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 21.7004 - val_loss: 7.7444\n",
            "Epoch 59/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 19.1389 - val_loss: 7.5358\n",
            "Epoch 60/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 23.3571 - val_loss: 7.8227\n",
            "Epoch 61/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 23.5607 - val_loss: 7.9804\n",
            "Epoch 62/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 25.8638 - val_loss: 7.6959\n",
            "Epoch 63/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 20.2196 - val_loss: 8.2401\n",
            "Epoch 64/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 23.8344 - val_loss: 8.0278\n",
            "Epoch 65/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 25.3589 - val_loss: 9.1818\n",
            "Epoch 66/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 20.6648 - val_loss: 7.8155\n",
            "Epoch 67/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 24.4426 - val_loss: 7.2801\n",
            "Epoch 68/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 22.3479 - val_loss: 7.5231\n",
            "Epoch 69/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 21.7785 - val_loss: 7.9720\n",
            "Epoch 70/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 19.9984 - val_loss: 7.3486\n",
            "Epoch 71/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 20.5238 - val_loss: 7.5949\n",
            "Epoch 72/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 26.2550 - val_loss: 7.4265\n",
            "Epoch 73/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 18.9397 - val_loss: 7.3057\n",
            "Epoch 74/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 16.6925 - val_loss: 7.9172\n",
            "Epoch 75/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 21.9194 - val_loss: 7.3302\n",
            "Epoch 76/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 19.7164 - val_loss: 7.3320\n",
            "Epoch 77/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 19.1125 - val_loss: 7.5332\n",
            "Epoch 78/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 18.4010 - val_loss: 7.4388\n",
            "Epoch 79/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 22.6632 - val_loss: 8.9142\n",
            "Epoch 80/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 16.7789 - val_loss: 7.8661\n",
            "Epoch 81/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 20.0735 - val_loss: 7.6310\n",
            "Epoch 82/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 20.3333 - val_loss: 7.5402\n",
            "Epoch 83/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 20.8101 - val_loss: 8.0037\n",
            "Epoch 84/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 21.4888 - val_loss: 7.4721\n",
            "Epoch 85/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 19.2882 - val_loss: 7.4014\n",
            "Epoch 86/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 14.9290 - val_loss: 7.3613\n",
            "Epoch 87/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 18.0592 - val_loss: 7.4499\n",
            "Epoch 88/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 16.1814 - val_loss: 7.2212\n",
            "Epoch 89/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 19.6174 - val_loss: 7.5333\n",
            "Epoch 90/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 16.9195 - val_loss: 7.5314\n",
            "Epoch 91/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 19.2933 - val_loss: 7.7402\n",
            "Epoch 92/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.5302 - val_loss: 8.0141\n",
            "Epoch 93/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 23.0512 - val_loss: 7.4473\n",
            "Epoch 94/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 18.9775 - val_loss: 7.6900\n",
            "Epoch 95/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 17.7184 - val_loss: 7.6469\n",
            "Epoch 96/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 20.2484 - val_loss: 7.4996\n",
            "Epoch 97/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 15.7892 - val_loss: 7.3210\n",
            "Epoch 98/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 17.4461 - val_loss: 7.0939\n",
            "Epoch 99/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 20.7916 - val_loss: 9.1425\n",
            "Epoch 100/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 16.9582 - val_loss: 7.6943\n",
            "Epoch 101/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 17.7069 - val_loss: 7.1999\n",
            "Epoch 102/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 18.8668 - val_loss: 7.4088\n",
            "Epoch 103/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 18.1252 - val_loss: 7.4539\n",
            "Epoch 104/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 18.4502 - val_loss: 7.5813\n",
            "Epoch 105/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.2459 - val_loss: 7.6505\n",
            "Epoch 106/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 15.9897 - val_loss: 8.1690\n",
            "Epoch 107/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 16.3100 - val_loss: 7.0634\n",
            "Epoch 108/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 22.2574 - val_loss: 9.2658\n",
            "Epoch 109/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 16.5541 - val_loss: 7.5824\n",
            "Epoch 110/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 24.8143 - val_loss: 7.0934\n",
            "Epoch 111/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 19.1692 - val_loss: 9.6722\n",
            "Epoch 112/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 16.7607 - val_loss: 7.1070\n",
            "Epoch 113/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 21.6204 - val_loss: 7.5124\n",
            "Epoch 114/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 18.2193 - val_loss: 7.1206\n",
            "Epoch 115/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 19.8691 - val_loss: 6.9810\n",
            "Epoch 116/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 18.4361 - val_loss: 7.2247\n",
            "Epoch 117/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 17.6914 - val_loss: 6.7567\n",
            "Epoch 118/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.0800 - val_loss: 6.9590\n",
            "Epoch 119/686\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 20.0204 - val_loss: 6.8930\n",
            "Epoch 120/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 15.8399 - val_loss: 6.9630\n",
            "Epoch 121/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 14.5445 - val_loss: 6.8409\n",
            "Epoch 122/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.1937 - val_loss: 7.3210\n",
            "Epoch 123/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 16.9225 - val_loss: 6.9725\n",
            "Epoch 124/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 16.8709 - val_loss: 7.3676\n",
            "Epoch 125/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 15.9876 - val_loss: 6.9785\n",
            "Epoch 126/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 14.8457 - val_loss: 6.9133\n",
            "Epoch 127/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 13.4571 - val_loss: 7.5570\n",
            "Epoch 128/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 14.7454 - val_loss: 6.7239\n",
            "Epoch 129/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 22.2905 - val_loss: 6.5760\n",
            "Epoch 130/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 19.8469 - val_loss: 7.1467\n",
            "Epoch 131/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 16.4119 - val_loss: 6.5061\n",
            "Epoch 132/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 17.5306 - val_loss: 6.6399\n",
            "Epoch 133/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 20.0496 - val_loss: 7.1007\n",
            "Epoch 134/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 18.3039 - val_loss: 7.6675\n",
            "Epoch 135/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 22.3950 - val_loss: 7.2265\n",
            "Epoch 136/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 20.3674 - val_loss: 6.9684\n",
            "Epoch 137/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.6885 - val_loss: 7.0058\n",
            "Epoch 138/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 18.6017 - val_loss: 7.5375\n",
            "Epoch 139/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.5156 - val_loss: 6.8651\n",
            "Epoch 140/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 19.5504 - val_loss: 7.1801\n",
            "Epoch 141/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 18.7586 - val_loss: 6.9112\n",
            "Epoch 142/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 16.2505 - val_loss: 6.6568\n",
            "Epoch 143/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 16.6866 - val_loss: 6.4810\n",
            "Epoch 144/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 17.5164 - val_loss: 7.4990\n",
            "Epoch 145/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 13.9573 - val_loss: 7.3040\n",
            "Epoch 146/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 20.2322 - val_loss: 7.7102\n",
            "Epoch 147/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 16.4341 - val_loss: 7.0310\n",
            "Epoch 148/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 19.6658 - val_loss: 6.6630\n",
            "Epoch 149/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 14.9762 - val_loss: 6.3346\n",
            "Epoch 150/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 16.1906 - val_loss: 7.4593\n",
            "Epoch 151/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 16.0651 - val_loss: 8.2052\n",
            "Epoch 152/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 22.8743 - val_loss: 6.8885\n",
            "Epoch 153/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 17.6225 - val_loss: 6.9019\n",
            "Epoch 154/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 16.3394 - val_loss: 6.4433\n",
            "Epoch 155/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.2309 - val_loss: 6.6423\n",
            "Epoch 156/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 16.4029 - val_loss: 7.5096\n",
            "Epoch 157/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 15.6925 - val_loss: 7.8274\n",
            "Epoch 158/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 12.9958 - val_loss: 7.8995\n",
            "Epoch 159/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 15.4892 - val_loss: 8.0844\n",
            "Epoch 160/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 16.5091 - val_loss: 8.7725\n",
            "Epoch 161/686\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 15.0543 - val_loss: 7.4298\n",
            "Epoch 162/686\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 15.4132 - val_loss: 8.0585\n",
            "Epoch 163/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 20.3135 - val_loss: 6.7536\n",
            "Epoch 164/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 16.1212 - val_loss: 6.6131\n",
            "Epoch 165/686\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 15.2493 - val_loss: 6.4729\n",
            "Epoch 166/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 16.0174 - val_loss: 6.8215\n",
            "Epoch 167/686\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.3930 - val_loss: 6.6939\n",
            "Epoch 168/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 13.2052 - val_loss: 7.1340\n",
            "Epoch 169/686\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 16.9294 - val_loss: 6.8540\n",
            "(116, 10, 1)\n",
            "(116, 10, 1)\n",
            "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/686\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 128.6809 - val_loss: 50.4650\n",
            "Epoch 2/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 114.5829 - val_loss: 37.1654\n",
            "Epoch 3/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 78.6509 - val_loss: 9.4623\n",
            "Epoch 4/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 30.4553 - val_loss: 27.1086\n",
            "Epoch 5/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 18.2710 - val_loss: 13.4389\n",
            "Epoch 6/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17.6750 - val_loss: 9.2365\n",
            "Epoch 7/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 18.8859 - val_loss: 16.0131\n",
            "Epoch 8/686\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15.5437 - val_loss: 18.3863\n",
            "Epoch 9/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.6300 - val_loss: 15.8791\n",
            "Epoch 10/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14.3626 - val_loss: 16.9241\n",
            "Epoch 11/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.2090 - val_loss: 15.3018\n",
            "Epoch 12/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.2244 - val_loss: 15.7335\n",
            "Epoch 13/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7003 - val_loss: 12.3756\n",
            "Epoch 14/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11.6854 - val_loss: 15.9437\n",
            "Epoch 15/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1691 - val_loss: 8.8287\n",
            "Epoch 16/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 16.5131 - val_loss: 20.7538\n",
            "Epoch 17/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.4440 - val_loss: 6.8506\n",
            "Epoch 18/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 22.6228 - val_loss: 11.4479\n",
            "Epoch 19/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 14.7323 - val_loss: 19.3907\n",
            "Epoch 20/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.9759 - val_loss: 12.8449\n",
            "Epoch 21/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.8501 - val_loss: 12.9229\n",
            "Epoch 22/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.0977 - val_loss: 13.8684\n",
            "Epoch 23/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.2769 - val_loss: 13.1951\n",
            "Epoch 24/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1733 - val_loss: 13.5131\n",
            "Epoch 25/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8188 - val_loss: 16.8223\n",
            "Epoch 26/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7438 - val_loss: 13.7994\n",
            "Epoch 27/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5415 - val_loss: 13.1347\n",
            "Epoch 28/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.9821 - val_loss: 15.2531\n",
            "Epoch 29/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8259 - val_loss: 15.3772\n",
            "Epoch 30/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5222 - val_loss: 12.6123\n",
            "Epoch 31/686\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.6933 - val_loss: 16.9400\n",
            "Epoch 32/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7711 - val_loss: 14.5758\n",
            "Epoch 33/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8182 - val_loss: 12.5495\n",
            "Epoch 34/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5967 - val_loss: 19.4447\n",
            "Epoch 35/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.0009 - val_loss: 11.1933\n",
            "Epoch 36/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3874 - val_loss: 15.5726\n",
            "Epoch 37/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5521 - val_loss: 13.5054\n",
            "Epoch 38/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9995 - val_loss: 13.3151\n",
            "Epoch 39/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1947 - val_loss: 15.5808\n",
            "Epoch 40/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1268 - val_loss: 13.8760\n",
            "Epoch 41/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7653 - val_loss: 14.5217\n",
            "Epoch 42/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4165 - val_loss: 11.6957\n",
            "Epoch 43/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1703 - val_loss: 14.2002\n",
            "Epoch 44/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6130 - val_loss: 13.8509\n",
            "Epoch 45/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7220 - val_loss: 15.1745\n",
            "Epoch 46/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.0276 - val_loss: 10.5992\n",
            "Epoch 47/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4331 - val_loss: 16.9371\n",
            "Epoch 48/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1090 - val_loss: 9.9160\n",
            "Epoch 49/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7319 - val_loss: 18.3795\n",
            "Epoch 50/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1901 - val_loss: 8.3254\n",
            "Epoch 51/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.7840 - val_loss: 21.2285\n",
            "Epoch 52/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15.6807 - val_loss: 9.0065\n",
            "Epoch 53/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 21.4221 - val_loss: 10.1835\n",
            "Epoch 54/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13.5618 - val_loss: 18.8379\n",
            "Epoch 55/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1525 - val_loss: 10.8769\n",
            "Epoch 56/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.6400 - val_loss: 14.9033\n",
            "Epoch 57/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.3941 - val_loss: 12.1510\n",
            "Epoch 58/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.1096 - val_loss: 14.9690\n",
            "Epoch 59/686\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9990 - val_loss: 9.3502\n",
            "Epoch 60/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.2286 - val_loss: 16.6260\n",
            "Epoch 61/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5912 - val_loss: 11.0668\n",
            "Epoch 62/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7975 - val_loss: 16.8792\n",
            "Epoch 63/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9146 - val_loss: 10.9324\n",
            "Epoch 64/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8338 - val_loss: 17.5715\n",
            "Epoch 65/686\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.2643 - val_loss: 10.2929\n",
            "Epoch 66/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7714 - val_loss: 18.5751\n",
            "Epoch 67/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.6248 - val_loss: 8.0771\n",
            "Epoch 68/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18.7931 - val_loss: 15.1924\n",
            "Epoch 69/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.6739 - val_loss: 13.6521\n",
            "Epoch 70/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1570 - val_loss: 15.2142\n",
            "Epoch 71/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6482 - val_loss: 11.0544\n",
            "Epoch 72/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.4265 - val_loss: 17.5259\n",
            "Epoch 73/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.2032 - val_loss: 9.9511\n",
            "Epoch 74/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.8838 - val_loss: 16.0262\n",
            "Epoch 75/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.2327 - val_loss: 12.1493\n",
            "Epoch 76/686\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10.7057 - val_loss: 16.3367\n",
            "Epoch 77/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1761 - val_loss: 11.0459\n",
            "Epoch 78/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.9776 - val_loss: 16.3890\n",
            "Epoch 79/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.0559 - val_loss: 11.9164\n",
            "Epoch 80/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.6636 - val_loss: 15.8638\n",
            "Epoch 81/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.1835 - val_loss: 11.3303\n",
            "Epoch 82/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.7675 - val_loss: 16.2168\n",
            "Epoch 83/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.9758 - val_loss: 10.5142\n",
            "Epoch 84/686\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11.6955 - val_loss: 16.4352\n",
            "Epoch 85/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.6021 - val_loss: 11.8442\n",
            "Epoch 86/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.7144 - val_loss: 15.3252\n",
            "Epoch 87/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.3776 - val_loss: 11.8655\n",
            "Epoch 88/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.8968 - val_loss: 15.9511\n",
            "Epoch 89/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.2727 - val_loss: 10.8180\n",
            "Epoch 90/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7672 - val_loss: 15.8535\n",
            "Epoch 91/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.9696 - val_loss: 10.9738\n",
            "Epoch 92/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.6125 - val_loss: 16.3319\n",
            "Epoch 93/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.7693 - val_loss: 11.2572\n",
            "Epoch 94/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.7982 - val_loss: 15.4441\n",
            "Epoch 95/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.5757 - val_loss: 12.0706\n",
            "Epoch 96/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.2854 - val_loss: 15.8587\n",
            "Epoch 97/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8966 - val_loss: 10.8182\n",
            "Epoch 98/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.6686 - val_loss: 15.9320\n",
            "Epoch 99/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.9798 - val_loss: 11.4269\n",
            "Epoch 100/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.4757 - val_loss: 15.5206\n",
            "Epoch 101/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1788 - val_loss: 11.6134\n",
            "Epoch 102/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.3828 - val_loss: 15.6797\n",
            "Epoch 103/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8426 - val_loss: 11.1354\n",
            "Epoch 104/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.4641 - val_loss: 15.9313\n",
            "Epoch 105/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8758 - val_loss: 11.6651\n",
            "Epoch 106/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8021 - val_loss: 15.6048\n",
            "Epoch 107/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2140 - val_loss: 11.5669\n",
            "Epoch 108/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.6204 - val_loss: 15.7810\n",
            "Epoch 109/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9350 - val_loss: 11.1091\n",
            "Epoch 110/686\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.3357 - val_loss: 16.1990\n",
            "Epoch 111/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.6842 - val_loss: 11.2883\n",
            "Epoch 112/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1822 - val_loss: 16.0680\n",
            "Epoch 113/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8916 - val_loss: 11.5821\n",
            "Epoch 114/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7352 - val_loss: 15.5081\n",
            "Epoch 115/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.1051 - val_loss: 11.4107\n",
            "Epoch 116/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5767 - val_loss: 15.4329\n",
            "Epoch 117/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.4547 - val_loss: 11.1595\n",
            "Epoch 118/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.9447 - val_loss: 16.0776\n",
            "Epoch 119/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2312 - val_loss: 11.0840\n",
            "Epoch 120/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.3740 - val_loss: 16.4447\n",
            "Epoch 121/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7323 - val_loss: 10.7223\n",
            "Epoch 122/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.2978 - val_loss: 15.8327\n",
            "Epoch 123/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1247 - val_loss: 11.8195\n",
            "Epoch 124/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.4501 - val_loss: 15.6077\n",
            "Epoch 125/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.0830 - val_loss: 11.5395\n",
            "Epoch 126/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.3542 - val_loss: 14.8986\n",
            "Epoch 127/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.4453 - val_loss: 11.4640\n",
            "Epoch 128/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9092 - val_loss: 15.0678\n",
            "Epoch 129/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5807 - val_loss: 10.7543\n",
            "Epoch 130/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.0139 - val_loss: 16.5008\n",
            "Epoch 131/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.3854 - val_loss: 10.7338\n",
            "Epoch 132/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.4396 - val_loss: 15.9670\n",
            "Epoch 133/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.2437 - val_loss: 11.9442\n",
            "Epoch 134/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.6103 - val_loss: 15.4876\n",
            "Epoch 135/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.0650 - val_loss: 12.0718\n",
            "Epoch 136/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8817 - val_loss: 15.3112\n",
            "Epoch 137/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.1346 - val_loss: 11.5179\n",
            "Epoch 138/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7374 - val_loss: 16.1401\n",
            "Epoch 139/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.4559 - val_loss: 11.3299\n",
            "Epoch 140/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.8598 - val_loss: 15.9347\n",
            "Epoch 141/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5273 - val_loss: 11.0988\n",
            "Epoch 142/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.9711 - val_loss: 16.1604\n",
            "Epoch 143/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8439 - val_loss: 11.2431\n",
            "Epoch 144/686\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9.2017 - val_loss: 16.1548\n",
            "Epoch 145/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7971 - val_loss: 11.6427\n",
            "Epoch 146/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.7702 - val_loss: 16.0355\n",
            "Epoch 147/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.6208 - val_loss: 11.4530\n",
            "Epoch 148/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.0036 - val_loss: 16.0294\n",
            "Epoch 149/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7559 - val_loss: 11.4341\n",
            "Epoch 150/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8618 - val_loss: 15.8997\n",
            "Epoch 151/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8527 - val_loss: 11.7534\n",
            "Epoch 152/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2334 - val_loss: 15.1014\n",
            "Epoch 153/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.6735 - val_loss: 11.5390\n",
            "Epoch 154/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2749 - val_loss: 15.1838\n",
            "Epoch 155/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4717 - val_loss: 11.4369\n",
            "Epoch 156/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.0964 - val_loss: 15.1031\n",
            "Epoch 157/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1816 - val_loss: 11.4303\n",
            "Epoch 158/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.2951 - val_loss: 15.7671\n",
            "Epoch 159/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2175 - val_loss: 11.5768\n",
            "Epoch 160/686\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5449 - val_loss: 15.6348\n",
            "Epoch 161/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.3694 - val_loss: 11.6429\n",
            "Epoch 162/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2580 - val_loss: 15.4156\n",
            "Epoch 163/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.6408 - val_loss: 12.1321\n",
            "Epoch 164/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.3505 - val_loss: 15.7978\n",
            "Epoch 165/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.4050 - val_loss: 11.5171\n",
            "Epoch 166/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9988 - val_loss: 15.1378\n",
            "Epoch 167/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5264 - val_loss: 11.4321\n",
            "Epoch 168/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4159 - val_loss: 15.5820\n",
            "Epoch 169/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.3423 - val_loss: 11.7438\n",
            "Epoch 170/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.1305 - val_loss: 15.4318\n",
            "Epoch 171/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.3748 - val_loss: 11.8807\n",
            "Epoch 172/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.6492 - val_loss: 15.6280\n",
            "Epoch 173/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4164 - val_loss: 11.5893\n",
            "Epoch 174/686\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6953 - val_loss: 15.1869\n",
            "Epoch 175/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.5936 - val_loss: 11.6353\n",
            "Epoch 176/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.2171 - val_loss: 15.7844\n",
            "Epoch 177/686\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.0090 - val_loss: 11.5798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A00FJT5eL1lV"
      },
      "source": [
        "Here I used the model that was trained from the train_test split of 97-3 and just made another 7 days prediction after test. If you run this cell with the whole training data the results may differ. \n",
        "\n",
        "Prediction is the last 7 values of the first printed list if the above split is used (else just the 7 first values if the whole training set is used)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEmag2PCrPEo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7ef6d270-8614-404d-ac53-00982f02251e"
      },
      "source": [
        "\n",
        "predictions_hosp_Galveston = predictionOnPredictionLSTM(initialvalue_Galveston_hosp,look_ahead+7,encoder_model_Galveston)\n",
        "predictions_hosp_Galveston = predictions_hosp_Galveston.reshape(len(predictions_hosp_Galveston))\n",
        "print(predictions_hosp_Galveston)\n",
        "print(test_deaths_hosp[6][window_2:])\n",
        "print(train_deaths_hosp[6][-30:])#best conv window 15, 50:, try expma, tommorow try window =2 \n",
        "#print(mean_absolute_error(predictions_hosp_Galveston,test_deaths_hosp[6][window_2:]))\n",
        "#print(mean_squared_log_error(predictions_hosp_Galveston,test_deaths_hosp[6][window_2:]))\n",
        "#79.18937 80.11344 80.65746 81.63252 81.89818 82.52528 82.98326\n",
        "#[80.88354  78.55621  76.09247  76.37674  76.250175 75.05425  74.66932] 1st week\n",
        "#[55.663937 ,54.6406  , 52.89285  ,49.816845 ,48.483604 ,47.001698, 42.390236] 2nd week"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[65.046486 65.16618  62.17182  59.90361  57.581673 57.781883 57.015587\n",
            " 55.663937 54.6406   52.89285  49.816845 48.483604 47.001698 45.615433]\n",
            "[65 67 68 49 45 48 57]\n",
            "[145 141 141 131 134 127 121 132 130 125 111 108 113 116 103  68  80  86\n",
            "  82  74  71  75  71  66  78  77  72  84  87  65]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8pQZQhkMXVs"
      },
      "source": [
        "Writing predictions for first week in a csv file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxYlX3HDvKOQ"
      },
      "source": [
        "Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORh6-h-ovL48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "298d8453-c982-4970-db9a-0648ac105db6"
      },
      "source": [
        "hospitalization = [721.77356 ,712.42664, 673.3252,  635.06647 ,610.22815, 581.2126 , 551.75415,0,0,0,0,0,0,0,66.97783, 68.46707 ,67.36516 ,66.63943, 64.96595 ,66.45057 ,62.30796,22.021269 ,20.658545, 19.740294 ,19.015366, 18.47681 , 18.032284 ,17.736917,0,0,0,0,0,0,0,51.975143, 52.42597 , 50.32082  ,49.313362 ,46.811794 ,45.39326,  42.778282,80.88354,  78.55621 , 76.09247 , 76.37674  ,76.250175, 75.05425 , 74.66932 ,0,0,0,0,0,0,0]\n",
        "mortality = [2335.3108 ,2337.2427 ,2339.745  ,2342.9365 ,2346.0798 ,2349.8184, 2354.185,46, 46, 46, 47, 47, 47, 48,133, 133, 133, 134, 134, 134, 134,\n",
        "             146, 146, 146, 146.35725 ,146.60017 ,147, 147,5,5,5,5,5,5,5,268.51748 ,272.66992, 275.28616 ,278.30945, 280.80664 ,283.64792 ,286.3341 ,\n",
        "             144.14627 ,144.56358 ,145.05827 ,145.34314 ,145.47849 ,145.67068, 145.84793,6,6,6,6,6,6,6]#,....]\n",
        "IDs = [\"Harris2020-09-07\",\"Harris2020-09-08\",\"Harris2020-09-09\",\"Harris2020-09-10\",\"Harris2020-09-11\",\"Harris2020-09-12\",\"Harris2020-09-13\",\"Liberty2020-09-07\",\"Liberty2020-09-08\",\"Liberty2020-09-09\",\"Liberty2020-09-10\",\"Liberty2020-09-11\",\"Liberty2020-09-12\",\"Liberty2020-09-13\",\n",
        "       \"Montgomery2020-09-07\",\"Montgomery2020-09-08\",\"Montgomery2020-09-09\",\"Montgomery2020-09-10\",\"Montgomery2020-09-11\",\"Montgomery2020-09-12\",\"Montgomery2020-09-13\",\"Brazoria2020-09-07\",\"Brazoria2020-09-08\",\"Brazoria2020-09-09\",\"Brazoria2020-09-10\",\"Brazoria2020-09-11\",\"Brazoria2020-09-12\",\"Brazoria2020-09-13\",\n",
        "       \"Chambers2020-09-07\",\"Chambers2020-09-08\",\"Chambers2020-09-09\",\"Chambers2020-09-10\",\"Chambers2020-09-11\",\"Chambers2020-09-12\",\"Chambers2020-09-13\",\"Fort Bend2020-09-07\",\"Fort Bend2020-09-08\",\"Fort Bend2020-09-09\",\"Fort Bend2020-09-10\",\"Fort Bend2020-09-11\",\"Fort Bend2020-09-12\",\"Fort Bend2020-09-13\",\n",
        "       \"Galveston2020-09-07\",\"Galveston2020-09-08\",\"Galveston2020-09-09\",\"Galveston2020-09-10\",\"Galveston2020-09-11\",\"Galveston2020-09-12\",\"Galveston2020-09-13\", \"Austin2020-09-07\",\"Austin2020-09-08\",\"Austin2020-09-09\",\"Austin2020-09-10\",\"Austin2020-09-11\",\"Austin2020-09-12\",\"Austin2020-09-13\"]\n",
        "submission = {'ID':IDs,'Hospitalization':hospitalization,'Mortality':mortality}\n",
        "submission = pd.DataFrame(submission)\n",
        "print(submission)\n",
        "submission.to_csv('/content/submission.csv',index=False)\n",
        "#submission.to_csv('data.csv')\n",
        "#!cp submission.csv \"drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      ID  Hospitalization   Mortality\n",
            "0       Harris2020-09-07       721.773560  2335.31080\n",
            "1       Harris2020-09-08       712.426640  2337.24270\n",
            "2       Harris2020-09-09       673.325200  2339.74500\n",
            "3       Harris2020-09-10       635.066470  2342.93650\n",
            "4       Harris2020-09-11       610.228150  2346.07980\n",
            "5       Harris2020-09-12       581.212600  2349.81840\n",
            "6       Harris2020-09-13       551.754150  2354.18500\n",
            "7      Liberty2020-09-07         0.000000    46.00000\n",
            "8      Liberty2020-09-08         0.000000    46.00000\n",
            "9      Liberty2020-09-09         0.000000    46.00000\n",
            "10     Liberty2020-09-10         0.000000    47.00000\n",
            "11     Liberty2020-09-11         0.000000    47.00000\n",
            "12     Liberty2020-09-12         0.000000    47.00000\n",
            "13     Liberty2020-09-13         0.000000    48.00000\n",
            "14  Montgomery2020-09-07        66.977830   133.00000\n",
            "15  Montgomery2020-09-08        68.467070   133.00000\n",
            "16  Montgomery2020-09-09        67.365160   133.00000\n",
            "17  Montgomery2020-09-10        66.639430   134.00000\n",
            "18  Montgomery2020-09-11        64.965950   134.00000\n",
            "19  Montgomery2020-09-12        66.450570   134.00000\n",
            "20  Montgomery2020-09-13        62.307960   134.00000\n",
            "21    Brazoria2020-09-07        22.021269   146.00000\n",
            "22    Brazoria2020-09-08        20.658545   146.00000\n",
            "23    Brazoria2020-09-09        19.740294   146.00000\n",
            "24    Brazoria2020-09-10        19.015366   146.35725\n",
            "25    Brazoria2020-09-11        18.476810   146.60017\n",
            "26    Brazoria2020-09-12        18.032284   147.00000\n",
            "27    Brazoria2020-09-13        17.736917   147.00000\n",
            "28    Chambers2020-09-07         0.000000     5.00000\n",
            "29    Chambers2020-09-08         0.000000     5.00000\n",
            "30    Chambers2020-09-09         0.000000     5.00000\n",
            "31    Chambers2020-09-10         0.000000     5.00000\n",
            "32    Chambers2020-09-11         0.000000     5.00000\n",
            "33    Chambers2020-09-12         0.000000     5.00000\n",
            "34    Chambers2020-09-13         0.000000     5.00000\n",
            "35   Fort Bend2020-09-07        51.975143   268.51748\n",
            "36   Fort Bend2020-09-08        52.425970   272.66992\n",
            "37   Fort Bend2020-09-09        50.320820   275.28616\n",
            "38   Fort Bend2020-09-10        49.313362   278.30945\n",
            "39   Fort Bend2020-09-11        46.811794   280.80664\n",
            "40   Fort Bend2020-09-12        45.393260   283.64792\n",
            "41   Fort Bend2020-09-13        42.778282   286.33410\n",
            "42   Galveston2020-09-07        80.883540   144.14627\n",
            "43   Galveston2020-09-08        78.556210   144.56358\n",
            "44   Galveston2020-09-09        76.092470   145.05827\n",
            "45   Galveston2020-09-10        76.376740   145.34314\n",
            "46   Galveston2020-09-11        76.250175   145.47849\n",
            "47   Galveston2020-09-12        75.054250   145.67068\n",
            "48   Galveston2020-09-13        74.669320   145.84793\n",
            "49      Austin2020-09-07         0.000000     6.00000\n",
            "50      Austin2020-09-08         0.000000     6.00000\n",
            "51      Austin2020-09-09         0.000000     6.00000\n",
            "52      Austin2020-09-10         0.000000     6.00000\n",
            "53      Austin2020-09-11         0.000000     6.00000\n",
            "54      Austin2020-09-12         0.000000     6.00000\n",
            "55      Austin2020-09-13         0.000000     6.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkinFCwWxF3L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93d5f842-1345-492f-97dd-26547ef94dc2"
      },
      "source": [
        "test = pd.read_csv('submission.csv')\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Hospitalization</th>\n",
              "      <th>Mortality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Harris2020-09-07</td>\n",
              "      <td>721.773560</td>\n",
              "      <td>2335.31080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Harris2020-09-08</td>\n",
              "      <td>712.426640</td>\n",
              "      <td>2337.24270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Harris2020-09-09</td>\n",
              "      <td>673.325200</td>\n",
              "      <td>2339.74500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Harris2020-09-10</td>\n",
              "      <td>635.066470</td>\n",
              "      <td>2342.93650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Harris2020-09-11</td>\n",
              "      <td>610.228150</td>\n",
              "      <td>2346.07980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Harris2020-09-12</td>\n",
              "      <td>581.212600</td>\n",
              "      <td>2349.81840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Harris2020-09-13</td>\n",
              "      <td>551.754150</td>\n",
              "      <td>2354.18500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Liberty2020-09-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Liberty2020-09-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Liberty2020-09-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Liberty2020-09-10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Liberty2020-09-11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Liberty2020-09-12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Liberty2020-09-13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Montgomery2020-09-07</td>\n",
              "      <td>66.977830</td>\n",
              "      <td>133.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Montgomery2020-09-08</td>\n",
              "      <td>68.467070</td>\n",
              "      <td>133.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Montgomery2020-09-09</td>\n",
              "      <td>67.365160</td>\n",
              "      <td>133.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Montgomery2020-09-10</td>\n",
              "      <td>66.639430</td>\n",
              "      <td>134.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Montgomery2020-09-11</td>\n",
              "      <td>64.965950</td>\n",
              "      <td>134.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Montgomery2020-09-12</td>\n",
              "      <td>66.450570</td>\n",
              "      <td>134.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Montgomery2020-09-13</td>\n",
              "      <td>62.307960</td>\n",
              "      <td>134.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Brazoria2020-09-07</td>\n",
              "      <td>22.021269</td>\n",
              "      <td>146.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Brazoria2020-09-08</td>\n",
              "      <td>20.658545</td>\n",
              "      <td>146.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Brazoria2020-09-09</td>\n",
              "      <td>19.740294</td>\n",
              "      <td>146.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Brazoria2020-09-10</td>\n",
              "      <td>19.015366</td>\n",
              "      <td>146.35725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Brazoria2020-09-11</td>\n",
              "      <td>18.476810</td>\n",
              "      <td>146.60017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Brazoria2020-09-12</td>\n",
              "      <td>18.032284</td>\n",
              "      <td>147.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Brazoria2020-09-13</td>\n",
              "      <td>17.736917</td>\n",
              "      <td>147.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Chambers2020-09-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Chambers2020-09-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Chambers2020-09-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Chambers2020-09-10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Chambers2020-09-11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Chambers2020-09-12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Chambers2020-09-13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Fort Bend2020-09-07</td>\n",
              "      <td>51.975143</td>\n",
              "      <td>268.51748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Fort Bend2020-09-08</td>\n",
              "      <td>52.425970</td>\n",
              "      <td>272.66992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Fort Bend2020-09-09</td>\n",
              "      <td>50.320820</td>\n",
              "      <td>275.28616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Fort Bend2020-09-10</td>\n",
              "      <td>49.313362</td>\n",
              "      <td>278.30945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Fort Bend2020-09-11</td>\n",
              "      <td>46.811794</td>\n",
              "      <td>280.80664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Fort Bend2020-09-12</td>\n",
              "      <td>45.393260</td>\n",
              "      <td>283.64792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Fort Bend2020-09-13</td>\n",
              "      <td>42.778282</td>\n",
              "      <td>286.33410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Galveston2020-09-07</td>\n",
              "      <td>80.883540</td>\n",
              "      <td>144.14627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Galveston2020-09-08</td>\n",
              "      <td>78.556210</td>\n",
              "      <td>144.56358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Galveston2020-09-09</td>\n",
              "      <td>76.092470</td>\n",
              "      <td>145.05827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Galveston2020-09-10</td>\n",
              "      <td>76.376740</td>\n",
              "      <td>145.34314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Galveston2020-09-11</td>\n",
              "      <td>76.250175</td>\n",
              "      <td>145.47849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Galveston2020-09-12</td>\n",
              "      <td>75.054250</td>\n",
              "      <td>145.67068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Galveston2020-09-13</td>\n",
              "      <td>74.669320</td>\n",
              "      <td>145.84793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Austin2020-09-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Austin2020-09-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Austin2020-09-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Austin2020-09-10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Austin2020-09-11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Austin2020-09-12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Austin2020-09-13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      ID  Hospitalization   Mortality\n",
              "0       Harris2020-09-07       721.773560  2335.31080\n",
              "1       Harris2020-09-08       712.426640  2337.24270\n",
              "2       Harris2020-09-09       673.325200  2339.74500\n",
              "3       Harris2020-09-10       635.066470  2342.93650\n",
              "4       Harris2020-09-11       610.228150  2346.07980\n",
              "5       Harris2020-09-12       581.212600  2349.81840\n",
              "6       Harris2020-09-13       551.754150  2354.18500\n",
              "7      Liberty2020-09-07         0.000000    46.00000\n",
              "8      Liberty2020-09-08         0.000000    46.00000\n",
              "9      Liberty2020-09-09         0.000000    46.00000\n",
              "10     Liberty2020-09-10         0.000000    47.00000\n",
              "11     Liberty2020-09-11         0.000000    47.00000\n",
              "12     Liberty2020-09-12         0.000000    47.00000\n",
              "13     Liberty2020-09-13         0.000000    48.00000\n",
              "14  Montgomery2020-09-07        66.977830   133.00000\n",
              "15  Montgomery2020-09-08        68.467070   133.00000\n",
              "16  Montgomery2020-09-09        67.365160   133.00000\n",
              "17  Montgomery2020-09-10        66.639430   134.00000\n",
              "18  Montgomery2020-09-11        64.965950   134.00000\n",
              "19  Montgomery2020-09-12        66.450570   134.00000\n",
              "20  Montgomery2020-09-13        62.307960   134.00000\n",
              "21    Brazoria2020-09-07        22.021269   146.00000\n",
              "22    Brazoria2020-09-08        20.658545   146.00000\n",
              "23    Brazoria2020-09-09        19.740294   146.00000\n",
              "24    Brazoria2020-09-10        19.015366   146.35725\n",
              "25    Brazoria2020-09-11        18.476810   146.60017\n",
              "26    Brazoria2020-09-12        18.032284   147.00000\n",
              "27    Brazoria2020-09-13        17.736917   147.00000\n",
              "28    Chambers2020-09-07         0.000000     5.00000\n",
              "29    Chambers2020-09-08         0.000000     5.00000\n",
              "30    Chambers2020-09-09         0.000000     5.00000\n",
              "31    Chambers2020-09-10         0.000000     5.00000\n",
              "32    Chambers2020-09-11         0.000000     5.00000\n",
              "33    Chambers2020-09-12         0.000000     5.00000\n",
              "34    Chambers2020-09-13         0.000000     5.00000\n",
              "35   Fort Bend2020-09-07        51.975143   268.51748\n",
              "36   Fort Bend2020-09-08        52.425970   272.66992\n",
              "37   Fort Bend2020-09-09        50.320820   275.28616\n",
              "38   Fort Bend2020-09-10        49.313362   278.30945\n",
              "39   Fort Bend2020-09-11        46.811794   280.80664\n",
              "40   Fort Bend2020-09-12        45.393260   283.64792\n",
              "41   Fort Bend2020-09-13        42.778282   286.33410\n",
              "42   Galveston2020-09-07        80.883540   144.14627\n",
              "43   Galveston2020-09-08        78.556210   144.56358\n",
              "44   Galveston2020-09-09        76.092470   145.05827\n",
              "45   Galveston2020-09-10        76.376740   145.34314\n",
              "46   Galveston2020-09-11        76.250175   145.47849\n",
              "47   Galveston2020-09-12        75.054250   145.67068\n",
              "48   Galveston2020-09-13        74.669320   145.84793\n",
              "49      Austin2020-09-07         0.000000     6.00000\n",
              "50      Austin2020-09-08         0.000000     6.00000\n",
              "51      Austin2020-09-09         0.000000     6.00000\n",
              "52      Austin2020-09-10         0.000000     6.00000\n",
              "53      Austin2020-09-11         0.000000     6.00000\n",
              "54      Austin2020-09-12         0.000000     6.00000\n",
              "55      Austin2020-09-13         0.000000     6.00000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuXuG-GmMdWo"
      },
      "source": [
        "Second week predictions start here. I use ensemble techniques for some counties where many prediction models were performing well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaRzavrGLrsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "9c013c29-dc82-4a01-e3f6-3f7b6485ef7a"
      },
      "source": [
        "# try ensemble tactic..\n",
        "Harris_deaths_1 = np.array([2421.0159, 2434.3486 ,2447.8862 ,2461.4531 ,2476.1924 ,2491.035 , 2506.2642])\n",
        "Harris_deaths_2 = np.array([2424, 2437.5059, 2449.8225, 2465.4849, 2479.7554 ,2495.0405 ,2510.6333])\n",
        "Harris_final_deaths = (Harris_deaths_1+Harris_deaths_2)/2.\n",
        "Brazoria_deaths_1 = np.array([154.62, 155.44801, 156.077 ,  157.16106, 158.01569 ,158.86296 ,159.82701])\n",
        "Brazoria_deaths_2 = np.array([154.9781 , 157.02975 ,158.32451, 160.2965,  161.9838 , 163.613   ,165.47772])\n",
        "Brazoria_deaths_final = (0.3*Brazoria_deaths_1+0.7*Brazoria_deaths_2)\n",
        "Fort_Bend_hosp_1 = np.array([39.00485  ,37.541004 ,34.439774 ,31.94413,  30.508825 ,29.098776 ,28.484945])\n",
        "Fort_Bend_hosp_2 = np.array([39.46749  ,37.984047 ,36.92402 , 35.572926, 34.42708 , 33.356216 ,32.413094])\n",
        "Fort_Bend_hosp_3 = np.array([38.99247 , 41.878197, 38.14488 , 37.15999  ,34.40238  ,32.872955 ,31.187769])\n",
        "Fort_Bend_hosp_final = (Fort_Bend_hosp_2+Fort_Bend_hosp_1+Fort_Bend_hosp_3)/3.\n",
        "print(Harris_final_deaths)\n",
        "print(Brazoria_deaths_final)\n",
        "print(Fort_Bend_hosp_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2422.50795 2435.92725 2448.85435 2463.469   2477.9739  2493.03775\n",
            " 2508.44875]\n",
            "[154.87067  156.555228 157.650257 159.355868 160.793367 162.187988\n",
            " 163.782507]\n",
            "[39.15493667 39.134416   36.50289133 34.89234867 33.11276167 31.77598233\n",
            " 30.69526933]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlH2H60ExvD2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "6e8f6a5c-7ed3-4463-c3bf-51474befce8d"
      },
      "source": [
        "hospitalization = [636.788 ,  626.026 ,  618.71826, 623.69507 ,600.22144,589.7575 , 580.5178 ,0,0,0,0,0,0,0,59.92499 , 54.64683,  53.495754, 49.320377, 49.55309 , 45.013844, 43.299374,29.993618 ,36.97773 , 36.9332 ,  33.37462627 ,27.497902,27.020609 ,21.223059,0,0,0,0,0,0,0,39.15493667 ,39.134416,   36.50289133 ,34.89234867, 33.11276167 ,31.77598233,\n",
        " 30.69526933,55.663937 ,54.6406  , 52.89285  ,49.816845 ,48.483604 ,47.001698, 42.390236,0,0,0,0,0,0,0]\n",
        "mortality = [2422.50795 ,2435.92725 ,2448.85435 ,2463.469  , 2477.9739  ,2493.03775 ,2508.44875,46, 46, 46, 46, 47, 47, 47.5,145.10944 ,146.31076, 147.6109 , 149.19351 ,151.1802 , 153.07767,\n",
        " 154.71606,154.87067  ,156.555228 ,157.650257, 159.355868 ,160.793367, 162.187988,163.782507,8.0012865,  8.324205 , 8.627693  , 8.991761  , 9.381204  , 9.81089,10.276717 ,267.67062, 270.18558 ,272.92804 ,275.56403 ,278.72568 ,281.89233, 285.80176,\n",
        " 165.00296, 165.09131, 169.01877, 170.19328 ,172.41519 ,174.02005 ,174.8002 ,9,9,9,9.5,9.5,10,10]#,....]\n",
        "\n",
        "IDs = [\"Harris2020-09-14\",\"Harris2020-09-15\",\"Harris2020-09-16\",\"Harris2020-09-17\",\"Harris2020-09-18\",\"Harris2020-09-19\",\"Harris2020-09-20\",\"Liberty2020-09-14\",\"Liberty2020-09-15\",\"Liberty2020-09-16\",\"Liberty2020-09-17\",\"Liberty2020-09-18\",\"Liberty2020-09-19\",\"Liberty2020-09-20\",\n",
        "       \"Montgomery2020-09-14\",\"Montgomery2020-09-15\",\"Montgomery2020-09-16\",\"Montgomery2020-09-17\",\"Montgomery2020-09-18\",\"Montgomery2020-09-19\",\"Montgomery2020-09-20\",\"Brazoria2020-09-14\",\"Brazoria2020-09-15\",\"Brazoria2020-09-16\",\"Brazoria2020-09-17\",\"Brazoria2020-09-18\",\"Brazoria2020-09-19\",\"Brazoria2020-09-20\",\n",
        "       \"Chambers2020-09-14\",\"Chambers2020-09-15\",\"Chambers2020-09-16\",\"Chambers2020-09-17\",\"Chambers2020-09-18\",\"Chambers2020-09-19\",\"Chambers2020-09-20\",\"Fort Bend2020-09-14\",\"Fort Bend2020-09-15\",\"Fort Bend2020-09-16\",\"Fort Bend2020-09-17\",\"Fort Bend2020-09-18\",\"Fort Bend2020-09-19\",\"Fort Bend2020-09-20\",\n",
        "       \"Galveston2020-09-14\",\"Galveston2020-09-15\",\"Galveston2020-09-16\",\"Galveston2020-09-17\",\"Galveston2020-09-18\",\"Galveston2020-09-19\",\"Galveston2020-09-20\", \"Austin2020-09-14\",\"Austin2020-09-15\",\"Austin2020-09-16\",\"Austin2020-09-17\",\"Austin2020-09-18\",\"Austin2020-09-19\",\"Austin2020-09-20\"]\n",
        "submission_2 = {'ID':IDs,'Hospitalization':hospitalization,'Mortality':mortality}\n",
        "submission_2 = pd.DataFrame(submission_2)\n",
        "print(submission_2)\n",
        "submission_2.to_csv('/content/submission_2.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      ID  Hospitalization    Mortality\n",
            "0       Harris2020-09-14       636.788000  2422.507950\n",
            "1       Harris2020-09-15       626.026000  2435.927250\n",
            "2       Harris2020-09-16       618.718260  2448.854350\n",
            "3       Harris2020-09-17       623.695070  2463.469000\n",
            "4       Harris2020-09-18       600.221440  2477.973900\n",
            "5       Harris2020-09-19       589.757500  2493.037750\n",
            "6       Harris2020-09-20       580.517800  2508.448750\n",
            "7      Liberty2020-09-14         0.000000    46.000000\n",
            "8      Liberty2020-09-15         0.000000    46.000000\n",
            "9      Liberty2020-09-16         0.000000    46.000000\n",
            "10     Liberty2020-09-17         0.000000    46.000000\n",
            "11     Liberty2020-09-18         0.000000    47.000000\n",
            "12     Liberty2020-09-19         0.000000    47.000000\n",
            "13     Liberty2020-09-20         0.000000    47.500000\n",
            "14  Montgomery2020-09-14        59.924990   145.109440\n",
            "15  Montgomery2020-09-15        54.646830   146.310760\n",
            "16  Montgomery2020-09-16        53.495754   147.610900\n",
            "17  Montgomery2020-09-17        49.320377   149.193510\n",
            "18  Montgomery2020-09-18        49.553090   151.180200\n",
            "19  Montgomery2020-09-19        45.013844   153.077670\n",
            "20  Montgomery2020-09-20        43.299374   154.716060\n",
            "21    Brazoria2020-09-14        29.993618   154.870670\n",
            "22    Brazoria2020-09-15        36.977730   156.555228\n",
            "23    Brazoria2020-09-16        36.933200   157.650257\n",
            "24    Brazoria2020-09-17        33.374626   159.355868\n",
            "25    Brazoria2020-09-18        27.497902   160.793367\n",
            "26    Brazoria2020-09-19        27.020609   162.187988\n",
            "27    Brazoria2020-09-20        21.223059   163.782507\n",
            "28    Chambers2020-09-14         0.000000     8.001287\n",
            "29    Chambers2020-09-15         0.000000     8.324205\n",
            "30    Chambers2020-09-16         0.000000     8.627693\n",
            "31    Chambers2020-09-17         0.000000     8.991761\n",
            "32    Chambers2020-09-18         0.000000     9.381204\n",
            "33    Chambers2020-09-19         0.000000     9.810890\n",
            "34    Chambers2020-09-20         0.000000    10.276717\n",
            "35   Fort Bend2020-09-14        39.154937   267.670620\n",
            "36   Fort Bend2020-09-15        39.134416   270.185580\n",
            "37   Fort Bend2020-09-16        36.502891   272.928040\n",
            "38   Fort Bend2020-09-17        34.892349   275.564030\n",
            "39   Fort Bend2020-09-18        33.112762   278.725680\n",
            "40   Fort Bend2020-09-19        31.775982   281.892330\n",
            "41   Fort Bend2020-09-20        30.695269   285.801760\n",
            "42   Galveston2020-09-14        55.663937   165.002960\n",
            "43   Galveston2020-09-15        54.640600   165.091310\n",
            "44   Galveston2020-09-16        52.892850   169.018770\n",
            "45   Galveston2020-09-17        49.816845   170.193280\n",
            "46   Galveston2020-09-18        48.483604   172.415190\n",
            "47   Galveston2020-09-19        47.001698   174.020050\n",
            "48   Galveston2020-09-20        42.390236   174.800200\n",
            "49      Austin2020-09-14         0.000000     9.000000\n",
            "50      Austin2020-09-15         0.000000     9.000000\n",
            "51      Austin2020-09-16         0.000000     9.000000\n",
            "52      Austin2020-09-17         0.000000     9.500000\n",
            "53      Austin2020-09-18         0.000000     9.500000\n",
            "54      Austin2020-09-19         0.000000    10.000000\n",
            "55      Austin2020-09-20         0.000000    10.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBmgzGU4pN8Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "f22addfe-9109-4a72-c6fe-8e549f926f8f"
      },
      "source": [
        "print(submission.iloc[35:42,2])\n",
        "print(submission_2.iloc[35:42,2])\n",
        "Fort_Bend_prediction_week_2 = np.array(submission_2.iloc[35:42,2])\n",
        "Fort_Bend_week_2 = np.array([267.,268.,273.,274.,275.,277,278.])\n",
        "Harris_week_2 = np.array([])\n",
        "fig, ax = plt.subplots()\n",
        "index = [\"09-14\",\"09-15\",\"09-16\",\"09-17\",\"09-18\",\"09-19\",\"09-20\"]\n",
        "plt.plot(index,Fort_Bend_week_2,color = 'r')\n",
        "plt.plot(index,Fort_Bend_prediction_week_2,color = 'b')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35    268.51748\n",
            "36    272.66992\n",
            "37    275.28616\n",
            "38    278.30945\n",
            "39    280.80664\n",
            "40    283.64792\n",
            "41    286.33410\n",
            "Name: Mortality, dtype: float64\n",
            "35    267.67062\n",
            "36    270.18558\n",
            "37    272.92804\n",
            "38    275.56403\n",
            "39    278.72568\n",
            "40    281.89233\n",
            "41    285.80176\n",
            "Name: Mortality, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt4WDPCpMutf"
      },
      "source": [
        "Below I used the data of the next week to check if my predictions were performing well using the metric MSLE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prurMslVx8Gi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kURSqy1nGfTq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "8f5be552-41d9-4bc2-ebae-1590393c66d6"
      },
      "source": [
        "\"\"\"#evaluation \n",
        "import math\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
        "actual = [2420.,2440.,2458.,2470.,2483.,46.,47.,47.,47.,47.,145.,147.,151.,152.,155.,155.,155.,155.,156.,157.,8.,8.,8.,8.,8.,267.,268.,273.,274.,275.,165.,165.,166.,167.,169.,9.,9.,9.,9.,9.]\n",
        "def rmsle(y, y_pred):\n",
        "\tterms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
        "\treturn (sum(terms_to_sum) * (1.0/len(y))) ** 0.5\n",
        "rmsles = []\n",
        "j=0\n",
        "k=5\n",
        "l=0\n",
        "z=5\n",
        "for i in range(0,8):\n",
        "  print(submission_2.values[l:z,2])\n",
        "  print(actual[j:k])\n",
        "  rmsles.append(mean_squared_log_error(actual[j:k],submission_2.values[l:z,2]))\n",
        "  j=j+5\n",
        "  k=k+5\n",
        "  l= l+7\n",
        "  z= z+7\n",
        "print(rmsles)\n",
        "print(mean_squared_log_error([46.,47.,47.,47.,47.,47.,47.5],[46.,46.,46.,46.,47.,47.,47.]))\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2422.50795 2435.92725 2448.85435 2463.469 2477.9739]\n",
            "[2420.0, 2440.0, 2458.0, 2470.0, 2483.0]\n",
            "[46.0 46.0 46.0 46.0 47.0]\n",
            "[46.0, 47.0, 47.0, 47.0, 47.0]\n",
            "[145.10944 146.31076 147.6109 149.19351 151.1802]\n",
            "[145.0, 147.0, 151.0, 152.0, 155.0]\n",
            "[154.87067 156.555228 157.650257 159.355868 160.793367]\n",
            "[155.0, 155.0, 155.0, 156.0, 157.0]\n",
            "[8.0012865 8.324205 8.627693 8.991761 9.381204]\n",
            "[8.0, 8.0, 8.0, 8.0, 8.0]\n",
            "[267.67062 270.18558 272.92804 275.56403 278.72568]\n",
            "[267.0, 268.0, 273.0, 274.0, 275.0]\n",
            "[165.00296 165.09131 169.01877 170.19328 172.41519]\n",
            "[165.0, 165.0, 166.0, 167.0, 169.0]\n",
            "[9.0 9.0 9.0 9.5 9.5]\n",
            "[9.0, 9.0, 9.0, 9.0, 9.0]\n",
            "[5.770327631053549e-06, 0.00026594762331082114, 0.0002976265244817743, 0.00027861443548993323, 0.007421899739409368, 5.6749556667786446e-05, 0.00021428240042084258, 0.0009521920478720393]\n",
            "0.00020530363881402872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkt-2xy-IV8q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtzsmiJ4M5hb"
      },
      "source": [
        "This is the end of my work for COVID-19 Houston Datathon. It was an interesting experience as I explored deeply the challenging problem of Time Series prediction. Specifically for Covid-19 it was great that I was able to contribute to the competition with my data analysis. For future work on this project I would definitely try to use external data to further improve my weekly predictions.I hope that you found it helpful."
      ]
    }
  ]
}